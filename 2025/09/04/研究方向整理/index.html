<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>且离且安的碎碎念 | 且离且安的碎碎念</title><meta name="author" content="lian"><meta name="copyright" content="lian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="用的都是开源数据集吗 小目标检测方法综述： 样本导向方法：解决样本不足  尺度感知方法：    尺度专属检测器：为不同尺度目标设计专门的检测分支 分层特征融合：融合不同层特征，给小目标补全信息   特征模仿方法：GAN  注意力方法（Attention-Based Methods）：解决 “特征噪声”  特征模仿方法（Feature-Imitation Methods）：解决 “小目标特征质量差”">
<meta property="og:type" content="article">
<meta property="og:title" content="且离且安的碎碎念">
<meta property="og:url" content="https://qieliqiean.github.io/blog/2025/09/04/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%95%B4%E7%90%86/index.html">
<meta property="og:site_name" content="且离且安的碎碎念">
<meta property="og:description" content="用的都是开源数据集吗 小目标检测方法综述： 样本导向方法：解决样本不足  尺度感知方法：    尺度专属检测器：为不同尺度目标设计专门的检测分支 分层特征融合：融合不同层特征，给小目标补全信息   特征模仿方法：GAN  注意力方法（Attention-Based Methods）：解决 “特征噪声”  特征模仿方法（Feature-Imitation Methods）：解决 “小目标特征质量差”">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qieliqiean.github.io/blog/image/IMG_20250131_155849.jpg">
<meta property="article:published_time" content="2025-09-04T08:19:36.040Z">
<meta property="article:modified_time" content="2025-09-06T12:33:01.957Z">
<meta property="article:author" content="lian">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qieliqiean.github.io/blog/image/IMG_20250131_155849.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "",
  "url": "https://qieliqiean.github.io/blog/2025/09/04/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%95%B4%E7%90%86/",
  "image": "https://qieliqiean.github.io/blog/image/IMG_20250131_155849.jpg",
  "datePublished": "2025-09-04T08:19:36.040Z",
  "dateModified": "2025-09-06T12:33:01.957Z",
  "author": [
    {
      "@type": "Person",
      "name": "lian",
      "url": "https://qieliqiean.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/image/1.jpg"><link rel="canonical" href="https://qieliqiean.github.io/blog/2025/09/04/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%95%B4%E7%90%86/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '且离且安的碎碎念',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(image/1363709.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><img class="site-icon" src="/blog/image/background1.png" alt="Logo"><span class="site-name">且离且安的碎碎念</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">且离且安的碎碎念</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">无标题</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-04T08:19:36.040Z" title="发表于 2025-09-04 16:19:36">2025-09-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-06T12:33:01.957Z" title="更新于 2025-09-06 20:33:01">2025-09-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p><strong>用的都是开源数据集吗</strong></p>
<h1 id="小目标检测方法综述："><a href="#小目标检测方法综述：" class="headerlink" title="小目标检测方法综述："></a>小目标检测方法综述：</h1><ol>
<li><p>样本导向方法：解决样本不足</p>
</li>
<li><p>尺度感知方法：</p>
</li>
</ol>
<ul>
<li>尺度专属检测器：为不同尺度目标设计专门的检测分支</li>
<li>分层特征融合：融合不同层特征，给小目标补全信息</li>
</ul>
<ol start="3">
<li><p>特征模仿方法：GAN</p>
</li>
<li><p>注意力方法（Attention-Based Methods）：解决 “特征噪声”</p>
</li>
<li><p>特征模仿方法（Feature-Imitation Methods）：解决 “小目标特征质量差”</p>
</li>
</ol>
<ul>
<li><strong>相似度学习：强制小目标特征和大目标特征相似</strong></li>
<li><strong>超分辨率重建：把小目标 “放大”，再提取特征</strong></li>
</ul>
<ol start="5">
<li>上下文建模方法（Context-Modeling Methods）：解决 “小目标信息不足”</li>
<li>聚焦检测方法：先粗后精，两步走”。第一步，先用一个轻量级的网络快速地扫描整张图，找到可能包含小目标的“嫌疑区域”（Region Proposal）。第二步，再对这些被筛选出来的“小块”区域进行精细化的、高成本的检测。</li>
</ol>
<h1 id="通用小目标检测算法"><a href="#通用小目标检测算法" class="headerlink" title="通用小目标检测算法"></a>通用小目标检测算法</h1><h2 id="思路-1：提升输入特征分辨率（最直接有效的方法）"><a href="#思路-1：提升输入特征分辨率（最直接有效的方法）" class="headerlink" title="思路 1：提升输入特征分辨率（最直接有效的方法）"></a>思路 1：提升输入特征分辨率（最直接有效的方法）</h2><p>核心逻辑：小目标检测难，本质是 “特征太模糊”，那我们就想办法让特征图变清晰（高分辨率），或者让小目标的特征 “放大”。但要注意：高分辨率会增加计算量，所以算法都在 “精度” 和 “速度” 之间找平衡。</p>
<p>我们来看几种典型算法：</p>
<ol>
<li><p><strong>FPN（特征金字塔网络）</strong>：2017 年的经典模型，至今还在被广泛使用。</p>
<ul>
<li>问题背景：之前的模型（比如 SSD）用 “不同层特征图检测不同尺度目标”，但低层特征图（分辨率高）语义弱（分不清是猫还是狗），高层特征图（语义强）分辨率低（找不到小目标）；</li>
<li>核心操作：“自上而下融合”—— 把高层语义强的特征图通过 “上采样”（放大），和低层分辨率高的特征图融合，这样融合后的特征图 “又有细节又有语义”；</li>
<li>效果：小目标检测精度显著提升，还能保持 6 FPS（每秒处理 6 张图）的速度；</li>
<li>后续改进：PANet、BiFPN、ASFF 这些，都是在 FPN 的基础上优化 “融合方式”，让特征融合更高效。</li>
</ul>
</li>
<li><p><strong>RetinaNet：解决 “前景背景不平衡” 的单阶段模型</strong></p>
<ul>
<li><p>问题背景：之前单阶段模型（比如 YOLO）比两阶段（比如 Faster R-CNN）快，但精度低，因为 “前景少、背景多”—— 一张图里可能只有 1 个小目标（前景），但有几百个背景区域，模型学偏了；</p>
</li>
<li><p>核心创新：提出</p>
<p>Focal Loss（聚焦损失）</p>
<p>，公式如下：</p>
<p>$FL(p)&#x3D;\begin{cases}      -\alpha (1-p)^{\gamma }log(p) &amp; if\ y&#x3D;1 \      -(1-\alpha )p^{\gamma }log(1-p) &amp; otherwise      \end{cases}$</p>
<p>简单解释：</p>
<ul>
<li>(y&#x3D;1)代表 “正样本”（有目标），(y&#x3D;0)是 “负样本”（无目标）；</li>
<li>p是模型预测为正样本的概率：如果p很大（简单背景样本），((1-p)^\gamma)就很小，损失被 “压低”；如果p很小（难样本，比如模糊的小目标），损失被 “放大”；</li>
<li>这样模型就会 “聚焦” 于难样本，而不是在简单背景上浪费精力；</li>
</ul>
</li>
<li><p>效果：第一次让单阶段模型的精度超过两阶段，小目标检测也更准。</p>
</li>
</ul>
</li>
<li><p><strong>超分辨率（Super-Resolution）方法：直接 “放大” 小目标</strong></p>
<ul>
<li>思路：既然小目标像素少，那我们就用算法把它 “放大”，比如用生成对抗网络（GAN）生成高分辨率的小目标特征；</li>
<li>例子：EESRGAN（边缘增强超分 GAN）：<ul>
<li>在普通超分网络（ESRGAN）里加了 “边缘增强子网络（EEN）”，专门优化小目标的边缘细节（比如小车牌的边框、小人脸的轮廓）；</li>
<li>让 “判别器”（判断图像是真实还是生成的）和 “检测器” 一起监督 “生成器”—— 生成器不仅要生成 “看起来真实” 的超分图像，还要让检测器能检测到目标，这样生成的特征更有用；</li>
</ul>
</li>
<li>注意：超分能提升精度，但会增加计算量，比如有的模型速度从 28 FPS 降到 3 FPS，实时场景（比如自动驾驶）用不了。</li>
</ul>
</li>
<li><p><strong>其他优化：减少计算量的小技巧</strong></p>
<ul>
<li>QueryDet：用 “查询机制”—— 先预测小目标可能的位置，只在这些位置上做检测，不用遍历整个高分辨率特征图，推理速度提升不少；</li>
<li>HRDNet：多分辨率输入 —— 高分辨率图像进 “浅层网络”（保位置细节），低分辨率图像进 “深层网络”（提语义），最后融合，既保精度又控计算。</li>
</ul>
</li>
</ol>
<h4 id="思路-2：尺度感知训练（让模型-“认识”-不同大小的目标）"><a href="#思路-2：尺度感知训练（让模型-“认识”-不同大小的目标）" class="headerlink" title="思路 2：尺度感知训练（让模型 “认识” 不同大小的目标）"></a>思路 2：尺度感知训练（让模型 “认识” 不同大小的目标）</h4><p>核心逻辑：小目标和大目标的尺度差异太大（COCO 里最大目标是最小目标的 20 倍），CNN 的 “尺度不变性” 不好（比如学了检测大猫，就检测不了小猫）。所以我们要让模型 “主动适应” 不同尺度，尤其是小尺度。</p>
<p>典型算法：</p>
<ol>
<li><strong>SNIP 和 SNIPER：优化图像金字塔训练</strong><ul>
<li>图像金字塔：把一张图缩放成多个尺度（比如 800×800、1000×1000、1200×1200），分别训练，让模型见多识广；</li>
<li>问题：全尺度训练内存不够；</li>
<li>SNIP：只对 “目标尺寸在预定范围” 的样本计算损失（比如小目标只在小尺度金字塔上训练），其他尺度的损失不反向传播，减少计算；</li>
<li>SNIPER：更极端，从每个金字塔层选 512×512 的 “芯片”（小块图像）训练，batch size 能更大，效率更高。</li>
</ul>
</li>
<li><strong>TridentNet（三叉戟网络）：多分支适配不同尺度</strong><ul>
<li>结构：3 个并行分支，每个分支用不同的 “膨胀率”（dilation rate）—— 膨胀率越大，感受野（卷积核能看到的原图区域）越大；</li>
<li>逻辑：小目标用小感受野分支，大目标用大感受野分支，每个分支只训练对应尺度的目标（公式(l_i \leq \sqrt{wh} \leq u_i)，(\sqrt{wh})是目标尺寸，(l_i、u_i)是分支的尺度范围）；</li>
<li>好处：避免小目标被大感受野 “淹没”（比如感受野是 200×200，小目标是 20×20，就像用大网捞小鱼，捞不到）。</li>
</ul>
</li>
</ol>
<h4 id="思路-3：融入上下文信息（“借周围环境判断”）"><a href="#思路-3：融入上下文信息（“借周围环境判断”）" class="headerlink" title="思路 3：融入上下文信息（“借周围环境判断”）"></a>思路 3：融入上下文信息（“借周围环境判断”）</h4><p>核心逻辑：小目标自身特征弱，但它的 “周围环境” 能提供线索 —— 比如 “马路上的小矩形” 大概率是车牌，“天空中的小亮点” 可能是飞机。所以我们要让模型利用 “上下文信息” 辅助检测。</p>
<p>上下文分两类：<strong>图像级上下文</strong>（全图环境）和<strong>实例级上下文</strong>（目标间的关系），典型算法：</p>
<ol>
<li><strong>ION（内外网）：利用 ROI 内外信息</strong><ul>
<li>ROI（感兴趣区域）内：用 “skip pooling” 提取多尺度特征（比如小目标的局部细节）；</li>
<li>ROI 外：用 “空间 RNN” 提取周围环境特征（比如小目标旁边的树、路），融合后提升检测精度。</li>
</ul>
</li>
<li><strong>SMN（空间记忆网络）：记住已检测目标，帮找漏检的</strong><ul>
<li>逻辑：小目标常被遮挡或扎堆（比如人群里的小脸），第一次检测可能漏检；</li>
<li>操作：检测到一个目标后，“记住” 它的位置和特征，下次检测时，用这个已检测目标作为 “先验”，推断周围可能有同类小目标（比如检测到一个行人，周围可能还有其他行人），减少漏检。</li>
</ul>
</li>
<li><strong>FA-SSD：结合上下文和注意力</strong><ul>
<li>F-SSD：把高层语义特征（上下文，比如 “这是街道场景”）和低层特征（小目标细节）拼接；</li>
<li>A-SSD：用注意力机制 “屏蔽” 背景无用特征（比如街道上的杂草），只关注可能有小目标的区域；</li>
<li>效果：比普通 SSD 的小目标检测精度提升 10% 左右。</li>
</ul>
</li>
</ol>
<h4 id="思路-4：数据增强（“造更多小目标样本”）"><a href="#思路-4：数据增强（“造更多小目标样本”）" class="headerlink" title="思路 4：数据增强（“造更多小目标样本”）"></a>思路 4：数据增强（“造更多小目标样本”）</h4><p>核心逻辑：小目标数据集少，标注贵，那我们就 “人造” 样本 —— 通过各种方法增加小目标的多样性，让模型见得多、学得好。</p>
<p>传统数据增强（比如旋转、裁剪）对中大型目标有效，但对小目标没用（旋转 20×20 的小目标，可能就糊了），所以研究者设计了针对小目标的增强方法：</p>
<ol>
<li><strong>过采样和自适应粘贴（Kisantal 等人 &amp; RRNet）</strong><ul>
<li>Kisantal 等人：发现 COCO 里 “含小目标的图像” 只占少数，所以 “过采样” 这些图像（比如重复用 10 次），还把小目标 “复制粘贴” 到其他图像里；</li>
<li>问题：复制粘贴会导致 “背景不匹配”（比如把小车牌贴到草地上，不合理）；</li>
<li>RRNet：用语义分割网络先 “标出图像里的合理区域”（比如车牌只能在汽车上），再把小目标粘贴到这些区域，解决背景不匹配问题。</li>
</ul>
</li>
<li><strong>切片增强（Ünel 等人）</strong><ul>
<li>操作：把一张大图像分成多个重叠的 “切片”（比如把 1000×1000 的图切成 5 个 512×512 的切片，重叠部分 200 像素）；</li>
<li>好处：小目标在切片里的 “相对像素面积” 变大了（比如 20×20 的小目标在 1000×1000 图里占 0.04%，在 512×512 切片里占 0.15%），模型更容易学到特征。</li>
</ul>
</li>
<li><strong>动态尺度训练（DST）</strong><ul>
<li>思路：用 “小目标的损失比例” 当反馈 —— 如果模型在小目标上的损失太小（说明没学好），下次训练就把图像 “放大拼接”（比如把两张 800×800 的图拼成 1600×800），增加小目标的占比，强迫模型学小目标。</li>
</ul>
</li>
</ol>
<h4 id="补充：其他有用的小技巧"><a href="#补充：其他有用的小技巧" class="headerlink" title="补充：其他有用的小技巧"></a>补充：其他有用的小技巧</h4><p>除了上述 4 种思路，还有一些针对性优化：</p>
<ul>
<li><strong>用新指标代替 IoU</strong>：IoU（交并比）对小目标的位置偏差特别敏感 —— 比如小目标框偏了 1 个像素，IoU 可能从 0.8 降到 0.2，导致模型误判。所以有人提出 NWD（归一化高斯 Wasserstein 距离），把框当成高斯分布，用分布相似度代替 IoU，对小目标更友好；</li>
<li><strong>无锚点模型（CenterNet++）</strong>：传统模型用 “锚点”（预设的框）匹配目标，小目标难匹配（锚点比小目标大太多）。CenterNet++ 用 “中心点 + 两个角点” 表示目标，不用锚点，更适合小目标；</li>
<li><strong>SAHI（切片推理）</strong>：推理时把图像切成切片，分别检测，再合并结果，不用改模型，直接提升小目标检测精度（比如在遥感图上，小目标 AP 提升 8%）。</li>
</ul>
<h1 id="方向"><a href="#方向" class="headerlink" title="方向"></a>方向</h1><p><span style="color:#FF0000">方向 1：设计专为小目标优化的特征提取器（Effective Feature Extractor for Small Objects）</span></p>
<ul>
<li><strong>低下采样率架构</strong>：通过 “空洞卷积（Dilated Convolution）”“转置卷积（Transposed Convolution）” 等技术，在不增加计算量的前提下降低下采样率，保留小目标细节；</li>
<li><strong>多尺度特征对齐</strong>：让提取器在不同深度自动对齐小目标的 “细节特征” 与 “语义特征”，避免传统架构中 “低层细节足但语义弱、高层语义强但细节丢” 的矛盾；</li>
<li><strong>轻量化设计</strong>：小目标检测常需部署于边缘设备（如自动驾驶车载终端、无人机），需在 “特征提取能力” 与 “计算效率” 间平衡，避免模型过大导致实时性不足。</li>
</ul>
<p><span style="color:#FF0000">方向 2：改进特征金字塔的高质量分层特征表示（High-Quality Hierarchical Representation）</span></p>
<ul>
<li><strong>适应尺度分配</strong>：让网络根据目标的实际尺寸自动选择 “最优金字塔层”，而非人工设定，确保每一层特征都能被小目标充分利用；</li>
<li><strong>跨层特征蒸馏</strong>：将高层的语义信息 “蒸馏” 到低层，同时将低层的细节信息 “传递” 到高层，实现 “全层特征为小目标服务”，避免高层特征浪费；</li>
<li><strong>动态特征选择</strong>：检测时仅激活 “含小目标概率高的金字塔层”，而非全层检测，降低计算量（如小目标密集区域激活 P2 层，大目标区域激活 P5 层）。</li>
</ul>
<p><span style="color:#FF0000">方向 3：优化小目标的标签分配策略（Optimized Label Assignment Strategy）</span></p>
<ul>
<li><strong>多因素融合匹配</strong>：不再依赖单一的 IoU 或距离，而是结合 “目标尺寸、中心距离、上下文信息、类别样本量” 多维度判断正样本（如极小小目标降低 IoU 阈值，同时参考其与相邻目标的上下文关联）；</li>
<li><strong>动态阈值调整</strong>：根据类别样本量动态调整正样本阈值（如少样本类别降低阈值，多样本类别提高阈值），缓解类别不均衡导致的正样本分配偏差；</li>
<li><strong>正样本质量筛选</strong>：在增加正样本数量的同时，通过 “特征质量评分” 筛选低质量正样本（如背景区域），避免噪声干扰训练。</li>
</ul>
<p><span style="color:#FF0000">方向 4：设计更适合 SOD 的评估指标（Proper Evaluation Metric for SOD）</span></p>
<ul>
<li><strong>动态 IoU 阈值</strong>：根据目标尺寸调整 IoU 阈值（如 eS 级小目标用 IoU≥0.3，gS 级用 IoU≥0.5），避免对小目标的过度严苛；</li>
<li><strong>召回率加权 AP</strong>：在重视定位精度的同时，对 “召回率” 赋予更高权重（如搜救场景），或根据场景需求动态调整权重，让指标更贴合实际应用；</li>
<li><strong>极小小目标专项指标</strong>：单独设计 “极小小目标召回率（RecallₑS）”“极小小目标定位误差（LocErrₑS）” 等指标，精准评估算法对最难场景的适配性。</li>
</ul>
<h4 id="2-未来研究方向（值得做的选题）"><a href="#2-未来研究方向（值得做的选题）" class="headerlink" title="2. 未来研究方向（值得做的选题）"></a>2. 未来研究方向（值得做的选题）</h4><ol>
<li><strong>弱监督 &#x2F; 无监督 SOD</strong>：全监督需要大量 bounding box 标注，成本太高。弱监督只用 “图像级标签”（比如标 “这张图有小行人”，不用标位置），无监督 &#x2F; 自监督（比如对比学习）不用任何标注，是未来的热点；</li>
<li><strong>设计 SOD 专用指标</strong>：目前的指标都是从普通目标检测沿用的，需要一个能 “公平衡量小目标检测性能” 的指标（比如结合位置偏差和尺度差异）；</li>
<li><strong>多任务联合优化</strong>：把 SOD 和超分、语义分割、目标跟踪结合 —— 比如超分提供高分辨率特征，语义分割提供上下文，联合训练可能比单独训练效果好；</li>
<li><strong>开放世界 &#x2F; 少样本 SOD</strong>：现实中会遇到 “没见过的小目标”（比如模型学了检测小车牌，突然遇到小井盖），开放世界 SOD 要让模型能 “识别未知小目标” 并 “增量学习”；少样本 SOD 则是用 10-50 个标注样本就能训练出好模型，解决标注成本问题。</li>
</ol>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<h1 id="红外目标检测"><a href="#红外目标检测" class="headerlink" title="红外目标检测"></a>红外目标检测</h1><h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><table>
<thead>
<tr>
<th>传统方法类别</th>
<th>核心思路</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>滤波与背景抑制</td>
<td>用滤波器（如中值滤波）或背景模型（如红外块模型）过滤背景，保留目标</td>
<td>计算简单、速度快</td>
<td>只能处理<strong>均匀背景</strong>（比如纯天空），复杂背景（多云、城市）里漏检 &#x2F; 虚警高</td>
</tr>
<tr>
<td>视觉对比度方法</td>
<td>模拟人眼：目标和周围像素的对比度高，据此构建显著性图，分割目标</td>
<td>实现简单</td>
<td>容易被背景中的 “强边缘”（如建筑物边缘、云边界）干扰，误把边缘当目标</td>
</tr>
<tr>
<td>低秩模型方法</td>
<td>把红外图像拆成 “低秩背景” 和 “稀疏目标”（背景有规律性，目标是零散的）</td>
<td>能分离背景和目标</td>
<td>计算慢（张量分解耗时），暗目标场景下虚警率高</td>
</tr>
</tbody></table>
<h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><h3 id="单帧检测（SIRST）：解决-“小目标特征丢失”-问题"><a href="#单帧检测（SIRST）：解决-“小目标特征丢失”-问题" class="headerlink" title="单帧检测（SIRST）：解决 “小目标特征丢失” 问题"></a>单帧检测（SIRST）：解决 “小目标特征丢失” 问题</h3><h4 id="全监督学习：分-“检测型”-和-“分割型”"><a href="#全监督学习：分-“检测型”-和-“分割型”" class="headerlink" title="全监督学习：分 “检测型” 和 “分割型”"></a>全监督学习：分 “检测型” 和 “分割型”</h4><ul>
<li><strong>检测型</strong>：输出目标的 bounding box（边界框），类似 YOLO；</li>
</ul>
<p>代表方法：<strong>YOLO-FR（Mou et al., 2023）</strong>—— 基于 YOLOv5 改进，核心是 “特征重组采样”，避免目标丢失：</p>
<ul>
<li><p>下采样改进：用 “时空下采样块（STD Block）”—— 下采样时把空间信息 “转移” 到通道维度，不丢小目标特征；</p>
</li>
<li><p>上采样改进：用 “CARAFE 算子”—— 基于区域内容的上采样（不是简单插值），能还原目标细节；</p>
</li>
<li><p>新增小目标检测头：减小感受野（感受野是网络能 “看到” 的图像范围，小目标需要小感受野）。<br>实验效果：在红外飞机数据集上，精度 97%，召回 95.4%，mAP50（IoU&#x3D;0.5 时的平均精度）97.4%—— 比原始 YOLOv5 提升明显。</p>
</li>
<li><p><strong>分割型</strong>：输出像素级的 “目标掩码”（区分每个像素是目标还是背景），精度更高，是当前主流。</p>
</li>
</ul>
<p>① 注意力机制：让网络 “聚焦” 目标区域</p>
<p>② 生成对抗网络（GAN）：让生成器 “学会” 区分目标与背景</p>
<p>③ 视觉 Transformer（ViT）：捕捉长距离依赖，处理复杂背景</p>
<p>④ 模型驱动 + 数据驱动融合：结合传统模型的 “先验知识” 和深度学习的 “自动学习”</p>
<p>⑤ 轻量化网络：适配嵌入式设备（如机载传感器）</p>
<h4 id="弱监督学习：减少-“标注成本”"><a href="#弱监督学习：减少-“标注成本”" class="headerlink" title="弱监督学习：减少 “标注成本”"></a>弱监督学习：减少 “标注成本”</h4><h3 id="多帧检测（MIRST）：深度学习-时空信息，降虚警"><a href="#多帧检测（MIRST）：深度学习-时空信息，降虚警" class="headerlink" title="多帧检测（MIRST）：深度学习 + 时空信息，降虚警"></a>多帧检测（MIRST）：深度学习 + 时空信息，降虚警</h3><h3 id="总结与未来方向：这个领域还能怎么发展？"><a href="#总结与未来方向：这个领域还能怎么发展？" class="headerlink" title="总结与未来方向：这个领域还能怎么发展？"></a>总结与未来方向：这个领域还能怎么发展？</h3><p>这篇综述的贡献很明确：梳理了 12 个数据集、近三年的核心网络、完整的指标体系，给研究者提供了 “全景图”。但领域还有很多待解决的问题，文献提出了 5 个未来方向，我们逐个理解：</p>
<ol>
<li><strong>需要更大规模、更多样的数据集</strong><ul>
<li>现状：真实数据集少，极端场景（如极低辐射目标、强干扰背景）的数据更少；多是单帧图像，视频序列数据少（视频能提供运动信息，利于跟踪）。</li>
<li>未来：建立 “工程级视频数据集”，细分背景类别（如 “海雾”“城市雾霾”），补充极端场景数据。</li>
</ul>
</li>
<li><strong>改进数据集标注质量</strong><ul>
<li>现状：手动标注小目标容易错（比如漏标 1 个像素的目标），且没考虑 “大气干扰、光学系统误差”（这些会影响真实检测效果）。</li>
<li>未来：开发自动标注工具，标注时加入物理误差（如大气衰减），同时设计算法修正错标数据。</li>
</ul>
</li>
<li><strong>传统方法与深度学习的深度融合</strong><ul>
<li>现状：目前只是 “简单结合”（如把局部对比度当模块嵌入网络），没有真正融合两者的优势（传统方法的可解释性、深度学习的泛化能力）。</li>
<li>未来：比如用传统方法的 “低秩背景建模” 指导深度学习的特征提取，让网络既会自动学习，又能 “理解” 为什么这么学。</li>
</ul>
</li>
<li><strong>多模态融合检测</strong><ul>
<li>现状：单波段红外图像缺少颜色、纹理、距离信息，复杂场景下容易误判。</li>
<li>未来：结合多光谱（如红外 + 可见光）、多探测器（如红外 + 雷达）、距离信息（如激光雷达），让网络获得更全面的目标信息 —— 比如 “红外看到小亮点，雷达确认是移动目标，可见光看到是无人机，三者结合就不会误判成云”。</li>
</ul>
</li>
<li><strong>平衡实时性与精度</strong><ul>
<li>现状：高精度网络都复杂（如 DNA-Net），轻量网络精度又不够（如早期轻量网）。</li>
<li>未来：用 “结构重参数化”“量化压缩”“硬件定制加速”（如 ST-Net 设计专用加速器）等方法，让轻量网络也能达到高精度。</li>
</ul>
</li>
</ol>
</article><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/blog/image/IMG_20250131_155849.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/09/01/%E7%BA%A2%E5%A4%96%E5%BC%B1%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASmall-and-dim-target-detection-in-infrared-imagery-A-review-current-techniques-and-future-directions/" title="红外弱小目标检测：Small and dim target detection in infrared imagery: A review, current techniques and future directions"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">红外弱小目标检测：Small and dim target detection in infrared imagery: A review, current techniques and future directions</div></div><div class="info-2"><div class="info-item-1">文献摘要（ABSTRACT）详细讲解摘要作为整篇综述的“浓缩版”，不仅概括了研究背景、核心内容和关键结论，还直接点明了这篇文献的学术价值——它是该领域第一篇全面覆盖红外小弱目标检测技术的综述。接下来，我们逐句拆解摘要的核心信息，结合基础概念帮大家彻底理解，确保没有遗漏任何关键要点。  一、背景：红外小弱目标检测的“新”与“难”摘要开篇先铺垫大背景： “While there has been significant progress in object detection using conventional image processing and machine learning algorithms, exploring small and dim target detection in the IR domain is a relatively new area of study.”这句话的核心是“对比”——传统目标检测（如RGB图像中的行人、车辆检测）已很成熟，但红外小弱目标检测是“较新的领域”。为什么新？我们要结合红外图像的特殊性理解： ...</div></div></div></a><a class="pagination-related" href="/blog/2025/09/17/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93%E8%A7%84%E5%88%92/" title="研究方向总结规划"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">研究方向总结规划</div></div><div class="info-2"><div class="info-item-1">用transformer做小目标检测 红外与可见光融合做小目标检测 </div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">lian</div><div class="author-info-description">太平山上修真我，祖师堂中续香火</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:2895014608@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">QQ-2895014608</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E7%BB%BC%E8%BF%B0%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">小目标检测方法综述：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">通用小目标检测算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF-1%EF%BC%9A%E6%8F%90%E5%8D%87%E8%BE%93%E5%85%A5%E7%89%B9%E5%BE%81%E5%88%86%E8%BE%A8%E7%8E%87%EF%BC%88%E6%9C%80%E7%9B%B4%E6%8E%A5%E6%9C%89%E6%95%88%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">思路 1：提升输入特征分辨率（最直接有效的方法）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF-2%EF%BC%9A%E5%B0%BA%E5%BA%A6%E6%84%9F%E7%9F%A5%E8%AE%AD%E7%BB%83%EF%BC%88%E8%AE%A9%E6%A8%A1%E5%9E%8B-%E2%80%9C%E8%AE%A4%E8%AF%86%E2%80%9D-%E4%B8%8D%E5%90%8C%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%9B%AE%E6%A0%87%EF%BC%89"><span class="toc-number">2.1.0.1.</span> <span class="toc-text">思路 2：尺度感知训练（让模型 “认识” 不同大小的目标）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF-3%EF%BC%9A%E8%9E%8D%E5%85%A5%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF%EF%BC%88%E2%80%9C%E5%80%9F%E5%91%A8%E5%9B%B4%E7%8E%AF%E5%A2%83%E5%88%A4%E6%96%AD%E2%80%9D%EF%BC%89"><span class="toc-number">2.1.0.2.</span> <span class="toc-text">思路 3：融入上下文信息（“借周围环境判断”）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF-4%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%EF%BC%88%E2%80%9C%E9%80%A0%E6%9B%B4%E5%A4%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A0%B7%E6%9C%AC%E2%80%9D%EF%BC%89"><span class="toc-number">2.1.0.3.</span> <span class="toc-text">思路 4：数据增强（“造更多小目标样本”）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9A%E5%85%B6%E4%BB%96%E6%9C%89%E7%94%A8%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7"><span class="toc-number">2.1.0.4.</span> <span class="toc-text">补充：其他有用的小技巧</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E5%90%91"><span class="toc-number">3.</span> <span class="toc-text">方向</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%9C%AA%E6%9D%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%EF%BC%88%E5%80%BC%E5%BE%97%E5%81%9A%E7%9A%84%E9%80%89%E9%A2%98%EF%BC%89"><span class="toc-number">3.0.0.1.</span> <span class="toc-text">2. 未来研究方向（值得做的选题）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%A2%E5%A4%96%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">4.</span> <span class="toc-text">红外目标检测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">传统方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">深度学习方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E5%B8%A7%E6%A3%80%E6%B5%8B%EF%BC%88SIRST%EF%BC%89%EF%BC%9A%E8%A7%A3%E5%86%B3-%E2%80%9C%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%89%B9%E5%BE%81%E4%B8%A2%E5%A4%B1%E2%80%9D-%E9%97%AE%E9%A2%98"><span class="toc-number">4.2.1.</span> <span class="toc-text">单帧检测（SIRST）：解决 “小目标特征丢失” 问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%88%86-%E2%80%9C%E6%A3%80%E6%B5%8B%E5%9E%8B%E2%80%9D-%E5%92%8C-%E2%80%9C%E5%88%86%E5%89%B2%E5%9E%8B%E2%80%9D"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">全监督学习：分 “检测型” 和 “分割型”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%B1%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%87%8F%E5%B0%91-%E2%80%9C%E6%A0%87%E6%B3%A8%E6%88%90%E6%9C%AC%E2%80%9D"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">弱监督学习：减少 “标注成本”</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%B8%A7%E6%A3%80%E6%B5%8B%EF%BC%88MIRST%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E6%97%B6%E7%A9%BA%E4%BF%A1%E6%81%AF%EF%BC%8C%E9%99%8D%E8%99%9A%E8%AD%A6"><span class="toc-number">4.2.2.</span> <span class="toc-text">多帧检测（MIRST）：深度学习 + 时空信息，降虚警</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91%EF%BC%9A%E8%BF%99%E4%B8%AA%E9%A2%86%E5%9F%9F%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8F%91%E5%B1%95%EF%BC%9F"><span class="toc-number">4.2.3.</span> <span class="toc-text">总结与未来方向：这个领域还能怎么发展？</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AZero-Shot-Detection/" title="论文阅读：Zero-Shot Detection"><img src="/blog/image/62aa03063f117eaad7c77592e3b98d7f05b0a86329e44a-TuUO3E.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="论文阅读：Zero-Shot Detection"/></a><div class="content"><a class="title" href="/blog/2025/10/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AZero-Shot-Detection/" title="论文阅读：Zero-Shot Detection">论文阅读：Zero-Shot Detection</a><time datetime="2025-10-20T11:34:17.000Z" title="发表于 2025-10-20 19:34:17">2025-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/17/Zero-Shot-Object-Detection/" title="Zero-Shot Object Detection"><img src="/blog/image/5268d877a2a04864b36b4961ab793f4f.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="Zero-Shot Object Detection"/></a><div class="content"><a class="title" href="/blog/2025/10/17/Zero-Shot-Object-Detection/" title="Zero-Shot Object Detection">Zero-Shot Object Detection</a><time datetime="2025-10-17T10:22:18.000Z" title="发表于 2025-10-17 18:22:18">2025-10-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/17/DeViSE-A-Deep-Visual-Semantic-Embedding-Model/" title="DeViSE: A Deep Visual-Semantic Embedding Model"><img src="/blog/image/2aa2662f-d453-4a09-8890-87440bd087b8.png" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="DeViSE: A Deep Visual-Semantic Embedding Model"/></a><div class="content"><a class="title" href="/blog/2025/10/17/DeViSE-A-Deep-Visual-Semantic-Embedding-Model/" title="DeViSE: A Deep Visual-Semantic Embedding Model">DeViSE: A Deep Visual-Semantic Embedding Model</a><time datetime="2025-10-17T06:20:10.000Z" title="发表于 2025-10-17 14:20:10">2025-10-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blog/2025/09/23/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" title="小样本目标检测">小样本目标检测</a><time datetime="2025-09-23T08:06:54.000Z" title="发表于 2025-09-23 16:06:54">2025-09-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blog/2025/09/17/keywords%E9%9B%86%E5%90%88/" title="keywords集合">keywords集合</a><time datetime="2025-09-17T01:27:17.000Z" title="发表于 2025-09-17 09:27:17">2025-09-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 By lian</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">岁岁平，岁岁安，岁岁平安</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="{&quot;site_uv&quot;:true,&quot;site_pv&quot;:true,&quot;page_pv&quot;:true}"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>