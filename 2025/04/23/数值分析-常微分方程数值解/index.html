<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>数值分析-常微分方程数值解 | 且离且安的碎碎念</title><meta name="author" content="lian"><meta name="copyright" content="lian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="此部分包含常微分方程的数值解部分———————————————————————————————————————————————————————————– 第五章 常微分方程数值解记忆内容汇总 欧拉法$$y_{n+1} &#x3D; y_n + h f(x_n, y_n)$$改进欧拉法$$y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(">
<meta property="og:type" content="article">
<meta property="og:title" content="数值分析-常微分方程数值解">
<meta property="og:url" content="https://qieliqiean.github.io/blog/2025/04/23/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3/index.html">
<meta property="og:site_name" content="且离且安的碎碎念">
<meta property="og:description" content="此部分包含常微分方程的数值解部分———————————————————————————————————————————————————————————– 第五章 常微分方程数值解记忆内容汇总 欧拉法$$y_{n+1} &#x3D; y_n + h f(x_n, y_n)$$改进欧拉法$$y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qieliqiean.github.io/blog/image/sakura.jpg">
<meta property="article:published_time" content="2025-04-23T07:10:43.000Z">
<meta property="article:modified_time" content="2025-05-27T07:37:01.058Z">
<meta property="article:author" content="lian">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qieliqiean.github.io/blog/image/sakura.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "数值分析-常微分方程数值解",
  "url": "https://qieliqiean.github.io/blog/2025/04/23/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3/",
  "image": "https://qieliqiean.github.io/blog/image/sakura.jpg",
  "datePublished": "2025-04-23T07:10:43.000Z",
  "dateModified": "2025-05-27T07:37:01.058Z",
  "author": [
    {
      "@type": "Person",
      "name": "lian",
      "url": "https://qieliqiean.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/image/1.jpg"><link rel="canonical" href="https://qieliqiean.github.io/blog/2025/04/23/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '数值分析-常微分方程数值解',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/image/sakura.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><img class="site-icon" src="/blog/image/background1.png" alt="Logo"><span class="site-name">且离且安的碎碎念</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">数值分析-常微分方程数值解</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">数值分析-常微分方程数值解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-23T07:10:43.000Z" title="发表于 2025-04-23 15:10:43">2025-04-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-27T07:37:01.058Z" title="更新于 2025-05-27 15:37:01">2025-05-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">7.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>35分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>此部分包含常微分方程的数值解部分———————————————————————————————————————————————————————————–</p>
<h1 id="第五章-常微分方程数值解"><a href="#第五章-常微分方程数值解" class="headerlink" title="第五章 常微分方程数值解"></a>第五章 常微分方程数值解</h1><h2 id="记忆内容汇总"><a href="#记忆内容汇总" class="headerlink" title="记忆内容汇总"></a>记忆内容汇总</h2><blockquote>
<p><strong>欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n)<br>$$<br><strong>改进欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_n + h f(x_n, y_n)) \right]<br>$$</p>
<p><strong>四阶经典R-K方法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} (K_1 + 2K_2 + 2K_3 + K_4)<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_1)<br>$$</p>
<p>$$<br>K_3 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_2)<br>$$</p>
<p>$$<br>K_4 &#x3D; f(x_n + h, y_n + h K_3)<br>$$</p>
<p><strong>稳定区间</strong></p>
<ol>
<li>欧拉法</li>
</ol>
  <div>

<p>  $$<br>  E(h\lambda)&#x3D;1+h\lambda \<br>  -2 &lt; \lambda h &lt; 0<br>  $$</p>
  </div>

<ol start="2">
<li>改进欧拉法</li>
</ol>
  <div>

<p>  $$<br>  E(h\lambda)&#x3D;1 + h\lambda + \frac{(h\lambda)^2}{2} \<br>  -2 &lt; h\lambda &lt; 0<br>  $$</p>
  </div>

<ol start="3">
<li>4阶经典龙格库塔方法<br>  $$<br>  E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!} + \frac{(h\lambda)^4}{4!}.<br>  $$</li>
</ol>
<p>  $$<br>  -2.78 &lt; h\lambda &lt; 0<br>  $$</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>考虑一阶常微分方程的初值问题 &#x2F;* Initial-Value Problem *&#x2F;:</p>
<span>
$$
\begin{cases}
\frac{dy}{dx} = f(x, y), & x \in [a, b] \\
y(a) = y_0
\end{cases}
$$

</span>

<p>只要 $f(x, y)$ 在 $[a, b] \times \mathbb{R}^1$ 上连续，且关于 $y$ 满足 Lipschitz 条件，即存在与 $x, y$ 无关的常数 $L$ 使得<br>$$<br>|f(x, y_1) - f(x, y_2)| \leq L |y_1 - y_2|<br>$$</p>
<p>对任意定义在 $[a, b]$ 上的 $y_1(x)$ 和 $y_2(x)$ 都成立，则上述 IVP (一阶常微分方程的初值问题)存在唯一解。</p>
<ul>
<li>本章的任务：计算出解函数 $y(x)$ 在一系列节点 $a &#x3D; x_0 &lt; x_1 &lt; \dots &lt; x_n &#x3D; b$ 处的近似值。</li>
</ul>
<p>$$<br>y_n \approx y(x_n) \quad (n &#x3D; 1, \dots, N)<br>$$</p>
<h2 id="建立常微分方程数值方法的基本思想"><a href="#建立常微分方程数值方法的基本思想" class="headerlink" title="建立常微分方程数值方法的基本思想"></a>建立常微分方程数值方法的基本思想</h2><p>微分方程数值解法，其实是求出方程的解 $y(x)$ 在一系列离散点上的近似值。则微分方程数值解的基本思想是：求解区间和方程离散化。</p>
<h3 id="求解区间离散化"><a href="#求解区间离散化" class="headerlink" title="求解区间离散化"></a>求解区间离散化</h3><p>将求解区间 $[a, b]$ 离散化，是在 $[a, b]$ 上插入一系列的分点 ${x_k}$ 使得<br>$$<br>a &#x3D; x_0 &lt; x_1 &lt; \dots &lt; x_n &lt; \dots &lt; x_N &#x3D; b<br>$$</p>
<ul>
<li><p>记 $h_n &#x3D; x_{n+1} - x_n$ ($n &#x3D; 0, 1, \dots, N-1$) 称为步长，一般取 $h_n &#x3D; h$（常数）</p>
</li>
<li><p>节点为 $x_n &#x3D; x_0 + nh$ ($n &#x3D; 0, 1, 2, \dots, N$)</p>
</li>
<li><p>$h &#x3D; \frac{b - a}{N}$ 为等步长节点。</p>
</li>
</ul>
<hr>
<h3 id="微分方程离散化"><a href="#微分方程离散化" class="headerlink" title="微分方程离散化"></a>微分方程离散化</h3><p>将微分方程离散化，通常有以下几种方法：</p>
<ol>
<li><p><strong>差商逼近法</strong></p>
<p>即是用适当的差商逼近导数值。</p>
</li>
<li><p><strong>数值积分法</strong></p>
<p>基本思想是先将问题转化为积分类方程</p>
<p>$$<br>y(x_m) - y(x_n) &#x3D; \int_{x_n}^{x_m} f(x, y(x)) dx \quad (y(x_0) &#x3D; y_0)<br>$$</p>
<p>然后将式子右端采用第四章介绍的数值积分离散化，从而获得初值问题的一个离散差分格式。</p>
</li>
<li><p><strong>Taylor 展开法</strong></p>
</li>
</ol>
<blockquote>
<p><strong>例题</strong></p>
<p>用二阶 Taylor 展开法求初值问题<br>$$<br>\begin{cases}<br>y’ &#x3D; x^2 + y^2 \<br>y(1) &#x3D; 1<br>\end{cases}<br>$$</p>
<p>求其在 $x &#x3D; 1.5$ 时的近似值（取步长 $h &#x3D; 0.25$，小数点后至少保留 5 位）。</p>
<hr>
<p><strong>解题过程</strong><br>二阶 Taylor 展开公式为：<br>$$<br>y(x_{n+1}) &#x3D; y(x_n) + y’(x_n) h + \frac{y’’(x_n)}{2!} h^2 + O(h^3)<br>$$</p>
<p>已知：</p>
<p>$$<br>y’ &#x3D; x^2 + y^2,\quad y’’ &#x3D; 2x + 2y \cdot y’ &#x3D; 2x + 2y(x^2 + y^2)<br>$$</p>
<p>代入上式，并略去高阶项 $O(h^3)$，则求解公式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h(x_n^2 + y_n^2) + \frac{h^2}{2} \left[ 2x_n + 2y_n(x_n^2 + y_n^2) \right]<br>$$</p>
<p>由 $y(1) &#x3D; y_0 &#x3D; 1$，计算得：</p>
<p>$$<br>y(1.25) \approx y_1 &#x3D; 1.6875 ;\<br>y(1.50) \approx y_2 &#x3D; 3.333298<br>$$</p>
</blockquote>
<h2 id="欧拉方法"><a href="#欧拉方法" class="headerlink" title="欧拉方法"></a>欧拉方法</h2><h3 id="欧拉公式"><a href="#欧拉公式" class="headerlink" title="欧拉公式"></a>欧拉公式</h3><p>向前差商近似导数  →  $y’(x_0) \approx \frac{y(x_1) - y(x_0)}{h}$</p>
<p>记为</p>
<p>$$<br>y(x_1) \approx y(x_0) + h y’(x_0) &#x3D; y_0 + h f(x_0, y_0)<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n) \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p><strong>原理图形</strong></p>
<p><img src="/blog/image/Snipaste_2025-05-20_14-47-05.png"></p>
<h2 id="隐式欧拉法"><a href="#隐式欧拉法" class="headerlink" title="隐式欧拉法"></a>隐式欧拉法</h2><p>向后差商近似导数  →  $y’(x_1) \approx \frac{y(x_1) - y(x_0)}{h}$</p>
<p>记为</p>
<p>$$<br>y(x_1) \approx y_0 + h f(x_1, y(x_1))<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1}) \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p>由于未知数 $y_{n+1}$ 同时出现在等式的两边，不能直接得到，故称为<strong>隐式欧拉公式</strong>，而前者称为<strong>显式欧拉公式</strong>。</p>
<p>一般先用显式计算一个初值，再递代求解。即</p>
<p>$$<br>y_{n+1}^{(0)} &#x3D; y_n + h f(x_n, y_n)<br>$$</p>
<p>$$<br>y_{n+1}^{(k+1)} &#x3D; y_n + h f(x_{n+1}, y_{n+1}^{(k)}) \quad k &#x3D; 0, 1, 2, \dots<br>$$</p>
<p>如果迭代过程收敛，则步后 $y_{n+1}^{(k+1)}$ 就可以作为 $y_{n+1}$，从而进行下一步的计算。</p>
<h2 id="梯形公式"><a href="#梯形公式" class="headerlink" title="梯形公式"></a>梯形公式</h2><p>显、隐式两种算法的平均<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_{n+1}) \right] \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<hr>
<h2 id="两步欧拉公式"><a href="#两步欧拉公式" class="headerlink" title="两步欧拉公式"></a>两步欧拉公式</h2><p>中心差商近似导数  →  $y’(x_1) \approx \frac{y(x_2) - y(x_0)}{2h}$</p>
<p>$$<br>y(x_2) \approx y(x_0) + 2h f(x_1, y(x_1))<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_{n-1} + 2h f(x_n, y_n) \quad n &#x3D; 1, \dots, N-1<br>$$</p>
<hr>
<blockquote>
<p>需要 2 个初值 $y_0$ 和 $y_1$ 来启动递推，这样的算法称为两步法 &#x2F;* double-step method <em>&#x2F;，而前面的三种算法都是单步法 &#x2F;</em> single-step method *&#x2F;。</p>
</blockquote>
<h2 id="改进欧拉法"><a href="#改进欧拉法" class="headerlink" title="改进欧拉法"></a>改进欧拉法</h2><p>Step 1: 先用显式欧拉公式作预测，算出 $\bar{y}_{n+1} &#x3D; y_n + h f(x_n, y_n)$</p>
<p>Step 2: 再将 $\bar y_{n+1}$ 代入隐式梯形公式的右边作校正，得到<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, \bar y_{n+1}) \right]<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_n + h f(x_n, y_n)) \right] \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p><strong>换一种表示方法</strong><span style="color:#FF0000">（考试记忆这个）</span></p>
<p>$y_p &#x3D; y_n + h f(x_n, y_n)$，$y_c &#x3D; y_n + h f(x_{n+1}, y_p)$，因此有<br>$$<br>y_{n+1} &#x3D; \frac{1}{2} (y_p + y_c)<br>$$</p>
<blockquote>
<p>此法也称为<strong>预测-校正法</strong> &#x2F;* predictor-corrector method *&#x2F;。可以证明该算法具有 <strong>2 阶精度</strong>，同时可以看到它是个单步递推格式，比隐式公式的解求过程简单。后面将看到，它的稳定性高于显式欧拉法。</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>用梯形法和改进的欧拉法求解初值问题</p>
<p>$$<br>\begin{cases}<br>y’ &#x3D; x + y, \quad 0 \leq x \leq 0.5 \<br>y(0) &#x3D; 1<br>\end{cases}<br>$$</p>
<p>取步长 $h &#x3D; 0.1$，并与准确解 $y &#x3D; -x - 1 + 2e^x$ 比较。</p>
<hr>
<p><strong>解题过程</strong></p>
<p>梯形法计算公式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{1}{2}h \left[ x_n + y_n + x_{n+1} + y_{n+1} \right]<br>$$</p>
<p>解得：</p>
<p>$$<br>y_{n+1} &#x3D; \frac{1}{1 - h&#x2F;2} \left[ \left(1 + \frac{h}{2} \right) y_n + \frac{h}{2} (x_n + x_{n+1}) \right], \quad (n &#x3D; 0,1,\cdots,4)<br>$$</p>
<p><span style="color:#FF0000">（这里需要记住梯形法计算时等式右边的$y_{n+1}$需要移项后计算）</span></p>
<p>改进的欧拉法为：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2}[f(x_n,y_n)+f(x_{n+1},y_n+hf(x_n,y_n))]<br>$$</p>
<p>即：</p>
<p>$$<br>y_{n+1} &#x3D; (1+h+\frac{h^2}{2})y_n+(\frac{h}{2}+\frac{h^2}{2})x_n+\frac{h}{2}x_{n+1}<br>$$</p>
<p>代入 $h &#x3D; 0.1, y_0 &#x3D; 1$ 代入上述两种方法计算，结果见下表：</p>
<table>
<thead>
<tr>
<th>n</th>
<th>$x_n$</th>
<th>梯形法 $y_n$</th>
<th>$y(x_n) - y_n$</th>
<th>n</th>
<th>$x_n$</th>
<th>改进欧拉法 $y_n$</th>
<th>$y(x_n) - y_n$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.1</td>
<td>1.110 526 316</td>
<td>0.184 479 × 10⁻³</td>
<td>0</td>
<td>0.1</td>
<td>1.111 000 000</td>
<td>0.341 836 × 10⁻³</td>
</tr>
<tr>
<td>1</td>
<td>0.2</td>
<td>1.243 213 296</td>
<td>0.407 779 × 10⁻³</td>
<td>1</td>
<td>0.2</td>
<td>1.242 050</td>
<td>0.755 516 × 10⁻³</td>
</tr>
<tr>
<td>2</td>
<td>0.3</td>
<td>1.400 393 643</td>
<td>0.676 027 × 10⁻³</td>
<td>2</td>
<td>0.3</td>
<td>1.398 465 250</td>
<td>1.252 365 × 10⁻³</td>
</tr>
<tr>
<td>3</td>
<td>0.4</td>
<td>1.584 645 606</td>
<td>0.996210 × 10⁻³</td>
<td>3</td>
<td>0.4</td>
<td>1.581804101</td>
<td>1.845 294 × 10⁻³</td>
</tr>
<tr>
<td>4</td>
<td>0.5</td>
<td>1.798 818 827</td>
<td>1.376285 × 10⁻³</td>
<td>4</td>
<td>0.5</td>
<td>1.794893532</td>
<td>2.549 009 × 10⁻³</td>
</tr>
</tbody></table>
<hr>
<p><strong>结论</strong><br>可以看出，就本题而言，梯形法比改进的欧拉法更精确。</p>
</blockquote>
<h2 id="局部截断误差和方法的阶"><a href="#局部截断误差和方法的阶" class="headerlink" title="局部截断误差和方法的阶"></a>局部截断误差和方法的阶</h2><p>初值问题的单步法可用一般形式表示为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h \varphi(x_n, y_n, y_{n+1}, h)<br>$$</p>
<p>其中，$\varphi$ 称为增量函数。</p>
<ul>
<li>若 $\varphi$ 包含 $y_{n+1}$ 时，方法是<strong>隐式</strong>的</li>
<li>若 $\varphi$ 不包含 $y_{n+1}$ 时，方法是<strong>显式</strong>的</li>
</ul>
<p>例如</p>
<ul>
<li><p>(显示)欧拉法有 $\varphi(x_n, y_n, h) &#x3D; f(x_n, y_n)$，</p>
</li>
<li><p>隐式欧拉法有 $\varphi(x_n, y_n, y_{n+1},h) &#x3D; f(x_{n+1}, y_{n+1})$</p>
</li>
</ul>
<p>从 $x_0$ 开始计算，如果考虑每一步产生的误差，直到 $x_n$ 则有误差<br>$$<br>e_n &#x3D; y(x_n) - y_n<br>$$</p>
<p>称为该方法在 $x_n$ 的<strong>整体截断误差</strong></p>
<p>分析和求得整体截断误差是复杂的。为此，我们只考虑从 $x_n$ 到 $x_{n+1}$ 的局部情况，并假设 $x_n$ 之前的计算没有误差，即$y(x_n)&#x3D;y_n$</p>
<p><strong>定义</strong></p>
<p>设 $y(x)$ 是初值问题的准确解，称</p>
<p>$$<br>T_{n+1} &#x3D;y(x_{n+1}) - y_{n+1}&#x3D; y(x_{n+1}) - y(x_n) - h \varphi(x_n, y(x_n),y(x_{n+1}) ,h)<br>$$</p>
<p>为单步法的<strong>局部截断误差</strong>。</p>
<p><strong>定义</strong></p>
<blockquote>
<p>若某算法的局部截断误差为 $O(h^{p+1})$，则该算法有 $p$ 阶精度。</p>
</blockquote>
<blockquote>
<span>
$$
\begin{aligned}
f(x + \Delta x, y + \Delta y) &= f(x, y) \\
&\quad + \Delta x \cdot f_x + \Delta y \cdot f_y \\
&\quad + \frac{1}{2} \left( \Delta x^{2} f_{xx} + 2 \Delta x \Delta y f_{xy} + \Delta y^{2} f_{yy} \right) \\
&\quad + \frac{1}{6} \left( \Delta x^{3} f_{xxx} + 3 \Delta x^{2} \Delta y f_{xxy} + 3 \Delta x \Delta y^{2} f_{xyy} + \Delta y^{3} f_{yyy} \right) \\
&\quad + \frac{1}{24} \left( \Delta x^{4} f_{xxxx} + 4 \Delta x^{3} \Delta y f_{xxxy} + 6 \Delta x^{2} \Delta y^{2} f_{xxyy} + 4 \Delta x \Delta y^{3} f_{xyyy} + \Delta y^{4} f_{yyyy} \right) \\
&\quad + O(\Delta x^{5}, \Delta y^{5})
\end{aligned}
$$


</span>

</blockquote>
<h3 id="欧拉法的局部截断误差"><a href="#欧拉法的局部截断误差" class="headerlink" title="欧拉法的局部截断误差"></a>欧拉法的局部截断误差</h3><p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1}   \<br>&#x3D; [y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3)] - [y_n + h f(x_n, y_n)] \<br>$$</p>
<p>$$<br>\text {其中} \quad y_n&#x3D;y(x_n) \quad  f(x_n, y_n)&#x3D;y’(x_n) \<br>$$</p>
<p>$$<br>T_{n+1}&#x3D;\frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>欧拉法具有 1 阶精度。</strong></p>
<h3 id="隐式欧拉法的局部截断误差"><a href="#隐式欧拉法的局部截断误差" class="headerlink" title="隐式欧拉法的局部截断误差"></a>隐式欧拉法的局部截断误差</h3><p>求隐式欧拉式 $y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1})$ 的局部截断误差。<br>$$<br>T_{n+1} &#x3D; y(x_{n+1})-y_{n+1} \<br>&#x3D;y(x_{n+1}) - y(x_n) - h f(x_{n+1}, y_{n+1}) \<br>&#x3D;y(x_{n+1}) - y(x_n) - hy’(x_{n+1}) \<br>&#x3D; h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3) - h[y’(x_n) + h y’’(x_n) + O(h^2)] \<br>&#x3D; -\frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>具有 1 阶精度。</strong></p>
<hr>
<h3 id="梯形公式的局部截断误差"><a href="#梯形公式的局部截断误差" class="headerlink" title="梯形公式的局部截断误差"></a>梯形公式的局部截断误差</h3><p>梯形公式 $y_{n+1} &#x3D; y_n + \frac{h}{2}[f(x_n, y_n) + f(x_{n+1}, y_{n+1})]$ 的局部截断误差。<br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y(x_n) - \frac{h}{2}[y’(x_n) + y’(x_{n+1})] \<br>&#x3D; h y’(x_n) + \frac{h^2}{2} y’’(x_n) + \frac{h^3}{3!} y^{(3)}(x_n) - \frac{h}{2}[y’(x_n) + y’(x_n) + hy’’(x_n) + \frac{h^2}{2} y^{(3)}(x_n) + O(h^4)] \<br>&#x3D; -\frac{h^3}{12} y^{(3)}(x_n) + O(h^4)<br>$$</p>
<p><strong>具有 2 阶精度。</strong></p>
<h3 id="改进欧拉法的局部截断误差"><a href="#改进欧拉法的局部截断误差" class="headerlink" title="改进欧拉法的局部截断误差"></a>改进欧拉法的局部截断误差</h3><p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) -  y_{n+1} &#x3D; O(h^3)<br>$$</p>
<p> $ y(x_{n+1}) $精确解在 $ x_n $ 处展开至三阶项：</p>
<span>
$$
\begin{aligned}
y(x_{n+1}) &= y(x_n) + h y'(x_n) + \frac{h^2}{2} y''(x_n) + \frac{h^3}{6} y'''(x_n) + O(h^4) \\
&= y(x_{n+1}) + h f + \frac{h^2}{2}(f_x + f f_y) + \frac{h^3}{6}(f_{xx} + 2f_{xy}f + f_{yy}f^2 + f_y f_x + f_y^2 f) + O(h^4)
\end{aligned}
$$

</span>



<p>预测-校正步骤：<br>$$<br>y_{n+1} &#x3D; y_n + h (f+f(x_n+h,y_n+hf))<br>$$</p>
<p>对 $f(x_n + h, y_n + h f)$ 进行二元泰勒展开（至二阶项）：<br>$$<br>f(x_n + h, y_n + h f) &#x3D; f + h f_x + h f f_y + \frac{h^2}{2}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + O(h^3)<br>$$</p>
<p>代入得数值解：<br>$$<br>y_{n+1} &#x3D; y_n + h f + \frac{h^2}{2}(f_x + f f_y) + \frac{h^3}{4}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + O(h^4)<br>$$</p>
<span>
$$
\begin{aligned}
T_{n+1} &= y(x_{n+1}) - y_{n+1} \\
&= \left[ \frac{h^3}{6}(f_{xx} + 2 f_{xy} f + f_{yy} f^2 + f_y f_x + f_y^2 f) \right] \\
&\quad - \left[ \frac{h^3}{4}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) \right] + O(h^4) \\
&= -\frac{h^3}{12}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + \frac{h^3}{6}(f_y f_x + f_y^2 f) + O(h^4)
\end{aligned}
$$

</span>

<p><strong>即两步欧拉公式具有 2 阶精度。</strong></p>
<h3 id="方法比较表"><a href="#方法比较表" class="headerlink" title="方法比较表"></a>方法比较表</h3><table>
<thead>
<tr>
<th>方法</th>
<th>局部截断误差</th>
<th>精度（阶）</th>
</tr>
</thead>
<tbody><tr>
<td>显式欧拉法</td>
<td>$\frac{h^2}{2} y’’(x_n) + O(h^3)$</td>
<td>1</td>
</tr>
<tr>
<td>隐式欧拉法</td>
<td>$-\frac{h^2}{2} y’’(x_n) + O(h^3)$</td>
<td>1</td>
</tr>
<tr>
<td>梯形公式</td>
<td>$-\frac{h^3}{12} y^{(3)}(x_n) + O(h^4)$</td>
<td>2</td>
</tr>
<tr>
<td>改进欧拉法</td>
<td>$O(h^3)$</td>
<td>2</td>
</tr>
</tbody></table>
<h2 id="龙格-库塔法"><a href="#龙格-库塔法" class="headerlink" title="龙格 - 库塔法"></a>龙格 - 库塔法</h2><h3 id="龙格-库塔法的基本思想"><a href="#龙格-库塔法的基本思想" class="headerlink" title="龙格 - 库塔法的基本思想"></a>龙格 - 库塔法的基本思想</h3><ul>
<li>建立高精度的单步逆推公式。</li>
</ul>
<p>单步逆推法的基本思想是从 $(x_n, y_n)$ 点出发，以某一斜率沿直线达到 $(x_{n+1}, y_{n+1})$ 点。欧拉法及其各种变形所能达到的最高精度为2阶。</p>
<p>考虑改进的欧拉法，可以将其改写为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h \left[ \frac{1}{2} K_1 + \frac{1}{2} K_2 \right]<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + h, y_n + h K_1)<br>$$</p>
<p>当然，$K_1, K_2$ 是在点 $x_n, x_{n+1}$ 处的斜率。以上公式用到了两个点的斜率的加权平均，它为构造算法提供了新的途径。<strong>Runge-Kutta方法就是这种思想的体现和发展</strong>。</p>
<p><strong>将改进欧拉法推广为</strong><br>$$<br>y_{n+1} &#x3D; y_n + h[\lambda_1 K_1 + \lambda_2 K_2]<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + ph, y_n + phK_1)<br>$$</p>
<p>首先希望能够确定系数 $\lambda_1, \lambda_2, p$，使得到的算法公式有2阶精度，即在 $y_n &#x3D; y(x_n)$ 的前提假设下，使得</p>
<p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; O(h^3)<br>$$</p>
<p><strong>Step 1</strong>: 将 $K_2$ 在 $(x_n, y_n)$ 点作 Taylor 展开<br>$$<br>K_2 &#x3D; f(x_n + ph, y_n + phK_1)<br>$$</p>
<blockquote>
<span>
$$
\begin{aligned}
f(x + \Delta x, y + \Delta y) &= f(x, y) \\
&\quad + \Delta x \cdot f_x + \Delta y \cdot f_y \\
&\quad + \frac{1}{2} \left( \Delta x^{2} f_{xx} + 2 \Delta x \Delta y f_{xy} + \Delta y^{2} f_{yy} \right) \\
&\quad + \frac{1}{6} \left( \Delta x^{3} f_{xxx} + 3 \Delta x^{2} \Delta y f_{xxy} + 3 \Delta x \Delta y^{2} f_{xyy} + \Delta y^{3} f_{yyy} \right) \\
&\quad + \frac{1}{24} \left( \Delta x^{4} f_{xxxx} + 4 \Delta x^{3} \Delta y f_{xxxy} + 6 \Delta x^{2} \Delta y^{2} f_{xxyy} + 4 \Delta x \Delta y^{3} f_{xyyy} + \Delta y^{4} f_{yyyy} \right) \\
&\quad + O(\Delta x^{5}, \Delta y^{5})
\end{aligned}
$$

</span>

</blockquote>
<p>$$<br>&#x3D; f(x_n, y_n) + phf_x(x_n, y_n) + phK_1 f_y(x_n, y_n) + O(h^2)<br>$$</p>
<blockquote>
<p>$$<br>y’’(x) &#x3D; \frac{d}{dx} f(x, y)&#x3D; f_x(x, y) + f_y(x, y) \frac{dy}{dx}&#x3D; f_x(x, y) + f_y(x, y) f(x, y)<br>$$</p>
</blockquote>
<p>$$<br>&#x3D; y’(x_n) + ph y’’(x_n) + O(h^2)<br>$$</p>
<p><strong>Step 2</strong>: 将 $K_2$ 代入第1式，得到<br>$$<br>y_{n+1} &#x3D; y_n + h \left( \lambda_1 y’(x_n) + \lambda_2 \left[ y’(x_n) + ph y’’(x_n) + O(h^2) \right] \right)<br>$$</p>
<p>$$<br>&#x3D; y_n + (\lambda_1 + \lambda_2) h y’(x_n) + \lambda_2 ph^2 y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>Step 3</strong>: 将 $y_{n+1}$ 与 $y(x_{n+1})$ 在 $x_n$ 点的泰勒展开比较<br>$$<br>y_{n+1} &#x3D; y_n + (\lambda_1 + \lambda_2) h y’(x_n) + \lambda_2 ph^2 y’’(x_n) + O(h^3)<br>$$</p>
<p>$$<br>y(x_{n+1}) &#x3D; y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p>要求 $T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; O(h^3)$，则必须有：</p>
<p>$$<br>\lambda_1 + \lambda_2 &#x3D; 1, \quad \lambda_2 p &#x3D; \frac{1}{2}<br>$$</p>
<p><strong>这里有3个未知数，2个方程</strong>。</p>
<p>存在无穷多个解。所有满足上述的格式系统称为2阶龙格-库塔格式。注意到，$p &#x3D; 1, \lambda_1 &#x3D; \lambda_2 &#x3D; \frac{1}{2}$ 就是改进的欧拉法。</p>
<h3 id="Runge-Kutta方法的一般形式"><a href="#Runge-Kutta方法的一般形式" class="headerlink" title="Runge-Kutta方法的一般形式"></a>Runge-Kutta方法的一般形式</h3><p>$$<br>y_{n+1} &#x3D; y_n + h \sum_{i&#x3D;1}^{L} \lambda_i k_i<br>$$</p>
<p>$$<br>k_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>k_2 &#x3D; f(x_n + c_2 h, y_n + c_2 h k_1)<br>$$</p>
<p>$$<br>k_3 &#x3D; f(x_n + c_3 h, y_n + c_3 h (a_{31} k_1 + a_{32} k_2))<br>$$</p>
<p>$$<br>\vdots<br>$$</p>
<p>$$<br>k_i &#x3D; f(x_n + c_i h, y_n + c_i h \sum_{j&#x3D;1}^{i-1} a_{ij} k_j) \quad i &#x3D; 2, 3, \dots, L<br>$$</p>
<p>其中，$\sum_{i&#x3D;1}^{L} \lambda_i &#x3D; 1, \quad c_i \leq 1, \quad \sum_{j&#x3D;1}^{i-1} a_{ij} &#x3D; 1$ 均为待定系数，确定这些系数的步骤与前面相似。</p>
<h3 id="二阶中点格式"><a href="#二阶中点格式" class="headerlink" title="二阶中点格式"></a>二阶中点格式</h3><p>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + h K_2 \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left( x_n + \frac{h}{2},\ y_n + \frac{h}{2} K_1 \right), \quad (n &#x3D; 0, 1, 2, \cdots)<br>\end{cases}<br>$$</p>
<h3 id="二阶休恩格式"><a href="#二阶休恩格式" class="headerlink" title="二阶休恩格式"></a>二阶休恩格式</h3><p>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + \frac{h}{4} \left( K_1 + 3K_2 \right) \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left( x_n + \frac{2}{3}h,\ y_n + \frac{2}{3}h K_1 \right), \quad (n &#x3D; 0, 1, 2, \cdots)<br>\end{cases}<br>$$</p>
<h3 id="四级4阶经典龙格-库塔法"><a href="#四级4阶经典龙格-库塔法" class="headerlink" title="四级4阶经典龙格-库塔法"></a>四级4阶经典龙格-库塔法</h3><p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} (K_1 + 2K_2 + 2K_3 + K_4)<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_1)<br>$$</p>
<p>$$<br>K_3 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_2)<br>$$</p>
<p>$$<br>K_4 &#x3D; f(x_n + h, y_n + h K_3)<br>$$</p>
<blockquote>
<p><strong>例题</strong><br>$$<br>y’&#x3D;y-\frac {2x}{y} \quad(0&lt;x&lt;1) \<br>y(0)&#x3D;1<br>$$<br><strong>解</strong>：对于本题，经典的四阶 Runge-Kutta 方法具有以下形式：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} \left( k_1 + 2k_2 + 2k_3 + k_4 \right)<br>$$</p>
<p>$$<br>k_1 &#x3D; y_n - \frac{2x_n}{y_n}<br>$$</p>
<p>$$<br>k_2 &#x3D; y_n + \frac{h}{2} k_1 - \frac{2x_n + h}{y_n + \frac{h}{2} k_1}<br>$$</p>
<p>$$<br>k_3 &#x3D; y_n + \frac{h}{2} k_2 - \frac{2x_n + h}{y_n + \frac{h}{2} k_2}<br>$$</p>
<p>$$<br>k_4 &#x3D; y_n + h k_3 - \frac{2(x_n + h)}{y_n + h k_3}<br>$$</p>
<p>这里，我们取步长 $h&#x3D;0.2$，下面是计算结果（符号的意义同前）：</p>
<table>
<thead>
<tr>
<th>$X_n$</th>
<th>$y_n$</th>
<th>$y(x_n)$</th>
</tr>
</thead>
<tbody><tr>
<td>0.2</td>
<td>1.1832</td>
<td>1.1832</td>
</tr>
<tr>
<td>0.4</td>
<td>1.3417</td>
<td>1.3416</td>
</tr>
<tr>
<td>0.6</td>
<td>1.4833</td>
<td>1.4832</td>
</tr>
<tr>
<td>0.8</td>
<td>1.6125</td>
<td>1.6125</td>
</tr>
<tr>
<td>1.0</td>
<td>1.7321</td>
<td>1.7321</td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<p><strong>注</strong>:<br>龙格-库塔法的主要运算是在计算 $K_i$ 的值，即计算 $f$ 的值。Butcher 于 1965 年给出了计算量与可达到的最高精度阶数的关系：</p>
<table>
<thead>
<tr>
<th>每步须计算 $K_i$ 的个数</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>$n \geq 8$</th>
</tr>
</thead>
<tbody><tr>
<td>可达到的最高精度</td>
<td>$O(h^2)$</td>
<td>$O(h^3)$</td>
<td>$O(h^4)$</td>
<td>$O(h^4)$</td>
<td>$O(h^5)$</td>
<td>$O(h^6)$</td>
<td>$O(h^{n-2})$</td>
</tr>
</tbody></table>
<p>由于龙格-库塔法的导出基于泰勒展开，故精度主要受解函数的光滑性影响。对于光滑性不太好的解，最好采用低阶方法而将步长 $h$ 取小。</p>
</blockquote>
<blockquote>
<p><strong>【题 1】（北京理工大学 2006 年）</strong></p>
<p><strong>考查初值问题</strong></p>
<span>
$$
\begin{cases}
y' = x^4, \quad x > 0 \\
y(0) = 1
\end{cases} \quad \text{①}
$$

</span>

<p>其准确解为 $y(x) &#x3D; 1 + \frac{x^5}{5}$。记 $x_i &#x3D; ih$, $i &#x3D; 0, 1, 2, \cdots$，设 ${y_i}_{i&#x3D;0}^\infty$ 为用经典 Runge-Kutta 公式所得近似解，证明：<br>$$<br>y(x_i) - y_i &#x3D; -\frac{x_i}{120}h^4, \quad i &#x3D; 0, 1, 2, \cdots \quad \text{②}<br>$$</p>
<hr>
<p><strong>解题过程</strong></p>
<p>求解 ① 的 Runge-Kutta 公式为：</p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + \frac{h}{6}(K_1 + 2K_2 + 2K_3 + K_4) \\
K_1 = f(x_i, y_i) = x_i^4 \\
K_2 = f\left(x_i + \frac{h}{2},\ y_i + \frac{1}{2}hK_1\right) = \left(x_i + \frac{h}{2} \right)^4 \\
K_3 = f\left(x_i + \frac{h}{2},\ y_i + \frac{1}{2}hK_2\right) = \left(x_i + \frac{h}{2} \right)^4 \\
K_4 = f(x_i + h, y_i + hK_3) = (x_i + h)^4 \\
y_0 = 1
\end{cases}
$$

</span>

<p>因此：<br>$$<br>y_{i+1} &#x3D; y_i + \frac{h}{6} \left[ x_i^4 + 2\left(x_i + \frac{h}{2}\right)^4 + 2\left(x_i + \frac{h}{2}\right)^4 + (x_i + h)^4 \right]<br>$$</p>
<blockquote>
<p>$$<br>(a + b)^n &#x3D; \sum_{k&#x3D;0}^{n} C_n^k a^{n-k} b^k<br>$$</p>
<p>$$<br>(a + b)^4 &#x3D; a^4 + 4a^3b + 6a^2b^2 + 4ab^3 + b^4<br>$$</p>
</blockquote>
<p>展开得：</p>
<p>$$<br>&#x3D; y_i + h \left(x_i^4 + 2x_i^3 h + 2x_i^2 h^2 + x_i h^3 + \frac{5}{24} h^4 \right) \quad \text{③}<br>$$</p>
<hr>
<p>另一方面：</p>
<p>$$<br>y(x_{i+1}) &#x3D; 1 + \frac{1}{5}x_{i+1}^5 &#x3D; 1 + \frac{1}{5}(x_i + h)^5<br>$$</p>
<p>展开：</p>
<p>$$<br>&#x3D; 1 + \frac{1}{5} \left[ x_i^5 + 5x_i^4 h + 10x_i^3 h^2 + 10x_i^2 h^3 + 5x_i h^4 + h^5 \right] \<br>&#x3D; y(x_i) + x_i^4 h + 2x_i^3 h^2 + 2x_i^2 h^3 + x_i h^4 + \frac{1}{5} h^5 \quad \text{④}<br>$$</p>
<hr>
<p>将③和④相减，得：</p>
<p>$$<br>y(x_{i+1}) - y_{i+1} &#x3D; y(x_i) - y_i + \frac{1}{5}h^5 - \frac{5}{24}h^5 \<br>&#x3D; y(x_i) - y_i - \frac{1}{120}h^5<br>$$</p>
<span>
$$
\begin{cases}
y(x_i) - y_i  = y(x_{i-1}) - y_{i-1} - \frac{1}{120}h^5 \\
y(x_{i-1}) - y_{i-1}=y(x_{i-2}) - y_{i-2}- \frac{1}{120}h^5\\
\vdots \vdots  \\
 y(x_{1}) - y_{1}= y(x_{0}) - y_{0}- \frac{1}{120}h^5
\end{cases}
$$

</span>

<p>上式相加整理得：<br>$$<br>y(x_i) - y_i &#x3D; - \frac{1}{120}h^5 \cdot i &#x3D; -\frac{x_i}{120}h^4<br>$$</p>
<p>因此最终结果为：</p>
<p>$$<br>\boxed{y(x_i) - y_i &#x3D; -\frac{x_i}{120}h^4}, \quad i &#x3D; 0, 1, 2, \cdots<br>$$</p>
</blockquote>
<h2 id="收敛性与稳定性"><a href="#收敛性与稳定性" class="headerlink" title="收敛性与稳定性"></a>收敛性与稳定性</h2><h3 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a>收敛性</h3><p><strong>定义</strong><br>若某算法对于任意固定的 $x &#x3D; x_n &#x3D; x_0 + n h$，当 $h \to 0$（同时 $n \to \infty$）时有 $y_n \to y(x_n)$，则称该算法是<strong>收敛</strong>的。</p>
<p><strong>例</strong>: 就初值问题<br>$$<br>y’ &#x3D; \lambda y<br>$$</p>
<p>$$<br>y(0) &#x3D; y_0<br>$$</p>
<p>考察欧拉显式格式的收敛性.</p>
<p><strong>解</strong>: 该问题的精确解为<br>$$<br>y(x) &#x3D; y_0 e^{\lambda x}<br>$$</p>
<p>欧拉公式为<br>$$<br>y_{n+1} &#x3D; y_n + h \lambda y_n &#x3D; (1 + \lambda h) y_n<br>\Rightarrow y_n &#x3D; (1 + \lambda h)^n y_0<br>$$</p>
<p>对于任意固定的 $x &#x3D; x_n &#x3D; n h$，有<br>$$<br>y_n &#x3D; y_0 (1 + \lambda h)^n &#x3D; y_0 \left[(1 + \lambda h)^{\frac{1}{\lambda h}}\right]^{\lambda x_n}<br>\Rightarrow y_0 e^{\lambda x_n} &#x3D; y(x_n) \checkmark<br>$$<br><strong>定理</strong><br>对于一个 $p$ 阶的显式单步法，若满足以下条件：</p>
<ol>
<li>增量函数 $\Phi$ 关于 $y$ 满足 Lipschitz 条件，即存在常数 $L_\varphi &gt; 0$，使得<br>$$<br>|\varphi(x, y, h) - \varphi(x, \bar{y}, h)| \leq L_\varphi |y - \bar{y}|, \quad \forall y, \bar{y} \in \mathbb{R}<br>$$</li>
<li>微分方程的初值是准确的，<br>则该方法收敛，其<strong>整体</strong>截断误差为：<br>$$<br>|e_n| &#x3D; |y(x_n) - y_n| &#x3D; O(h^p).<br>$$</li>
</ol>
<p><strong>注</strong>:</p>
<ol>
<li>判定显式单步格式的收敛性，归结为验证增量函数 $\Phi$ 是否满足 Lipschitz 条件。</li>
<li><strong>单步格式的整体截断误差</strong>差由<strong>初值误差</strong>及<strong>局部截断误差</strong>决定，整体截断误差比局部截断误差的阶数<strong>低一阶</strong>。</li>
<li>要构造高精度的计算方法，只需设计提高局部截断误差的阶即可。</li>
</ol>
<h3 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h3><p><strong>定义</strong><br>若某算法在计算过程中任一步产生的误差在以后的计算中都<strong>逐步衰减</strong>，则称该算法是<strong>绝对稳定的</strong> 。</p>
<p>一般分析时为简便起见，只考虑<strong>试验方程</strong>：</p>
<p>$$<br>y’ &#x3D; \lambda y \quad \text{Re}(\lambda) &lt; 0<br>$$</p>
<p>若得到的解<br>$y_{n+1} &#x3D; E(h\lambda) y_n$，满足 $|E(h\lambda)| &lt; 1$，则称该方法是<strong>绝对稳定</strong>的。<br>在 $\mu &#x3D; h\lambda$ 平面上，使 $|E(h\lambda)| &lt; 1$ 的区域称为<strong>绝对稳定域</strong>，<br>它与实轴的交称为<strong>绝对稳定区间</strong>。<span style="color:blue">（求$\lambda h$的取值范围，即$h$的取值范围）</span></p>
<blockquote>
<p><strong>一阶线性微分方程的通解</strong></p>
<p>一阶线性微分方程的标准形式为：</p>
<p>$$<br>\frac{dy}{dx} + P(x)y &#x3D; Q(x)<br>$$</p>
<p>其中，$ P(x) $ 和 $ Q(x) $ 是已知函数。</p>
<p>$$<br>y &#x3D; e^{-\int P(x) dx} \left( \int Q(x) e^{\int P(x) dx} dx + C \right)<br>$$</p>
</blockquote>
<hr>
<h4 id="欧拉法"><a href="#欧拉法" class="headerlink" title="欧拉法"></a>欧拉法</h4><p><strong>例：</strong> </p>
<p>对<strong>欧拉法</strong>有<br>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n) &#x3D; y_n + \lambda h y_n &#x3D; (1 + \lambda h) y_n,<br>$$<br>$$<br>\Rightarrow \text{稳定区间为 } -2 &lt; \lambda h &lt; 0。<br>$$</p>
<p>当 $\lambda &#x3D; -100$ 时，$0 &lt; h &lt; \frac{2}{100} &#x3D; 0.02$，<br>例如 $h &#x3D; 0.025$ 不稳定，$h &#x3D; 0.005$ 稳定</p>
<hr>
<h4 id="隐式欧拉法-1"><a href="#隐式欧拉法-1" class="headerlink" title="隐式欧拉法"></a>隐式欧拉法</h4><p><strong>例：</strong> </p>
<p>考察隐式欧拉法<br>$$<br>y_{i+1} &#x3D; y_i + h\lambda y_{i+1}<br>$$</p>
<p>解得：<br>$$<br>y_{i+1} &#x3D; \left(\frac{1}{1 - \lambda h}\right) y_i<br>$$</p>
<p>可见绝对稳定区域为：<br>$$<br>|1 - \lambda h| &gt; 1<br>$$</p>
<p>绝对稳定区间为 $-\infty &lt; \lambda h &lt; 0$。</p>
<p>当 $\lambda &lt; 0$ 时，$0 &lt; h &lt; \infty$，即对任何步长稳定。</p>
<blockquote>
<p><strong>注：</strong> 一般来说，隐式欧拉法的绝对稳定性比同阶的显式法的好。</p>
</blockquote>
<hr>
<h4 id="改进欧拉法-1"><a href="#改进欧拉法-1" class="headerlink" title="改进欧拉法"></a>改进欧拉法</h4><p><strong>例</strong></p>
<p>改进欧拉法（预测—校正，即二阶 $R-K$ 法）：<br>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + h \left( \frac{k_1}{2} + \frac{k_2}{2} \right), \<br>k_1 &#x3D; f(x_n, y_n) &#x3D; \lambda y_n, \<br>k_2 &#x3D; f(x_n + h, y_n + h k_1) &#x3D; \lambda (y_n + h \lambda y_n),<br>\end{cases}<br>$$</p>
<p>即：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h\lambda}{2} \left( y_n + (y_n + h\lambda y_n) \right)<br>&#x3D; \left( 1 + h\lambda + \frac{(h\lambda)^2}{2} \right) y_n.<br>$$</p>
<p>故：</p>
<p>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2}.<br>$$</p>
<p>$$<br>\left| 1 + h\lambda + \frac{(h\lambda)^2}{2} \right| &lt; 1<br>\Leftrightarrow -2 &lt; 2 + 2h\lambda + (h\lambda)^2 &lt; 2<br>$$</p>
<p>$$<br>\Leftrightarrow -2 &lt; 1 + (1 + h\lambda)^2 &lt; 2<br>\Leftrightarrow |1 + h\lambda| &lt; 1 \Leftrightarrow -2 &lt; h\lambda &lt; 0.<br>$$</p>
<hr>
<h4 id="梯形方法"><a href="#梯形方法" class="headerlink" title="梯形方法"></a>梯形方法</h4><p><strong>例</strong></p>
<p>梯形方法：对模型方程 $y’ &#x3D; \lambda y$ 使用梯形法（隐式中点法）</p>
<p>其更新格式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_{n+1}) \right]<br>$$</p>
<p>代入模型方程得：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ \lambda y_n + \lambda y_{n+1} \right]<br>&#x3D; y_n + \frac{h\lambda}{2} (y_n + y_{n+1})<br>$$</p>
<p>将 $y_{n+1}$ 移项整理：</p>
<p>$$<br>y_{n+1} - \frac{h\lambda}{2} y_{n+1} &#x3D; y_n + \frac{h\lambda}{2} y_n<br>\Rightarrow \left( 1 - \frac{h\lambda}{2} \right) y_{n+1} &#x3D; \left( 1 + \frac{h\lambda}{2} \right) y_n<br>$$</p>
<p>因此，得到递推公式：</p>
<p>$$<br>y_{n+1} &#x3D; \frac{1 + \frac{h\lambda}{2}}{1 - \frac{h\lambda}{2}} y_n<br>$$</p>
<p>于是</p>
<p>$$<br>E(h\lambda) &#x3D; \frac{1 + \frac{h\lambda}{2}}{1 - \frac{h\lambda}{2}}<br>$$</p>
<p>只要 $\operatorname{Re}(\lambda) &lt; 0$，则：</p>
<p>$$<br>\left|E(h\lambda)\right| &lt; 1<br>$$</p>
<ul>
<li>绝对稳定域为 $\mu &#x3D; h\lambda$ 的左半平面， </li>
<li>绝对稳定区间为 $-\infty &lt; \lambda h &lt; 0$，即 $0 &lt; h &lt; \infty$ 时梯形法均是稳定的。</li>
</ul>
<hr>
<h4 id="三阶、四阶-R-K-法"><a href="#三阶、四阶-R-K-法" class="headerlink" title="三阶、四阶 $R-K$ 法"></a>三阶、四阶 $R-K$ 法</h4><p><strong>例</strong></p>
<p>三阶、四阶 $R-K$ 法分别有：<br>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!},<br>$$</p>
<p>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!} + \frac{(h\lambda)^4}{4!}.<br>$$</p>
<p>由 $|E(h\lambda)| &lt; 1$，当 $\lambda$ 为实数时，得绝对稳定区间分别为：</p>
<p><span style="color:blue">三阶显式 $R-K$ 法：$-2.51 &lt; h\lambda &lt; 0$，即 $0 &lt; h &lt; -2.51 &#x2F; \lambda$</span></p>
<p><span style="color:blue">四阶显式 $R-K$ 法：$-2.78 &lt; h\lambda &lt; 0$，即 $0 &lt; h &lt; -2.78 &#x2F; \lambda$</span></p>
<hr>
<h4 id="中点公式"><a href="#中点公式" class="headerlink" title="中点公式"></a>中点公式</h4><p>证明中点公式<br>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + hK_2 \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left(x_n + \frac{h}{2}, y_n + \frac{h}{2}K_1\right)<br>\end{cases}<br>$$</p>
<p>是二阶的，并求其绝对稳定区间。</p>
<p><strong>分析</strong>　本题考查了中点公式及其绝对稳定区间。</p>
<p><strong>解</strong><br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y(x_n) - h f\left(x_n + \frac{h}{2}, y(x_n) + \frac{h}{2} y’(x_n)\right)<br>$$</p>
<p>$$<br>&#x3D; y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + \frac{1}{3!} h^3 y^{(3)}(x_n) + O(h^4)<br>$$</p>
<p>$$<br>&#x3D; y(x_n) + h ( f(x_n, y(x_n)) + \frac{h}{2} \frac{\partial f(x_n, y(x_n))}{\partial x}<br>$$</p>
<p>$$<br>+\frac{h}{2} y’(x_n) \frac{\partial f(x_n, y(x_n))}{\partial y}<br>$$</p>
<p>$$<br>+\frac{1}{2!} \left[ \frac{h}{2} \right]^2 \frac{\partial^2 f(x_n, y(x_n))}{\partial x^2}<br>$$</p>
<p>$$<br>+\frac{h}{2} \cdot \frac{h}{2} y’(x_n) \frac{\partial^2 f(x_n, y(x_n))}{\partial x \partial y}<br>$$</p>
<p>$$<br>+\left( \frac{h}{2} y’(x_n) \right)^2 \frac{\partial^2 f(x_n, y(x_n))}{\partial y^2} + O(h^3) )<br>$$</p>
<p>$$<br>&#x3D; \frac{h^3}{3!} y^{(3)}(x_n) - \frac{h^3}{8} \left[ \frac{\partial^2 f}{\partial x^2} +2 y’(x) \frac{\partial^2 f}{\partial x \partial y}<br>+(y’(x))^2 \frac{\partial^2 f}{\partial y^2} \right]_{(x_n, y(x_n))} + O(h^4) &#x3D; O(h^3)<br>$$</p>
<p>因此，中点公式是二阶的。</p>
<p>对模型方程 $y’ &#x3D; \lambda y\ ( \operatorname{Re}(\lambda) &lt; 0 )$ 使用中点公式求解，得：</p>
<p>$$<br>y_{n+1} &#x3D; \left[ 1 + \lambda h + \frac{1}{2} (\lambda h)^2 \right] y_n<br>$$</p>
<p>易知，当<br>$$<br>\left| 1 + \lambda h + \frac{1}{2} (\lambda h)^2 \right| \leq 1<br>$$<br>时，中点公式绝对稳定。特别当 $\lambda$ 为实数且 $\lambda &lt; 0$ 时，上不等式的解为：</p>
<p>$$<br>-2 \leq \lambda h \leq 0<br>$$</p>
<hr>
<h4 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h4><p> 对于初值问题<br>$$<br>y’ &#x3D; -100(y - x^2) + 2x, \quad y(0) &#x3D; 1.<br>$$</p>
<p>(1) 用欧拉法求解，步长 $h$ 取什么范围的值，才能使计算稳定。  </p>
<p>(2) 若用四阶龙格–库塔方法计算，步长 $h$ 如何选取？<br>(3) 若用梯形公式计算，步长 $h$ 有无限制。</p>
<p><strong>解</strong></p>
<p>(1) 原方程为<br>$$<br>y’ &#x3D; -100y+100x^2+2x<br>$$</p>
<p>稳定性分析主要关注<strong>齐次方程</strong>部分$y’ &#x3D; -100y$</p>
<p>用欧拉法求解题中初值问题，递推公式为<br>$$<br>y_{n+1}&#x3D;y_n+hf(x_n,y_n)&#x3D;y_n+h(-100y_n)&#x3D;(1-100h)y_n<br>$$</p>
<p>故当<br>$$<br>|1 + (-100h)| \leq 1<br>$$</p>
<p>时绝对稳定，即当 $0 &lt; h \leq 0.02$ 时欧拉法绝对稳定。</p>
<hr>
<p>(2) 当 $\lambda h &#x3D; -100h$ 满足不等式</p>
<p>$$<br>\left| 1 + \lambda h + \frac{1}{2}(\lambda h)^2 + \frac{1}{3!}(\lambda h)^3 + \frac{1}{4!}(\lambda h)^4 \right| \leq 1<br>$$</p>
<p>时，四阶龙格–库塔法绝对稳定，也即当 $\lambda h$ 满足</p>
<p>$$<br>-2.785 \leq \lambda h &lt; 0, \quad 0 &lt; h \leq \frac{-2.785}{\lambda} &#x3D; \frac{2.785}{100} &#x3D; 0.02785<br>$$</p>
<p>时绝对稳定。</p>
<p>(3) 对于梯形公式，当 $\lambda h &#x3D; -100h \in (-\infty, 0)$ 时，绝对稳定，<br>此条件 $\forall h \in (0, +\infty)$ 都成立，即梯形法对 $h$ 无限制。</p>
<hr>
<p><strong>例：</strong> 隐式龙格-库塔法  </p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + h[\lambda_1 K_1 + \cdots + \lambda_m K_m] \\
K_j = f\left(x_i + \alpha_j h, y_i + \beta_{j1} h K_1 + \cdots + \beta_{jm} h K_m \right), \quad (j = 1, \ldots, m)
\end{cases}
$$

</span>

<p>其中 <strong>2 阶方法</strong>：</p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + h K_1 \\
K_1 = f\left(x_i + \frac{h}{2}, y_i + \frac{h}{2} K_1\right)
\end{cases}
$$

</span>

<p>该方法的<strong>绝对稳定区域</strong>为图中左侧阴影区域（无条件稳定）。</p>
<p><img src="/blog/image/Snipaste_2025-04-28_15-16-58.png"></p>
<p>而<strong>显式 1～4 阶方法</strong>的绝对稳定区域如下图所示（随阶数增加扩大但仍有限）：</p>
<p><img src="/blog/image/Snipaste_2025-04-28_15-17-09.png"></p>
<p>图示区域说明：</p>
<ul>
<li>$k&#x3D;1$ 到 $k&#x3D;4$ 分别表示显式龙格-库塔法从一阶到四阶的稳定区域</li>
</ul>
<h2 id="线性多步法"><a href="#线性多步法" class="headerlink" title="线性多步法"></a>线性多步法</h2><p>用<strong>若干</strong>节点处的 $y$ 及 $y’$ 值的<strong>线性组合</strong>来近似 $y(x_{n+1})$。其通式可写为：</p>
<p>$$<br>y_{n+1} &#x3D; \alpha_0 y_n + \alpha_1 y_{n-1} + \dots + \alpha_k y_{n-k} + h\left( \beta_{-1} f_{n+1} + \beta_0 f_n + \beta_1 f_{n-1} + \dots + \beta_k f_{n-k} \right)<br>$$</p>
<ul>
<li><p>当$\beta_{-1} \neq 0$时，为隐式公式</p>
</li>
<li><p>当$\beta_{-1} &#x3D; 0$时，为显式公式</p>
</li>
</ul>
<h3 id="基于数值积分的构造法"><a href="#基于数值积分的构造法" class="headerlink" title="基于数值积分的构造法"></a>基于数值积分的构造法</h3><p>将 $y’ &#x3D; f(x, y)$ 在 $[x_n, x_{n+1}]$ 上积分，得到：</p>
<p>$$<br>y(x_{n+1}) - y(x_n) &#x3D; \int_{x_n}^{x_{n+1}} f(x, y(x)) , dx<br>$$</p>
<p>只要<strong>近似地算出右边的积分</strong> $I_n \approx \int_{x_n}^{x_{n+1}} f(x, y(x)) , dx$，则可通过<br>$$<br>y_{n+1} &#x3D; y_n + I_n<br>$$<br>近似 $y(x_{n+1})$。而<strong>选用不同近似式 $I_n$</strong>，可得到不同的计算公式。</p>
<h3 id="亚当姆斯显式公式"><a href="#亚当姆斯显式公式" class="headerlink" title="亚当姆斯显式公式"></a>亚当姆斯显式公式</h3><p>利用 $k+1$ 个节点上的被积函数值 $f_n, f_{n-1}, \ldots, f_{n-k}$ 构造 $k$ 阶牛顿<strong>后插多项式</strong> $N_k(x_n + th)$，$t \in [0,1]$，有：</p>
<p>$$<br>\int_{x_n}^{x_{n+1}} f(x, y(x)) dx &#x3D; \int_0^1 N_k(x_n + th) h , dt + \int_0^1 R_k(x_n + th) h , dt<br>$$</p>
<p>从而得<strong>显式计算公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + h \int_0^1 N_k(x_n + th) , dt<br>$$</p>
<p>局部截断误差为：<br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; h \int_0^1 R_k(x_n + th) , dt<br>$$</p>
<hr>
<p><strong>例：</strong> 当 $k &#x3D; 1$ 时，有<br>$$<br>N_1(x_n + th) &#x3D; f_n + t \nabla f_n &#x3D; f_n + t(f_n - f_{n-1})<br>$$</p>
<p>代入得：<br>$$<br>y_{n+1} &#x3D; y_n + h \int_0^1 [f_n + t(f_n - f_{n-1})] dt &#x3D; y_n + \frac{h}{2} (3f_n - f_{n-1})<br>$$</p>
<p>局部截断误差为：<br>$$<br>T_{n+1} &#x3D; h \int_0^1  \frac{d^2}{dx^2} f(\xi_x, y(\xi_x)) \cdot \frac{1}{2!} th(t+1) h , dt &#x3D; \frac{5}{12} h^3 y’’’(\xi_n)<br>$$</p>
<hr>
<p><strong>注：</strong> 一般有<br>$$<br>T_{n+1} &#x3D; B_k h^{k+2} y^{(k+2)} (\xi_n)<br>$$<br>其中 $B_k$ 与 $y_{n+1}$ 计算公式中的系数 $f_n, f_{n-1}, \dots, f_{n-k}$ 各项的系数均可表示得到。</p>
<table>
<thead>
<tr>
<th>k</th>
<th>$f_n$</th>
<th>$f_{n-1}$</th>
<th>$f_{n-2}$</th>
<th>$f_{n-3}$</th>
<th>…</th>
<th>$B_k$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td>…</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>$\frac{3}{2}$</td>
<td>$-\frac{1}{2}$</td>
<td></td>
<td></td>
<td>…</td>
<td>$\frac{1}{2}$</td>
</tr>
<tr>
<td>2</td>
<td>$\frac{23}{12}$</td>
<td>$-\frac{16}{12}$</td>
<td>$\frac{5}{12}$</td>
<td></td>
<td>…</td>
<td>$\frac{5}{12}$</td>
</tr>
<tr>
<td>3</td>
<td>$\frac{55}{24}$</td>
<td>$-\frac{59}{24}$</td>
<td>$\frac{37}{24}$</td>
<td>$-\frac{9}{24}$</td>
<td>…</td>
<td>$\frac{251}{720}$</td>
</tr>
</tbody></table>
<hr>
<p><strong>常用的</strong> $k &#x3D; 3$ <strong>的 4 阶亚当姆斯显式公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{24} \left( 55 f_n - 59 f_{n-1} + 37 f_{n-2} - 9 f_{n-3} \right)<br>$$<br><strong>常用的</strong> $k &#x3D; 3$ <strong>的 4 阶亚当姆斯隐式公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{24} \left( 9 f_{n+1} + 19 f_n - 5 f_{n-1} + f_{n-2} \right)<br>$$</p>
</article><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/blog/image/sakura.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/03/26/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E6%B1%82%E6%A0%B9/" title="数值分析-非线性方程求根"><img class="cover" src="/blog/image/img3.jpg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">数值分析-非线性方程求根</div></div><div class="info-2"><div class="info-item-1">此文章包含非线性方程组求根部分—————————————————————————————————————————————————————- 第七章 非线性方程求根前言求 f(x) &#x3D; 0 的根  数学物理中的许多问题常常归结为解函数方程 f(x) &#x3D; 0，方程 f(x) &#x3D; 0 的解 x* 称作它的根，或称为 f(x) 的零点。 设函数 f(x) 在 [a,b] 上连续且 f(a)f(b) &lt; 0，根据连续函数的性质可知方程 f(x) &#x3D; 0 在区间 [a,b] 内一定有实根，这时称 (a,b) 为方程 f(x) &#x3D; 0 的有根区间。  二分法 二分法的思想是将有根区间折半进行搜索，即对有根区间 $[a, b]$，取中点 $x_1 &#x3D; \frac{a + b}{2}$ 将它分为两半，检查 $f(a)$ 与 $f(x)$ 是否同号，如果确系同号，说明所求的根在 $[x_1, b]$ ；否则根必在 $[a, x_1]$不管出现哪一种情况，新的有根区间仅为原来的一半。  误差分析 第1步产生的 $x_1 &#x3D;...</div></div></div></a><a class="pagination-related" href="/blog/2025/04/30/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E8%AF%AF%E5%B7%AE/" title="数值分析-误差"><img class="cover" src="/blog/image/2023-10-01-083219.jpg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">数值分析-误差</div></div><div class="info-2"><div class="info-item-1">此文章包含数值分析的误差部分—————————————————————————————————————————————————————————————————- $C^p[a,b]$表示具有$p$阶连续导数的函数空间；$C^0$表述函数连续，没有要求可导 第一章 误差误差的度量方式 设 $x$ 为准确值，$x^* $ 为 $x$ 的一个近似值，称  $$e^* &#x3D; x^* - x$$  为绝对误差，简称为误差。  对于一般情形   $$| x^*  - x | ≤ ε^*$$ $ε^* $为绝对误差限   相对误差的公式表示为：  $$e_r^* &#x3D; \frac{e^* }{x}$$，实际中一般取$$e_r^* &#x3D; \frac{e^* }{x^* }$$  $x$ 的相对误差上限定义为$\varepsilon^* &#x3D; \frac{\varepsilon^* }{|x^* |}$   有效数字有效数字的定义若近似值 $ x^* $ 的误差限是某一位的半个单位，该位到 $ x $ 的第一位非零数字共有 $ n $ 位，则 $ x $ 有 $...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">lian</div><div class="author-info-description">太平山上修真我，祖师堂中续香火</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:2895014608@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">QQ-2895014608</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">第五章 常微分方程数值解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%B0%E5%BF%86%E5%86%85%E5%AE%B9%E6%B1%87%E6%80%BB"><span class="toc-number">1.1.</span> <span class="toc-text">记忆内容汇总</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.2.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E7%AB%8B%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E6%96%B9%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-number">1.3.</span> <span class="toc-text">建立常微分方程数值方法的基本思想</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%82%E8%A7%A3%E5%8C%BA%E9%97%B4%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-number">1.3.1.</span> <span class="toc-text">求解区间离散化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-number">1.3.2.</span> <span class="toc-text">微分方程离散化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AC%A7%E6%8B%89%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.</span> <span class="toc-text">欧拉方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F"><span class="toc-number">1.4.1.</span> <span class="toc-text">欧拉公式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E6%AC%A7%E6%8B%89%E6%B3%95"><span class="toc-number">1.5.</span> <span class="toc-text">隐式欧拉法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BD%A2%E5%85%AC%E5%BC%8F"><span class="toc-number">1.6.</span> <span class="toc-text">梯形公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E6%AD%A5%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F"><span class="toc-number">1.7.</span> <span class="toc-text">两步欧拉公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B%E6%AC%A7%E6%8B%89%E6%B3%95"><span class="toc-number">1.8.</span> <span class="toc-text">改进欧拉法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B1%80%E9%83%A8%E6%88%AA%E6%96%AD%E8%AF%AF%E5%B7%AE%E5%92%8C%E6%96%B9%E6%B3%95%E7%9A%84%E9%98%B6"><span class="toc-number">1.9.</span> <span class="toc-text">局部截断误差和方法的阶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A7%E6%8B%89%E6%B3%95%E7%9A%84%E5%B1%80%E9%83%A8%E6%88%AA%E6%96%AD%E8%AF%AF%E5%B7%AE"><span class="toc-number">1.9.1.</span> <span class="toc-text">欧拉法的局部截断误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E6%AC%A7%E6%8B%89%E6%B3%95%E7%9A%84%E5%B1%80%E9%83%A8%E6%88%AA%E6%96%AD%E8%AF%AF%E5%B7%AE"><span class="toc-number">1.9.2.</span> <span class="toc-text">隐式欧拉法的局部截断误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BD%A2%E5%85%AC%E5%BC%8F%E7%9A%84%E5%B1%80%E9%83%A8%E6%88%AA%E6%96%AD%E8%AF%AF%E5%B7%AE"><span class="toc-number">1.9.3.</span> <span class="toc-text">梯形公式的局部截断误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B%E6%AC%A7%E6%8B%89%E6%B3%95%E7%9A%84%E5%B1%80%E9%83%A8%E6%88%AA%E6%96%AD%E8%AF%AF%E5%B7%AE"><span class="toc-number">1.9.4.</span> <span class="toc-text">改进欧拉法的局部截断误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83%E8%A1%A8"><span class="toc-number">1.9.5.</span> <span class="toc-text">方法比较表</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%BE%99%E6%A0%BC-%E5%BA%93%E5%A1%94%E6%B3%95"><span class="toc-number">1.10.</span> <span class="toc-text">龙格 - 库塔法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BE%99%E6%A0%BC-%E5%BA%93%E5%A1%94%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-number">1.10.1.</span> <span class="toc-text">龙格 - 库塔法的基本思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Runge-Kutta%E6%96%B9%E6%B3%95%E7%9A%84%E4%B8%80%E8%88%AC%E5%BD%A2%E5%BC%8F"><span class="toc-number">1.10.2.</span> <span class="toc-text">Runge-Kutta方法的一般形式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%98%B6%E4%B8%AD%E7%82%B9%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.10.3.</span> <span class="toc-text">二阶中点格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%98%B6%E4%BC%91%E6%81%A9%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.10.4.</span> <span class="toc-text">二阶休恩格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E7%BA%A74%E9%98%B6%E7%BB%8F%E5%85%B8%E9%BE%99%E6%A0%BC-%E5%BA%93%E5%A1%94%E6%B3%95"><span class="toc-number">1.10.5.</span> <span class="toc-text">四级4阶经典龙格-库塔法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%B6%E6%95%9B%E6%80%A7%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7"><span class="toc-number">1.11.</span> <span class="toc-text">收敛性与稳定性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B6%E6%95%9B%E6%80%A7"><span class="toc-number">1.11.1.</span> <span class="toc-text">收敛性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%B3%E5%AE%9A%E6%80%A7"><span class="toc-number">1.11.2.</span> <span class="toc-text">稳定性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AC%A7%E6%8B%89%E6%B3%95"><span class="toc-number">1.11.2.1.</span> <span class="toc-text">欧拉法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E6%AC%A7%E6%8B%89%E6%B3%95-1"><span class="toc-number">1.11.2.2.</span> <span class="toc-text">隐式欧拉法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B%E6%AC%A7%E6%8B%89%E6%B3%95-1"><span class="toc-number">1.11.2.3.</span> <span class="toc-text">改进欧拉法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A2%AF%E5%BD%A2%E6%96%B9%E6%B3%95"><span class="toc-number">1.11.2.4.</span> <span class="toc-text">梯形方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E9%98%B6%E3%80%81%E5%9B%9B%E9%98%B6-R-K-%E6%B3%95"><span class="toc-number">1.11.2.5.</span> <span class="toc-text">三阶、四阶 $R-K$ 法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%AD%E7%82%B9%E5%85%AC%E5%BC%8F"><span class="toc-number">1.11.2.6.</span> <span class="toc-text">中点公式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E9%A2%98"><span class="toc-number">1.11.2.7.</span> <span class="toc-text">例题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%A4%9A%E6%AD%A5%E6%B3%95"><span class="toc-number">1.12.</span> <span class="toc-text">线性多步法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86%E7%9A%84%E6%9E%84%E9%80%A0%E6%B3%95"><span class="toc-number">1.12.1.</span> <span class="toc-text">基于数值积分的构造法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%9A%E5%BD%93%E5%A7%86%E6%96%AF%E6%98%BE%E5%BC%8F%E5%85%AC%E5%BC%8F"><span class="toc-number">1.12.2.</span> <span class="toc-text">亚当姆斯显式公式</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blog/2025/06/06/%E6%AD%A4%E6%96%87%E7%AB%A0%E5%8C%85%E5%90%AB%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E8%A7%A3%E6%B3%95%E9%83%A8%E5%88%86----------------------------------------------------------------------------------------------------------9LTL8JYF/" title="无标题">无标题</a><time datetime="2025-06-06T10:39:14.687Z" title="发表于 2025-06-06 18:39:14">2025-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/05/15/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" title="数值分析-函数逼近"><img src="/blog/image/20250505084722.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="数值分析-函数逼近"/></a><div class="content"><a class="title" href="/blog/2025/05/15/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/" title="数值分析-函数逼近">数值分析-函数逼近</a><time datetime="2025-05-15T07:37:45.000Z" title="发表于 2025-05-15 15:37:45">2025-05-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/05/12/%E6%9C%BA%E7%94%B5%E4%B8%80%E4%BD%93%E5%8C%96%E5%88%86%E6%9E%90%E4%B8%8E%E5%BB%BA%E6%A8%A1%EF%BC%88%E9%95%BF%E6%98%A5%E5%85%89%E6%9C%BA%E6%89%80%EF%BC%89/" title="机电一体化分析与建模（长春光机所）"><img src="/blog/image/20250505084723-2.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="机电一体化分析与建模（长春光机所）"/></a><div class="content"><a class="title" href="/blog/2025/05/12/%E6%9C%BA%E7%94%B5%E4%B8%80%E4%BD%93%E5%8C%96%E5%88%86%E6%9E%90%E4%B8%8E%E5%BB%BA%E6%A8%A1%EF%BC%88%E9%95%BF%E6%98%A5%E5%85%89%E6%9C%BA%E6%89%80%EF%BC%89/" title="机电一体化分析与建模（长春光机所）">机电一体化分析与建模（长春光机所）</a><time datetime="2025-05-12T11:27:23.000Z" title="发表于 2025-05-12 19:27:23">2025-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/05/08/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E6%8F%92%E5%80%BC%E6%B3%95/" title="数值分析-插值法"><img src="/blog/image/hgud.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="数值分析-插值法"/></a><div class="content"><a class="title" href="/blog/2025/05/08/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E6%8F%92%E5%80%BC%E6%B3%95/" title="数值分析-插值法">数值分析-插值法</a><time datetime="2025-05-08T00:50:35.000Z" title="发表于 2025-05-08 08:50:35">2025-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/04/30/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E8%AF%AF%E5%B7%AE/" title="数值分析-误差"><img src="/blog/image/2023-10-01-083219.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="数值分析-误差"/></a><div class="content"><a class="title" href="/blog/2025/04/30/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E8%AF%AF%E5%B7%AE/" title="数值分析-误差">数值分析-误差</a><time datetime="2025-04-30T01:42:45.000Z" title="发表于 2025-04-30 09:42:45">2025-04-30</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 By lian</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">岁岁平，岁岁安，岁岁平安</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="{&quot;site_uv&quot;:true,&quot;site_pv&quot;:true,&quot;page_pv&quot;:true}"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>