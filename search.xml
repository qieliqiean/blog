<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>A Review of Optical and SAR Image Deep Feature Fusion in Semantic Segmentation</title>
    <url>/blog/2025/08/27/A-Review-of-Optical-and-SAR-Image-Deep-Feature-Fusion-in-Semantic-Segmentation/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>好的，同学们，请坐。今天我们要一起深入探讨一篇非常有价值的综述性文献：《A Review of Optical and SAR Image Deep Feature Fusion in Semantic Segmentation》，即《光学与SAR影像在语义分割中的深度特征融合综述》。</p>
<p>我知道大家可能对遥感、合成孔径雷达（SAR）或者深度学习这些领域不甚了解，但这没关系。我会像上课一样，一步步地为大家拆解这篇文章的每一个概念、每一个细节。请随时在脑海里记下问题，我们争取在讲解结束时，让大家对这个领域有一个清晰、全面的认识。</p>
<hr>
<h3 id="第一部分：文献概述与核心概念解读-引言-Introduction"><a href="#第一部分：文献概述与核心概念解读-引言-Introduction" class="headerlink" title="第一部分：文献概述与核心概念解读 (引言 Introduction)"></a><strong>第一部分：文献概述与核心概念解读 (引言 Introduction)</strong></h3><p>首先，我们来看标题。这篇论文的标题就包含了它的核心内容，我们来逐个剖析：</p>
<ol>
<li><p><strong>语义分割 (Semantic Segmentation)</strong>：这是我们的<strong>目标任务</strong>。想象一下你有一张航拍照片，语义分割就是要给这张照片里的<strong>每一个像素</strong>都打上一个标签。比如，这个像素是“建筑”，那个像素是“水体”，旁边的像素是“植被”。它不像目标检测那样只画一个框框住一栋楼，而是要精确到像素级别，把楼的轮廓完整地描绘出来。这在城市规划、土地资源管理、灾害监测等领域至关重要。你看论文中的 <strong>图1 (Fig. 1)</strong>，就展示了语义分割的几个主要应用方向，其中土地利用&#x2F;土地覆盖（LULC）分类占了半壁江山。</p>
</li>
<li><p><strong>光学影像 (Optical Images)</strong>：这是我们最熟悉的<strong>数据源之一</strong>。它就像我们手机或数码相机拍出的照片，记录的是地物反射的可见光和红外光。它的<strong>优点</strong>是信息丰富、色彩鲜艳、纹理清晰，非常直观。但<strong>缺点</strong>也很致命：它依赖太阳光，所以晚上无法成像；更重要的是，它穿不透云、雾、霾，天气不好就“抓瞎”。</p>
</li>
<li><p><strong>SAR影像 (Synthetic Aperture Radar Images)</strong>：这是另一种关键的<strong>数据源</strong>。SAR是一种<strong>主动式</strong>的微波雷达。所谓“主动”，就是它自己发射电磁波，然后接收地物反射回来的回波来成像，就像蝙蝠的声纳系统。这赋予了它两大<strong>优点</strong>：</p>
<ul>
<li><strong>全天时全天候</strong>：不依赖太阳光，白天黑夜都能工作；微波能穿透云雾，不受天气影响。</li>
<li><strong>对结构敏感</strong>：它对地物的几何结构、材质、粗糙度非常敏感。比如，金属建筑的回波会非常强。<br>它的<strong>缺点</strong>是图像不直观，看起来是灰度的，而且充满了“相干斑噪声”（speckle noise），就像电视雪花点一样，信噪比低。</li>
</ul>
<p>大家可以看 <strong>图2 (Fig. 2)</strong>，左边是光学影像，右边是同一地点的SAR影像。能明显看出它们的成像机理和视觉表现完全不同。</p>
</li>
<li><p><strong>深度特征融合 (Deep Feature Fusion)</strong>：这是本文探讨的<strong>核心技术</strong>。既然光学和SAR影像各有优劣，那么把它们的信息结合起来，不就能取长补短，得到更准确的结果吗？这就是“融合”的目的。而“深度特征”指的是我们不直接融合原始的像素，而是利用<strong>深度学习</strong>（特别是卷积神经网络CNN）来分别从两种影像中提取出更高级、更抽象的特征信息（比如建筑的边缘、植被的纹理），然后再对这些“特征”进行融合。</p>
</li>
</ol>
<p>所以，这篇论文要解决的核心问题是：<strong>如何最有效地利用深度学习技术，将光学影像和SAR影像的优势特征结合起来，以实现更精准的遥感影像语义分割。</strong></p>
<p>这篇论文是一篇<strong>综述 (Review)</strong>，意味着它的目的不是提出一个全新的方法，而是系统地梳理、总结和评价该领域现有的研究成果，指出当前的挑战，并展望未来的发展方向。这对于我们初学者来说，是进入一个领域的绝佳向导。</p>
<hr>
<h3 id="第二部分：遥感影像语义分割的方法演进-Section-II"><a href="#第二部分：遥感影像语义分割的方法演进-Section-II" class="headerlink" title="第二部分：遥感影像语义分割的方法演进 (Section II)"></a><strong>第二部分：遥感影像语义分割的方法演进 (Section II)</strong></h3><p>在讨论“融合”之前，我们得先了解“分割”本身是怎么做的。作者首先回顾了遥感影像语义分割技术的发展。</p>
<ol>
<li><p><strong>传统方法</strong>：在深度学习兴起之前，研究者们需要手动设计特征，比如纹理特征、光谱特征、形状特征等，然后用支持向量机（SVM）、随机森林等传统机器学习方法进行分类。这种方法非常依赖专家的经验，耗时耗力，而且设计的特征泛化能力差。</p>
</li>
<li><p><strong>基于深度学习的方法</strong>：随着数据量的增大和计算能力的提升，深度学习成为了主流。文章介绍了几个关键的架构：</p>
<ul>
<li><strong>CNN (卷积神经网络)</strong>：早期的应用是采用“滑窗法”（见 <strong>图6</strong>）。就是用一个小窗口在图像上滑动，每次对窗口内的图像块进行分类，判断中心像素属于哪一类。这种方法效率低下，且会丢失像素间的空间关联信息。</li>
<li><strong>FCN (全卷积网络)</strong>：这是一个里程碑式的进步（见 <strong>图7</strong>）。FCN将传统CNN最后的“全连接层”换成了“卷积层”，实现了从输入一张完整图像到输出一张同样大小的分割图的“端到端”处理。它经典的“编码器-解码器”（Encoder-Decoder）结构，先通过编码器（卷积和池化）不断压缩图像，提取高级语义特征；再通过解码器（上采样和反卷积）逐步恢复图像尺寸，实现像素级的定位。像U-Net、DeepLab都是这个思想的优秀代表。</li>
<li><strong>RNN (循环神经网络)</strong>：RNN擅长处理序列数据。在遥感领域，这通常指<strong>时间序列</strong>影像，比如对同一个地方连续拍摄一年的影像来监测作物生长周期。RNN（特别是其变种LSTM）能有效地捕捉这种时间维度上的变化信息（见 <strong>图8</strong>）。</li>
<li><strong>其他新模型（Transformer, Mamba等）</strong>：近年来，源于自然语言处理领域的Transformer模型也被引入了计算机视觉。它通过“自注意力机制”能更好地捕捉图像中的长距离依赖关系。Mamba则是更新的架构，试图在保持长距离建模能力的同时降低计算复杂度。这些模型虽然强大，但它们本身并不能解决单一数据源（比如只有光学影像）的固有缺陷。</li>
</ul>
</li>
</ol>
<p><strong>小结</strong>：这一部分告诉我们，深度学习方法，特别是FCN架构，是当前语义分割的主流。但无论模型设计得多么精巧，如果只用单一类型的数据，总会遇到瓶颈。比如，光学影像会因为云雾或阴影导致分割错误，而SAR影像则可能因为噪声干扰而边界模糊。这就自然而然地引出了“融合”的必要性。</p>
<hr>
<h3 id="第三部分：影像融合的三种策略-Section-III"><a href="#第三部分：影像融合的三种策略-Section-III" class="headerlink" title="第三部分：影像融合的三种策略 (Section III)"></a><strong>第三部分：影像融合的三种策略 (Section III)</strong></h3><p>好，既然要融合，具体该怎么做呢？作者总结了三种不同层次的融合策略。大家可以参考 <strong>表一 (Table I)</strong> 和 <strong>图9、10、11</strong>。</p>
<ol>
<li><p><strong>像素级融合 (Pixel-level Fusion &#x2F; Early Fusion)</strong>：这是最直接的融合方式（见 <strong>图9</strong>）。在输入网络<strong>之前</strong>，就将配准好的光学和SAR影像在像素层面进行合并，比如将SAR影像作为一个额外的通道疊加到光学影像上，然后一起送入一个深度学习网络。</p>
<ul>
<li><strong>优点</strong>：最大限度地保留了原始信息。</li>
<li><strong>缺点</strong>：对影像的配准精度要求极高；两种影像的物理意义和数据分布差异巨大，强行“捆绑”在一起，可能会让网络难以学习，甚至相互干扰。</li>
</ul>
</li>
<li><p><strong>决策级融合 (Decision-level Fusion &#x2F; Late Fusion)</strong>：这是最末端的融合（见 <strong>图10</strong>）。我们分别用两个独立的网络处理光学和SAR影像，各自得到一个初步的分割结果（决策），最后再用某种规则（如投票、加权平均等）将这两个结果融合，得到最终的分割图。</p>
<ul>
<li><strong>优点</strong>：对配准要求低，实现简单，容错性好。</li>
<li><strong>缺点</strong>：信息损失严重。因为两个网络在中间过程完全没有交流，很多有价值的中间特征都被丢弃了，只融合了最终的“粗糙”结果，无法实现深层次的互补。</li>
</ul>
</li>
<li><p><strong>特征级融合 (Feature-level Fusion &#x2F; Intermediate Fusion)</strong>：这是目前研究的<strong>重点和主流</strong>（见 <strong>图11</strong>）。采用双分支（或多分支）网络结构，一个分支处理光学影像，另一个处理SAR影像。网络在中间的某几层将两个分支提取出的<strong>特征图 (feature maps)</strong> 进行融合，然后继续后续的处理。</p>
<ul>
<li><strong>优点</strong>：这是像素级和决策级融合的折中。它既避免了在原始数据层面的直接冲突，又能在抽象的特征层面进行深度交互，让网络学习到两种数据如何互补。</li>
<li><strong>缺点</strong>：融合模块的设计更复杂，需要仔细考虑在哪个阶段融合、以及如何融合。</li>
</ul>
</li>
</ol>
<p>这篇文章的<strong>核心</strong>，正是围绕着第三种策略——<strong>特征级融合</strong>展开的。</p>
<hr>
<h3 id="第四部分：光学与SAR特征级融合的核心技术-Section-IV"><a href="#第四部分：光学与SAR特征级融合的核心技术-Section-IV" class="headerlink" title="第四部分：光学与SAR特征级融合的核心技术 (Section IV)"></a><strong>第四部分：光学与SAR特征级融合的核心技术 (Section IV)</strong></h3><p>这是本文最精华的部分。作者将特征级融合的方法，根据其融合模块的设计思路，分成了四大类。我们可以结合 <strong>表二 (Table II)</strong> 和后面的大量图示来理解。</p>
<p>在介绍这些策略前，要明确一个前提：大部分方法都采用<strong>双分支网络</strong>，即一个分支提光学特征，一个分支提SAR特征，然后在中间用下面这些“花式”模块进行融合。</p>
<ol>
<li><p><strong>线性融合策略 (Linear Fusion Strategy)</strong>：这是最基础的融合方法。</p>
<ul>
<li><strong>特征拼接 (Concatenation)</strong>：见 <strong>图12</strong>。将两个分支的特征图在通道维度上直接堆叠起来。比如，光学特征图有64个通道，SAR特征图也有64个通道，拼接后就得到一个128通道的新特征图。</li>
<li><strong>特征求和 (Summation)</strong>：见 <strong>图13</strong>。将两个特征图对应元素相加。这要求它们的通道数相同。</li>
<li><strong>特征点积 (Dot Product)</strong>：见 <strong>图14</strong>。对应元素相乘。<br><strong>评价</strong>：简单粗暴，易于实现。但缺点是它平等地对待所有特征，没有区分哪些特征更重要，也无法进行复杂的信息交互。</li>
</ul>
</li>
<li><p><strong>基于注意力的融合策略 (Attention-based Fusion Strategy)</strong>：这是目前非常流行的方法。其核心思想是模仿人类的视觉注意力机制，让网络<strong>学会关注重要的信息，抑制无关的信息</strong>。</p>
<ul>
<li><strong>通道注意力 (Channel Attention)</strong>：见 <strong>图15</strong>。它学习每个特征<strong>通道</strong>的重要性。比如，对于识别植被，光学影像的“近红外”通道可能比SAR的某个通道更重要，那么网络就给“近红外”通道分配更高的权重。</li>
<li><strong>空间注意力 (Spatial Attention)</strong>：见 <strong>图16</strong>。它学习特征图上<strong>不同空间位置</strong>的重要性。比如，在分割建筑时，网络应该更关注那些有明显边缘轮廓的区域。</li>
<li><strong>混合注意力 (Mixed Attention)</strong>：见 <strong>图17</strong>。将通道和空间注意力结合起来，效果更好。</li>
<li><strong>自注意力 (Self-Attention)</strong>：见 <strong>图21</strong>。不仅关注局部，还能建立图像中任意两个像素之间的关系，捕捉长距离依赖。<br><strong>评价</strong>：注意力机制能让融合过程变得更“智能”，动态地调整不同模态、不同特征的权重，极大地提升了融合效果。</li>
</ul>
</li>
<li><p><strong>基于门控的融合策略 (Gate-based Fusion Strategy)</strong>：这个策略可以理解为设置一个“信息阀门”或“门卫”。网络学习一个“门控单元”（gate），来控制来自不同分支的信息流。</p>
<ul>
<li><strong>独立门 (Independent Gate)</strong>：见 <strong>图22</strong>。为光学和SAR特征分别设置独立的门，各自控制流量。</li>
<li><strong>互补门 (Complementary Gate)</strong>：见 <strong>图23, 25, 26</strong>。只学习一个门控信号G（值在0-1之间）。光学特征乘以G，SAR特征则乘以(1-G)。这样一来，两者就有了此消彼长的互补关系。</li>
<li><strong>交互门 (Interactive Gate)</strong>：见 <strong>图24</strong>。这是最复杂的。光学特征的“阀门”由SAR特征来决定，反之亦然。实现了深度的信息交互。<br><strong>评价</strong>：门控机制能非常灵活地筛选和加权特征，过滤掉冗余或噪声信息，保留最有用的互补特征。</li>
</ul>
</li>
<li><p><strong>特征对齐策略 (Feature Alignment Strategy)</strong>：这个策略直面一个根本问题：光学和SAR的成像机理差异太大，导致它们提取出的特征分布在完全不同的“特征空间”里，好比一个说中文，一个说英文，直接融合会“鸡同鸭讲”。</p>
<ul>
<li><strong>思路</strong>：在融合之前，先通过某种变换，将两种特征“翻译”到一个<strong>共同的、对齐的特征空间</strong>中（见 <strong>图27</strong>），让它们的语义能够对应上，然后再进行融合。<br><strong>评价</strong>：这个策略从根本上解决了异质性（heterogeneity）带来的问题，能有效提升分割精度，尤其是在边界和细节上。</li>
</ul>
</li>
</ol>
<p><strong>小结</strong>：第四部分是技术的“军火库”。从简单的线性叠加，到智能的注意力加权，再到精细的门控筛选和根本的特征对齐，研究者们设计了各种巧妙的模块来解决特征融合的难题。在实际应用中，这些策略也常常被组合使用。</p>
<hr>
<h3 id="第五、六部分：实践基础——数据集与评价指标"><a href="#第五、六部分：实践基础——数据集与评价指标" class="headerlink" title="第五、六部分：实践基础——数据集与评价指标"></a><strong>第五、六部分：实践基础——数据集与评价指标</strong></h3><ol>
<li><p><strong>数据集 (Datasets, Section V)</strong>：工欲善其事，必先利其器。深度学习是数据驱动的，没有好的数据集，再好的模型也只是空中楼阁。作者在 <strong>表三 (Table III)</strong> 中为我们整理了当前公开可用的、同时包含光学和SAR影像的语义分割数据集。</p>
<ul>
<li><strong>核心痛点</strong>：作者指出，目前该领域<strong>严重缺乏大规模、高分辨率、像素级精准配准</strong>的基准数据集。这是制约领域发展的一大瓶颈。现有数据集要么分辨率不够高，要么覆盖范围小，要么类别不够丰富。</li>
</ul>
</li>
<li><p><strong>评价指标 (Evaluation Indicators, Section VI)</strong>：我们怎么评价一个分割模型的好坏呢？作者介绍了几个常用的指标：</p>
<ul>
<li><strong>PA (Pixel Accuracy)</strong>：像素精度。就是被正确分类的像素占总像素的比例。简单直观，但当类别不均衡时（比如背景像素远多于目标像素），这个指标会产生误导。</li>
<li><strong>MPA (Mean Pixel Accuracy)</strong>：平均像素精度。计算每个类别的像素精度，然后取平均。比PA更公平。</li>
<li><strong>IoU (Intersection over Union)</strong>：交并比。这是语义分割中<strong>最核心、最常用</strong>的指标。它衡量的是预测结果与真实标签之间的重合程度，计算公式是 <code>(预测区域 ∩ 真实区域) / (预测区域 ∪ 真实区域)</code>。值越接近1，说明分割得越好。</li>
<li><strong>MIoU (Mean IoU)</strong>：平均交并比。计算每个类别的IoU，然后取平均。这是评价模型整体性能的黄金标准。</li>
<li><strong>计算复杂度</strong>：除了精度，模型的运行速度（FLOPs）和内存占用（参数量）也是实际应用中需要考虑的重要因素。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="第七、八部分：挑战、未来方向与总结"><a href="#第七、八部分：挑战、未来方向与总结" class="headerlink" title="第七、八部分：挑战、未来方向与总结"></a><strong>第七、八部分：挑战、未来方向与总结</strong></h3><p>最后，作为一篇优秀的综述，作者高屋建瓴地指出了当前面临的挑战和未来的研究方向。</p>
<ol>
<li><p><strong>主要挑战 (Challenges)</strong>：</p>
<ul>
<li><strong>特征贡献度分配难题</strong>：对于不同的地物类别，光学和SAR的贡献度应该是不同的。比如，识别植被，光学数据更重要；而识别建筑轮廓，SAR数据可能更有用。如何让模型<strong>动态地、自适应地</strong>为不同类别分配不同模态的权重，是一个核心挑战。</li>
<li><strong>数据需求挑战</strong>：前面提到的，缺乏高质量的基准数据集。这不仅阻碍了新算法的公平比较，也限制了模型的性能上限。</li>
</ul>
</li>
<li><p><strong>未来方向 (Future Directions)</strong>：</p>
<ul>
<li><strong>动态特征贡献度分配</strong>：设计更智能的网络，能学习到模态与类别之间的复杂关系。</li>
<li><strong>构建大规模基准数据集</strong>：这是整个社区的共同呼声，需要有组织地去采集、标注和发布。</li>
<li><strong>小样本&#x2F;低质量数据下的融合</strong>：在现实中，我们可能只有少量标注数据或质量不佳的数据，如何在这种情况下做好融合，是一个很有价值的研究方向（例如，利用无监督或自监督学习）。</li>
<li><strong>基于大模型的融合研究</strong>：随着“基础模型”（Foundation Model）的兴起，如何利用这些预训练好的大模型来增强多模态信息的融合能力，是一个前沿热点。</li>
</ul>
</li>
<li><p><strong>总结 (Conclusion)</strong>：文章最后总结，深度学习极大地推动了遥感语义分割的发展。光学与SAR影像的互补性使其融合成为研究热点。本文系统地回顾了从分割方法到融合策略的技术演进，特别是详细梳理了各种特征级融合模块的设计思路，为研究者和从业者提供了一个全面的技术概览和清晰的未来路线图。</p>
</li>
</ol>
<hr>
<p>好了，同学们，以上就是我对这篇综述文献的详细讲解。希望通过这次“课程”，大家不仅理解了这篇论文的内容，也对“光学与SAR影像融合”这个研究领域建立起了一个宏观的认知框架。我们看到了这个领域的巨大潜力和价值，也认识到了它所面临的挑战。这正是一个充满机遇的研究方向。</p>
<p>大家有什么问题吗？</p>
<hr>
<h1 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h1><ul>
<li><strong>语义分割（Semantic Segmentation）</strong>：计算机视觉与遥感领域的核心任务之一，核心是为图像中的每个像素分配对应的语义类别标签（如 “农田”“建筑”“水体” 等），实现从 “图像” 到 “语义信息” 的转化。</li>
<li><strong>配准 (Co-registration)</strong> 指的是将来自不同传感器、在不同时间拍摄的关于同一区域的图像，进行几何上的对齐，使得图像中同一个地物在所有图像上的像素坐标都是一致的。</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>DeViSE: A Deep Visual-Semantic Embedding Model</title>
    <url>/blog/2025/10/17/DeViSE-A-Deep-Visual-Semantic-Embedding-Model/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>好的，接下来我将以<strong>教授讲授研究生课程</strong>的口吻，系统、深入地为你讲解这篇经典论文——<br> <strong>Frome et al., “DeViSE: A Deep Visual-Semantic Embedding Model” (NIPS 2013)</strong>。<br> 我会假设你此前对计算机视觉与深度学习领域尚不熟悉，因此讲解会从背景原理讲起，一步步解析论文的设计思路、技术实现、实验方法和学术意义。</p>
<hr>
<h2 id="一、研究背景与问题提出"><a href="#一、研究背景与问题提出" class="headerlink" title="一、研究背景与问题提出"></a>一、研究背景与问题提出</h2><p>在 2013 年以前，主流的视觉识别方法主要是基于深度卷积神经网络（CNN）的分类模型。例如 Krizhevsky 等人在同年提出的 <strong>AlexNet</strong>，在 ImageNet 图像识别比赛中大获成功。<br> 这类模型通常在一个固定的、离散的标签集合上训练（如 1000 个类别），并使用一个 softmax 输出层对每张图片进行分类。</p>
<p>然而，这种传统方法有两大局限性：</p>
<ol>
<li><strong>扩展性差（Scalability）</strong>：<br> 随着类别数量的增加（例如从 1000 增加到 20,000），需要的标注图像数量呈指数级增长，获取代价极高。</li>
<li><strong>语义隔离（Semantic Isolation）</strong>：<br> 模型将每个标签视为互不相关的离散项（one-hot 向量），无法理解“狗”和“狼”之间的语义相似性，也无法将已学知识迁移到未见过的新类别。</li>
</ol>
<p>Frome 等人提出的 <strong>DeViSE 模型（Deep Visual-Semantic Embedding）</strong>，旨在突破这一局限。<br> 他们提出让<strong>图像特征空间</strong>与**语义空间（来自文本）**建立直接联系，从而实现两大目标：</p>
<ul>
<li><strong>语义合理的错误</strong>（Semantic errors）：模型即便识别错，也错得“有道理”。</li>
<li><strong>零样本学习（Zero-shot learning）</strong>：模型能识别从未见过类别的图像。</li>
</ul>
<hr>
<h2 id="二、核心思想：视觉–语义联合嵌入（Visual-Semantic-Embedding）"><a href="#二、核心思想：视觉–语义联合嵌入（Visual-Semantic-Embedding）" class="headerlink" title="二、核心思想：视觉–语义联合嵌入（Visual-Semantic Embedding）"></a>二、核心思想：视觉–语义联合嵌入（Visual-Semantic Embedding）</h2><p>DeViSE 的核心思想是：</p>
<blockquote>
<p>将图像与文字标签映射到同一个连续的向量空间中，使得相似的图像和语义上相似的标签在空间中距离更近。</p>
</blockquote>
<p>也就是说，它不是直接预测一个类别，而是学习一个<strong>映射函数</strong>：<br>$$<br>f_{image}: \text{Image} \rightarrow \mathbb{R}^d<br>$$</p>
<p>$$<br>f_{text}: \text{Label} \rightarrow \mathbb{R}^d<br>$$</p>
<p>最终，给定一张图片，模型输出的向量应尽量与正确标签的语义向量接近。</p>
<hr>
<h2 id="三、模型总体结构"><a href="#三、模型总体结构" class="headerlink" title="三、模型总体结构"></a>三、模型总体结构</h2><p>论文在**图 1（第 3 页）**中给出了总体结构图，可分为三部分：</p>
<ol>
<li><p><strong>语言模型（Language Model）</strong><br> 使用 <em>skip-gram</em>（word2vec）模型，将文字标签映射为稠密的向量表示。</p>
<ul>
<li>训练语料：维基百科（5.7 百万篇文章，5.4 十亿词）。</li>
<li>词汇量：约 155,000 个单词和短语。</li>
<li>向量维度：500 或 1000 维。</li>
<li>相似词测试表明嵌入质量很好，例如 <em>tiger shark</em> 的近邻包括 <em>bull shark, blue shark, great white shark</em> 等。</li>
</ul>
</li>
<li><p><strong>视觉模型（Visual Model）</strong><br> 基于当年 ImageNet 竞赛的冠军模型（即 AlexNet 架构），包括卷积层、归一化层、池化层和全连接层。<br> 最初训练目标是传统的 1000 类 softmax 分类。</p>
</li>
<li><p><strong>联合嵌入模型（Joint Embedding Model）</strong><br> 将上述两个模型结合：</p>
<ul>
<li>移除视觉模型的 softmax 层；</li>
<li>添加一个线性投影层，将视觉特征（4096 维）映射到语义空间（500 或 1000 维）；</li>
<li>训练目标是让图像输出向量与正确标签的词向量尽可能接近。</li>
</ul>
<blockquote>
<p>下面把这张配图<strong>逐块</strong>讲清楚（它对应论文的 <em>Figure 1</em>，位于第 3 页）。</p>
<p><img src="/blog/./image/Snipaste_2025-10-17_14-31-11.png"></p>
</blockquote>
<blockquote>
<p>A 图（左半部分）：三种网络在一个框图里</p>
<ol>
<li>左：<strong>Traditional Visual Model（传统视觉模型）</strong></li>
</ol>
<ul>
<li><strong>输入</strong>：image（图像）。</li>
<li><strong>主干</strong>：紫色方块 <em>core visual model</em>（卷积+池化+全连接的 CNN 主干，AlexNet 一类架构）。</li>
<li><strong>输出</strong>：顶端接一个 <em>softmax layer</em>（1000 类分类头），直接输出最可能的类别 id。</li>
<li><strong>含义</strong>：这就是当时的标准做法——在固定、离散的 1-of-N 标签集合上做分类。</li>
</ul>
<ol start="2">
<li>中：<strong>Deep Visual Semantic Embedding Model（DeViSE 联合嵌入模型）</strong></li>
</ol>
<ul>
<li><strong>输入</strong>：同样是图像。</li>
<li><strong>主干</strong>：同一个 <em>core visual model</em>（与左侧相同的 CNN 主干）。</li>
<li><strong>变换层</strong>：在主干顶层接一个 <em>transformation</em>（线性投影层），把 4096 维视觉特征映射到<strong>语义空间</strong>（500&#x2F;1000 维）。</li>
<li><strong>语义库</strong>：右侧灰色方块 <em>embedding vector lookup table</em> 存放<strong>每个文字标签</strong>的词向量（来自语言模型）。</li>
<li><strong>相似度</strong>：顶部 <em>similarity metric</em> 表示用<strong>点积&#x2F;余弦</strong>等度量图像向量与<strong>正确标签</strong>词向量的接近程度；训练时用<strong>排序（hinge rank）损失</strong>，让“正确标签的相似度”比“任一负样本标签的相似度”高出一个边界（margin）。</li>
<li><strong>参数初始化箭头（parameter initialization）</strong>：从左边传统视觉模型把主干参数迁移过来；从右边语言模型把<strong>词向量表</strong>迁移过来。DeViSE 以这两者为<strong>初始化</strong>再进行联合训练（先训投影层，再微调视觉主干）。</li>
</ul>
<blockquote>
<p>直观理解：DeViSE 不再直接“选一个类”，而是把图像<strong>投到语义空间</strong>，去“找最相近的词向量”。这使得它能对<strong>未见过的类别</strong>做出合理预测（零样本），并在出错时更“语义接近”。</p>
</blockquote>
<ol start="3">
<li>右：<strong>Skip-gram Language Model（skip-gram 语言模型）</strong></li>
</ol>
<ul>
<li><strong>输入&#x2F;输出</strong>：底部 <em>source word</em>（中心词）→ 顶部 <em>nearby word</em>（上下文词），通过一个 <em>softmax layer</em> 预测“邻近词”。</li>
<li><strong>中间</strong>：灰色方块 <em>embedding vector lookup table</em>，即<strong>词向量表</strong>（把词映成稠密向量）。</li>
<li><strong>作用</strong>：在海量未标注文本上学到<strong>语义结构</strong>（语义近的词向量更相近），然后把这张向量表提供给中间的 DeViSE 模型使用。</li>
</ul>
<blockquote>
<p>论文里具体做法是：用 Wikipedia 语料训练 skip-gram，得到 500&#x2F;1000 维词向量；DeViSE 再把视觉特征投到这个空间里，用排序损失贴近“正确标签”的词向量。</p>
</blockquote>
<hr>
<p>B 图（右半部分）：t-SNE 可视化的一团“语义星系”</p>
<ul>
<li>右边大散点图是把<strong>ImageNet 1K 标签的词向量</strong>（由 skip-gram 学到）用 <strong>t-SNE</strong> 降到 2D 的可视化。</li>
<li><strong>颜色与图例</strong>：右下角的图例列出了若干<strong>语义簇</strong>（比如 <em>reptiles</em> 爬行动物、<em>birds</em> 鸟类、<em>musical instruments</em> 乐器、<em>aquatic life</em> 水生生物、<em>insects</em> 昆虫、<em>clothing</em> 服饰、<em>animals</em> 动物、<em>food</em> 食物、<em>dogs</em> 犬类、<em>transportation</em> 交通工具）。你能看到这些类别在 2D 空间里形成<strong>清晰的簇团</strong>——这说明语言模型的词向量<strong>天然带有语义结构</strong>：语义相近的标签靠得更近。</li>
<li><strong>意义</strong>：DeViSE 正是把图像<strong>映射到这张“语义地图”上</strong>。因此，当它遇到训练中<strong>从未见过</strong>的标签时，仍可根据“图像向量与哪个标签簇更近”去做<strong>零样本推断</strong>；同时，即便预测错，也更可能错在“邻近概念”上（例如把“海豚”错成“鲸”，而不是“茶壶”）。</li>
</ul>
<hr>
<p><u>一图读懂的因果链</u></p>
<ol>
<li><strong>skip-gram</strong> 从文本里学到“语义地图”（词向量表）。</li>
<li><strong>CNN 主干</strong> 从图像里学到“视觉表征”。</li>
<li><strong>DeViSE</strong> 用一层线性投影把“视觉表征”送进“语义地图”，并用<strong>排序损失</strong>把“正确标签”拉近、“错误标签”推远。<br>→ 效果：<strong>与 softmax 持平的 Top-k 准确率</strong>，但<strong>语义更合理</strong>；并且具备<strong>零样本识别</strong>能力。</li>
</ol>
<blockquote>
<p>这张图因此把论文的三件事同时讲清楚：传统视觉分类、语言侧的语义学习、以及二者如何在 DeViSE 中“对齐”为同一个嵌入空间（加上参数迁移的来龙去脉）。</p>
</blockquote>
</blockquote>
</li>
</ol>
<hr>
<h2 id="四、损失函数设计：排序损失（Ranking-Loss）"><a href="#四、损失函数设计：排序损失（Ranking-Loss）" class="headerlink" title="四、损失函数设计：排序损失（Ranking Loss）"></a>四、损失函数设计：排序损失（Ranking Loss）</h2><p>DeViSE 的关键创新之一是<strong>损失函数的选择</strong>。</p>
<p>作者使用了一个<strong>基于点积的 Hinge Rank Loss</strong>：<br>$$<br>loss(image,label)&#x3D; \sum_{j \neq l a b e l}  \max (0,  margin - \vec{t}<em>{label} M  \vec{v}(image)+ \vec{t}</em>{j} M \vec{v}(image))<br>$$</p>
<ol>
<li>为何要这样设计损失</li>
</ol>
<ul>
<li><p>目标是让<strong>图像向量</strong>和<strong>正确标签的词向量</strong>之间的<strong>相似度更高</strong>，且要<strong>高过所有错误标签</strong>的相似度一个固定的“安全边际”（margin）。</p>
</li>
<li><p>作者选择了<strong>点积相似度 + 排序（hinge rank）损失</strong>，而不是把图像向量直接回归到标签向量的 <strong>L2 损失</strong>；因为<strong>检索&#x2F;最近邻判别</strong>本质是<strong>排序问题</strong>，排序损失能直接优化“正确 &gt; 错误”的相对关系，实验证明它比 L2 准确率高出约一倍。</p>
<ol start="2">
<li>数学定义</li>
</ol>
<p>$$<br>\text { loss }(\text { image }, \text { label })&#x3D;\sum_{j \neq l a b e l} \max \left[0, \text { margin }-\vec{t}<em>{\text {label }} M \vec{v}(\text { image })+\vec{t}</em>{j} M \vec{v}(\text { image })\right]<br>$$</p>
</li>
<li><p>$ \vec{v}(\text { image }) $ ：视觉主干顶层的图像向量（列向量）。</p>
</li>
<li><p>M ：线性投影层，把 4096 维视觉特征映到语言嵌入空间（500&#x2F;1000维）。</p>
</li>
<li><p>$ \tilde{t}<em>{ \text { label }} $ 、 $ \tilde{t}</em>{j} $ ：单位范数的词向量（行向量），分别对应正确标签与负样本标签。单位化后，点积就等价于余弦相似度的线性缩放。</p>
</li>
<li><p>m ：margin ，固定为 0.1。</p>
</li>
<li><p>“$ \max (0, \cdot) $ ”就是 hinge ：若“正确比分错的高m”已满足，就不产生损失；否则就按违反的幅度累计惩罚。</p>
</li>
</ul>
<blockquote>
<p>直觉：</p>
<p>对于每个负标签 j ，都要满足</p>
<p>$$ \tilde{t}<em>{ \text { label }} M \vec{v}-\tilde{t}</em>{j} M \vec{v} \geq m $$</p>
<p>不满足者就被“推远”，直到满足为止。</p>
</blockquote>
<hr>
<ol start="3">
<li>两个“工程化”随机化&#x2F;加速技巧</li>
</ol>
<p>作者为了高效、稳定地训练，做了两件事（都在截图段落中明确写出）：</p>
<ol>
<li><strong>负样本集合限制</strong>：只从“可能的图像标签集合”（而非整个词汇表）里采样负标签。</li>
<li><strong>提前截断求和</strong>：一旦发现<strong>第一个</strong>违反 margin 的负样本，就<strong>停止</strong>继续累加后续的负样本损失（相当于一次只处理一个“困难负样本”）。</li>
</ol>
<p>这两个处理起到了类似<strong>在线难例挖掘（hard negative mining）与噪声对冲</strong>的效果：既加快训练，又让梯度更聚焦。</p>
<hr>
<ol start="4">
<li>与 L2 损失的对比与原因</li>
</ol>
<ul>
<li><strong>L2（回归）损失</strong>的目标是“把两者拉得尽量近”，却<strong>不关心</strong>是否有<strong>错误标签更近</strong>；因此在“最近邻&#x2F;检索”的评测中常常<strong>不对题</strong>。</li>
<li><strong>排序（hinge）损失</strong>直接优化“正确要比任意错误<strong>更相似</strong>（且多 mm）”，与<strong>Top-k&#x2F;NN</strong>评测强相关，作者报告其<strong>准确率约为 L2 的两倍</strong>。</li>
</ul>
<hr>
<ol start="5">
<li>训练流程中的细节</li>
</ol>
<ul>
<li><strong>阶段化训练</strong>：先<strong>冻结</strong>视觉主干与文本嵌入，只训练投影层 MM；再把梯度<strong>回传进视觉主干</strong>做<strong>微调（fine-tune）</strong>，这一步一般能带来 <strong>1–3%</strong> 的<strong>绝对提升</strong>。</li>
<li><strong>优化器</strong>：分布式异步 SGD + <strong>Adagrad</strong>（为不同层自适应学习率，避免梯度尺度失衡）。</li>
<li><strong>词向量约束</strong>：$\tilde{t}$ 向量<strong>单位化</strong>并<strong>保持固定</strong>（否则若同时更新词向量，需要同步继续训练语言模型以维持全局语义结构，作者在正文中选择固定它们）。</li>
</ul>
<hr>
<ol start="6">
<li>测试时如何“用”这个损失学到的模型</li>
</ol>
<ul>
<li>对新图像，先用视觉主干 + MM 得到嵌入向量；</li>
<li>再在<strong>标签词向量库</strong>中做<strong>最近邻搜索</strong>（可用树或哈希做近似 NN，加速到亚线性时间），取 Top-k 标签作为输出；</li>
<li>评测需要时再把词&#x2F;短语映回 ImageNet synset 计分。</li>
</ul>
<hr>
<ol start="7">
<li>梯度与优化的直观理解（不写公式版）</li>
</ol>
<ul>
<li>若某个负标签 j<strong>侵犯了 margin</strong>，梯度会推动参数：<ul>
<li><strong>拉近</strong>图像向量与正确标签的点积；</li>
<li><strong>拉远</strong>与该负标签的点积。</li>
</ul>
</li>
<li>因为只处理“第一个违反者”，每步更新都聚焦在“最难的负样本”上，等价于<strong>针对当前最混淆的类别做对比学习</strong>。</li>
<li>m&#x3D;0.1m&#x3D;0.1 作为<strong>单位范数</strong>向量的“尺度相对 margin”，经验上稳定有效；一般<strong>更大</strong>会难学、<strong>更小</strong>会约束不够。</li>
</ul>
<hr>
<ol start="8">
<li><p>小结（损失的三句话）</p>
</li>
<li><p><strong>形式</strong>：点积相似 + <strong>hinge 排序损失</strong>，要求“正确比分错的高 mm”。</p>
</li>
<li><p><strong>实现</strong>：限制负样本集合 + 首个违例即截断；先训 MM，再微调视觉主干；Adagrad 优化；词向量单位化并固定。</p>
</li>
<li><p><strong>效果</strong>：比 L2 更贴合“最近邻&#x2F;Top-k”评测，带来显著更高的准确率与更语义合理的结果。</p>
</li>
</ol>
<hr>
<h2 id="五、实验设计与结果"><a href="#五、实验设计与结果" class="headerlink" title="五、实验设计与结果"></a>五、实验设计与结果</h2><h3 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1. 数据集"></a>1. 数据集</h3><p>使用 ImageNet ILSVRC 2012（1000 类别，120 万张训练图像）。</p>
<h3 id="2-对比模型"><a href="#2-对比模型" class="headerlink" title="2. 对比模型"></a>2. 对比模型</h3><ul>
<li><strong>Softmax baseline</strong>：标准 CNN + 1000 类 softmax。</li>
<li><strong>Random embeddings</strong>：使用随机语义向量代替 word2vec 向量，以验证语义信息的作用。</li>
</ul>
<hr>
<h3 id="3-结果一：常规分类性能（表-1，第-5-页）"><a href="#3-结果一：常规分类性能（表-1，第-5-页）" class="headerlink" title="3. 结果一：常规分类性能（表 1，第 5 页）"></a>3. 结果一：常规分类性能（表 1，第 5 页）</h3><table>
<thead>
<tr>
<th>模型</th>
<th>维度</th>
<th>Top-1</th>
<th>Top-5</th>
<th>Hierarchical P@5</th>
</tr>
</thead>
<tbody><tr>
<td>Softmax</td>
<td>N&#x2F;A</td>
<td>55.6%</td>
<td>78.5%</td>
<td>0.342</td>
</tr>
<tr>
<td>DeViSE (1000D)</td>
<td>1000</td>
<td>54.9%</td>
<td>78.4%</td>
<td><strong>0.351</strong></td>
</tr>
<tr>
<td>Random</td>
<td>1000</td>
<td>50.5%</td>
<td>74.2%</td>
<td>0.318</td>
</tr>
</tbody></table>
<p>解释：</p>
<ul>
<li>在传统指标（Top-1&#x2F;Top-5）上，DeViSE 与 Softmax 相当；</li>
<li>在语义层级指标（Hierarchical precision）上，DeViSE 明显更优；</li>
<li>这意味着 DeViSE 的错误“更合理”，即如果它错了，也往往错在语义邻近的类别上。</li>
</ul>
<hr>
<h3 id="4-结果二：零样本学习（Zero-Shot-Learning）"><a href="#4-结果二：零样本学习（Zero-Shot-Learning）" class="headerlink" title="4. 结果二：零样本学习（Zero-Shot Learning）"></a>4. 结果二：零样本学习（Zero-Shot Learning）</h3><p><strong>实验方法：</strong></p>
<ul>
<li>从 ImageNet 2011 21K 中选取不在 2012 1K 中的标签作为“零样本”；</li>
<li>测试模型在未见类别上的预测能力。</li>
</ul>
<p><strong>表 2 与图 2（第 6 页）</strong> 展示了多个例子：</p>
<ul>
<li>例如模型从未见过“telephoto lens”的图像，但能输出与镜头相关的标签；</li>
<li>错误预测往往语义相近，而非荒谬结果。</li>
</ul>
<p><strong>量化结果（2-hop, 3-hop, 21K 零样本集）：</strong></p>
<ul>
<li>DeViSE-0（仅预测零样本标签）在最易任务上 Top-20 命中率为 36.4%；</li>
<li>即使在最难的 21K 标签上，Top-20 命中率仍达 6%。</li>
</ul>
<p>相比之下，传统 softmax 在零样本情况下准确率为 0%。</p>
<hr>
<h3 id="5-结果三：层级精度比较（表-3，第-7-页）"><a href="#5-结果三：层级精度比较（表-3，第-7-页）" class="headerlink" title="5. 结果三：层级精度比较（表 3，第 7 页）"></a>5. 结果三：层级精度比较（表 3，第 7 页）</h3><ul>
<li>在语义精度指标上，DeViSE 在大多数情况下明显优于 softmax；</li>
<li>对更困难的任务（3-hop, 21K），相对提升最高可达 82%。</li>
</ul>
<hr>
<h3 id="6-对比其他工作（表-4）"><a href="#6-对比其他工作（表-4）" class="headerlink" title="6. 对比其他工作（表 4）"></a>6. 对比其他工作（表 4）</h3><p>与 Mensink et al. (2012) 和 Rohrbach et al. (2011) 的零样本模型比较，DeViSE 即使不依赖人工语义层级（如 WordNet），表现仍相当或更优。这表明其语义学习是<strong>自发从文本数据中获得的</strong>。</p>
<hr>
<h2 id="六、结论与意义"><a href="#六、结论与意义" class="headerlink" title="六、结论与意义"></a>六、结论与意义</h2><p>论文在第 8 页总结了以下要点：</p>
<ol>
<li><strong>性能与传统模型持平</strong><br> DeViSE 在常规分类上不逊于当时最优 CNN。</li>
<li><strong>语义合理的错误</strong><br> 模型的错误预测往往语义接近（如“虎鲨”错成“牛鲨”），而非随机。</li>
<li><strong>零样本学习能力强</strong><br> 能识别数千个未见过的类别，仅依赖语言模型的语义信息。</li>
<li><strong>可扩展性强</strong><br> 模型可轻松扩展到更大规模数据集（如上万类别），甚至可跨任务复用。</li>
<li><strong>学术影响</strong><br> DeViSE 是后来众多视觉–语言模型（如 CLIP, ALIGN, BLIP）的早期理论基础，首次成功将<strong>图像与文本的语义空间对齐</strong>。</li>
</ol>
<hr>
<h2 id="七、延伸理解"><a href="#七、延伸理解" class="headerlink" title="七、延伸理解"></a>七、延伸理解</h2><p>如果把 DeViSE 放在历史脉络中：</p>
<table>
<thead>
<tr>
<th>年份</th>
<th>模型</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>2013</td>
<td><strong>DeViSE</strong></td>
<td>CNN + word2vec 联合嵌入，零样本识别</td>
</tr>
<tr>
<td>2015</td>
<td>DeViSE 改进版 &#x2F; Convex combination</td>
<td>改善训练稳定性</td>
</tr>
<tr>
<td>2021</td>
<td><strong>CLIP (OpenAI)</strong></td>
<td>Transformer + 对比学习，通用视觉语言预训练</td>
</tr>
<tr>
<td>2022+</td>
<td>BLIP, Flamingo 等</td>
<td>多模态大模型方向发展</td>
</tr>
</tbody></table>
<p>可以说，DeViSE 是跨模态表示学习的奠基工作之一。</p>
<hr>
<h2 id="八、总结"><a href="#八、总结" class="headerlink" title="八、总结"></a>八、总结</h2><blockquote>
<p><strong>一句话总结：</strong></p>
<p>DeViSE 首次提出了一个可扩展的视觉–语义联合嵌入模型，通过将图像映射到由语言模型学习的语义空间，使计算机视觉系统具备了“理解文字语义”的能力，从而能识别未见过的新类别，并产生更合理的错误。</p>
</blockquote>
]]></content>
      <categories>
        <category>零样本检测</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>小样本目标检测</title>
    <url>/blog/2025/09/23/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="名词概念"><a href="#名词概念" class="headerlink" title="名词概念"></a>名词概念</h1><ul>
<li><p><strong>少样本对象检测 (Few-Shot Object Detection, FSOD):</strong> 每个新类别提供少量（比如1到10个）标注样本 。这是最主流的研究方向。</p>
</li>
<li><p><strong>单样本对象定位 (One-Shot Object Localization, OSOL):</strong> 这是 FSOD 的一个特例，每个新类别只提供<strong>一个</strong>标注样本 。</p>
</li>
<li><p><strong>零样本对象检测 (Zero-Shot Object Detection, ZSOD):</strong> 这是最极端的情况，新类别<strong>没有任何</strong>标注的图像样本 。那模型怎么学呢？它依赖于额外的信息，比如描述这些类别的<strong>语义属性</strong>（例如，描述“斑马”的词是“条纹”、“像马的动物”）</p>
</li>
</ul>
<h1 id="key-words"><a href="#key-words" class="headerlink" title="key words"></a>key words</h1><p><code>深度学习在低样本目标检测中的综述</code></p>
<p><code>A Survey of Deep Learning for Low-Shot Object Detection</code></p>
<p><strong>Additional Key Words and Phrases</strong>: Few-Shot Object Detection, One-Shot Object Detection, Zero-Shot Object detection, Transfer-Learning, Meta-Learning</p>
<p><code>少样本物体检测：研究进展与挑战</code></p>
<p><code>Few-shot object detection: Research advances and challenges</code></p>
<p><strong>Keywords:</strong>  Object detection ;Few-shot learning; Transfer learning</p>
]]></content>
  </entry>
  <entry>
    <title>keywords集合</title>
    <url>/blog/2025/09/17/keywords%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="标题及keywords"><a href="#标题及keywords" class="headerlink" title="标题及keywords"></a>标题及keywords</h1><p><code>A Review of DEtection TRansformer: From Basic Architecture to Advanced Developments and Visual Perception Applications</code></p>
<p><strong>Keywords</strong>: object detection; DETR; transformer; attention; end to end; deep learning</p>
<p><code>A review of small object detection based on deep learning</code></p>
<p><strong>Keywords</strong>： Small object detection; Deep learning ;Object detection ;Computer vision</p>
<p><code>Small object detection: A comprehensive survey on challenges, techniques and real-world applications</code></p>
<p><strong>Keywords</strong>：Computer vision Deep learning Small object detection Survey</p>
<p><code>Comprehensive review of deep learning-based tiny object detection: challenges, strategies, and future directions</code></p>
<p><strong>Keywords</strong> :Tiny object detection · Deep learning · Transformer-based models · Vision transformers · Evaluation metrics · Small object datasets · Autonomous systems · Challenges and solutions</p>
<p><code>ESM‐YOLO:基于可见光与红外多模态融合的增强型小目标检测</code></p>
<p><code>ESM-YOLO: Enhanced Small Target  Detection Based on Visible and Infrared  Multi-modal Fusion</code></p>
<p><strong>Keywords:</strong> Multi-modal fusion · Visible light images · Infrared  images · Small Targets</p>
<p><code>可见光-热敏微小物体检测：基准数据集和基线</code></p>
<p><code>Visible-Thermal Tiny Object Detection: A Benchmark Dataset and Baselines</code></p>
<p><strong>Index Terms</strong>—Visible-thermal, tiny object detection, benchmark dataset.</p>
<p><code>红外和可见光图像融合：从数据兼容性到任务适应性</code></p>
<p><code>Infrared and Visible Image Fusion: From Data  Compatibility to Task Adaption</code></p>
<p><strong>Index Terms</strong>—Image Fusion, Infrared and Visible, Image Registration, Object Detection.</p>
<p><code>基于多模态和自适应特征融合的机载小目标探测方法</code></p>
<p><code>Airborne Small Target Detection Method Based on  Multimodal and Adaptive Feature Fusion</code></p>
<p><strong>Index Terms</strong>— Attention mechanism, feature fusion, multimodal, small target detection, unmanned aerial vehicle (UAV) aerial imagery.</p>
<p><code>基于多模态茶叶嫩枝的实时密集小物体检测算法</code></p>
<p><code>Real-time dense small object  detection algorithm based on  multi-modal tea shoots</code></p>
<p><strong>KEYWORDS</strong>  dense small object detection, multimodal image fusion, RGB-D-IR, scale matching, frequency domain, attention mechanism, tea shoots</p>
<p><code>错位可见光-热目标检测：  基于无人机的基准和基线</code></p>
<p><code>Misaligned Visible-Thermal Object Detection:  A Drone-Based Benchmark and Baseline</code></p>
<p><strong>Index Terms</strong>—Multispectral object detection, visible-thermal dataset, cross-modal alignment, feature alignment.</p>
<p><code>ST-Trans：用于序列图像中红外小目标检测的时空变换器</code></p>
<p><code>ST-Trans: Spatial-Temporal Transformer for  Infrared Small Target Detection in  Sequential Images</code></p>
<p><strong>Index Terms</strong>— Infrared small target detection (IRSTD), sequential IRSTD (SIRSTD) dataset, spatial-temporal (ST) transformer.</p>
<p><code>红外图像中的小目标和暗目标探测：综述、当前技术和未来方向</code></p>
<p><code>Small and dim target detection in infrared imagery: A review, current techniques and future directions</code></p>
<p><strong>Keywords:</strong>  Infrared imaging ;Small and dim target detection ;Object detection; Deep learning ;SIRST; MIRST</p>
<p><code>SSTNet:基于跨切片卷积长短期记忆网络  的切片时空网络用于运动红外弱小目标检测</code></p>
<p><code>SSTNet: Sliced Spatio-Temporal Network With  Cross-Slice ConvLSTM for Moving Infrared  Dim-Small Target Detection</code></p>
<p><strong>Index Terms</strong>— Infrared dim-small target detection, motioncoordination loss (MCL), motion-coupling neck, sliced spatio-temporal network (SSTNet).</p>
<h1 id="检索关键词"><a href="#检索关键词" class="headerlink" title="检索关键词"></a>检索关键词</h1><h2 id="多模态融合的小目标检测"><a href="#多模态融合的小目标检测" class="headerlink" title="多模态融合的小目标检测"></a>多模态融合的小目标检测</h2><p>(“small object detection” OR “small target detection” OR “tiny object detection”) AND (“multimodal” OR “multi-modal” OR “multi-sensor fusion” OR “future fusion”)</p>
<blockquote>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>井中月</title>
    <url>/blog/2025/02/25/%E4%BA%95%E4%B8%AD%E6%9C%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
      <categories>
        <category>想法</category>
      </categories>
      <tags>
        <tag>井中月</tag>
      </tags>
  </entry>
  <entry>
    <title>Zero-Shot Object Detection</title>
    <url>/blog/2025/10/17/Zero-Shot-Object-Detection/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这一部分介绍了<strong>零样本物体检测</strong>（Zero-Shot Object Detection, ZSD）问题的背景、动机和挑战。为了帮助你更好地理解，我将从几个关键点进行详细讲解。</p>
<h2 id="问题背景："><a href="#问题背景：" class="headerlink" title="问题背景："></a>问题背景：</h2><ul>
<li><p><strong>人类与机器的区别</strong>：<br>引言一开始提到，<strong>人类</strong>能够轻松地通过语言描述构建对物体的心智模型。举个例子，即使我们从未见过某个物体，但只要听到它的描述，我们就能大致想象出它的样子。<strong>机器视觉系统</strong>则没有这种能力。传统的机器学习方法要求机器在训练阶段看到每一个物体类别的视觉样本，然后才能在测试阶段识别这些物体。</p>
<p>然而，这种方法存在问题：获取大量标注数据非常昂贵，因此在很多应用场景下，机器无法看到所有类别的物体样本。例如，如果训练集里只有“手”和“胳膊”的样本，机器无法自动推测出“肩膀”这个物体。</p>
</li>
</ul>
<h2 id="零样本学习（Zero-Shot-Learning-ZSL）的出现"><a href="#零样本学习（Zero-Shot-Learning-ZSL）的出现" class="headerlink" title="零样本学习（Zero-Shot Learning, ZSL）的出现"></a>零样本学习（Zero-Shot Learning, ZSL）的出现</h2><ul>
<li><p><strong>零样本学习的定义</strong>：<br>零样本学习（ZSL）试图解决上面提到的问题，即让模型能够识别那些在训练时没有见过的物体类别。ZSL通常通过<strong>语义关系</strong>来进行推理，例如，训练时见过“手”和“胳膊”，而在测试时模型可以识别“肩膀”，因为“肩膀”在语义上与“手”和“胳膊”是相关的。换句话说，模型并不需要每个物体的视觉样本，而是通过<strong>语义嵌入</strong>（例如，使用文本描述或者属性信息）将未见物体的特征与已见物体的特征进行匹配。</p>
<p>文章提到的零样本学习是基于<strong>视觉-语义嵌入</strong>的，即将图像和文本标签（如物体的名称）映射到一个共享的向量空间中，这样模型可以通过计算相似度来推测未见类别。</p>
</li>
</ul>
<h2 id="零样本学习与物体检测的差异"><a href="#零样本学习与物体检测的差异" class="headerlink" title="零样本学习与物体检测的差异"></a>零样本学习与物体检测的差异</h2><ul>
<li><p><strong>物体分类与物体检测的区别</strong>：</p>
<ul>
<li><strong>物体分类</strong>任务的目标是识别图像中是否存在某个物体，并为该物体分配一个标签。比如，给定一张图片，模型判断这张图片中是“狗”还是“猫”。</li>
<li><strong>物体检测</strong>任务的目标则更加复杂，不仅要为物体分配标签，还要找到它在图像中的位置（即预测边界框）。这就意味着，在物体检测中，模型不仅需要识别“狗”或“猫”，还需要在图像中精确标出这些物体的边界。</li>
</ul>
<blockquote>
<p>零样本物体分类的问题相对简单，因为分类任务只需要考虑标签匹配问题，不需要考虑物体的空间位置信息（即边界框）。而<strong>零样本物体检测</strong>的难度更高，因为除了要推测标签外，还要解决如何定位未见类别的物体。</p>
</blockquote>
</li>
</ul>
<h2 id="物体检测的挑战"><a href="#物体检测的挑战" class="headerlink" title="物体检测的挑战"></a>物体检测的挑战</h2><ul>
<li><p><strong>比分类更加复杂的检测问题</strong>：<br>物体检测相比物体分类更为复杂，原因在于它不仅仅依赖于物体的语义信息，还要考虑物体在图像中的位置、遮挡、视角变化、尺寸变化等因素。比如，“飞机”通常出现在“云层”旁边，但这并不能直接帮助检测“飞机”的具体位置，模型还需要学习如何精确地划定物体的边界框。</p>
</li>
<li><p><strong>背景与目标的区分</strong>：<br>在物体检测中，常常会加入一个“背景”类（background class），用来区分物体和非物体区域。背景类通常指的是没有目标物体的区域，如“天空”、“墙壁”等。背景类有助于模型区分“物体”与“背景”，但在零样本物体检测中，背景的定义变得模糊，因为背景区域可能包含未见类别的物体，而这些物体并不属于传统意义上的背景。</p>
</li>
</ul>
<h2 id="本研究的目标与贡献"><a href="#本研究的目标与贡献" class="headerlink" title="本研究的目标与贡献"></a>本研究的目标与贡献</h2><p>文章的目标是<strong>将零样本学习应用到物体检测任务中</strong>，并提出新的方法来处理背景类和类别稀疏的问题。具体来说，研究人员：</p>
<ul>
<li><strong>引入零样本物体检测问题</strong>，并提出了一种基于视觉-语义嵌入的方法来解决这个问题。</li>
<li><strong>探讨了背景类的选择问题</strong>，提出了两种方法：一种是使用固定背景类，另一种是通过迭代的潜在赋值方法（LAB）来处理背景问题。</li>
<li><strong>提出了一种稠密采样的方法</strong>，通过增加外部数据来扩充训练数据集，解决训练类别稀疏的问题。</li>
<li><strong>在标准数据集上进行实验</strong>，并给出了实验结果，展示了所提出方法的有效性。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简而言之，本研究的核心贡献是提出了一种可以进行零样本物体检测的框架，并在此基础上解决了背景处理、类别稀疏等关键问题。该框架不仅可以在已见类别的基础上推测未见类别的标签，还能够精确地定位这些物体在图像中的位置，从而实现零样本物体检测。</p>
<hr>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="🧩-Word-Embeddings（词向量嵌入）"><a href="#🧩-Word-Embeddings（词向量嵌入）" class="headerlink" title="🧩  Word Embeddings（词向量嵌入）"></a>🧩  Word Embeddings（词向量嵌入）</h2><p>首先，作者介绍了**词嵌入（word embeddings）**在自然语言处理和视觉语义任务中的重要性。</p>
<h3 id="✳️-背景"><a href="#✳️-背景" class="headerlink" title="✳️ 背景"></a>✳️ 背景</h3><p>词嵌入的核心思想是：<strong>用连续向量表示离散的词语</strong>，使得语义相似的词在向量空间中距离更近。例如，“猫（cat）”和“狗（dog）”在语义空间中相距较近，而与“飞机（airplane）”相距较远。</p>
<p>这类嵌入通常通过在大规模语料中学习词共现关系来实现。代表性方法包括：</p>
<ul>
<li><strong>word2vec（Mikolov et al., 2013）</strong></li>
<li><strong>GloVe（Pennington et al., 2014）</strong></li>
<li><strong>fastText（Joulin et al., 2016）</strong></li>
</ul>
<h3 id="✳️-在本文中的作用"><a href="#✳️-在本文中的作用" class="headerlink" title="✳️ 在本文中的作用"></a>✳️ 在本文中的作用</h3><p>作者利用词嵌入作为一个<strong>公共语义空间</strong>，将图像特征（由CNN提取）和类标签（由word embedding 表示）映射到同一空间中，从而实现<strong>视觉—语义对齐（visual-semantic alignment）</strong>。<br> 这种语义空间的引入，使得模型在没有见过某些类别的视觉样本时，仍能通过语义相似度（cosine similarity）进行识别。例如，模型从“马（horse）”学到的特征可以迁移到“斑马（zebra）”上。</p>
<hr>
<h2 id="🖼️-2-2-Zero-Shot-Image-Classification（零样本图像分类）"><a href="#🖼️-2-2-Zero-Shot-Image-Classification（零样本图像分类）" class="headerlink" title="🖼️ 2.2 Zero-Shot Image Classification（零样本图像分类）"></a>🖼️ 2.2 Zero-Shot Image Classification（零样本图像分类）</h2><p>接下来，作者回顾了**零样本图像分类（ZSL）**领域的已有工作。</p>
<h3 id="✳️-早期方法"><a href="#✳️-早期方法" class="headerlink" title="✳️ 早期方法"></a>✳️ 早期方法</h3><p>最初的零样本分类方法主要依赖<strong>人工定义的属性（attributes）</strong>，例如：</p>
<ul>
<li>颜色、形状、姿态、部位等（如Lampert等人的工作[26,27]）</li>
<li>地理或语义属性（如Fu等人的研究[12]）</li>
</ul>
<p>这些方法使用属性作为桥梁，将已见类别与未见类别联系起来。</p>
<h3 id="✳️-深度视觉-语义方法"><a href="#✳️-深度视觉-语义方法" class="headerlink" title="✳️ 深度视觉-语义方法"></a>✳️ 深度视觉-语义方法</h3><p>随着深度学习的发展，研究者提出了**多模态嵌入（multimodal embedding）**方法，用神经网络将图像特征与语义标签映射到一个共享空间。例如：</p>
<ul>
<li><strong>DeViSE模型（Frome et al., 2013）</strong>：使用图像特征和语义嵌入之间的兼容性函数（compatibility function）进行训练。</li>
<li><strong>Latent Embedding Models（Xian et al., 2016）</strong>：在双线性模型的基础上引入潜在变量，使嵌入关系更加灵活。</li>
<li><strong>Semantic Autoencoder（Kodirov et al., 2017）</strong>：通过重建约束（reconstruction loss）保证语义空间与视觉特征空间的一致性。</li>
</ul>
<h3 id="✳️-本文的延伸"><a href="#✳️-本文的延伸" class="headerlink" title="✳️ 本文的延伸"></a>✳️ 本文的延伸</h3><p>Bansal等人借鉴了这些思想，但<strong>将零样本学习从分类扩展到检测</strong>。不同于分类，物体检测需要同时处理<strong>定位与识别</strong>，因此他们结合了视觉嵌入与语义嵌入，在检测任务中预测未见类别的边界框与标签。</p>
<hr>
<h2 id="🎯-2-3-Object-Detection（物体检测）"><a href="#🎯-2-3-Object-Detection（物体检测）" class="headerlink" title="🎯 2.3 Object Detection（物体检测）"></a>🎯 2.3 Object Detection（物体检测）</h2><p>这一节简要回顾了物体检测领域的发展历程。</p>
<h3 id="✳️-早期方法-1"><a href="#✳️-早期方法-1" class="headerlink" title="✳️ 早期方法"></a>✳️ 早期方法</h3><p>传统的检测方法采用<strong>候选区域（region proposals）+分类器</strong>的两步策略：</p>
<ul>
<li>R-CNN、Fast R-CNN、Faster R-CNN等方法【Girshick et al., 2014–2016】</li>
<li>这些方法先生成数千个候选框，再用CNN对每个区域分类。</li>
</ul>
<h3 id="✳️-一阶段检测器"><a href="#✳️-一阶段检测器" class="headerlink" title="✳️ 一阶段检测器"></a>✳️ 一阶段检测器</h3><p>后来出现了<strong>单阶段检测方法</strong>，如：</p>
<ul>
<li><strong>YOLO（Redmon et al., 2016）</strong></li>
<li><strong>SSD（Liu et al., 2016）</strong></li>
</ul>
<p>它们直接在整张图像上预测物体的位置和类别，提高了速度。</p>
<h3 id="✳️-与本文的关系"><a href="#✳️-与本文的关系" class="headerlink" title="✳️ 与本文的关系"></a>✳️ 与本文的关系</h3><p>这些方法都基于<strong>全监督学习</strong>，需要大量的边界框标注。<br> 然而，在现实中，不可能为成千上万类物体都标注边框。<br> 因此，Bansal等人提出的ZSD方法正是为了<strong>在没有未见类别标注的情况下实现检测</strong>。<br> 他们基于R-CNN框架构建检测器，但训练时仅使用<strong>已见类别</strong>，并通过语义空间迁移实现未见类别检测。</p>
<hr>
<h2 id="🔀-2-4-Multi-Modal-Learning（多模态学习）"><a href="#🔀-2-4-Multi-Modal-Learning（多模态学习）" class="headerlink" title="🔀 2.4 Multi-Modal Learning（多模态学习）"></a>🔀 2.4 Multi-Modal Learning（多模态学习）</h2><p>作者指出，<strong>多模态学习（Multi-modal learning）</strong>——即结合不同模态（图像、文本、声音等）——已经在计算机视觉中取得显著成果。</p>
<h3 id="✳️-相关研究"><a href="#✳️-相关研究" class="headerlink" title="✳️ 相关研究"></a>✳️ 相关研究</h3><ul>
<li><strong>Aytar et al. (2017)</strong>：联合图像、文本和声音学习跨模态共享表示。</li>
<li><strong>Zhang et al. (2017)</strong>：使用文本描述来辅助图像中物体的定位。</li>
<li><strong>Gupta et al. (2017)</strong>：构建图像区域与词语的共享空间，用于视觉-语言任务的迁移。</li>
</ul>
<p>这些工作启发了作者使用<strong>多模态共享语义空间</strong>来进行零样本检测。</p>
<h3 id="✳️-与本文的区别"><a href="#✳️-与本文的区别" class="headerlink" title="✳️ 与本文的区别"></a>✳️ 与本文的区别</h3><p>本文的重点不在于生成新的多模态表示，而是在检测框架中利用<strong>语义嵌入</strong>进行<strong>类别迁移</strong>。此外，与Li等人（2014）基于属性的物体分类不同，Bansal等人的方法不依赖于属性描述，而是依靠<strong>无监督的词向量</strong>。</p>
<hr>
<h2 id="⚖️-2-5-Comparison-with-Recent-ZSD-Works（与同期工作的比较）"><a href="#⚖️-2-5-Comparison-with-Recent-ZSD-Works（与同期工作的比较）" class="headerlink" title="⚖️ 2.5 Comparison with Recent ZSD Works（与同期工作的比较）"></a>⚖️ 2.5 Comparison with Recent ZSD Works（与同期工作的比较）</h2><p>作者最后提到，他们的研究完成后出现了两篇并行的工作，也探讨了类似的零样本检测问题：</p>
<ol>
<li><strong>Zhu et al. (2018)</strong>：研究重点在于<strong>为未见类别生成候选区域（object proposals）</strong>，而非完整的检测任务。</li>
<li><strong>Rahman et al. (2018)</strong>：提出一种结合最大间隔损失（max-margin loss）与语义聚类损失（semantic clustering loss）的检测模型，以减少语义空间的噪声。</li>
</ol>
<h3 id="✳️-本文的独特性"><a href="#✳️-本文的独特性" class="headerlink" title="✳️ 本文的独特性"></a>✳️ 本文的独特性</h3><ul>
<li>使用更<strong>复杂且多样化的数据集</strong>（MSCOCO与VisualGenome），而不是相对简单的ILSVRC。</li>
<li>特别关注<strong>背景类污染问题</strong>（即背景区域可能包含未见类别），并提出两种解决方案（SB与LAB）。</li>
<li>探索了如何通过<strong>密集采样语义空间</strong>改善检测效果，这是Rahman等人未考虑的。</li>
</ul>
<hr>
<h2 id="📚-小结"><a href="#📚-小结" class="headerlink" title="📚 小结"></a>📚 小结</h2><p>这一章的核心在于为本文的研究奠定基础，说明其创新点和必要性：</p>
<ol>
<li><strong>方法论上</strong>：从词嵌入与多模态学习中汲取灵感，将零样本分类方法扩展到检测任务。</li>
<li><strong>技术上</strong>：引入语义嵌入空间，支持跨类别知识迁移。</li>
<li><strong>创新点</strong>：首次系统地解决了“背景类”和“语义稀疏”问题，并在复杂数据集上验证。</li>
</ol>
<hr>
<p>非常好！<br> 接下来我将以教授讲课的方式，<strong>详细讲解论文《Zero-Shot Object Detection》第3章——Approach（方法）</strong>。<br> 这是论文的核心部分，作者在这一章中正式提出他们的算法框架、模型结构以及训练机制。我们会逐步解释每个小节（3.1、3.2、3.3），并穿插讲解公式与直观理解，帮助你从零基础完全掌握。</p>
<h1 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h1><p>在前两章中，作者已经说明了：</p>
<ul>
<li><strong>研究目标</strong>：让模型检测出训练中未见过的物体类别；</li>
<li><strong>关键挑战</strong>：包括背景类处理与语义空间稀疏问题。</li>
</ul>
<p>在这一章中，作者系统提出了他们的解决方案，整个方法的逻辑可以概括为：</p>
<blockquote>
<p>从“已见类别”中学习视觉—语义映射关系 **→**用语义嵌入扩展到“未见类别” **→**在检测框架中引入背景建模与语义空间稠密化以提升泛化。</p>
</blockquote>
<hr>
<h2 id="🌟-3-1-Baseline-Zero-Shot-Detection-ZSD"><a href="#🌟-3-1-Baseline-Zero-Shot-Detection-ZSD" class="headerlink" title="🌟 3.1 Baseline Zero-Shot Detection (ZSD)"></a>🌟 3.1 Baseline Zero-Shot Detection (ZSD)</h2><p>（基线模型：零样本物体检测）</p>
<h3 id="🧩-基本思路"><a href="#🧩-基本思路" class="headerlink" title="🧩 基本思路"></a>🧩 基本思路</h3><p>作者从<strong>零样本分类模型（如DeViSE）出发，将其适配到物体检测</strong>任务。<br> 这意味着模型必须能：</p>
<ol>
<li><strong>定位</strong>目标（bounding box），</li>
<li><strong>识别</strong>类别（包括未见类别）。</li>
</ol>
<h3 id="⚙️-数据设定与符号说明"><a href="#⚙️-数据设定与符号说明" class="headerlink" title="⚙️ 数据设定与符号说明"></a>⚙️ 数据设定与符号说明</h3><p>作者定义了三个集合：</p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>S</td>
<td>已见类别（Seen classes）</td>
</tr>
<tr>
<td>U</td>
<td>未见类别（Unseen classes）</td>
</tr>
<tr>
<td>O</td>
<td>其他类别（既不是训练类也不是测试类）</td>
</tr>
<tr>
<td>C</td>
<td>所有类别的集合：C &#x3D; S ∪ U ∪ O</td>
</tr>
</tbody></table>
<p>在训练阶段，模型只能看到 <code>S</code> 类的图像与标注框；<br> 在测试阶段，需要检测 <code>U</code> 类。</p>
<p>图像记为 <code>I ∈ R^&#123;M×N×3&#125;</code>，<br> 每个候选框记为 <code>b_i ∈ N⁴</code>（表示坐标），<br> 其对应类别标签为 <code>y_i ∈ S</code>。</p>
<hr>
<h3 id="🧠-模型结构：视觉—语义嵌入"><a href="#🧠-模型结构：视觉—语义嵌入" class="headerlink" title="🧠 模型结构：视觉—语义嵌入"></a>🧠 模型结构：视觉—语义嵌入</h3><ol>
<li><p><strong>提取视觉特征</strong><br> 利用CNN（文中采用Inception-ResNet v2）从候选框区域提取深度特征：<br>$$<br>φ(b_i) ∈ R^{D_1}<br>$$</p>
</li>
<li><p><strong>获取语义特征</strong><br> 对应的类标签（如“dog”、“car”）使用<strong>词向量</strong>（如GloVe或fastText）表示：<br>$$<br>w_j ∈ R^{D_2}<br>$$</p>
</li>
<li><p><strong>学习投影矩阵</strong><br> 作者学习一个线性投影<br>$$<br>W_p ∈ R^{D_2×D_1}<br>$$</p>
<p> 将视觉特征映射到语义空间：<br>$$<br>ψ_i &#x3D; W_p φ(b_i)<br>$$<br>这样，视觉特征与语义特征处于同一空间中，便于比较。</p>
</li>
</ol>
<hr>
<h3 id="⚖️-相似度与损失函数"><a href="#⚖️-相似度与损失函数" class="headerlink" title="⚖️ 相似度与损失函数"></a>⚖️ 相似度与损失函数</h3><p>模型通过<strong>余弦相似度</strong>衡量投影特征 $ψ_i$ 与类语义向量 $w_j$ 的匹配程度：<br>$$<br>S_{ij} &#x3D; \cos(ψ_i, w_j)<br>$$<br>训练时采用<strong>最大间隔损失（max-margin loss）</strong>，保证正确类别的相似度高于错误类别：<br>$$<br>L(b_i, y_i, θ) &#x3D; \sum_{j∈S, j≠i} \max(0, m - S_{ii} + S_{ij})<br>$$<br>其中：</p>
<ul>
<li>$m$ 是margin；</li>
<li>$θ$ 表示CNN参数与投影参数。</li>
</ul>
<blockquote>
<p><strong>目标：</strong> 该损失函数的目标是使得每个物体框（bounding box）的类别预测能够尽可能正确，并且预测的类别与其他类别之间的差异尽可能大，达到最大间隔</p>
<p><strong>损失计算：</strong></p>
<ul>
<li>该损失函数要求，真实类别$y_i$的相似度$S_{ii}$ 要大于所有其他类别$j \in S, j \neq i$的相似度$S_{ij}$</li>
<li><strong>最大间隔</strong>：为了确保正确类别的预测相对于错误类别的预测有足够大的间隔，损失函数通过<strong>最大间隔</strong>的思想来优化：</li>
<li><strong>若</strong>$S_{ii}$ 与$ S_{ij}$ 之间的差距小于预设的 $ m$，则损失会产生值：$m - S_{ii} + S_{ij}$，从而惩罚预测错误的情况。</li>
<li><strong>若</strong>$S_{ii}$ 与$ S_{ij}$ 之间的差距大于  $ m$，则损失为 0，即不产生惩罚。</li>
</ul>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a><strong>总结：</strong></h4><p>该损失函数的作用是让模型学习到一个有效的特征空间，使得正确类别的相似度更高，错误类别的相似度更低，从而保证对未知类别的有效检测。</p>
</blockquote>
<p>此外，为了防止语义空间塌陷，作者加上<strong>重建损失（reconstruction loss）</strong>，使投影后的特征能重构原始视觉特征。<br> 这一做法借鉴了 <strong>Kodirov et al. (2017)</strong> 的语义自编码器。</p>
<hr>
<h3 id="🔍-测试阶段（Zero-Shot-Detection）"><a href="#🔍-测试阶段（Zero-Shot-Detection）" class="headerlink" title="🔍 测试阶段（Zero-Shot Detection）"></a>🔍 测试阶段（Zero-Shot Detection）</h3><p>测试时，对于每个候选框 $b_i$，模型计算它与所有<strong>未见类别</strong>语义向量的相似度，然后取最相似的类别：<br>$$<br>\hat{y_i} &#x3D; \arg \max_{j∈U} S_{ij}<br>$$</p>
<blockquote>
<p><strong>公式含义：</strong></p>
<ul>
<li><strong>目标：</strong> 该公式表示了在测试阶段，如何通过计算每个候选框与<strong>未见类别</strong>的相似度来选择最合适的类别标签。</li>
</ul>
<h4 id="变量解释："><a href="#变量解释：" class="headerlink" title="变量解释："></a><strong>变量解释：</strong></h4><ul>
<li>$\hat{y}_i$：表示第$ i$个候选框的<strong>预测类别</strong>。</li>
<li>$S_{ij}$：表示第$ i$个候选框与第$ j$ 个类别$j \in U$之间的相似度。</li>
<li>$U$：表示所有的<strong>未见类别</strong>集合。</li>
</ul>
<p><strong>预测计算：</strong></p>
<ul>
<li>在测试阶段，模型已经学会了从已见类别中获取特征，并将这些特征映射到一个共享的语义空间。</li>
<li>对于每个候选框 $b_i$，模型计算该框与所有未见类别的相似度 $S_{ij}$。</li>
<li>公式中的<strong>arg max</strong>操作表示从所有未见类别中选择<strong>相似度最大</strong>的类别作为最终的预测类别 $\hat{y}_i$</li>
</ul>
<h4 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a><strong>总结：</strong></h4><p>在零样本检测的测试阶段，模型通过计算候选框与未见类别的相似度，选择最合适的类别标签来进行预测。这正是零样本学习的核心：即使在没有见过某些类别的情况下，模型也能通过已有的语义信息进行有效的推理。</p>
</blockquote>
<h3 id="⚠️-问题一：背景类的困境"><a href="#⚠️-问题一：背景类的困境" class="headerlink" title="⚠️ 问题一：背景类的困境"></a>⚠️ 问题一：背景类的困境</h3><p>在传统检测中，会设置一个“背景类（background）”，帮助模型识别非目标区域。<br> 但在<strong>零样本检测</strong>中，这个背景类的定义变得复杂，因为“背景”可能包含：</p>
<ul>
<li>真正的背景（如天空、地面）；</li>
<li>未见类别的物体（如测试时出现的新物体）。</li>
</ul>
<p>这会导致模型把“未见物体”错误地当作“背景”。<br> 因此，作者提出了两种新的背景建模方法（3.2节）。</p>
<hr>
<h2 id="🌌-Background-Aware-Zero-Shot-Detection"><a href="#🌌-Background-Aware-Zero-Shot-Detection" class="headerlink" title="🌌  Background-Aware Zero-Shot Detection"></a>🌌  Background-Aware Zero-Shot Detection</h2><p>（背景感知的零样本检测）</p>
<p>作者提出两种改进方法来更合理地处理背景信息：</p>
<hr>
<h3 id="🧱-1-Static-Background-SB-Model-—-静态背景模型"><a href="#🧱-1-Static-Background-SB-Model-—-静态背景模型" class="headerlink" title="🧱 (1) Static Background (SB) Model — 静态背景模型"></a>🧱 (1) Static Background (SB) Model — 静态背景模型</h3><h4 id="🔹-思路："><a href="#🔹-思路：" class="headerlink" title="🔹 思路："></a>🔹 思路：</h4><p>将传统检测中的“背景”视为一个独立的固定类（static class），并为它分配一个固定的语义向量（embedding vector）。训练时，模型学习把明显不是任何已见类别的区域映射到这个“背景向量”。</p>
<h4 id="🔹-优点："><a href="#🔹-优点：" class="headerlink" title="🔹 优点："></a>🔹 优点：</h4><ul>
<li>简单直接；</li>
<li>有效利用背景样本来训练检测器的判别能力。</li>
</ul>
<h4 id="🔹-缺点："><a href="#🔹-缺点：" class="headerlink" title="🔹 缺点："></a>🔹 缺点：</h4><ul>
<li>语义空间中，真实背景（如“天空”）和未知物体（如“斑马”）会被<strong>混为一谈</strong>；</li>
<li>模型可能过度学习“非训练类 &#x3D; 背景”，从而抑制了对未见类别的检测能力。</li>
</ul>
<hr>
<h3 id="🌠-2-Latent-Assignment-Based-LAB-Model-—-潜在赋值模型"><a href="#🌠-2-Latent-Assignment-Based-LAB-Model-—-潜在赋值模型" class="headerlink" title="🌠 (2) Latent Assignment-Based (LAB) Model — 潜在赋值模型"></a>🌠 (2) Latent Assignment-Based (LAB) Model — 潜在赋值模型</h3><p>为解决SB模型的局限，作者设计了一个<strong>EM-like算法（期望最大化迭代）</strong>，让背景区域分配到多个潜在语义类中。</p>
<h4 id="🔹-思想："><a href="#🔹-思想：" class="headerlink" title="🔹 思想："></a>🔹 思想：</h4><blockquote>
<p>背景框不是都属于一个单一的“背景类”，它们可以属于一个**开放词汇集合（open vocabulary）**中的不同类。</p>
</blockquote>
<p>算法流程（见论文中的 Algorithm 1）：</p>
<p><img src="/blog/image/Snipaste_2025-10-20_10-34-22.png"></p>
<ol>
<li><strong>初始阶段</strong>：先用已见类训练一个基线模型；</li>
<li><strong>E步（Expectation）</strong>：用当前模型预测每个背景框最可能对应的语义类（从开放词汇集合中选取）；</li>
<li><strong>M步（Maximization）</strong>：将这些伪标签加入训练集，重新训练模型；</li>
<li><strong>重复以上步骤多次（如5次迭代）</strong>。</li>
</ol>
<p>这样，背景样本被分散到多个语义上合理的类别中，而非集中于单一“背景类”，有效减轻了“语义污染”问题。</p>
<p>🔹 <strong>优点</strong>：</p>
<ul>
<li>背景被“语义分解”，模型更具泛化能力；</li>
<li>类似于半监督学习（labeled + unlabeled data）。</li>
</ul>
<p>🔹 <strong>缺点</strong>：</p>
<ul>
<li>需要多轮迭代；</li>
<li>伪标签可能存在噪声（错误赋值）。</li>
</ul>
<hr>
<h2 id="🪐-3-3-Densely-Sampled-Embedding-Space-DSES"><a href="#🪐-3-3-Densely-Sampled-Embedding-Space-DSES" class="headerlink" title="🪐 3.3 Densely Sampled Embedding Space (DSES)"></a>🪐 3.3 Densely Sampled Embedding Space (DSES)</h2><p>（密集采样的语义嵌入空间）</p>
<p><strong>🔹 问题：训练类别太少 → 语义空间稀疏</strong></p>
<p>如果训练集中只有几十个已见类别（如MSCOCO的48个），<br> 则语义嵌入空间中大部分区域未被覆盖。<br> 这会导致：</p>
<ul>
<li>模型难以学到全面的视觉—语义对应；</li>
<li>未见类别往往落在“语义孤岛”中，模型无法泛化。</li>
</ul>
<p><strong>🔹 解决方案：使用外部数据进行“语义填充”</strong></p>
<p>作者使用<strong>OpenImages (OI)</strong> 数据集（含545类）来丰富训练样本。<br> 他们只选择其中不属于未见类的样本（避免数据泄漏），并将这些新类别加入训练集。</p>
<p>这被称为<strong>Densely Sampled Embedding Space (DSES)</strong>。<br> 它能显著改善嵌入空间的覆盖度，使模型更容易迁移到未见类。</p>
<hr>
<h2 id="🔚-小结：这一章的核心思想"><a href="#🔚-小结：这一章的核心思想" class="headerlink" title="🔚 小结：这一章的核心思想"></a>🔚 小结：这一章的核心思想</h2><table>
<thead>
<tr>
<th>关键模块</th>
<th>作用</th>
<th>创新点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Baseline ZSD</strong></td>
<td>利用视觉-语义嵌入预测未见类</td>
<td>将ZSL扩展到检测任务</td>
</tr>
<tr>
<td><strong>SB模型</strong></td>
<td>静态背景处理</td>
<td>保持检测器鲁棒性</td>
</tr>
<tr>
<td><strong>LAB模型</strong></td>
<td>动态背景建模</td>
<td>通过迭代伪标签提升泛化</td>
</tr>
<tr>
<td><strong>DSES</strong></td>
<td>语义空间稠密化</td>
<td>引入外部数据增强语义覆盖</td>
</tr>
</tbody></table>
<hr>
<p>非常好👍<br> 接下来我将以教授讲课的方式，<strong>系统讲解论文《Zero-Shot Object Detection》第4章（Experiments 实验部分）</strong>，重点解析作者如何通过实验验证他们提出的三种模型（Baseline、SB、LAB、DSES）的效果与差异，并结合表格、结果与论文结论逐步说明。</p>
<hr>
<h2 id="🌟-第4章-Experiments（实验）"><a href="#🌟-第4章-Experiments（实验）" class="headerlink" title="🌟 第4章 Experiments（实验）"></a>🌟 第4章 Experiments（实验）</h2><p>这一章是论文的实证部分，作者主要通过两个大型数据集 <strong>MSCOCO</strong> 和 <strong>VisualGenome (VG)</strong> 来评估他们提出的模型性能。<br> 他们比较了以下几种方法：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Baseline ZSD</strong></td>
<td>只用已见类别训练的基础模型，没有背景处理。</td>
</tr>
<tr>
<td><strong>SB (Static Background)</strong></td>
<td>使用固定的背景类建模。</td>
</tr>
<tr>
<td><strong>LAB (Latent Assignment Based)</strong></td>
<td>使用迭代潜在标签分配算法（Algorithm 1）。</td>
</tr>
<tr>
<td><strong>DSES (Densely Sampled Embedding Space)</strong></td>
<td>使用外部数据集密集采样语义空间。</td>
</tr>
</tbody></table>
<hr>
<h2 id="🧩-数据集介绍与实验设置"><a href="#🧩-数据集介绍与实验设置" class="headerlink" title="🧩  数据集介绍与实验设置"></a>🧩  数据集介绍与实验设置</h2><p>📘 <strong>MSCOCO</strong></p>
<ul>
<li>来源：Microsoft COCO 2014 版。</li>
<li>包含 80 个物体类别。</li>
<li>作者将其中的类分为：<ul>
<li><strong>48 个训练类（seen）</strong></li>
<li><strong>17 个测试类（unseen）</strong></li>
</ul>
</li>
<li>训练集大小：73,774 张图像</li>
<li>测试集大小：6,608 张图像</li>
<li>采用 EdgeBoxes 生成候选框。</li>
</ul>
<p>📗 <strong>VisualGenome (VG)</strong></p>
<ul>
<li>更复杂的视觉语义数据集，含 600 多类物体。</li>
<li>作者清理后：<ul>
<li><strong>478 个训练类（seen）</strong></li>
<li><strong>130 个测试类（unseen）</strong></li>
</ul>
</li>
<li>训练集大小：54,913 张图像</li>
<li>测试集大小：7,788 张图像</li>
<li>场景更复杂、标注更密集，是一个高难度检测场景。</li>
</ul>
<hr>
<p>🧠 类别划分方法</p>
<p>作者使用语义嵌入的**聚类方法（word embedding clustering）**来划分 seen &#x2F; unseen 类别：</p>
<ol>
<li>使用 GloVe 向量；</li>
<li>基于余弦相似度聚类；</li>
<li>每个聚类中随机选 80% 类别为训练类，其余 20% 为未见类；</li>
<li>保证语义分布均匀。</li>
</ol>
<hr>
<p><strong>核心目标</strong>：如何公平地做零样本检测的划分？</p>
<p>零样本检测（ZSD）的关键是：<strong>训练阶段只用“已见类”（seen），测试阶段只评估“未见类”（unseen）</strong>。<br> 所以，划分要同时满足两点：</p>
<ol>
<li><strong>语义上公平</strong>：已见&#x2F;未见类在语义空间里不要“扎堆”，否则测试太容易或太难。</li>
<li><strong>数据上可行</strong>：训练集中的图像不能“偷偷包含”未见类，否则这些未见类会被当成背景，污染训练（对ZSD极其致命）。</li>
</ol>
<p>这段话说的就是：作者是如何把<strong>类别</strong>和<strong>图像</strong>两层都切干净的。</p>
<p><span style="color:#FF0000">1）先在语义空间里把“类别”做成簇，再从每个簇里抽 80% 做 seen、20% 做 unseen</span></p>
<ul>
<li><strong>做法</strong>：<ul>
<li>对所有候选类别拿到它们的<strong>词向量</strong>（word vector embeddings）。</li>
<li>以词向量的<strong>余弦相似度</strong>为距离，在语义空间里把类别做成 <strong>K 个簇（clusters）</strong>。</li>
<li>对<strong>每个簇</strong>随机选 <strong>80%</strong> 的类别作为 <strong>seen</strong>，剩余 <strong>20%</strong> 作为 <strong>unseen</strong>。</li>
</ul>
</li>
<li><strong>为什么要“先聚类、再分簇抽签”</strong>？<ul>
<li>因为词向量捕捉了语义相似性。</li>
<li>如果你不聚类而是全局随机抽，很可能出现“猫&#x2F;狗&#x2F;狼&#x2F;狐”都落在训练集，测试集只剩下“螃蟹&#x2F;火车”这种语义很远的类；那样测试就<strong>太难</strong>了。</li>
<li>反过来，如果测试集全是“马&#x2F;斑马&#x2F;驴&#x2F;骡”这样和训练类过分接近，又会<strong>太容易</strong>。</li>
<li><strong>按簇 8:2 抽取</strong>能让 seen 与 unseen 在<strong>每个语义簇</strong>里都保留一部分，确保测试既不偏难也不偏易，<strong>更公平</strong>。</li>
</ul>
</li>
<li><strong>K 的取值</strong>：<ul>
<li><strong>MSCOCO：K &#x3D; 10</strong></li>
<li><strong>VisualGenome：K &#x3D; 20</strong></li>
<li>VG 的类更多、更杂，因此用更多簇更合理。</li>
</ul>
</li>
</ul>
<p><span style="color:#FF0000">2）只保留“在 WordNet 有 synset 且有词向量”的类别</span></p>
<ul>
<li><strong>做法</strong>：把没有 WordNet 同义词集（synset）或缺少词向量的类剔掉。</li>
<li><strong>原因</strong>：ZSD需要把视觉特征投到<strong>语义空间</strong>；没有可靠的语义表示（synset + 词向量）的类，<strong>无法参与语义对齐</strong>。</li>
<li><strong>结果</strong>（作者最终可用的类）：<ul>
<li><strong>MSCOCO：训练类 48、测试类 17</strong></li>
<li><strong>VisualGenome：训练类 478、测试类 130</strong></li>
</ul>
</li>
</ul>
<blockquote>
<p>这也解释了为什么 VG 上“类很多”但依然要过滤：不是所有原始标签都能稳定地映射到标准语义空间。</p>
</blockquote>
<p><span style="color:#FF0000">3）图像层面的清洗：避免把“未见类”当背景（MSCOCO 能做、VG 做不了）</span></p>
<ul>
<li><strong>MSCOCO 的处理</strong>：<ul>
<li><strong>把训练集中“含有未见类实例”的图像统统移除</strong>。</li>
<li>目的：如果这些图像保留在训练集中，未见类的实例会被训练管线当作“背景框”使用（因为没有标注为某个 seen 类），这会强烈误导模型学到“未见&#x3D;背景”，<strong>破坏零样本泛化</strong>。</li>
<li>由于 COCO 的未见类数量相对少、图像密度相对低，移除这些图像<strong>仍能保留足够多的训练数据</strong>。</li>
</ul>
</li>
<li><strong>VG 的处理</strong>：<ul>
<li><strong>无法做上述移除</strong>。</li>
<li>由于 <strong>VG 的测试类很多、标注极其密集</strong>，如果把含有任何未见类的训练图像都移除，<strong>大多数训练图像都会被删光</strong>，训练根本无法进行。</li>
<li>这也解释了为什么论文里**静态背景（SB）**在 VG 上会变差：因为“背景”里的确混入了大量未见类实例，<strong>背景被语义污染</strong>。</li>
</ul>
</li>
</ul>
<p><span style="color:#FF0000">4）最终图像规模（按作者实际筛完的结果）</span></p>
<ul>
<li><strong>MSCOCO</strong>：<ul>
<li><strong>训练</strong> 73,774 张</li>
<li><strong>测试</strong> 6,608 张</li>
</ul>
</li>
<li><strong>VisualGenome</strong>：<ul>
<li><strong>训练</strong> 54,913 张</li>
<li><strong>测试</strong> 7,788 张</li>
</ul>
</li>
</ul>
<blockquote>
<p>这些数字能让你评估：在“严格去除未见类图像”的 COCO 上，训练规模仍然很可观；而 VG 即使不剔除含未见类的图像，训练规模也足够大，但<strong>背景污染是客观存在</strong>的。</p>
</blockquote>
<hr>
<ol>
<li><strong>公平性</strong>（语义层面）<ul>
<li>“先聚类、再每簇 8:2 抽取”控制了 seen&#x2F;unseen 的<strong>语义距离分布</strong>，避免极端情况，保证评测<strong>更稳健、更可复现</strong>。</li>
</ul>
</li>
<li><strong>纯净性</strong>（图像层面）<ul>
<li>COCO 训练集<strong>尽量避免</strong>未见类被当作背景，<strong>利好 SB</strong> 这类把“背景当单一类”的方法；</li>
<li>VG 由于做不了清洗，<strong>LAB</strong>（把背景分解给开放词汇的伪标签）<strong>更占优势</strong>，这也吻合论文实验结论。</li>
</ul>
</li>
<li><strong>可复现性</strong>（工程落地）<ul>
<li>给出了 K、比例（80&#x2F;20）、过滤规则（WordNet+词向量）、以及最终的类与图像数量，别人可以按同样流程<strong>复现相近分布</strong>。</li>
</ul>
</li>
</ol>
<blockquote>
<p>把“类别聚类后 8:2 抽签”想成<strong>分年级考试</strong>：<br> 先按“知识点相似度”把题库分成若干章节（聚类），再在<strong>每个章节</strong>里抽 80% 的题作为“讲过的内容”（训练类），剩下 20% 的题作为“没讲过但同一章节的内容”（测试类）。这样既考<strong>迁移能力</strong>，又不至于考到完全陌生的领域。</p>
</blockquote>
<hr>
<h2 id="🧮-实现细节（Implementation-Details）"><a href="#🧮-实现细节（Implementation-Details）" class="headerlink" title="🧮 实现细节（Implementation Details）"></a>🧮 实现细节（Implementation Details）</h2><ol>
<li>总体框架：两阶段检测 + 视觉—语义对齐</li>
</ol>
<ul>
<li><strong>框架形态</strong>：遵循 <strong>R-CNN&#x2F;Fast R-CNN 风格的两阶段检测</strong>。先生成候选框（region proposals），再对每个候选框提特征并分类回归。</li>
<li><strong>零样本关键</strong>：不直接学固定的 one-hot 分类器；而是学一个<strong>投影函数</strong>，把候选框的<strong>视觉特征</strong>映射到<strong>语义空间</strong>，再与<strong>类别的词向量</strong>做相似度匹配（余弦相似度）。这样即便“未见类”没有训练样本，也能在语义空间里被“对齐”。</li>
</ul>
<blockquote>
<p>直观比喻：检测头不是学“猫&#x2F;狗&#x2F;车”的独立分类器，而是学“把图块送到词向量世界里”的规则；到了词向量世界，任何有词向量的类都能被匹配——哪怕训练时没见过。</p>
</blockquote>
<hr>
<ol start="2">
<li>候选框生成（Region Proposals）</li>
</ol>
<ul>
<li><strong>工具</strong>：采用传统的 <strong>EdgeBoxes</strong> 生成候选框（速度快、召回高）。</li>
<li><strong>数量设置</strong>：每张图提取大量候选（常见量级在几百到两千），再走后续打分与 NMS。<br> 目的：<strong>保证召回</strong>——零样本检测宁可多给一些框，也不能漏掉真实物体位置。</li>
</ul>
<hr>
<ol start="3">
<li>视觉特征提取（Backbone &amp; RoI 特征）</li>
</ol>
<ul>
<li><strong>主干网络</strong>：使用 <strong>Inception-ResNet v2（ImageNet 预训练）</strong>。<ul>
<li>这样做能直接获得强表征，减少从零训练的负担。</li>
</ul>
</li>
<li><strong>候选框特征</strong>：在主干特征图上对 proposal 执行 <strong>RoI Pooling &#x2F; RoI Align</strong>（具体实现随你选，语义不变），得到定长的 <strong>RoI 级特征向量</strong> ϕ(b)\phi(b)。</li>
</ul>
<hr>
<ol start="4">
<li>语义表示（Label Embeddings）</li>
</ol>
<ul>
<li><strong>类别向量</strong>：为每个类别使用 <strong>分布式词向量</strong>（常见为 <strong>GloVe&#x2F;fastText</strong>，维度 300），记为 $w_c$。</li>
<li><strong>必要性</strong>：这就是“零样本”的桥梁；未见类没有视觉样本，但<strong>有词向量</strong>，所以能与 RoI 投影结果进行相似度比对。</li>
</ul>
<hr>
<ol start="5">
<li>视觉→语义投影与相似度（核心 ZSD 头）</li>
</ol>
<ul>
<li><p><strong>线性投影</strong>：学习一个矩阵 $W_p$，把 RoI 视觉特征$\phi(b) $映射到语义空间：<br>$$<br>\psi(b) &#x3D; W_p,\phi(b)<br>$$</p>
</li>
<li><p><strong>打分方式</strong>：与每个类别的词向量做 <strong>余弦相似度</strong> $S(b,c) &#x3D; \cos(\psi(b), w_c)$</p>
<ul>
<li><strong>训练期</strong>：与 <strong>已见类集合 $S$</strong> 比分，让真类相似度高、其他类低。</li>
<li><strong>测试期（ZSD）</strong>：只在 <strong>未见类集合$ U$</strong> 上取 argmax。</li>
</ul>
</li>
</ul>
<hr>
<ol start="6">
<li>损失函数（学习“对齐”而非硬分类）</li>
</ol>
<ul>
<li><strong>最大间隔（max-margin）损失</strong>：鼓励“真类相似度”比“其他已见类相似度”至少大一个 margin。</li>
<li><strong>重建&#x2F;正则项（可选）</strong>：常见做法是在语义自编码思想下加<strong>轻量重建约束</strong>，防止投影空间“塌缩”（让投影不过分偏向少数方向）。</li>
<li><strong>边框分支</strong>：位置回归仍按检测常规做（例如 Smooth L1）；<br> 但要注意：<strong>未见类没有框级监督</strong>，所以回归分支只由已见类样本驱动学习。</li>
</ul>
<blockquote>
<p>要点：分类头的“监督”来自<strong>已见类语义对齐</strong>，不是标准的 softmax over C；回归头的监督来源于已见类的真实框。</p>
</blockquote>
<hr>
<ol start="7">
<li>训练细节（优化器&#x2F;学习率&#x2F;采样）</li>
</ol>
<ul>
<li><strong>优化器</strong>：常用 <strong>Adam</strong>。<ul>
<li><strong>梯度分配</strong>：投影层学习率较高（需要快速学对齐），主干较低（微调）。</li>
</ul>
</li>
<li><strong>正负采样</strong>：对 proposals 采用 standard 的正负样本策略（IoU 阈值划分），以稳定训练。</li>
<li><strong>NMS</strong>：在候选层面与类别打分后均使用 <strong>非极大抑制（NMS）</strong> 控冗余。</li>
</ul>
<hr>
<ol start="8">
<li>推理与评测（Testing &amp; Metrics）</li>
</ol>
<ul>
<li><strong>ZSD（纯未见）</strong>：对每个 RoI，仅在 <strong>未见类集合 U</strong> 上打分，取最高者为预测类；再做 NMS，得到检测结果。</li>
<li><strong>GZSD（泛化零样本）</strong>：需要在$S \cup U$上统一打分；通常会引入<strong>新颖度阈值&#x2F;校准因子</strong>来缓解“已见类偏置”。</li>
<li><strong>指标</strong>：论文主要用 <strong>Recall@K (IoU&#x3D;0.5)</strong>（例如 Recall@100），因为<strong>零样本阶段分类不一定很准，但先看召回是否“找到对的框&#x2F;类簇”</strong>；<br> GZSD 还会给 <strong>Seen&#x2F;Unseen 的 Recall</strong> 以及 <strong>调和平均</strong>（平衡两端）。</li>
</ul>
<hr>
<ol start="9">
<li>三个变体的“额外实现”要点</li>
</ol>
<p>(a) SB（Static Background，静态背景）</p>
<ul>
<li><strong>做法</strong>：把“背景”当作一个<strong>固定的单一类</strong>加进语义空间（可给一个专门的背景嵌入向量或常量方向）。</li>
<li><strong>训练</strong>：把与任何已见类都不匹配的 RoI 标成“背景”，参与 max-margin 训练。</li>
<li><strong>作用</strong>：简单、鲁棒，但当训练图里<strong>真的存在未见类</strong>时，会把它们<strong>错误吸进背景</strong>，污染语义。</li>
</ul>
<p>(b) LAB（Latent Assignment-Based，潜在赋值）</p>
<ul>
<li><strong>核心</strong>：按 <strong>EM&#x2F;自训练</strong> 思路迭代：<ul>
<li><strong>E 步</strong>：用当前模型给“背景 RoI”在一个<strong>更大的开放词表 OO</strong> 上打伪标签（不是仅1个“背景”）。</li>
<li><strong>M 步</strong>：把这些带伪标签的 RoI 加回训练，更新投影与检测头。</li>
</ul>
</li>
<li><strong>目的</strong>：把“背景”<strong>语义分解</strong>到许多潜在类，减轻“未见&#x3D;背景”的混淆。</li>
<li><strong>实现提示</strong>：控制迭代轮数；给伪标签设<strong>置信度阈值</strong>与<strong>去重规则</strong>，避免噪声放大。</li>
</ul>
<p>(c) DSES（Densely Sampled Embedding Space，语义稠密化）</p>
<ul>
<li><strong>做法</strong>：从<strong>外部数据集</strong>（如 OpenImages）引入大量<strong>非测试类</strong>的标注样本，一起训练。</li>
<li><strong>原则</strong>：<strong>严禁</strong>使用测试未见类的标注（避免泄漏）；只选与 UU 不重叠的类来“填满”语义空间。</li>
<li><strong>收益</strong>：训练类更多 → 视觉—语义对齐学得更稳 → 未见类泛化更好。</li>
</ul>
<hr>
<ol start="10">
<li><p>复现时的“工程清单”</p>
</li>
<li><p><strong>数据与划分</strong>：按 4.2 的 split 规则（类聚类后 8:2 seen&#x2F;unseen；COCO 训练集去掉含未见类的图像，VG 不去）。</p>
</li>
<li><p><strong>候选框</strong>：EdgeBoxes（或用 RPN 替代，注意召回）。</p>
</li>
<li><p><strong>骨干</strong>：Inception-ResNet v2（或 ResNet-50&#x2F;101，保持可比性）。</p>
</li>
<li><p><strong>词向量</strong>：GloVe&#x2F;fastText（保持 300 维统一）。</p>
</li>
<li><p><strong>投影头</strong>：线性层 + 归一化（配合余弦相似度）。</p>
</li>
<li><p><strong>损失</strong>：max-margin（语义对齐） + 回归损失（仅已见类框）；可叠加轻量重建&#x2F;正则。</p>
</li>
<li><p><strong>优化</strong>：Adam；投影头 lr 高，骨干 lr 低；常规正负采样与 NMS。</p>
</li>
<li><p><strong>变体</strong>：</p>
<ul>
<li>SB：加入 background embedding，常规训练；</li>
<li>LAB：迭代伪标签（阈值&#x2F;去重&#x2F;轮数）；</li>
<li>DSES：并入外部“安全类”样本再训练。</li>
</ul>
</li>
<li><p><strong>评测</strong>：Recall@100（IoU&#x3D;0.5），同时给出 ZSD 与 GZSD 指标。</p>
</li>
</ol>
<hr>
<p>结束语</p>
<ul>
<li>4.1 的“实现细节”告诉我们：<strong>ZSD 的难点不在模型复杂度，而在训练&#x2F;语义对齐与数据处理</strong>。</li>
<li>只要把“候选框—视觉特征—语义投影—相似度—损失—评测”这条链条打通，再按 SB&#x2F;LAB&#x2F;DSES 的规则做<strong>背景与语义密度</strong>处理，就能得到与论文相符的表现。</li>
<li>真正影响结果的，往往是：<strong>（i）训练集是否含未见类污染；（ii）语义空间是否足够稠密；（iii）伪标签的质量控制。</strong></li>
</ul>
<h2 id="Evaluation-Protocol（评估协议）"><a href="#Evaluation-Protocol（评估协议）" class="headerlink" title="Evaluation Protocol（评估协议）"></a>Evaluation Protocol（评估协议）</h2><p> 这一节主要讲解：作者是如何评估模型性能的、使用了哪些指标、在什么场景下测试（ZSD 与 GZSD）、以及为什么选用这些评估方式。</p>
<hr>
<p><span style="color:#FF0000">🌟 一、章节目的：评估的目标是什么？</span></p>
<p>作者提出的任务是 <strong>Zero-Shot Object Detection（零样本物体检测，ZSD）</strong>，而评估的目标是验证：</p>
<ol>
<li>模型是否能在 <strong>只看过“已见类”</strong> 的情况下检测出 <strong>“未见类”</strong>；</li>
<li>模型在 <strong>Generalized Zero-Shot Detection（泛化零样本检测，GZSD）</strong> 场景下能否同时识别 seen 和 unseen；</li>
<li>背景处理（SB &#x2F; LAB）与语义扩展（DSES）是否真的提升了检测效果。</li>
</ol>
<p>因此，作者设计了两套评测协议，对应两种任务场景：</p>
<ul>
<li><strong>(1) ZSD：纯零样本检测</strong></li>
<li><strong>(2) GZSD：泛化零样本检测</strong></li>
</ul>
<hr>
<p><span style="color:#FF0000">🧩 二、ZSD（Zero-Shot Detection）评估协议</span></p>
<p>(1) 测试集设置</p>
<ul>
<li><strong>只包含未见类（unseen classes）</strong> 的实例。<br> 即测试集中出现的物体类别在训练阶段从未出现过。</li>
<li>模型从所有候选框中检测这些物体。</li>
</ul>
<p>(2) 测试流程</p>
<ol>
<li><p><strong>模型训练阶段</strong>：<br> 只用已见类 S 的图像和标注框进行训练。</p>
</li>
<li><p><strong>模型测试阶段</strong>：<br> 对每张测试图像，模型输出一系列候选框及其类别预测。<br> 但在计算得分时，<strong>只在未见类集合 U</strong> 上打分。<br>$$<br>\hat{y_i} &#x3D; \arg\max_{j \in U} S_{ij}<br>$$</p>
</li>
<li><p><strong>候选框后处理</strong>：<br> 应用非极大值抑制（NMS）去除重复框。</p>
</li>
</ol>
<hr>
<p>(3) 评价指标</p>
<p>作者没有使用传统的 <strong>mAP（mean Average Precision）</strong>，而是采用 <strong>Recall@K（召回率）</strong>。<br> 原因如下👇</p>
<h4 id="为什么不用-mAP？"><a href="#为什么不用-mAP？" class="headerlink" title="为什么不用 mAP？"></a><strong>为什么不用 mAP？</strong></h4><ul>
<li>ZSD 任务的重点不是精确排序（rank）或置信度优化；</li>
<li>未见类缺乏训练监督，置信度分数的分布难以对齐；</li>
<li>若用 mAP，很多“正确框但分数略低”的情况会被过分惩罚；</li>
<li>Recall 指标更能反映“模型有没有找到正确的目标”。</li>
</ul>
<h4 id="Recall-K-的定义"><a href="#Recall-K-的定义" class="headerlink" title="Recall@K 的定义"></a><strong>Recall@K 的定义</strong></h4><blockquote>
<p>在每张测试图像中，取得分最高的 <strong>K 个候选框</strong>，统计它们是否覆盖了测试集中所有未见类实例。</p>
</blockquote>
<p>具体计算：<br>$$<br>Recall@K &#x3D; \frac{\text{正确检测到的未见类物体数}}{\text{测试集中所有未见类物体数}}<br>$$</p>
<p>要求：</p>
<ul>
<li>IoU（Intersection over Union）≥ 0.5；</li>
<li>“正确检测” &#x3D; 预测框与真实框的 IoU≥0.5 且类别一致；</li>
<li>通常取 K&#x3D;100。</li>
</ul>
<h4 id="为什么选-K-100？"><a href="#为什么选-K-100？" class="headerlink" title="为什么选 K&#x3D;100？"></a><strong>为什么选 K&#x3D;100？</strong></h4><ul>
<li>K&#x3D;100 兼顾性能与稳定性；</li>
<li>若 K 太小（如 10），Recall 会过低；</li>
<li>若 K 太大（如所有框），噪声太多。</li>
</ul>
<hr>
<p>(4) 小结（ZSD 评估逻辑）</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td>数据</td>
<td>只测试未见类</td>
</tr>
<tr>
<td>打分</td>
<td>只计算未见类语义空间内相似度</td>
</tr>
<tr>
<td>指标</td>
<td>Recall@K (IoU≥0.5)</td>
</tr>
<tr>
<td>目的</td>
<td>检查模型是否能“找到”未见类物体</td>
</tr>
</tbody></table>
<p>ZSD 的目标是评估模型的<strong>语义迁移能力</strong>。</p>
<hr>
<p><span style="color:#FF0000">🌈 三、GZSD（Generalized Zero-Shot Detection）评估协议</span></p>
<p>ZSD 假设“测试集中全是未见类”，但真实世界不这样。<br> 因此作者引入了更实际的任务设定：</p>
<blockquote>
<p><strong>Generalized Zero-Shot Detection (GZSD)</strong>：<br> 测试图像中既包含 seen 类，也包含 unseen 类的物体。</p>
</blockquote>
<hr>
<p>(1) 问题与挑战</p>
<p>这种设定更贴近实际部署场景，但更困难。<br> 因为模型在训练时只见过 seen 类，它可能出现<strong>严重偏见</strong>：</p>
<ul>
<li>往往倾向于把所有物体都预测为“已见类”；</li>
<li>导致未见类检测召回率极低。</li>
</ul>
<hr>
<p>(2) 测试流程</p>
<p>与 ZSD 类似，但这次模型的打分范围扩大到：<br>$$<br>S_{ij} \quad j \in (S \cup U)<br>$$</p>
<p>即：在测试阶段同时考虑所有 seen 和 unseen 类。</p>
<p>模型会输出：</p>
<ul>
<li>一部分框预测为 seen 类；</li>
<li>一部分预测为 unseen 类。</li>
</ul>
<hr>
<p>(3) 新颖度检测（Novelty Detection）</p>
<p>为区分 seen &#x2F; unseen 类，作者引入了一个<strong>新颖度阈值 (novelty threshold, n_t)</strong>。<br> 具体做法：</p>
<ol>
<li>对于每个候选框，模型计算与所有类的相似度；</li>
<li>若该框的最大相似度小于阈值 $n_t$，则认为它属于 <strong>unseen 类集合</strong>；</li>
<li>否则，认为它属于 <strong>seen 类集合</strong>。</li>
</ol>
<p>通过调整 $n_t$，可以平衡对 seen 和 unseen 类的召回率。</p>
<hr>
<p>(4) 评估指标：Harmonic Mean（调和平均）</p>
<p>在 GZSD 中，需要同时评估两种召回率：</p>
<ul>
<li>$Recall_s$：检测到的 seen 类实例数 &#x2F; seen 类总数；</li>
<li>$Recall_u$：检测到的 unseen 类实例数 &#x2F; unseen 类总数。</li>
</ul>
<p>单看任何一个指标都不公平，于是作者采用<strong>调和平均（H-Mean）</strong>：<br>$$<br>H &#x3D; \frac{2 \times Recall_s \times Recall_u}{Recall_s + Recall_u}<br>$$</p>
<ul>
<li>当模型只关注 seen 类时，$Recall_s $高但 $Recall_u$ 低 → H 很低；</li>
<li>当模型只关注 unseen 类时，$Recall_u$ 高但 $Recall_s$ 低 → H 也低；</li>
<li><strong>高 H 值</strong> 表明模型在两者之间取得平衡。</li>
</ul>
<hr>
<p>(5) 结果解读标准</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Recall@K (ZSD)</td>
<td>模型发现未见类的能力</td>
</tr>
<tr>
<td>$Recall_s$ &#x2F; $Recall_u$ (GZSD)</td>
<td>模型对 seen&#x2F;unseen 的检测能力</td>
</tr>
<tr>
<td>H-Mean</td>
<td>综合平衡性能</td>
</tr>
</tbody></table>
<p><strong>理想模型：</strong></p>
<ul>
<li>在 ZSD 中：Recall 高；</li>
<li>在 GZSD 中：$Recall_s$ 和 $Recall_u$ 都高，H-Mean 最大。</li>
</ul>
<hr>
<p><span style="color:#FF0000">🧠 四、选择 Recall 而非 AP 的深层原因</span></p>
<p>作者专门强调了一点：</p>
<blockquote>
<p><strong>Zero-shot detection 的关键在于“能否识别出未见类”，不是精确排序。</strong></p>
</blockquote>
<p>因此：</p>
<ul>
<li>Recall 更关注“找到没找到”；</li>
<li>AP 更依赖置信度排序，而 ZSD 的置信度并不可靠（因类分布偏移）；</li>
<li>Recall 对于跨语义泛化更稳健。</li>
</ul>
<hr>
<p><span style="color:#FF0000">📊 五、论文中的指标使用总结表</span></p>
<table>
<thead>
<tr>
<th>任务类型</th>
<th>数据集</th>
<th>类别范围</th>
<th>评估指标</th>
<th>IoU 阈值</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>ZSD</td>
<td>MSCOCO, VG</td>
<td>仅未见类 UU</td>
<td>Recall@K</td>
<td>0.5</td>
<td>检测迁移能力</td>
</tr>
<tr>
<td>GZSD</td>
<td>MSCOCO, VG</td>
<td>已见 + 未见 S∪US∪U</td>
<td>Recall_s, Recall_u, Harmonic Mean</td>
<td>0.5</td>
<td>平衡泛化能力</td>
</tr>
</tbody></table>
<hr>
<p>🎓 六、教授总结</p>
<table>
<thead>
<tr>
<th>层面</th>
<th>要点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>核心思想</strong></td>
<td>用 Recall 而非 AP 来衡量能否“发现”未见类</td>
</tr>
<tr>
<td><strong>ZSD</strong></td>
<td>测试集只含未见类，关注语义迁移</td>
</tr>
<tr>
<td><strong>GZSD</strong></td>
<td>测试集含已见+未见类，引入新颖度阈值与调和平均</td>
</tr>
<tr>
<td><strong>创新性</strong></td>
<td>把零样本学习引入检测任务后，首次系统提出了针对检测的评估协议</td>
</tr>
<tr>
<td><strong>研究价值</strong></td>
<td>为后续所有 Zero-shot &#x2F; Open-vocabulary detection 提供了标准化评测流程</td>
</tr>
</tbody></table>
<hr>
<h2 id="Results-and-Discussion（结果与讨论）"><a href="#Results-and-Discussion（结果与讨论）" class="headerlink" title="Results and Discussion（结果与讨论）"></a>Results and Discussion（结果与讨论）</h2><p> 这部分是论文的实验核心，作者在这里展示了他们的实验数据、性能指标、不同模型之间的对比，以及对结果的深入分析。</p>
<hr>
<p><strong>🌟 一、概览：本节要回答的核心问题</strong></p>
<p>作者在这一节中主要想回答三个问题：</p>
<ol>
<li><strong>他们提出的几种方法（Baseline、SB、LAB、DSES）效果如何？</strong></li>
<li><strong>不同数据集（MSCOCO 与 VisualGenome）上，表现差异的原因是什么？</strong></li>
<li><strong>这些方法在更现实的 GZSD（Generalized Zero-Shot Detection）场景下是否依然有效？</strong></li>
</ol>
<p>他们通过一系列实验结果（表格与图像）系统回答了这些问题。</p>
<hr>
<p><strong>📊 二、MSCOCO 数据集结果分析</strong></p>
<p>1️⃣ 实验设置回顾</p>
<ul>
<li>Seen classes: 48</li>
<li>Unseen classes: 17</li>
<li>训练集中移除了所有包含未见类的图像，确保“纯净训练”。</li>
<li>评测指标：Recall@100，IoU≥0.5。</li>
</ul>
<p>2️⃣ 实验结果表（摘自论文 Table 1）</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>背景机制</th>
<th>Seen 类数</th>
<th>Unseen 类数</th>
<th>额外类 (O)</th>
<th>Recall@100 (IoU&#x3D;0.5)</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>×</td>
<td>48</td>
<td>17</td>
<td>0</td>
<td>22.14</td>
</tr>
<tr>
<td>SB</td>
<td>✓ (Static)</td>
<td>48</td>
<td>17</td>
<td>1</td>
<td>24.39</td>
</tr>
<tr>
<td>LAB</td>
<td>✓ (Latent)</td>
<td>48</td>
<td>17</td>
<td>343</td>
<td>20.52</td>
</tr>
<tr>
<td>DSES</td>
<td>×</td>
<td>378</td>
<td>17</td>
<td>0</td>
<td><strong>27.19</strong></td>
</tr>
</tbody></table>
<p>3️⃣ 分析解读</p>
<ul>
<li><strong>SB 提升显著（+2.25）</strong>：<br> 因为MSCOCO的训练数据经过严格清洗，没有未见类污染，“背景”确实就是背景。<br> → 固定背景类（SB）有助于区分“物体 vs 非物体”。</li>
<li><strong>LAB 反而下降（-1.62）</strong>：<br> 因为MSCOCO类目太少（48类），语义空间稀疏。<br> LAB在这种稀疏语义空间中为背景分配伪标签时容易出错，导致错误累积。</li>
<li><strong>DSES 效果最好（27.19）</strong>：<br> 引入 OpenImages 的额外 300+ 类，显著提升语义空间的覆盖密度，<br> → 模型学到更稳健的视觉–语义映射，对未见类迁移能力更强。</li>
</ul>
<p>🧩 <strong>总结：</strong></p>
<blockquote>
<p>对于类目较少、背景干净的数据集（如MSCOCO），**语义空间稠密化（DSES）**是最有效的策略。</p>
</blockquote>
<hr>
<p><strong>🖼️ 三、VisualGenome 数据集结果分析</strong></p>
<p>1️⃣ 实验设置回顾</p>
<ul>
<li>Seen classes: 478</li>
<li>Unseen classes: 130</li>
<li>未见类分布密集，训练集中包含未见类实例（无法去除）。</li>
</ul>
<p>2️⃣ 实验结果表</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>背景机制</th>
<th>Seen 类数</th>
<th>Unseen 类数</th>
<th>额外类 (O)</th>
<th>Recall@100</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>×</td>
<td>478</td>
<td>130</td>
<td>0</td>
<td>5.19</td>
</tr>
<tr>
<td>SB</td>
<td>✓</td>
<td>478</td>
<td>130</td>
<td>1</td>
<td>4.09</td>
</tr>
<tr>
<td>LAB</td>
<td>✓</td>
<td>478</td>
<td>130</td>
<td>1673</td>
<td><strong>5.40</strong></td>
</tr>
<tr>
<td>DSES</td>
<td>×</td>
<td>716</td>
<td>130</td>
<td>0</td>
<td>4.75</td>
</tr>
</tbody></table>
<p>3️⃣ 分析解读</p>
<ul>
<li><strong>SB 模型性能下降（5.19 → 4.09）</strong>：<br> 因为 VG 的训练集背景污染严重，许多背景区域其实包含未见类物体。<br> 把它们硬塞进“固定背景类”反而让模型学坏（即把未见类当背景学掉了）。</li>
<li><strong>LAB 模型提升最明显（+0.21）</strong>：<br> LAB 通过“潜在赋值”让背景框分散到大量潜在语义类（1673个），<br> 避免了“背景&#x3D;未见类”的混淆，从而在复杂语义环境下表现更稳。</li>
<li><strong>DSES 在 VG 上帮助有限（+0.44）</strong>：<br> 因为 VG 已经含有数百个类，本身语义空间就很稠密，再加外部数据提升不大。</li>
</ul>
<p>🧩 <strong>总结：</strong></p>
<blockquote>
<p>对于语义丰富、背景复杂的数据集（如 VG），**LAB（语义扩展背景）**优于固定背景与稠密采样。</p>
</blockquote>
<hr>
<p>🌐 四、Generalized Zero-Shot Detection (GZSD) 实验结果</p>
<p>1️⃣ 背景</p>
<p>在真实世界中，测试图像通常包含 seen + unseen 混合类别，因此作者进一步评估模型在 <strong>GZSD</strong> 任务上的表现。</p>
<p>2️⃣ 指标</p>
<ul>
<li><p><strong>Recall_s</strong>：已见类召回率</p>
</li>
<li><p><strong>Recall_u</strong>：未见类召回率</p>
</li>
<li><p><strong>H-Mean（调和平均）</strong>：</p>
<p>H&#x3D;2×Recalls×RecalluRecalls+RecalluH &#x3D; \frac{2 \times Recall_s \times Recall_u}{Recall_s + Recall_u}</p>
</li>
</ul>
<p>3️⃣ 结果表（以 MSCOCO 为例）</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>Recall_s</th>
<th>Recall_u</th>
<th>H-Mean</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>16.93</td>
<td>8.91</td>
<td>11.67</td>
</tr>
<tr>
<td>LAB</td>
<td>14.54</td>
<td>10.57</td>
<td>12.24</td>
</tr>
<tr>
<td>DSES</td>
<td>15.02</td>
<td>15.32</td>
<td><strong>15.17</strong></td>
</tr>
</tbody></table>
<p>4️⃣ 结果分析</p>
<ul>
<li><strong>Baseline 偏向已见类</strong>：Recall_s 高但 Recall_u 极低。</li>
<li><strong>LAB 稍微改善未见类性能</strong>：通过背景语义扩展，Recall_u 增加；但 Recall_s 略降（模型有轻微偏向未见类）。</li>
<li><strong>DSES 达到最佳平衡</strong>：在 seen&#x2F;unseen 上召回率接近，调和平均最高（15.17）。</li>
</ul>
<p>🧩 <strong>总结：</strong></p>
<blockquote>
<p>DSES 提供了<strong>泛化性最好的模型</strong>，说明“语义空间稠密化”不仅对 ZSD 有效，对 GZSD 也能显著减少“类偏置问题”。</p>
</blockquote>
<hr>
<p><strong>🖼️ 五、Qualitative Results（定性结果）</strong></p>
<p>论文最后展示了一些<strong>可视化结果（Figure 2）</strong>，展示了模型对未见类物体的检测效果。</p>
<p>✅ 成功案例</p>
<ul>
<li>模型成功检测出“肩膀 (shoulder)”、“裙子 (skirt)”、“植被 (vegetation)”等未见类；</li>
<li>即使这些类从未在训练集中出现过，模型仍能通过语义关系识别出来；</li>
<li>证明语义嵌入迁移机制有效。</li>
</ul>
<p>❌ 失败案例</p>
<ul>
<li>例如把 “zebra” 错认成 “horse”，因为语义相似、外观也近；</li>
<li>或将“arm”误判为“leg”，说明模型缺乏更细粒度的辨别能力；</li>
<li>这些错误揭示出：当前模型在<strong>细粒度视觉差异捕捉</strong>上仍存在局限。</li>
</ul>
<hr>
<p>🧠 六、总体讨论与结论</p>
<table>
<thead>
<tr>
<th>观察</th>
<th>原因</th>
<th>启示</th>
</tr>
</thead>
<tbody><tr>
<td>MSCOCO 上 DSES 最好</td>
<td>类少、语义稀疏，稠密采样有效</td>
<td>语义空间密度关键</td>
</tr>
<tr>
<td>VG 上 LAB 最好</td>
<td>背景污染严重，潜在赋值可分解背景语义</td>
<td>背景建模重要</td>
</tr>
<tr>
<td>GZSD 上 DSES 最稳</td>
<td>语义稠密化减少偏置</td>
<td>泛化性提升</td>
</tr>
<tr>
<td>Recall 优先于 mAP</td>
<td>置信度分布不可比</td>
<td>衡量发现能力更合适</td>
</tr>
</tbody></table>
<blockquote>
<p>作者通过这组实验验证了：</p>
<ul>
<li>语义空间的<strong>稠密性</strong>与模型泛化能力密切相关；</li>
<li>背景处理方式对不同数据集影响显著；</li>
<li>零样本检测任务的公平评估必须区分 ZSD 与 GZSD 场景。</li>
</ul>
</blockquote>
<hr>
<p>🎓 七、教授总结</p>
<blockquote>
<p><strong>核心结论：</strong></p>
<ol>
<li>在语义空间稀疏、背景干净的数据集上，<strong>DSES</strong> 提升最大。</li>
<li>在语义复杂、背景污染严重的场景中，<strong>LAB</strong> 最具优势。</li>
<li><strong>SB</strong> 虽简单，但易受背景污染影响。</li>
<li><strong>Recall@K + H-Mean</strong> 成为后来所有 Open-Vocabulary Detection 的标准评测方式。</li>
</ol>
</blockquote>
<h2 id="Ablation-Studies（消融实验）"><a href="#Ablation-Studies（消融实验）" class="headerlink" title="Ablation Studies（消融实验）"></a>Ablation Studies（消融实验）</h2><hr>
<p>🌟 一、Ablation Studies 的研究目的</p>
<p>消融实验（Ablation Study）是机器学习论文中常见的验证环节。它的目标是：</p>
<blockquote>
<p><strong>验证模型中每个设计是否真的有用，还是可有可无。</strong></p>
</blockquote>
<p>在本文中，作者主要想弄清楚以下问题：</p>
<ol>
<li><strong>Recall@K 的选择（K取值）是否影响结果？</strong></li>
<li><strong>不同背景建模方式（无背景、SB、LAB）谁更好？</strong></li>
<li><strong>语义空间稠密化（DSES）对性能提升有多大？</strong></li>
<li><strong>不同 IoU 阈值（0.4 vs 0.5）下性能是否稳定？</strong></li>
</ol>
<hr>
<p><strong>🧩 二、实验 1：K 值（Recall@K）对性能的影响</strong></p>
<p>💡 实验设计</p>
<p>Recall@K 是论文的主要指标。这里作者测试了不同的 K 值（K&#x3D;50、100、200、All）对 Recall 的影响。</p>
<p>📊 实验结果（以 MSCOCO 为例）</p>
<table>
<thead>
<tr>
<th>K 值</th>
<th>Recall@K (Baseline)</th>
<th>Recall@K (SB)</th>
</tr>
</thead>
<tbody><tr>
<td>50</td>
<td>18.92</td>
<td>20.60</td>
</tr>
<tr>
<td>100</td>
<td>22.14</td>
<td>24.39</td>
</tr>
<tr>
<td>200</td>
<td>23.00</td>
<td>25.00</td>
</tr>
<tr>
<td>All</td>
<td>24.00</td>
<td>25.50</td>
</tr>
</tbody></table>
<p>🔍 分析解读</p>
<ul>
<li>当 <strong>K 从 50 增加到 100</strong>，Recall 明显上升；</li>
<li>当 <strong>K 超过 100</strong>，增幅变得极小（几乎饱和）；</li>
<li>因此作者选择 <strong>K&#x3D;100</strong> 作为标准评测点。</li>
</ul>
<p>📘 <strong>原因：</strong></p>
<blockquote>
<p>Recall@100 能在“足够检测出目标”与“避免噪声过多”之间取得最佳平衡。<br> K&#x3D;50 时召回偏低，K&gt;100 时只增加少量噪声检测。</p>
</blockquote>
<p>🧩 <strong>结论：</strong></p>
<blockquote>
<p>论文后续所有结果（包括表 1）都基于 Recall@100。</p>
</blockquote>
<hr>
<p><strong>🧱 三、实验 2：不同 IoU 阈值的影响</strong></p>
<p>💡 实验目的</p>
<p>在目标检测中，IoU（Intersection over Union）阈值用于判断检测是否“命中”目标。<br> 作者测试了 <strong>IoU &#x3D; 0.4、0.5、0.6</strong> 三种阈值，看看结果是否稳定。</p>
<p>📊 实验结果（VisualGenome 上的 Recall@100）</p>
<table>
<thead>
<tr>
<th>IoU 阈值</th>
<th>Baseline</th>
<th>LAB</th>
</tr>
</thead>
<tbody><tr>
<td>0.4</td>
<td>6.01</td>
<td>6.30</td>
</tr>
<tr>
<td>0.5</td>
<td>5.19</td>
<td>5.40</td>
</tr>
<tr>
<td>0.6</td>
<td>4.10</td>
<td>4.30</td>
</tr>
</tbody></table>
<p>🔍 分析解读</p>
<ul>
<li>随着 IoU 提高，Recall 自然下降（更严格）；</li>
<li>但<strong>LAB 一直比 Baseline 高约 0.2–0.3 个百分点</strong>；</li>
<li>说明 LAB 的改进<strong>在不同 IoU 阈值下都稳健</strong>。</li>
</ul>
<p>🧩 <strong>结论：</strong></p>
<blockquote>
<p>模型性能不依赖特定 IoU 阈值；<br> LAB 模型的优势不仅是偶然，而是对不同匹配条件都有效。</p>
</blockquote>
<hr>
<p><strong>🧠 四、实验 3：背景建模方式的消融</strong></p>
<p>💡 实验目的</p>
<p>验证三种背景处理方式的区别与效果：</p>
<ul>
<li><strong>无背景</strong>（Baseline）；</li>
<li><strong>固定背景类（SB）</strong>；</li>
<li><strong>潜在背景赋值（LAB）</strong>。</li>
</ul>
<p>📊 实验结果总结（MSCOCO vs VG）</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>MSCOCO Recall@100</th>
<th>VG Recall@100</th>
<th>背景策略说明</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>22.14</td>
<td>5.19</td>
<td>无背景类</td>
</tr>
<tr>
<td>SB</td>
<td>24.39</td>
<td>4.09</td>
<td>静态背景</td>
</tr>
<tr>
<td>LAB</td>
<td>20.52</td>
<td><strong>5.40</strong></td>
<td>潜在赋值背景</td>
</tr>
</tbody></table>
<p>🔍 分析</p>
<ul>
<li>在 <strong>MSCOCO</strong> 上，SB 最佳；原因是训练集背景干净。</li>
<li>在 <strong>VG</strong> 上，LAB 最佳；原因是背景污染严重，LAB 能用语义扩展分解背景。</li>
</ul>
<p>🧩 <strong>结论：</strong></p>
<blockquote>
<p>背景建模策略与数据特性密切相关：</p>
<ul>
<li>干净数据 → SB 更好；</li>
<li>复杂语义场景 → LAB 更鲁棒。</li>
</ul>
</blockquote>
<hr>
<p><strong>🪐 五、实验 4：语义空间稠密化（DSES）效果验证</strong></p>
<p>💡 实验目的</p>
<p>验证引入外部数据集（OpenImages）进行 <strong>语义稠密化</strong> 是否有效。</p>
<p>📊 实验结果（MSCOCO）</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>Seen 类</th>
<th>Unseen 类</th>
<th>Recall@100</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>48</td>
<td>17</td>
<td>22.14</td>
</tr>
<tr>
<td>DSES</td>
<td>378</td>
<td>17</td>
<td><strong>27.19</strong></td>
</tr>
</tbody></table>
<p>🔍 分析</p>
<ul>
<li>增加外部类数量 → 语义空间更密集；</li>
<li>模型更好地学习了“视觉–语义映射”，从而提升未见类检测性能；</li>
<li>提升幅度约 +5%，显著。</li>
</ul>
<p>🧩 <strong>结论：</strong></p>
<blockquote>
<p>稠密语义嵌入显著提升模型泛化性能，是论文最强的改进策略之一。</p>
</blockquote>
<hr>
<p><strong>🧩 六、实验 5：Generalized ZSD 的平衡性测试</strong></p>
<p>作者还对 GZSD（含 seen+unseen）做了平衡性分析，考察不同模型对类偏置的敏感度。</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>Recall_seen</th>
<th>Recall_unseen</th>
<th>H-Mean</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>16.93</td>
<td>8.91</td>
<td>11.67</td>
</tr>
<tr>
<td>LAB</td>
<td>14.54</td>
<td>10.57</td>
<td>12.24</td>
</tr>
<tr>
<td>DSES</td>
<td>15.02</td>
<td>15.32</td>
<td><strong>15.17</strong></td>
</tr>
</tbody></table>
<p>🔍 <strong>分析</strong></p>
<ul>
<li>Baseline：偏向 seen 类；</li>
<li>LAB：稍改善 unseen，但 seen 有轻微损失；</li>
<li>DSES：最平衡，泛化性最强。</li>
</ul>
<p>🧩 <strong>结论：</strong></p>
<blockquote>
<p>稠密语义学习（DSES）不仅提升未见类检测，也能<strong>缓解类偏置</strong>，在 GZSD 中表现最稳。</p>
</blockquote>
<hr>
<p><strong>📘 七、论文中的实验设计逻辑总结</strong></p>
<table>
<thead>
<tr>
<th>实验内容</th>
<th>变量</th>
<th>数据集</th>
<th>结论</th>
</tr>
</thead>
<tbody><tr>
<td>K 值</td>
<td>50&#x2F;100&#x2F;200&#x2F;All</td>
<td>COCO</td>
<td>K&#x3D;100 最平衡</td>
</tr>
<tr>
<td>IoU 阈值</td>
<td>0.4–0.6</td>
<td>VG</td>
<td>LAB 稳健</td>
</tr>
<tr>
<td>背景建模</td>
<td>Baseline &#x2F; SB &#x2F; LAB</td>
<td>COCO &#x2F; VG</td>
<td>数据集特性决定优劣</td>
</tr>
<tr>
<td>稠密语义</td>
<td>DSES</td>
<td>COCO</td>
<td>明显提升</td>
</tr>
<tr>
<td>类偏置</td>
<td>GZSD</td>
<td>COCO</td>
<td>DSES 平衡性最佳</td>
</tr>
</tbody></table>
<hr>
<p><strong>🎓 八、教授总结</strong></p>
<blockquote>
<p><strong>Ablation Studies 的意义在于“证明设计是必要的”。</strong><br> 通过逐项对比，作者证明了：</p>
<p>1️⃣ Recall@100 是稳定且合理的指标；<br> 2️⃣ 背景建模方式对不同数据集有不同适配性；<br> 3️⃣ 语义空间稠密化（DSES）对泛化性能提升显著；<br> 4️⃣ LAB 在语义复杂场景中有效缓解背景污染；<br> 5️⃣ 模型在不同 IoU 阈值下表现稳定，说明泛化良好。</p>
</blockquote>
<hr>
<h2 id="Qualitative-Results（定性结果）"><a href="#Qualitative-Results（定性结果）" class="headerlink" title="Qualitative Results（定性结果）"></a>Qualitative Results（定性结果）</h2><p> 这是整篇论文中最直观的一部分，作者用图像示例展示了他们的模型在真实图像上的检测效果，帮助我们理解模型<strong>能检测出哪些未见类</strong>、<strong>在哪些情况下失败</strong>、以及<strong>为什么成功或失败</strong>。<br> 我会结合论文中的图（Figure 2 与 Figure 3）内容，为你详细讲解这些结果所体现的原理和意义。</p>
<hr>
<p>🌟 一、章节目的：为什么需要定性分析？</p>
<p>在前几节（4.1–4.5）中，作者主要通过 <strong>量化指标（Recall@100, H-Mean）</strong> 来衡量模型性能。<br> 然而这些数字虽然能说明性能变化，但不能<strong>直观展示模型到底学到了什么</strong>。</p>
<p>因此，作者在 4.6 节中加入了图像可视化结果，用于说明：</p>
<ol>
<li>模型确实能检测出<strong>未在训练中出现的类别（unseen classes）</strong>；</li>
<li>模型的检测结果<strong>与语义相似性相关</strong>；</li>
<li>LAB 和 DSES 在复杂场景中的行为；</li>
<li>模型的<strong>常见错误类型</strong>（尤其是语义混淆）。</li>
</ol>
<hr>
<p>🖼️ 二、Figure 2：ZSD 检测结果可视化</p>
<p>在这张图中，作者展示了 <strong>MSCOCO</strong> 和 <strong>VisualGenome</strong> 数据集上检测出的若干实例。</p>
<p>✅ 成功案例</p>
<p>这些示例证明了模型确实“迁移”了语义知识：</p>
<table>
<thead>
<tr>
<th>未见类</th>
<th>模型如何识别</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><strong>shoulder（肩膀）</strong></td>
<td>模型从“arm、hand”等已见类学到人体部位的语义关系</td>
<td>表明模型掌握了人体结构的上下文关系</td>
</tr>
<tr>
<td><strong>skirt（裙子）</strong></td>
<td>模型从“pants、shirt”等已见类泛化而来</td>
<td>表明模型理解“服装类”的语义子空间</td>
</tr>
<tr>
<td><strong>vegetation（植被）</strong></td>
<td>模型从“tree、grass”等类推理出来</td>
<td>显示模型能捕捉到自然环境的语义聚类</td>
</tr>
<tr>
<td><strong>hat（帽子）</strong></td>
<td>虽未见过，但从“head、hair”中学到“头部装饰”的关系</td>
<td>展示语义嵌入的迁移能力</td>
</tr>
</tbody></table>
<p>这些成功检测的结果通常有两个特点：</p>
<ol>
<li><strong>语义相近</strong>：unseen 类与 seen 类在 GloVe 向量空间中距离较近；</li>
<li><strong>外观相似</strong>：视觉特征（颜色、纹理、形状）具有共性。</li>
</ol>
<p>这表明论文提出的视觉–语义嵌入确实学会了跨类推理（semantic transfer）。</p>
<hr>
<p>❌ 失败案例</p>
<p>作者也展示了模型的错误预测，用于分析当前方法的局限性。</p>
<table>
<thead>
<tr>
<th>错误类型</th>
<th>示例</th>
<th>原因分析</th>
</tr>
</thead>
<tbody><tr>
<td><strong>语义混淆</strong></td>
<td>把“zebra（斑马）”预测成“horse（马）”</td>
<td>二者语义相近且外观极其相似，说明语义空间过度依赖视觉相似性</td>
</tr>
<tr>
<td><strong>细粒度错误</strong></td>
<td>“arm” 被识别为 “leg”；“table” 被识别为 “desk”</td>
<td>模型缺乏细粒度区分能力，语义空间无法区分同类细分概念</td>
</tr>
<tr>
<td><strong>背景干扰</strong></td>
<td>“boat” 被误识别为 “car” 或 “train”</td>
<td>复杂背景中的上下文干扰视觉特征</td>
</tr>
<tr>
<td><strong>尺度问题</strong></td>
<td>小目标（如“earring”）未检测出</td>
<td>候选框生成器（EdgeBoxes）难以捕获极小目标</td>
</tr>
</tbody></table>
<p>这些错误揭示了两个核心挑战：</p>
<ol>
<li><strong>语义嵌入的局限</strong>：词向量仅反映语义相似性，缺乏视觉差异建模；</li>
<li><strong>检测框架的缺陷</strong>：EdgeBoxes 的 proposal 粒度固定，对小目标或重叠目标不敏感。</li>
</ol>
<hr>
<p>🧠 三、Figure 3：不同模型可视化对比（LAB vs SB vs DSES）</p>
<p>这部分可视化展示了三种不同模型（SB、LAB、DSES）的预测差异。</p>
<p>🔹 (1) Static Background (SB)</p>
<ul>
<li>检测框较干净，漏检少；</li>
<li>但对“未见类”的检测明显不足；</li>
<li>很多未见物体（如“hat”、“book”）被错误标为“background”。</li>
</ul>
<p><strong>解释</strong>：SB 的背景嵌入是固定的 → 模型学会把所有未知语义当“非物体”，无法发现真正的 unseen 类。</p>
<hr>
<p>🔹 (2) Latent Assignment-Based (LAB)</p>
<ul>
<li>检测结果更加丰富；</li>
<li>能发现一些原本被忽略的未见类；</li>
<li>但也带来一些伪标签噪声（如误识别“shadow”为“car”）。</li>
</ul>
<p><strong>解释</strong>：LAB 通过迭代背景语义分配，使得模型“敢于尝试”更多语义匹配，因此召回提升，但精度略降。</p>
<hr>
<p>🔹 (3) DSES</p>
<ul>
<li>检测框数量与 LAB 接近；</li>
<li>精度和语义一致性更高；</li>
<li>能正确区分视觉上相似但语义不同的类（例如“zebra” vs “horse”）。</li>
</ul>
<p><strong>解释</strong>：DSES 通过外部类数据（OpenImages）稠密化语义空间，使语义距离的几何结构更加平滑，减少语义混淆。</p>
<hr>
<p>🌈 四、作者的观察总结</p>
<p>作者从这些图像示例中归纳出以下重要观察：</p>
<table>
<thead>
<tr>
<th>观察</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>模型确实学到了跨语义迁移</td>
<td>视觉特征能泛化到未见类语义向量</td>
</tr>
<tr>
<td>背景处理方式显著影响检测质量</td>
<td>SB 过度压制未见类，LAB 改善召回</td>
</tr>
<tr>
<td>稠密语义嵌入减少语义误判</td>
<td>DSES 缩短语义空间的“空洞距离”，提升泛化一致性</td>
</tr>
<tr>
<td>模型仍易受视觉相似性干扰</td>
<td>需要更细粒度的视觉差异建模</td>
</tr>
</tbody></table>
<hr>
<p>📘 五、这部分的学术意义</p>
<p>这一节虽然只是展示几张图，却非常关键。<br> 它说明了：</p>
<ol>
<li>模型的<strong>可解释性（interpretability）</strong>；</li>
<li>不同方法（SB&#x2F;LAB&#x2F;DSES）在图像层面的实际表现；</li>
<li>零样本检测确实能在<strong>真实复杂场景</strong>中识别出未见类。</li>
</ol>
<p>这些可视化结果让论文的理论部分（语义嵌入、背景建模）变得更加可信。</p>
<hr>
<p>🧩 六、作者提出的后续改进方向</p>
<p>在这一节的结尾，作者提出两个思考：</p>
<ol>
<li><strong>细粒度语义建模</strong>：<br> 当前模型依赖词向量（GloVe），但这种嵌入太粗糙。未来可使用 WordNet 层级结构或属性向量（attribute vectors）增强语义区分力。</li>
<li><strong>开放词汇检测（Open-Vocabulary Detection）</strong>：<br> 本研究是该方向的早期探索。未来可以在更大词汇空间中，用文本描述或语言模型嵌入（如 BERT）实现真正的开放检测。</li>
</ol>
<hr>
<p>🎓 七、教授总结</p>
<blockquote>
<p><strong>定性分析告诉我们：</strong></p>
<ul>
<li>模型不仅能“数值上”检测未见类，还能“视觉上”识别它们；</li>
<li>语义迁移确实有效，但容易受视觉相似度干扰；</li>
<li>不同的背景策略导致检测行为截然不同；</li>
<li>语义稠密化（DSES）是最稳健的解决方案；</li>
<li>这部分实验直接验证了零样本检测在真实世界中的可行性。</li>
</ul>
</blockquote>
<hr>
<h1 id="Conclusion（结论）"><a href="#Conclusion（结论）" class="headerlink" title="Conclusion（结论）"></a>Conclusion（结论）</h1><p>🌟 一、章节定位：总结整篇论文的贡献</p>
<p>作者在开篇重申了本文的主题：</p>
<blockquote>
<p>“我们首次系统地研究了 <strong>Zero-Shot Object Detection (ZSD)</strong> 这一新问题。”</p>
</blockquote>
<p>这句话其实标志着论文的核心创新点——<br> 在此之前，**零样本学习（Zero-Shot Learning, ZSL）**主要应用于图像分类任务（Image Classification），而不是检测（Detection）。本文首次把这一理念扩展到目标检测中，使模型能够在未见过的类别上进行检测。</p>
<hr>
<p>🧠 二、主要贡献总结（Key Contributions）</p>
<p>作者将研究工作总结为三个关键创新点：</p>
<p><strong>1️⃣ 提出了全新的问题定义：Zero-Shot Object Detection (ZSD)</strong></p>
<ul>
<li>传统检测模型依赖大量有标注的训练样本，而现实中我们无法为所有类别都提供标注。</li>
<li>作者定义了 <strong>ZSD</strong>：模型仅通过已见类（seen classes）的训练，就能检测未见类（unseen classes）的物体。</li>
<li>这是一个更贴近现实世界的检测问题，因为新类别不断出现（例如新车型、新物种、新商品）。</li>
</ul>
<blockquote>
<p>✅ <strong>意义：</strong><br> 将“零样本学习”从分类问题扩展到检测问题，为后续开放词汇检测（Open-Vocabulary Detection）奠定了基础。</p>
</blockquote>
<hr>
<p><strong>2️⃣ 研究并提出了背景建模问题及解决方案</strong></p>
<p>在 ZSD 中，<strong>背景（background）</strong> 的定义是一个核心挑战。<br> 传统检测器依靠“背景类”区分物体与非物体，但在 ZSD 中，“背景”可能包含未见类物体——这会导致训练时<strong>误把未见类学成“背景”</strong>。</p>
<p>作者提出了两种背景感知模型：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>思想</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>SB (Static Background)</strong></td>
<td>使用固定的背景嵌入向量，将所有非物体区域归为一类</td>
<td>适合干净数据集（如 MSCOCO）</td>
</tr>
<tr>
<td><strong>LAB (Latent Assignment-Based)</strong></td>
<td>用 EM-like 迭代方法，为背景框动态分配伪标签（潜在类别）</td>
<td>适合复杂场景（如 VisualGenome）</td>
</tr>
</tbody></table>
<blockquote>
<p>✅ <strong>意义：</strong><br> 这是第一篇系统探讨“背景污染（background contamination）”的 ZSD 论文，<br> 并提出能有效缓解的建模方法（LAB）。</p>
</blockquote>
<hr>
<p><strong>3️⃣ 提出了语义稠密化策略（DSES）以缓解语义稀疏问题</strong></p>
<p>ZSD 依赖语义嵌入空间（如 GloVe 向量）来实现视觉–语义映射。<br> 然而，当训练类别太少时，这个语义空间会非常“稀疏”（semantic sparsity），导致模型泛化性差。</p>
<p>为此，作者提出：</p>
<blockquote>
<p><strong>Densely Sampled Embedding Space (DSES)</strong><br> 利用外部数据集（如 OpenImages）引入更多语义相关类，以填补语义空间空白。</p>
</blockquote>
<p>实验表明：</p>
<ul>
<li>在类较少的 <strong>MSCOCO</strong> 上，DSES 提升 Recall@100 高达 +5%。</li>
<li>在类丰富的 <strong>VisualGenome</strong> 上提升略小，但仍有稳定收益。</li>
</ul>
<blockquote>
<p>✅ <strong>意义：</strong><br> 证明了语义空间的“密度”是零样本检测性能的关键影响因素。</p>
</blockquote>
<hr>
<p>📊 三、实验发现总结（Findings Summary）</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>主要优势</th>
<th>典型数据集表现</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Baseline</strong></td>
<td>简单基准模型，可检测 seen 类</td>
<td>最低 Recall</td>
</tr>
<tr>
<td><strong>SB</strong></td>
<td>背景干净时有效（COCO）</td>
<td>Recall 提升 +2%</td>
</tr>
<tr>
<td><strong>LAB</strong></td>
<td>背景复杂时表现最佳（VG）</td>
<td>Recall 提升 +0.2–0.3%</td>
</tr>
<tr>
<td><strong>DSES</strong></td>
<td>全局语义泛化最强</td>
<td>Recall 提升 +5% (COCO)</td>
</tr>
</tbody></table>
<p>此外：</p>
<ul>
<li>在 <strong>GZSD</strong>（Generalized ZSD） 场景中，DSES 模型在 seen&#x2F;unseen 上保持最平衡性能；</li>
<li><strong>Recall@100</strong> 被证明是最合理的检测指标；</li>
<li><strong>LAB 模型</strong> 能显著缓解“背景污染”现象；</li>
<li><strong>DSES 模型</strong> 改善了 unseen 类检测与泛化能力。</li>
</ul>
<hr>
<p>🧩 四、研究局限性（Limitations）</p>
<p>作者在结论中非常诚实地指出了模型的局限性：</p>
<ol>
<li><strong>语义嵌入精度有限</strong><ul>
<li>模型依赖词向量（GloVe），它只能表示语义相关性，但无法捕捉细粒度差异（如“horse” vs “zebra”）。</li>
<li>这也是论文中出现混淆预测的根源。</li>
</ul>
</li>
<li><strong>对背景伪标签依赖较强</strong><ul>
<li>LAB 模型的伪标签可能带来噪声，尤其在语义空间稀疏时（MSCOCO）。</li>
<li>没有高置信度筛选机制，容易错误扩展背景。</li>
</ul>
</li>
<li><strong>未考虑层级语义结构</strong><ul>
<li>类别间的层次关系（如 “vehicle → car → sedan”）未在语义空间中体现；</li>
<li>未来可以结合 WordNet 层次结构或图神经网络（GNN）改进。</li>
</ul>
</li>
</ol>
<hr>
<p>🔮 五、未来研究方向（Future Work）</p>
<p>作者在最后提出了三个重要的未来方向：</p>
<p><strong>1️⃣ 使用更强的语义表征模型</strong></p>
<ul>
<li>当前使用的 GloVe 词向量是静态的；</li>
<li>未来可以使用上下文相关的语言模型（如 BERT、CLIP、GPT embedding）；</li>
<li>这样模型能更准确地理解语义层级与上下文关系。</li>
</ul>
<blockquote>
<p>💬 这直接启发了后来的 “Open-Vocabulary Detection” 和 “Vision-Language Models”。</p>
</blockquote>
<hr>
<p><strong>2️⃣ 探索层次化或图结构语义空间</strong></p>
<ul>
<li>使用 <strong>WordNet 层级结构</strong> 或 <strong>语义图（Semantic Graph）</strong>；</li>
<li>通过建模“父子类关系”，让模型理解“zebra 属于 animal”；</li>
<li>有助于避免语义空间中“孤立未见类”的问题。</li>
</ul>
<hr>
<p><strong>3️⃣ 结合语言描述（Textual Descriptions）进行多模态学习</strong></p>
<ul>
<li>除了词向量，还可使用句子级别描述（如“a horse with stripes is a zebra”）；</li>
<li>将文本特征与视觉特征联合训练，可进一步提高未见类识别能力；</li>
<li>这为后来 <strong>CLIP（2021）</strong> 等模型的发展奠定了思路。</li>
</ul>
<hr>
<p>🎓 六、教授总结：论文的科学价值与地位</p>
<table>
<thead>
<tr>
<th>维度</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td><strong>研究创新性</strong></td>
<td>首次定义并系统研究 Zero-Shot Object Detection 问题</td>
</tr>
<tr>
<td><strong>方法论贡献</strong></td>
<td>提出两类背景建模方法（SB, LAB）与稠密语义采样策略（DSES）</td>
</tr>
<tr>
<td><strong>实验验证</strong></td>
<td>多数据集对比 + 消融分析 + 定性可视化</td>
</tr>
<tr>
<td><strong>影响力</strong></td>
<td>为后续开放词汇检测（OVD）与视觉-语言模型奠定方向</td>
</tr>
<tr>
<td><strong>核心思想</strong></td>
<td>通过视觉-语义映射让模型“理解”而非“记忆”类别</td>
</tr>
</tbody></table>
<hr>
<p>📘 七、延伸意义：从 ZSD → Open-Vocabulary Detection</p>
<p>事实上，这篇论文的影响远超其发表时间。<br> 在后续几年中，许多视觉-语言模型（如 CLIP、ViLD、Detic）都<strong>直接继承了本文的思想</strong>：</p>
<table>
<thead>
<tr>
<th>演进方向</th>
<th>新增技术</th>
<th>概念承袭自本文</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ViLD (2021)</strong></td>
<td>CLIP 语义嵌入 + 视觉检测</td>
<td>继承 ZSD 的语义投影思想</td>
</tr>
<tr>
<td><strong>Detic (2022)</strong></td>
<td>文本描述监督 + 扩展类检测</td>
<td>类似 DSES 的语义稠密化</td>
</tr>
<tr>
<td><strong>GLIP (2022)</strong></td>
<td>文本-视觉联合训练</td>
<td>延伸 LAB 的语义赋值理念</td>
</tr>
<tr>
<td><strong>Grounding DINO (2023)</strong></td>
<td>开放词汇检测 + 匹配文本描述</td>
<td>直接延续 ZSD 的评估思想</td>
</tr>
</tbody></table>
<p>可以说，这篇论文是 “Open-Vocabulary Detection” 的奠基工作之一。</p>
<hr>
<p>非常好 👍<br> 下面我们来做论文 <strong>《Zero-Shot Object Detection》</strong> 的<strong>整篇总结（1–5章总复习版）</strong>。<br> 这相当于一次“教授式复盘讲解”——我将从整体框架、逻辑线、核心创新、实验结论到学术影响，系统地帮你整理出一份结构化复习笔记，适合用来写读书报告或做学术汇报。</p>
<hr>
<h1 id="🧩-论文总览：《Zero-Shot-Object-Detection》"><a href="#🧩-论文总览：《Zero-Shot-Object-Detection》" class="headerlink" title="🧩 论文总览：《Zero-Shot Object Detection》"></a>🧩 论文总览：《Zero-Shot Object Detection》</h1><p><strong>作者</strong>：Ankan Bansal, Karan Sikka, Gaurav Sharma, Rama Chellappa<br> <strong>会议</strong>：ECCV 2018<br> <strong>关键词</strong>：Zero-Shot Learning, Object Detection, Visual-Semantic Embedding, Background Modeling</p>
<hr>
<h2 id="🧠-一、研究背景与动机（Chapter-1-Introduction）"><a href="#🧠-一、研究背景与动机（Chapter-1-Introduction）" class="headerlink" title="🧠 一、研究背景与动机（Chapter 1: Introduction）"></a>🧠 一、研究背景与动机（Chapter 1: Introduction）</h2><h3 id="🌍-背景"><a href="#🌍-背景" class="headerlink" title="🌍 背景"></a>🌍 背景</h3><ul>
<li>传统物体检测（如 Faster R-CNN、YOLO）依赖<strong>大量标注数据</strong>。</li>
<li>现实中，新类别不断出现（如新车型、新物种），标注成本高昂。</li>
<li>零样本学习（Zero-Shot Learning, ZSL）允许模型识别<strong>未见过的类别</strong>，通过<strong>语义嵌入</strong>（词向量、属性）实现知识迁移。</li>
<li>但 ZSL 主要应用于<strong>图像分类</strong>，尚未解决<strong>检测</strong>（定位+分类）问题。</li>
</ul>
<h3 id="🎯-本文目标"><a href="#🎯-本文目标" class="headerlink" title="🎯 本文目标"></a>🎯 本文目标</h3><blockquote>
<p>将零样本学习扩展到物体检测领域，提出 <strong>Zero-Shot Object Detection (ZSD)</strong> 任务。</p>
</blockquote>
<h3 id="⚠️-关键挑战"><a href="#⚠️-关键挑战" class="headerlink" title="⚠️ 关键挑战"></a>⚠️ 关键挑战</h3><ol>
<li><strong>背景污染</strong>：未见类在训练集中会被错误标记为“背景”。</li>
<li><strong>语义空间稀疏</strong>：训练类太少时，语义嵌入空间覆盖不全。</li>
</ol>
<hr>
<h2 id="🧩-二、相关工作（Chapter-2-Related-Work）"><a href="#🧩-二、相关工作（Chapter-2-Related-Work）" class="headerlink" title="🧩 二、相关工作（Chapter 2: Related Work）"></a>🧩 二、相关工作（Chapter 2: Related Work）</h2><h3 id="🧱-涉及领域"><a href="#🧱-涉及领域" class="headerlink" title="🧱 涉及领域"></a>🧱 涉及领域</h3><ol>
<li><strong>词嵌入（Word Embeddings）</strong>：如 word2vec、GloVe，用于建立类间语义关系。</li>
<li><strong>零样本分类（ZSL）</strong>：基于视觉–语义对齐，将图像特征投影到语义空间。</li>
<li><strong>物体检测（Object Detection）</strong>：R-CNN 系列等全监督方法。</li>
<li><strong>多模态学习（Multi-Modal Learning）</strong>：将视觉和语言嵌入对齐。</li>
</ol>
<h3 id="✨-本文创新"><a href="#✨-本文创新" class="headerlink" title="✨ 本文创新"></a>✨ 本文创新</h3><blockquote>
<p>与以往不同，本研究首次将<strong>视觉–语义映射</strong>引入检测框架，<br> 并系统分析了背景建模与语义稠密化在零样本检测中的作用。</p>
</blockquote>
<hr>
<h2 id="⚙️-三、方法（Chapter-3-Approach）"><a href="#⚙️-三、方法（Chapter-3-Approach）" class="headerlink" title="⚙️ 三、方法（Chapter 3: Approach）"></a>⚙️ 三、方法（Chapter 3: Approach）</h2><p>整个方法分为三个部分：<strong>ZSD 基线模型 + 背景建模 + 语义稠密化。</strong></p>
<h3 id="3-1-基线模型（Baseline-ZSD）"><a href="#3-1-基线模型（Baseline-ZSD）" class="headerlink" title="3.1 基线模型（Baseline ZSD）"></a>3.1 基线模型（Baseline ZSD）</h3><ul>
<li>使用 Inception-ResNet v2 提取候选框特征；</li>
<li>候选框投影到语义空间（GloVe 向量）；</li>
<li>使用**最大间隔损失（max-margin loss）**确保真实类相似度高于其他类；</li>
<li>测试时：计算与未见类语义向量的相似度，取最高者为预测类。</li>
</ul>
<p>$$<br>\hat{y_i} &#x3D; \arg\max_{j\in U} \cos(W_p φ(b_i), w_j)<br>$$</p>
<hr>
<h3 id="3-2-背景感知模型（Background-Aware-Models）"><a href="#3-2-背景感知模型（Background-Aware-Models）" class="headerlink" title="3.2 背景感知模型（Background-Aware Models）"></a>3.2 背景感知模型（Background-Aware Models）</h3><h4 id="a-SB-Static-Background"><a href="#a-SB-Static-Background" class="headerlink" title="(a) SB (Static Background)"></a>(a) <strong>SB (Static Background)</strong></h4><ul>
<li>为背景定义一个固定嵌入向量。</li>
<li>训练时，所有非物体区域都映射到该背景向量。</li>
<li>简单有效，但会将未见类误学为背景。</li>
</ul>
<h4 id="b-LAB-Latent-Assignment-Based"><a href="#b-LAB-Latent-Assignment-Based" class="headerlink" title="(b) LAB (Latent Assignment-Based)"></a>(b) <strong>LAB (Latent Assignment-Based)</strong></h4><ul>
<li>采用 EM-like 迭代训练：<ol>
<li>先用当前模型预测背景框的语义标签；</li>
<li>将高置信度伪标签加入训练；</li>
<li>重复迭代更新模型。</li>
</ol>
</li>
<li>背景被分解为多个语义相关的潜在类别，减少污染。</li>
</ul>
<hr>
<h3 id="3-3-DSES-Densely-Sampled-Embedding-Space"><a href="#3-3-DSES-Densely-Sampled-Embedding-Space" class="headerlink" title="3.3 DSES (Densely Sampled Embedding Space)"></a>3.3 <strong>DSES (Densely Sampled Embedding Space)</strong></h3><ul>
<li>通过引入外部数据集（OpenImages），增加语义空间密度；</li>
<li>只使用不属于测试类的外部类别，避免信息泄漏；</li>
<li>改善模型的语义泛化能力。</li>
</ul>
<hr>
<h2 id="🧮-四、实验（Chapter-4）"><a href="#🧮-四、实验（Chapter-4）" class="headerlink" title="🧮 四、实验（Chapter 4）"></a>🧮 四、实验（Chapter 4）</h2><h3 id="4-1-实现细节"><a href="#4-1-实现细节" class="headerlink" title="4.1 实现细节"></a>4.1 实现细节</h3><ul>
<li>候选框生成：EdgeBoxes</li>
<li>Backbone：Inception-ResNet v2</li>
<li>词向量：GloVe (300维)</li>
<li>优化器：Adam</li>
<li>主要指标：Recall@K (IoU≥0.5)</li>
</ul>
<hr>
<h3 id="4-2-评估协议（Evaluation-Protocol）"><a href="#4-2-评估协议（Evaluation-Protocol）" class="headerlink" title="4.2 评估协议（Evaluation Protocol）"></a>4.2 评估协议（Evaluation Protocol）</h3><ol>
<li><strong>ZSD</strong>：测试集中只包含未见类；指标 Recall@100。</li>
<li><strong>GZSD</strong>（Generalized ZSD）：测试集含 seen+unseen；<ul>
<li>指标：Recall_s、Recall_u、调和平均 HH。</li>
</ul>
</li>
<li>使用 Recall 而非 mAP，因为 ZSD 置信度分布不稳定。</li>
</ol>
<hr>
<h3 id="4-3-结果与讨论（Results-and-Discussion）"><a href="#4-3-结果与讨论（Results-and-Discussion）" class="headerlink" title="4.3 结果与讨论（Results and Discussion）"></a>4.3 结果与讨论（Results and Discussion）</h3><table>
<thead>
<tr>
<th>模型</th>
<th>MSCOCO Recall@100</th>
<th>VG Recall@100</th>
</tr>
</thead>
<tbody><tr>
<td>Baseline</td>
<td>22.14</td>
<td>5.19</td>
</tr>
<tr>
<td>SB</td>
<td>24.39</td>
<td>4.09</td>
</tr>
<tr>
<td>LAB</td>
<td>20.52</td>
<td><strong>5.40</strong></td>
</tr>
<tr>
<td>DSES</td>
<td><strong>27.19</strong></td>
<td>4.75</td>
</tr>
</tbody></table>
<h4 id="📌-分析："><a href="#📌-分析：" class="headerlink" title="📌 分析："></a>📌 分析：</h4><ul>
<li><strong>MSCOCO</strong>：SB 最优（背景干净），DSES 提升最大（+5%）。</li>
<li><strong>VG</strong>：LAB 最优（背景污染严重，潜在赋值有优势）。</li>
</ul>
<p><strong>在 GZSD 中：</strong><br> DSES 在 seen&#x2F;unseen 间最平衡，H-Mean 最高。</p>
<hr>
<h3 id="4-5-消融实验（Ablation-Studies）"><a href="#4-5-消融实验（Ablation-Studies）" class="headerlink" title="4.5 消融实验（Ablation Studies）"></a>4.5 消融实验（Ablation Studies）</h3><table>
<thead>
<tr>
<th>变量</th>
<th>测试内容</th>
<th>主要结论</th>
</tr>
</thead>
<tbody><tr>
<td>K 值</td>
<td>50&#x2F;100&#x2F;200&#x2F;All</td>
<td>K&#x3D;100 最稳，平衡召回与噪声</td>
</tr>
<tr>
<td>IoU 阈值</td>
<td>0.4–0.6</td>
<td>模型性能稳定，LAB 稍优</td>
</tr>
<tr>
<td>背景方式</td>
<td>Baseline &#x2F; SB &#x2F; LAB</td>
<td>SB 适合干净集，LAB 适合复杂集</td>
</tr>
<tr>
<td>语义稠密化</td>
<td>加入 OpenImages</td>
<td>Recall 提升显著（+5%）</td>
</tr>
</tbody></table>
<hr>
<h3 id="4-6-定性结果（Qualitative-Results）"><a href="#4-6-定性结果（Qualitative-Results）" class="headerlink" title="4.6 定性结果（Qualitative Results）"></a>4.6 定性结果（Qualitative Results）</h3><ul>
<li>成功检测 unseen 类如：<ul>
<li>“shoulder”、“skirt”、“vegetation”、“hat”；</li>
</ul>
</li>
<li>失败案例：<ul>
<li>“zebra→horse”、“arm→leg”；</li>
</ul>
</li>
<li>原因：语义混淆 + 视觉相似；</li>
<li>LAB 减少背景误判，DSES 提升语义泛化。</li>
</ul>
<hr>
<h2 id="🧩-五、结论（Chapter-5-Conclusion）"><a href="#🧩-五、结论（Chapter-5-Conclusion）" class="headerlink" title="🧩 五、结论（Chapter 5: Conclusion）"></a>🧩 五、结论（Chapter 5: Conclusion）</h2><h3 id="📘-主要结论"><a href="#📘-主要结论" class="headerlink" title="📘 主要结论"></a>📘 主要结论</h3><ol>
<li>首次系统提出 <strong>Zero-Shot Object Detection (ZSD)</strong>；</li>
<li>提出两种背景建模策略（SB、LAB）；</li>
<li>提出 <strong>DSES</strong> 缓解语义稀疏；</li>
<li>通过 MSCOCO &amp; VisualGenome 实验验证有效性；</li>
<li>指标 Recall@K 与 H-Mean 成为 ZSD 标准评估方式。</li>
</ol>
<h3 id="⚠️-局限性"><a href="#⚠️-局限性" class="headerlink" title="⚠️ 局限性"></a>⚠️ 局限性</h3><ul>
<li>词向量过于粗糙，缺乏细粒度区分；</li>
<li>LAB 伪标签存在噪声；</li>
<li>未建模类别层次结构（Hierarchy）。</li>
</ul>
<h3 id="🔮-未来方向"><a href="#🔮-未来方向" class="headerlink" title="🔮 未来方向"></a>🔮 未来方向</h3><ul>
<li>使用上下文语言模型（如 BERT、CLIP）；</li>
<li>引入层次化语义图（WordNet&#x2F;GNN）；</li>
<li>多模态描述学习（图像 + 文本）；</li>
<li>推动**开放词汇检测（Open-Vocabulary Detection）**的发展。</li>
</ul>
<hr>
<h2 id="🧠-六、整篇逻辑脉络总结图"><a href="#🧠-六、整篇逻辑脉络总结图" class="headerlink" title="🧠 六、整篇逻辑脉络总结图"></a>🧠 六、整篇逻辑脉络总结图</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    ┌────────────────────────────┐</span><br><span class="line">    │  Zero-Shot Object Detection│</span><br><span class="line">    └────────────┬───────────────┘</span><br><span class="line">                 │</span><br><span class="line">       ┌─────────┴─────────┐</span><br><span class="line">       │                   │</span><br><span class="line">  背景建模             语义稠密化</span><br><span class="line"> (SB / LAB)                (DSES)</span><br><span class="line">       │                   │</span><br><span class="line">SB：静态背景        DSES：扩展外部类</span><br><span class="line">LAB：迭代伪标签     减少语义稀疏</span><br><span class="line">       │                   │</span><br><span class="line">       └─────────┬─────────┘</span><br><span class="line">                 │</span><br><span class="line">             性能评估</span><br><span class="line"> ┌──────────────────────────┐</span><br><span class="line"> │ Recall@K (ZSD)           │</span><br><span class="line"> │ H-Mean (GZSD)            │</span><br><span class="line"> └──────────────────────────┘</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="🎓-七、教授总结（核心洞见）"><a href="#🎓-七、教授总结（核心洞见）" class="headerlink" title="🎓 七、教授总结（核心洞见）"></a>🎓 七、教授总结（核心洞见）</h2><table>
<thead>
<tr>
<th>主题</th>
<th>作者洞见</th>
<th>学术价值</th>
</tr>
</thead>
<tbody><tr>
<td><strong>任务创新</strong></td>
<td>将 ZSL 从分类扩展到检测</td>
<td>开启 Open-Vocabulary Detection 方向</td>
</tr>
<tr>
<td><strong>核心挑战</strong></td>
<td>背景污染 + 语义稀疏</td>
<td>指明开放检测的关键瓶颈</td>
</tr>
<tr>
<td><strong>模型贡献</strong></td>
<td>SB、LAB、DSES 三种机制</td>
<td>提供实用方案与思路</td>
</tr>
<tr>
<td><strong>实验分析</strong></td>
<td>多指标、多数据集、消融验证</td>
<td>研究方法严谨</td>
</tr>
<tr>
<td><strong>学术影响</strong></td>
<td>对 ViLD、Detic、GLIP 等模型有直接启发</td>
<td>奠基性工作</td>
</tr>
</tbody></table>
<hr>
<p>✅ <strong>一句话总结整篇论文：</strong></p>
<blockquote>
<p>Bansal 等人首次让“检测器”具备了<strong>语义迁移能力</strong>，<br> 能够在从未见过的新类别上实现有效检测。<br> 它是从“封闭世界检测”迈向“开放世界视觉理解”的重要一步。</p>
</blockquote>
]]></content>
      <categories>
        <category>零样本检测</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析-数值积分</title>
    <url>/blog/2025/03/26/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E6%95%B0%E5%80%BC%E7%A7%AF%E5%88%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文章包含数值积分部分—————————————————————————————————————————————————————-</p>
<h1 id="数值积分"><a href="#数值积分" class="headerlink" title="数值积分"></a>数值积分</h1><h2 id="记忆内容汇总"><a href="#记忆内容汇总" class="headerlink" title="记忆内容汇总"></a>记忆内容汇总</h2><blockquote>
<h3 id="梯形公式"><a href="#梯形公式" class="headerlink" title="梯形公式"></a>梯形公式</h3><p><strong>n&#x3D;1</strong></p>
<p><strong>积分公式</strong>:<br>$$<br>\int_{a}^{b} f(x) dx \approx \frac{b-a}{2} \left[ f(a) + f(b) \right]<br>$$</p>
<p><strong>代数精度</strong>: 1</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D;-\frac{1}{12} (b-a)^3 f’’(\xi)<br>$$</p>
<p>$$<br>\xi \in [a,b]<br>$$</p>
<h3 id="辛普森公式"><a href="#辛普森公式" class="headerlink" title="辛普森公式"></a>辛普森公式</h3><p><strong>n&#x3D;2</strong></p>
<p><strong>积分公式</strong>:<br>$$<br>\int_{a}^{b} f(x) dx \approx \frac{b-a}{6} \left[ f(a) + 4f\left( \frac{a+b}{2} \right) + f(b) \right]<br>$$</p>
<p><strong>代数精度</strong>: 3</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D; -\frac{1}{2880} (b-a)^5 f^{(4)}(\xi)<br>$$</p>
<p>$$<br>\xi \in (a,b)<br>$$</p>
<h3 id="复化梯形公式"><a href="#复化梯形公式" class="headerlink" title="复化梯形公式"></a>复化梯形公式</h3><p>$$<br>\int_a^b f(x) dx &#x3D; \frac{h}{2} \left[ f(a) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right]<br>$$</p>
<p>$$<br>R[f] &#x3D; -\frac{(b - a)}{12} h^2 f’’(\xi), \quad \xi \in (a, b)<br>$$</p>
<h3 id="复化辛普森公式"><a href="#复化辛普森公式" class="headerlink" title="复化辛普森公式"></a>复化辛普森公式</h3><p>$$<br>\int_a^b f(x) dx \approx \frac{h}{6} \left[ f(a) + 4\sum_{k&#x3D;0}^{n-1} f\left(x_{k+\frac{1}{2}}\right) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right]<br>$$</p>
<p>$$<br>R[f] &#x3D;-\frac{b - a}{2880} h^4 f^{(4)}(\xi), \quad \xi \in (a,b)<br>$$</p>
</blockquote>
<h2 id="数值积分近似公式"><a href="#数值积分近似公式" class="headerlink" title="数值积分近似公式"></a>数值积分近似公式</h2><h3 id="梯形公式-1"><a href="#梯形公式-1" class="headerlink" title="梯形公式"></a>梯形公式</h3><p>$$<br>\int _{a}^{b} f(x) dx \approx \frac{(b - a)}{2} \left[ f(a) + f(b) \right]<br>$$</p>
<h3 id="矩形公式"><a href="#矩形公式" class="headerlink" title="矩形公式"></a>矩形公式</h3><p>$$<br>\int _{a}^{b} f(x) dx \approx (b - a) f\left( \frac{a + b}{2} \right)<br>$$</p>
<h3 id="辛普森公式（Simpson’s-Rule）"><a href="#辛普森公式（Simpson’s-Rule）" class="headerlink" title="辛普森公式（Simpson’s Rule）"></a>辛普森公式（Simpson’s Rule）</h3><p>$$<br>\int _{a}^{b} f(x) dx \approx \frac{(b - a)}{6} \left[ f(a) + 4f\left( \frac{a + b}{2} \right) + f(b) \right]<br>$$</p>
<h3 id="机械求积公式"><a href="#机械求积公式" class="headerlink" title="机械求积公式"></a>机械求积公式</h3><p>一般的，我们取区间 $[a, b]$ 内若干个节点 $x_k$ 处的函数值 $f(x_k)$，通过加权平均的方法近似地得出平均高度。这类求积公式的一般形式为：</p>
<p>$$<br>\int_a^b f(x) , dx \approx \sum_{k&#x3D;0}^n A_k f(x_k)<br>$$</p>
<p>式中：</p>
<ul>
<li>$x_k$ 称为<strong>求积节点</strong></li>
<li>$A_k$ 称为<strong>求积系数</strong>，亦称伴随节点 $x_k$ 的<strong>权</strong>。</li>
</ul>
<h2 id="代数精度的概念"><a href="#代数精度的概念" class="headerlink" title="代数精度的概念"></a>代数精度的概念</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>如果某个求积公式对于次数不超过 $m$ 的多项式均能准确成立，但对于 $m+1$ 次多项式就不一定准确，则称该求积公式具有 <strong>$m$ 次代数精度</strong>。</p>
<p>即若某个求积公式所对应的误差 $R[f]$ 满足：</p>
<span>
$$
\begin{cases}
R[P_k] = 0 & \text{对任意 } k \leq m \text{ 阶的多项式成立} \\
R[P_{m+1}] \neq 0 & \text{对某个 } m+1 \text{ 阶多项式不成立}
\end{cases}
$$
</span>

<p>则称此求积公式的代数精度为 $m$</p>
<h3 id="实现条件"><a href="#实现条件" class="headerlink" title="实现条件"></a>实现条件</h3><p>欲使求积公式有 $m$ 次代数精度，需满足它对 $f(x) &#x3D; 1, x, x^2, \ldots, x^m$ 都能准确成立：<br>$$<br>\sum_{k&#x3D;0}^n A_k x_k^\alpha &#x3D; \int_a^b x^\alpha dx \quad (\alpha &#x3D; 0,1,2,\ldots,m)<br>$$<br>具体表现为：</p>
<span>
$$
\begin{aligned}
\sum_{k=0}^n A_k &= b - a \\
\sum_{k=0}^n A_k x_k &= \frac{1}{2}(b^2 - a^2) \\
\sum_{k=0}^n A_k x_k^2 &= \frac{1}{3}(b^3 - a^3) \\
&\vdots \\
\sum_{k=0}^n A_k x_k^m &= \frac{1}{m+1}(b^{m+1} - a^{m+1})
\end{aligned}
$$

</span>

<blockquote>
<p><strong>定理</strong></p>
<p>在区间 $[a,\ b]$ 上，对于给定的 $n+1$ 个互异节点：<br>$$<br>a \leq x_0 &lt; x_1 &lt; \ldots &lt; x_n \leq b<br>$$<br>总存在求积系数 $A_0,\ A_1,\ \ldots,\ A_n$，使求积公式至少具有 <strong>$n$</strong> 次代数精度。</p>
</blockquote>
<h2 id="插值型的求积公式"><a href="#插值型的求积公式" class="headerlink" title="插值型的求积公式"></a>插值型的求积公式</h2><p>设给定一组节点：<br>$$<br>a \leq x _ { 0 } &lt; x _ { 1 } &lt; \cdots &lt; x _ { n } \leq b<br>$$<br>且已知函数 $ f(x) $ 在这些节点上的值，作插值函数：<br>$$<br>L_{n} ( x ) &#x3D; \sum _{ k&#x3D;0 }^{ n } l _{ k } ( x ) f ( x _{ k } )<br>$$<br>其中 $ l _{ k } ( x ) $ 为插值基函数。</p>
<h3 id="积分近似表达式"><a href="#积分近似表达式" class="headerlink" title="积分近似表达式"></a>积分近似表达式</h3><p>将积分 $ I &#x3D; \int _{ a }^{ b } f(x) dx $ 近似为：</p>
<span>
$$
I _{ n } = \int _{ a }^{ b } L _{ n } ( x ) dx =\int_a^b \sum_{k=0}^{n} f(x_k) l_k(x) dx \\
= \sum _{ k=0 }^{ n } \left( \int _{ a }^{ b } l _{ k } ( x ) dx \right) f ( x _{ k } )=\sum_{k=0}^{n} A_k f(x_k)
$$

</span>

<p>求积系数：</p>
<span>
$$
A _{ k } = \int _{ a }^{ b } l _{ k } ( x ) dx \quad (k = 0,1,\ldots,n) \\
$$
</span>

<span>
$$
l_k(x) = \prod_{\substack{j=0 \\ j \neq k}}^{n} \frac{x - x_j}{x_k - x_j}
$$

</span>

<p><strong>最终得到插值型求积公式：</strong><br>$$<br>I _{ n } &#x3D; \sum _{ k&#x3D;0 }^{ n } A _{ k } f ( x _{ k } )<br>$$</p>
<h3 id="余项公式"><a href="#余项公式" class="headerlink" title="余项公式"></a>余项公式</h3><p>插值型求积公式的余项为：<br>$$<br>R[f] &#x3D; I - I_n &#x3D; \int_a^b \frac{f^{(n+1)}(\xi)}{(n+1)!} \omega_{n+1}(x) dx<br>$$<br>式中 $\xi$ 与变量 $x$ 有关，<br>$$<br>\omega_{n+1}(x) &#x3D; (x - x_0)(x - x_1) \cdots (x - x_n)<br>$$</p>
<blockquote>
<p><strong>定理</strong></p>
<p>形如<br>$$<br>\sum_{k&#x3D;0}^n A_k f(x_k)<br>$$<br>的求积公式至少有 $n$ 次代数精度 $\Leftrightarrow$ 该公式为插值型（即：$A_k &#x3D; \int_a^b l_k(x) dx$)</p>
</blockquote>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/IMG_0148.jpg"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_09-35-05.png"></p>
<p><img src="/blog/image/IMG_0149.jpg"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-16_16-21-07.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-16_16-21-15.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-16_16-21-19.png"></p>
</blockquote>
<h2 id="牛顿—柯特斯公式"><a href="#牛顿—柯特斯公式" class="headerlink" title="牛顿—柯特斯公式"></a>牛顿—柯特斯公式</h2><p>节点等距分布时的求积公式<br>$$<br>x _ { k } &#x3D; a + k h<br>$$<br>$$<br>h &#x3D; \frac { b - a } { n }<br>$$<br>$$<br>k &#x3D; 0,\ 1,\ \cdots ,\ n<br>$$</p>
<p><strong>积分系数公式</strong><br>$$<br>A _ { k } &#x3D; \int _ { x _ { 0 } } ^ { x _ { n } } \prod _ { j \neq k } \frac { ( x - x _ { j } ) } { ( x _ { k } - x _ { j } ) } d x<br>$$</p>
<p>令 $x &#x3D; a + t h$，则：<br>$$<br>A_k&#x3D; \int _ { 0 } ^ { n } \prod _ { j \neq k } \frac { ( t - j ) h } { ( k - j ) h } \times h d t<br>$$<br>$$<br>&#x3D; \frac { ( b - a ) ( -1 ) ^ { n - k } } { n k ! ( n - k ) ! } \int _ { 0 } ^ { n } \prod _ { j \neq k } ( t - j ) d t \<br>&#x3D;(b-a)C _ { k } ^ { ( n ) }<br>$$</p>
<blockquote>
<ol>
<li><strong>Cotes系数性质</strong>：</li>
</ol>
<ul>
<li>仅取决于 $n$ 和 $k$</li>
<li>与函数 $f(x)$ 及积分区间 $[a,\ b]$ 均无关</li>
</ul>
<ol start="2">
<li><strong>Cotes系数表示</strong>：</li>
</ol>
<ul>
<li>记作<br>$$<br>C _ { k } ^ { ( n ) }&#x3D; \frac {( -1 ) ^ { n - k } } { n k ! ( n - k ) ! } \int _ { 0 } ^ { n } \prod _ { j \neq k } ( t - j ) d t<br>$$</li>
</ul>
</blockquote>
<h3 id="柯特斯系数表-Newton-Cotes-公式"><a href="#柯特斯系数表-Newton-Cotes-公式" class="headerlink" title="柯特斯系数表 (Newton-Cotes 公式)"></a>柯特斯系数表 (Newton-Cotes 公式)</h3><table>
<thead>
<tr>
<th>$n$</th>
<th>$C_0^{(n)}$</th>
<th>$C_1^{(n)}$</th>
<th>$C_2^{(n)}$</th>
<th>$C_3^{(n)}$</th>
<th>$C_4^{(n)}$</th>
<th>$C_5^{(n)}$</th>
<th>$C_6^{(n)}$</th>
<th>$C_7^{(n)}$</th>
<th>$C_8^{(n)}$</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>$\frac{1}{2}$</td>
<td>$\frac{1}{2}$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>$\frac{1}{6}$</td>
<td>$\frac{2}{3}$</td>
<td>$\frac{1}{6}$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>$\frac{1}{8}$</td>
<td>$\frac{3}{8}$</td>
<td>$\frac{3}{8}$</td>
<td>$\frac{1}{8}$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>$\frac{7}{90}$</td>
<td>$\frac{16}{45}$</td>
<td>$\frac{2}{15}$</td>
<td>$\frac{16}{45}$</td>
<td>$\frac{7}{90}$</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>$\frac{19}{288}$</td>
<td>$\frac{25}{96}$</td>
<td>$\frac{25}{144}$</td>
<td>$\frac{25}{144}$</td>
<td>$\frac{25}{96}$</td>
<td>$\frac{19}{288}$</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>$\frac{41}{840}$</td>
<td>$\frac{9}{35}$</td>
<td>$\frac{9}{280}$</td>
<td>$\frac{34}{105}$</td>
<td>$\frac{9}{280}$</td>
<td>$\frac{9}{35}$</td>
<td>$\frac{41}{840}$</td>
<td></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>$\frac{715}{17280}$</td>
<td>$\frac{3577}{17280}$</td>
<td>$\frac{1323}{17280}$</td>
<td>$\frac{2989}{17280}$</td>
<td>$\frac{2989}{17280}$</td>
<td>$\frac{1323}{17280}$</td>
<td>$\frac{3577}{17280}$</td>
<td>$\frac{715}{17280}$</td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>$\frac{989}{28350}$</td>
<td>$\frac{5888}{28350}$</td>
<td>$\frac{-928}{28350}$</td>
<td>$\frac{10496}{28350}$</td>
<td>$\frac{-4540}{28350}$</td>
<td>$\frac{10496}{28350}$</td>
<td>$\frac{-928}{28350}$</td>
<td>$\frac{5888}{28350}$</td>
<td>$\frac{989}{28350}$</td>
</tr>
</tbody></table>
<blockquote>
<p>当 $n \geq 8$ 时，柯特斯系数有正有负，这时稳定性得不到保证。</p>
</blockquote>
<h3 id="梯形公式-2"><a href="#梯形公式-2" class="headerlink" title="梯形公式"></a>梯形公式</h3><p><strong>n&#x3D;1</strong></p>
<p><strong>求积系数</strong>:<br>$$<br>C_0^{(1)} &#x3D; \frac{1}{2}, \quad C_1^{(1)} &#x3D; \frac{1}{2}<br>$$</p>
<p><strong>积分公式</strong>:<br>$$<br>\int_{a}^{b} f(x) dx \approx \frac{b-a}{2} \left[ f(a) + f(b) \right]<br>$$</p>
<p><strong>代数精度</strong>: 1</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D; -\frac{1}{12} h^3 f’’(\xi)&#x3D;-\frac{1}{12} (b-a)^3 f’’(\xi)<br>$$</p>
<p>$$<br> \xi \in [a,b], \quad h &#x3D; \frac{b-a}{1}<br>$$</p>
<h3 id="辛普森公式-1"><a href="#辛普森公式-1" class="headerlink" title="辛普森公式"></a>辛普森公式</h3><p><strong>n&#x3D;2</strong></p>
<p><strong>求积系数</strong>:<br>$$<br>C_0^{(2)} &#x3D; \frac{1}{6}, \quad C_1^{(2)} &#x3D; \frac{2}{3}, \quad C_2^{(2)} &#x3D; \frac{1}{6}<br>$$</p>
<p><strong>积分公式</strong>:<br>$$<br>\int_{a}^{b} f(x) dx \approx \frac{b-a}{6} \left[ f(a) + 4f\left( \frac{a+b}{2} \right) + f(b) \right]<br>$$</p>
<p><strong>代数精度</strong>: 3</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D; -\frac{1}{90} h^5 f^{(4)}(\xi)&#x3D;-\frac{1}{2880} (b-a)^5 f^{(4)}(\xi)<br>$$</p>
<p>$$<br>\xi \in (a,b), \quad h &#x3D; \frac{b-a}{2}<br>$$</p>
<p><u>3. 辛普森3&#x2F;8法则 (Simpson’s 3&#x2F;8 Rule) - <strong>n&#x3D;3</strong></u></p>
<p><strong>代数精度</strong>: 3</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D; -\frac{3}{80} h^5 f^{(4)}(\xi), \quad \xi \in (a,b), \quad h &#x3D; \frac{b-a}{3}<br>$$</p>
<p><u>4. 科特斯公式- <strong>n&#x3D;4</strong></u></p>
<p><strong>代数精度</strong>: 5</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D; -\frac{8}{945} h^7 f^{(6)}(\xi), \quad \xi \in (a,b), \quad h &#x3D; \frac{b-a}{4}<br>$$</p>
<blockquote>
<p>$n$为偶数阶的$Newton-Cotes$公式至少有$n+1$次代数精度</p>
<p>$n$为奇数阶的$Newton-Cotes$公式至少有$n$次代数精度</p>
</blockquote>
<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_15-02-57.png"></p>
</blockquote>
<h2 id="求积公式的收敛性与稳定性"><a href="#求积公式的收敛性与稳定性" class="headerlink" title="求积公式的收敛性与稳定性"></a>求积公式的收敛性与稳定性</h2><h3 id="收敛性定义"><a href="#收敛性定义" class="headerlink" title="收敛性定义"></a>收敛性定义</h3><p>当求积公式$\int_a^b f(x) , dx \approx \sum_{k&#x3D;0}^n A_k f(x_k)$满足：<br>$$<br>\lim_{\substack{n \to \infty \ h \to 0}} \sum_{k&#x3D;0}^{n} A_k f(x_k) &#x3D; \int_{a}^{b} f(x) , dx<br>$$<br>其中：<br>$$<br>h &#x3D; \max_{1 \leq i \leq n} (x_i - x_{i-1})<br>$$<br>则称该求积公式是<strong>收敛的</strong>。</p>
<h3 id="稳定性定义"><a href="#稳定性定义" class="headerlink" title="稳定性定义"></a>稳定性定义</h3><p>对任给 $\epsilon &gt; 0$，若存在 $\delta &gt; 0$，使得只要满足：<br>$$<br>|f(x_k) - \tilde{f}_k| &lt; \delta<br>$$</p>
<p>就有：</p>
<p>$$<br>|\sum_{k&#x3D;0}^{n} A_k \cdot [f(x_k) - \tilde{f}_k]| \leq \epsilon<br>$$<br>成立，则称该求积公式是<strong>稳定的</strong>。</p>
<blockquote>
<p><span style="color:red">定理</span></p>
<p>若求积公式<br>$$<br>\int_a^b f(x) , dx \approx \sum_{k&#x3D;0}^n A_k f(x_k)<br>$$<br>其中系数满足<br>$$<br>A_k &gt; 0 \quad (k &#x3D; 0, 1, \ldots, n)<br>$$</p>
<p>则此求积公式是稳定的。</p>
</blockquote>
<h2 id="复化求积"><a href="#复化求积" class="headerlink" title="复化求积"></a>复化求积</h2><p><strong>基本概念</strong></p>
<p>高次插值有Runge现象，故采用分段低次插值<br>⇒ 分段低次合成的Newton-Cotes复化求积公式</p>
<h3 id="复化梯形公式-1"><a href="#复化梯形公式-1" class="headerlink" title="复化梯形公式"></a>复化梯形公式</h3><p><strong>1. 区间划分</strong></p>
<p>$$<br> h &#x3D; \frac{b - a}{n}, \quad x_k &#x3D; a + kh \quad (k &#x3D; 0, \ldots, n)<br>$$</p>
<p><strong>2. 子区间积分近似</strong></p>
<p>在每个$[x_{k-1}, x_k]$上使用梯形公式：<br>$$<br>\int_{x_{k-1}}^{x_k} f(x) dx \approx \frac{x_k - x_{k-1}}{2} [f(x_{k-1}) + f(x_k)], \quad k &#x3D; 1, \ldots, n<br>$$</p>
<p><strong>3. 整体复化公式</strong><br>$$<br>\begin{aligned}<br>\int_a^b f(x) dx &amp;\approx \sum_{k&#x3D;1}^n \frac{h}{2} [f(x_{k-1}) + f(x_k)] \<br>&amp;&#x3D; \frac{h}{2} \left[ f(a) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right] \<br>&amp;&#x3D; T_n<br>\end{aligned}<br>$$</p>
<p><strong>4.误差分析</strong></p>
<p>$$<br>\begin{aligned}<br>R[f] &amp;&#x3D; \sum_{k&#x3D;1}^n \left[ -\frac{h^3}{12} f’’(\xi_k) \right] \<br>&amp;&#x3D; -\frac{h^2}{12} (b - a) \frac{\sum_{k&#x3D;1}^n f’’(\xi_k)}{n} \quad \text{&#x2F;* 中值定理 *&#x2F;} \<br>&amp;&#x3D; -\frac{(b - a)}{12} h^2 f’’(\xi), \quad \xi \in (a, b)<br>\end{aligned}<br>$$</p>
<h3 id="复化Simpson公式"><a href="#复化Simpson公式" class="headerlink" title="复化Simpson公式"></a>复化Simpson公式</h3><p><strong>1. 区间划分</strong></p>
<p>$$<br> h &#x3D; \frac{b - a}{n}<br>$$</p>
<p>$$<br> x_k &#x3D; a + kh \quad (k &#x3D; 0, \ldots, n)<br>$$</p>
<p><strong>2. 子区间积分近似</strong></p>
<p>在$[x_k, x_{k+1}]$上的近似：<br>$$<br>\int_{x_k}^{x_{k+1}} f(x) dx \approx \frac{h}{6} \left[ f(x_k) + 4f\left(x_{k+\frac{1}{2}}\right) + f(x_{k+1}) \right]<br>$$</p>
<p><strong>3. 整体复化公式</strong><br>$$<br>\begin{aligned}<br>\int_a^b f(x) dx &amp;\approx \frac{h}{6} \left[ f(a) + 4\sum_{k&#x3D;0}^{n-1} f\left(x_{k+\frac{1}{2}}\right) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right] \<br>&amp;&#x3D; S_n<br>\end{aligned}<br>$$</p>
<p><strong>4.误差分析</strong><br>$$<br>R[f] &#x3D; -\frac{b - a}{180} \left( \frac{h}{2} \right)^4 f^{(4)}(\xi)&#x3D;-\frac{b - a}{2880} h^4 f^{(4)}(\xi), \quad \xi \in (a,b)<br>$$</p>
<h3 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>地球轨道是一个椭圆，其周长为<br>$$<br>S &#x3D; 4a \int_{0}^{\pi&#x2F;2} \sqrt{1-\left(\frac{c}{a}\right)^2 \sin^2 \theta},d\theta<br>$$<br>其中 $a$ 是椭圆的半长轴，$c$ 是地球中心与轨道中心（椭圆中心）的距离。记 $h$ 为近地点距离，$H$ 为远地点距离，$R &#x3D; 6371\ \text{km}$ 为地球半径，则<br>$$<br>a &#x3D; \frac{2R + H + h}{2},\qquad<br>c &#x3D; \frac{H - h}{2}<br>$$<br>我国第一颗人造地球卫星近地点距离 $h &#x3D; 439\ \text{km}$，远地点距离 $H &#x3D; 2384\ \text{km}$。  试求卫星轨道的周长（用复化辛普森公式，$n &#x3D; 3$）。</p>
<p><strong>解</strong></p>
<p>$$<br>a &#x3D; \frac{2R + H + h}{2}&#x3D; 7782.5<br>$$</p>
<p>$$<br>c &#x3D; \frac{H - h}{2} &#x3D; 972.5<br>$$</p>
<p>$$<br>e &#x3D; \frac{c}{a} \approx 0.125.<br>$$</p>
<h4 id="2-计算积分"><a href="#2-计算积分" class="headerlink" title="2. 计算积分"></a>2. 计算积分</h4><p>$$<br>I &#x3D; \int_{0}^{\pi&#x2F;2} \sqrt{1 - e^{2}\sin^{2}\theta},d\theta.<br>$$</p>
<p>复化辛普森公式（$n &#x3D; 3$，步长 $h&#x3D;\dfrac{\pi}{6}$，$\theta_i&#x3D;\dfrac{\pi}{6}i$ ）</p>
<table>
<thead>
<tr>
<th>$i$</th>
<th>$\theta_i$ (rad)</th>
<th>$f(\theta_i)&#x3D;\sqrt{1-e^{2}\sin^{2}\theta_i}$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>$0$</td>
<td>$1.000000$</td>
</tr>
<tr>
<td>1&#x2F;2</td>
<td>$\dfrac{\pi}{12}$</td>
<td>$0.999$</td>
</tr>
<tr>
<td>1</td>
<td>$\dfrac{\pi}{6}$</td>
<td>$0.998$</td>
</tr>
<tr>
<td>3&#x2F;2</td>
<td>$\dfrac{\pi}{4}$</td>
<td>$0.996$</td>
</tr>
<tr>
<td>2</td>
<td>$\dfrac{\pi}{3}$</td>
<td>$0.994$</td>
</tr>
<tr>
<td>5&#x2F;2</td>
<td>$\dfrac{5\pi}{12}$</td>
<td>$0.993$</td>
</tr>
<tr>
<td>3</td>
<td>$\dfrac{\pi}{2}$</td>
<td>$0.992$</td>
</tr>
</tbody></table>
<p>$$<br>I \approx \frac{h}{6}\Bigl[f_0 + 4(f_1 + f_3 + f_5) + 2(f_2 + f_4) + f_6\Bigr]<br>     \approx 1.5645<br>$$</p>
<h4 id="3-求椭圆轨道周长"><a href="#3-求椭圆轨道周长" class="headerlink" title="3. 求椭圆轨道周长"></a>3. 求椭圆轨道周长</h4><p>$$<br>S &#x3D; 4a,I &#x3D; 4 \times 7782.5 \times 1.5645 \approx48703.29<br>$$</p>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>卫星椭圆轨道周长约为<br>$$<br>\boxed{S \approx 4.87\times10^{4}\ \text{km}}.<br>$$</p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_10-48-03.png"></p>
<p><img src="/blog/image/IMG_0150.jpg"></p>
</blockquote>
<blockquote>
<p>计算积分：<br>$$<br>I &#x3D; \int_{0}^{1} e^{x} dx<br>$$</p>
<p>要求：</p>
<ol>
<li>使用复化梯形公式和复化辛普森公式</li>
<li>截断误差 $\leq \frac{1}{2} \times 10^{-4}$</li>
<li>确定所需节点数</li>
</ol>
<p><strong>解</strong><br>$$<br>f(x) &#x3D; e^{x} \qquad f’(x) &#x3D; f’’(x) &#x3D; f^{(4)}(x) &#x3D; e^{x}<br>$$</p>
<p>在区间 $[0,\ 1]$ 上：<br>$$<br>\max|f’’(x)| &#x3D; \max|f^{(4)}(x)| &#x3D; e<br>$$</p>
<p>1.复化梯形公式计算</p>
<p>误差公式：<br>$$<br>|R_T[f]| \leq \frac{e}{12} h^2 \leq \frac{1}{2} \times 10^{-4}<br>$$</p>
<p>解得：<br>$$<br>h \leq 0.0149<br>$$</p>
<p>节点数：<br>$$<br>N \geq \frac{1}{h} &#x3D;67.1<br>$$</p>
<p>$$<br>\Rightarrow N + 1 &#x3D; 69 \text{个节点}<br>$$</p>
<hr>
<p>2.复化辛普森公式计算</p>
<p>误差公式：</p>
<p>$$ |R_S[f]| \leq \frac{e}{2880} h^4 \leq \frac{1}{2} \times 10^{-4} $$</p>
<ol>
<li>解得：<br>$$ h \leq 0.4798 $$</li>
<li>节点数：<br>$$ N \geq \frac{1}{h} &#x3D; 2.085 $$</li>
<li>取：<br>$$ N &#x3D; 3 $$<br>$$ \Rightarrow 2N + 1 &#x3D; 7 \text{个节点} $$</li>
</ol>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_10-50-56.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-04_10-51-01.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_15-40-32.png"></p>
</blockquote>
<h2 id="高斯求积公式"><a href="#高斯求积公式" class="headerlink" title="高斯求积公式"></a>高斯求积公式</h2><p>构造具有2n+1次代数精度的求积公式</p>
<p>$$<br>\int_a^b \rho(x) f(x) dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<ul>
<li><p>节点：$x_0, \ldots, x_n$（共n+1个）</p>
</li>
<li><p>系数：$A_0, \ldots, A_n$（共n+1个）</p>
<p>二者都作为待定系数</p>
</li>
</ul>
<p><strong>精度条件方程</strong>：<br>$$<br>\int \rho(x) \cdot 1 dx &#x3D; \sum_{k&#x3D;0}^{n} A_k \<br>\int \rho(x) x dx &#x3D; \sum_{k&#x3D;0}^{n} A_k x_k \<br>\vdots \<br>\int \rho(x) x^{2n+1} dx &#x3D; \sum_{k&#x3D;0}^{n} A_k x_k^{2n+1}<br>$$</p>
<p><strong>代数精度</strong>：</p>
<blockquote>
<p>当取$f(x)&#x3D;1,x,x^2,\ldots,x^{2n+1}$代入可求解，得到的公式具有<strong>2n+1次代数精度</strong></p>
</blockquote>
<ul>
<li>节点称为<strong>Gauss点</strong></li>
<li>公式称为<strong>Gauss型求积公式</strong></li>
</ul>
<blockquote>
<p><strong>定义</strong>：</p>
<p>选取互异节点 $x_{0}, x_{1}, \ldots, x_{n}$，使插值型求积公式的代数精度达到 $2n+1$，则称该求积公式为<strong>Gauss型</strong>的，称这些节点为<strong>Gauss点</strong>。</p>
</blockquote>
<h3 id="例题-3"><a href="#例题-3" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>试构造高斯求积公式 $\int_{-1}^{1}f(x)dx\approx w_{0}f(x_{0})+w_{1}f(x_{1})$.</p>
<ul>
<li><p>显然$n&#x3D;1$，则具有$2 \cdot 1+1$次代数精度</p>
</li>
<li><p>分别将$f(x)&#x3D;1,x,x^2,x^{3}$依次带入</p>
</li>
</ul>
<div>

<p>$$<br>w_{0} + w_{1} &#x3D; 2,\<br>w_{0}x_{0} + w_{1}x_{1} &#x3D; 0,\<br>w_{0}x_{0}^{2} + w_{1}x_{1}^{2} &#x3D; \frac{2}{3},\<br>w_{0}x_{0}^{3} + w_{1}x_{1}^{3} &#x3D; 0<br>$$</p>
</div>
$$
\int_{-1}^{1}f(x)dx\approx f\left(-\frac{1}{\sqrt{3}}\right)+f\left(\frac{1}{\sqrt{3}}\right)
$$
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-04_14-28-26.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-04_14-28-39.png"></p>
</blockquote>
<h3 id="Gauss点与正交多项式零点的关系"><a href="#Gauss点与正交多项式零点的关系" class="headerlink" title="Gauss点与正交多项式零点的关系"></a>Gauss点与正交多项式零点的关系</h3><ol>
<li>一般利用正交多项式来确定Gauss点 $x_{0}, x_{1}, \ldots, x_{n}$</li>
<li>然后利用插值原理确定Gauss求积系数 $A_{k}$</li>
</ol>
<p>$$<br>A_{k} &#x3D; \int_a^b \rho(x)  l_{k}(x) dx<br>$$</p>
<p>其中：</p>
<ul>
<li>$l_{k}(x)$ 是关于Gauss点的Lagrange插值基函数</li>
</ul>
<p><strong>插值型求积公式</strong><br>$$<br>\int_a^b \rho(x) f(x) dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<hr>
<blockquote>
<p><strong>定理</strong></p>
<p>设节点 $x_0, \ldots, x_n$ 为 Gauss 点</p>
<p>$\Leftrightarrow$</p>
<p>$ \omega(x) &#x3D; \prod_{k&#x3D;0}^n (x - x_k) $<br>与任意次数不大于 $n$ 的多项式 $P(x)$（带权）正交。</p>
</blockquote>
<blockquote>
<p><strong>正交多项式族与Gauss点关系:</strong></p>
<p>设正交多项式族为 ${\phi_0, \phi_1, \ldots, \phi_n, \ldots}$，具有以下性质：</p>
<p>对任意次数<strong>不大于</strong>$n$的多项式$P(x)$，必与$\phi_{n+1}$正交：<br>$\Rightarrow$若取$\omega(x)$为其中的$\phi_{n+1}$，则：$\phi_{n+1}$的零点${x_k}_{k&#x3D;0}^n$即为<strong>Gauss点</strong></p>
</blockquote>
<h3 id="高斯求积公式的余项"><a href="#高斯求积公式的余项" class="headerlink" title="高斯求积公式的余项"></a>高斯求积公式的余项</h3><p>$$<br>R_n[f] &#x3D; \int_a^b \rho(x) f(x) , dx - \sum_{k&#x3D;0}^{n} A_k f(x_k) \<br> &#x3D; \frac{f^{(2n+2)}(\eta)}{(2n+2)!} \int_a^b \omega_{n+1}^2(x) \rho(x) , dx, \quad \eta \in [a, b]<br>$$</p>
<h3 id="例题-4"><a href="#例题-4" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>求形如<br>$$<br>\int_{0}^{1} \sqrt{x} f(x) dx \approx A_0 f(x_0) + A_1 f(x_1)<br>$$</p>
<p>的两点Gauss型求积公式</p>
<p><strong>法一：正交多项式法</strong></p>
<p>Step 1：构造正交多项式</p>
<p>设 $\varphi_2(x) &#x3D; x^2 + b x + c$ 为区间 $[0,1]$ 上带权 $\sqrt{x}$ 正交的多项式</p>
<p>正交条件：</p>
<ol>
<li>$(\varphi_2, 1) &#x3D; 0 \Rightarrow \int_{0}^{1} \sqrt{x} (x^2 + b x + c) dx &#x3D; 0$</li>
<li>$(\varphi_2, x) &#x3D; 0 \Rightarrow \int_{0}^{1} \sqrt{x} (x^3 + b x^2 + c x) dx &#x3D; 0$</li>
</ol>
<p>解得：<br>$$ \varphi_2(x) &#x3D; x^2 - \frac{10}{9}x + \frac{5}{21} $$</p>
<p>Step 2：求Gauss点</p>
<p>解 $\varphi_2(x)&#x3D;0$ 得：<br>$$ x_{0,1} &#x3D; \frac{\frac{10}{9} \pm \sqrt{\left(\frac{10}{9}\right)^2 - \frac{20}{21}}}{2} $$<br>数值解：<br>$$ x_0 \approx 0.821162,\quad x_1 \approx 0.289949 $$</p>
<p>Step 3：求系数</p>
<p>通过解方程组：</p>
<ol>
<li>$\int_{0}^{1} \sqrt{x} dx &#x3D; \frac{2}{3} &#x3D; A_0 + A_1$</li>
<li>$\int_{0}^{1} \sqrt{x} x dx &#x3D; \frac{2}{5} &#x3D; A_0 x_0 + A_1 x_1$</li>
</ol>
<p>解得：<br>$$ A_0 \approx 0.389111,\quad A_1 \approx 0.277556 $$</p>
<p>最终公式：<br>$$ \int_{0}^{1} \sqrt{x} f(x) dx \approx 0.389111 f(0.821162) + 0.277556 f(0.289949) $$</p>
<p>PS：$A_0 \quad A_1$也可由公式$A_{k} &#x3D; \int_a^b \rho(x)  l_{k}(x) dx$求出</p>
<p><strong>法二：直接构造法</strong></p>
<p>设 $\omega(x) &#x3D; (x-x_0)(x-x_1)$ 满足：<br>$$ \int_{0}^{1} \sqrt{x} \omega(x) dx &#x3D; 0 $$<br>$$ \int_{0}^{1} \sqrt{x} x \omega(x) dx &#x3D; 0 $$</p>
<p>解出$x_0,x_1$ ，后续方法同上</p>
</blockquote>
<h3 id="高斯-勒让德-Gauss-Legendre-求积公式"><a href="#高斯-勒让德-Gauss-Legendre-求积公式" class="headerlink" title="高斯-勒让德(Gauss-Legendre)求积公式"></a>高斯-勒让德(Gauss-Legendre)求积公式</h3><p>构造形如：<br>$$<br>\int_{-1}^{1} f(x)dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<p>的求积公式，使其为Gauss型的。</p>
<p>当积分区间为$[-1,1]$时，求积公式的代数精度为$2n+1$的<strong>充要条件</strong>是：<br>$$ \omega(x) \text{ 在 } [-1,1] \text{ 上与一切次数不超过 } n \text{ 的多项式正交} $$</p>
<p><strong>由正交多项式的性质可知：</strong></p>
<ol>
<li>$n+1$次勒让德多项式$P_{n+1}(x)$具有这个性质</li>
<li>用$n+1$次勒让德多项式的零点作为节点，可得高斯型求积公式</li>
</ol>
<hr>
<p>$$<br> \int_{-1}^{1} f(x)dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<p>该公式通常称为<strong>高斯-勒让德(Gauss-Legendre)求积公式</strong></p>
<blockquote>
<p><strong>Legendre多项式族</strong></p>
<p>定义在区间$[-1,1]$上，权函数$\rho(x)&#x3D;1$：<br>$$<br>P_k(x) &#x3D; \frac{1}{2^k k!} \cdot \frac{d^k}{dx^k}(x^2-1)^k<br>$$<br>正交性条件</p>
<p>$$ (P_k, P_l) &#x3D; \left{<br>\begin{matrix}<br>0 &amp; k \neq l \<br>\frac{2}{2k+1} &amp; k &#x3D; l<br>\end{matrix}<br>\right. $$</p>
<p>其中<br>$$ P_0 &#x3D; 1,\quad P_1 &#x3D; x ,\quad P_2(x) &#x3D; \frac{1}{2}(3x^2 - 1) \quad P_3(x) &#x3D; \frac{1}{2}(5x^3-3x)  $$</p>
<p>递推公式：<br>$$ (k+1)P_{k+1} &#x3D; (2k+1)xP_k - kP_{k-1} $$</p>
<p>以$P_{n+1}$的根为节点的求积公式称为<strong>Gauss-Legendre公式</strong></p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>构造两点的高斯-勒让德求积分公式：<br>$$<br>\int_{-1}^{1} f(x)dx \approx A_0 f(x_0) + A_1 f(x_1)<br>$$</p>
<ol>
<li>取勒让德多项式零点</li>
</ol>
<p>取二次勒让德多项式：<br>$$ P_2(x) &#x3D; \frac{1}{2}(3x^2 - 1) $$</p>
<p>求其两个零点：<br>$$ x_{0,1} &#x3D; \pm \frac{1}{\sqrt{3}} $$</p>
<ol start="2">
<li>建立求积公式</li>
</ol>
<p>设求积公式为：<br>$$ \int_{-1}^{1} f(x)dx \approx A_0 f\left(-\frac{1}{\sqrt{3}}\right) + A_1 f\left(\frac{1}{\sqrt{3}}\right) $$</p>
<ol start="3">
<li>确定系数</li>
</ol>
<p>当$f(x)&#x3D;1$时：<br>$$ A_0 + A_1 &#x3D; \int_{-1}^{1} 1 dx &#x3D; 2 $$</p>
<p>当$f(x)&#x3D;x$时：<br>$$ A_0 \left(-\frac{1}{\sqrt{3}}\right) + A_1 \left(\frac{1}{\sqrt{3}}\right) &#x3D; \int_{-1}^{1} x dx &#x3D; 0 $$</p>
<p>解得：<br>$$ A_0 &#x3D; A_1 &#x3D; 1 $$</p>
<ol start="4">
<li>最终公式</li>
</ol>
<p>得到两点高斯-勒让德求积公式：<br>$$ \int_{-1}^{1} f(x)dx \approx f\left(-\frac{1}{\sqrt{3}}\right) + f\left(\frac{1}{\sqrt{3}}\right) $$</p>
<ol start="5">
<li>验证代数精度</li>
</ol>
<p>可以验证，该公式对$f(x)&#x3D;x^3$也精确成立，因此代数精度为3。</p>
</blockquote>
<blockquote>
<p>对于积分 $\int_{a}^{b} f(x) dx$，通过变量替换：<br>$$<br>x &#x3D; \frac{b-a}{2} t + \frac{b+a}{2}<br>$$</p>
<p>可以转化为：<br>$$<br>\int_{a}^{b} f(x) dx &#x3D; \frac{b-a}{2} \int_{-1}^{1} f\left(\frac{b-a}{2} t + \frac{b+a}{2}\right) dt<br>$$</p>
</blockquote>
<blockquote>
<p>(1) 一个节点时  <strong>$n&#x3D;0$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx 2f(0).<br>$$</p>
<p>(2) 两个节点时 <strong>$n&#x3D;1$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx<br>f\left(-\frac{1}{\sqrt{3}}\right)+<br>f\left(\frac{1}{\sqrt{3}}\right).<br>$$</p>
<p>(3) 三个节点时 <strong>$n&#x3D;2$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx<br>\frac{5}{9}f\left(-\sqrt{\frac{3}{5}}\right)+<br>\frac{8}{9}f(0)+<br>\frac{5}{9}f\left(\sqrt{\frac{3}{5}}\right).<br>$$</p>
<p>(4) 四个节点时   <strong>$n&#x3D;3$</strong><br>$$<br>\begin{aligned}<br>\int_{-1}^{1} f(x),dx &amp;\approx<br>0.3478548f(-0.8611363)+{}\<br>&amp;\quad 0.6521452f(-0.3399810)+{}\<br>&amp;\quad 0.6521452f(0.3399810)+{}\<br>&amp;\quad 0.3478548f(0.8611363).<br>\end{aligned}<br>$$</p>
</blockquote>
<h3 id="高斯-切比雪夫-Gauss-Chebyshev-求积公式）"><a href="#高斯-切比雪夫-Gauss-Chebyshev-求积公式）" class="headerlink" title="高斯-切比雪夫(Gauss-Chebyshev)求积公式）"></a>高斯-切比雪夫(Gauss-Chebyshev)求积公式）</h3><p>形如：<br>$$<br> \int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<p>的求积公式，若其代数精度为$2n+1$，则称其为<strong>高斯-切比雪夫求积公式</strong>。</p>
<blockquote>
<p><strong>Chebyshev多项式族</strong></p>
<p>定义在区间$[-1,1]$上，权函数$\rho(x)&#x3D;\frac{1}{\sqrt{1-x^2}}$：<br>$$<br>T_k(x) &#x3D; \cos(k \cdot \arccos x)<br>$$</p>
<p>$T_{n+1}$的根为：<br>$$<br>x_k &#x3D; \cos\left(\frac{(2k+1)\pi}{2n+2}\right),\quad k&#x3D;0,1,\ldots,n<br>$$</p>
<p>$$<br>\int_{-1}^1 \frac{1}{\sqrt{1-x^2}} f(x)dx \approx \sum_{k&#x3D;0}^n A_kf(x_k)<br>$$</p>
<p>称为<strong>Gauss-Chebyshev公式</strong></p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>求形如：<br>$$<br>\int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx A_0 f(x_0) + A_1 f(x_1)<br>$$</p>
<p>的两点Gauss型求积公式。</p>
<ol>
<li><p><strong>确定节点</strong>：<br>由于节点必是区间$[-1,1]$上带权$p(x)&#x3D;\frac{1}{\sqrt{1-x^2}}$的二次正交多项式的零点，这个正交多项式就是二次切比雪夫多项式：<br>$$ T_2(x) &#x3D; \cos(2 \arccos x) $$<br>其零点为：<br>$$ x_0 &#x3D; -\frac{\sqrt{2}}{2},\quad x_1 &#x3D; \frac{\sqrt{2}}{2} $$</p>
</li>
<li><p><strong>确定系数</strong>：<br>要求公式对$f(x)&#x3D;1$和$f(x)&#x3D;x$都准确成立，可得方程组：</p>
<div>

<p>$$ \begin{cases}<br>A_0 + A_1 &#x3D; \pi \<br>A_0 \left(-\frac{\sqrt{2}}{2}\right) + A_1 \left(\frac{\sqrt{2}}{2}\right) &#x3D; 0<br>\end{cases} $$</p>
</div>

<p>解得：<br>$$ A_0 &#x3D; A_1 &#x3D; \frac{\pi}{2} $$</p>
</li>
<li><p><strong>最终公式</strong>：<br>$$<br>\int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \frac{\pi}{2} f\left(-\frac{\sqrt{2}}{2}\right) + \frac{\pi}{2} f\left(\frac{\sqrt{2}}{2}\right)<br>$$</p>
</li>
</ol>
</blockquote>
<p>利用$n+1$次切比雪夫多项式$T_{n+1}(x)$的零点：<br>$$<br>x_k &#x3D; \cos\left(\frac{2k+1}{2(n+1)}\pi\right) \quad (k&#x3D;0,1,\ldots,n)<br>$$</p>
<p>可以得到$n+1$点的Gauss型求积公式：<br>$$<br> \int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \frac{\pi}{n+1} \sum_{k&#x3D;0}^{n} f\left(\cos\frac{2k+1}{2(n+1)}\pi\right)<br>$$</p>
<blockquote>
<p><strong>例题</strong></p>
<p>计算积分：<br>$$ \int_{-1}^{1} \sqrt\frac{2+x}{1-x^2} dx $$</p>
<p>选用$n&#x3D;2$的Gauss-Chebyshev公式</p>
<p>节点和系数为：<br>$$<br>\begin{cases}<br>x_0 &#x3D; \cos\left(\frac{5}{6}\pi\right) &#x3D; -0.866025403 \<br>x_1 &#x3D; \cos\left(\frac{\pi}{2}\right) &#x3D; 0 \<br>x_2 &#x3D; \cos\left(\frac{\pi}{6}\right) &#x3D; 0.866025403 \<br>A_k &#x3D; \frac{\pi}{3}, \quad k&#x3D;0,1,2<br>\end{cases}<br>$$<br>即<br>$$<br>\int_{-1}^{1} \frac{2+x}{\sqrt{1-x^2}} dx \approx \frac{\pi}{3} \left[ \sqrt{2+x_0} + \sqrt{2+x_1} + \sqrt{2+x_2} \right] \<br>&#x3D; \frac{\pi}{3} \left[ \sqrt{2-0.866025403} + \sqrt{2+0} + \sqrt{2+0.866025403} \right]  \<br>&#x3D; 4.368939556<br>$$</p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析-函数逼近</title>
    <url>/blog/2025/05/15/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%87%BD%E6%95%B0%E9%80%BC%E8%BF%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="第三章-函数逼近"><a href="#第三章-函数逼近" class="headerlink" title="第三章 函数逼近"></a>第三章 函数逼近</h1><h2 id="范数与赋范线性空间"><a href="#范数与赋范线性空间" class="headerlink" title="范数与赋范线性空间"></a>范数与赋范线性空间</h2><p>设 $S$ 是实数域上的线性空间，$x \in S$，如果存在唯一实数 $||\cdot||$，满足以下条件：  </p>
<ol>
<li><p><strong>正定性</strong>：<br>$$<br>||x|| \geq 0，\quad \text{当且仅当} \ x &#x3D; 0 \ \text{时，} \ ||x|| &#x3D; 0<br>$$</p>
</li>
<li><p><strong>齐次性</strong>：<br>$$<br>|| \alpha x || &#x3D; |\alpha| \cdot ||x||，\quad \alpha \in \mathbb{R}<br>$$</p>
</li>
<li><p><strong>三角不等式</strong>：<br>$$<br>||x + y|| \leq ||x|| + ||y||，\quad x, y \in S<br>$$</p>
</li>
</ol>
<p>则称 $||\cdot||$ 为线性空间 $S$ 上的<strong>范数</strong>，$S$ 与 $||\cdot||$ 一起称为<strong>赋范线性空间</strong>，记为 $X$。</p>
<p><strong>常用范数定义</strong></p>
<h4 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h4><p>设 $x &#x3D; (x_1, \dots, x_n)^T \in \mathbb{R}^n$，定义以下三种常用范数：  </p>
<ol>
<li><p><strong>∞-范数（最大范数）</strong>：<br>$$<br>||x|| _ \infty &#x3D; \max_{1 \leq i \leq n} |x_i|<br>$$</p>
</li>
<li><p><strong>1-范数</strong>：<br>$$<br>||x|| _ 1 &#x3D; \sum_{i&#x3D;1}^n |x_i|<br>$$</p>
</li>
<li><p><strong>2-范数</strong>：<br>$$<br>||x|| _ 2 &#x3D; \left( \sum_{i&#x3D;1}^n x_i^2 \right)^{1&#x2F;2}<br>$$</p>
</li>
</ol>
<hr>
<h4 id="函数范数"><a href="#函数范数" class="headerlink" title="函数范数"></a>函数范数</h4><p>设 $f(x) \in C[a, b]$，定义以下三种常用范数：  </p>
<ol>
<li><p><strong>∞-范数</strong>：<br>$$<br>||f||_ \infty &#x3D; \max_{a \leq x \leq b} |f(x)|<br>$$</p>
</li>
<li><p><strong>1-范数</strong>：<br>$$<br>||f||_1 &#x3D; \int_a^b |f(x)| , dx<br>$$</p>
</li>
<li><p><strong>2-范数</strong>：<br>$$<br>||f||_2 &#x3D; \left( \int_a^b f^2(x) , dx \right)^{1&#x2F;2}<br>$$</p>
</li>
</ol>
<h2 id="内积与内积空间"><a href="#内积与内积空间" class="headerlink" title="内积与内积空间"></a>内积与内积空间</h2><h3 id="权函数的定义"><a href="#权函数的定义" class="headerlink" title="权函数的定义"></a>权函数的定义</h3><p>设 $[a, b]$ 是有限或无限区间，在 $[a, b]$ 上的<strong>非负</strong>函数 $\rho(x)$ 满足以下条件：  </p>
<ol>
<li><p><strong>积分存在性</strong>：<br>对任意非负整数 $k &#x3D; 0, 1, 2, \ldots$，积分<br>$$<br>\int_a^b x^k \rho(x)dx<br>$$<br>存在且为有限值。  </p>
</li>
<li><p><strong>非负连续性条件</strong>：<br>对 $[a, b]$ 上的任意非负连续函数 $g(x)$，若满足<br>$$<br>\int_a^b g(x)\rho(x) dx &#x3D; 0<br>$$<br>则必有 $g(x) \equiv 0$（即 $g(x)$ 在 $[a, b]$ 上恒为零）。</p>
</li>
</ol>
<p>满足上述条件的函数 $\rho(x)$ 称为 $[a, b]$ 上的一个<strong>权函数</strong>。</p>
<h3 id="向量内积"><a href="#向量内积" class="headerlink" title="向量内积"></a>向量内积</h3><p>在 $\mathbb{R}^n$ 中，向量 $x &#x3D; (x_1, x_2, \dots, x_n)^T$ 和 $y &#x3D; (y_1, y_2, \dots, y_n)^T$ 的内积定义为：<br>$$<br>(x, y) &#x3D; x_1 y_1 + x_2 y_2 + \dots + x_n y_n \tag{1.5}<br>$$</p>
<p>设 $X$ 是数域 $K$（实数域 $\mathbb{R}$ 或复数域 $\mathbb{C}$）上的线性空间。对任意 $u, v \in X$，有K中一个数与之对应，记为$(u,v)$，它满足以下条件：</p>
<ol>
<li><p><strong>共轭对称性</strong>：<br>$$<br>(u, v) &#x3D; \overline{(v, u)}<br>$$<br>其中 $\overline{(v, u)}$ 表示 $(v, u)$ 的复共轭。当 $K &#x3D; \mathbb{R}$ 时，简化为对称性 $(u, v) &#x3D; (v, u)$。  </p>
</li>
<li><p><strong>线性性</strong>：<br>$$<br>(\alpha u, v) &#x3D; \alpha (u, v), \quad \forall \alpha \in K<br>$$</p>
</li>
<li><p><strong>可加性</strong>：<br>$$<br>(u + v, w) &#x3D; (u, w) + (v, w), \quad \forall w \in X<br>$$</p>
</li>
<li><p><strong>正定性</strong>：<br>$$<br>(u, u) \geq 0<br>$$<br>当且仅当 $u &#x3D; 0$ 时，$(u, u) &#x3D; 0$。</p>
</li>
</ol>
<p>定义了内积的线性空间称为<strong>内积空间</strong>。</p>
<hr>
<h3 id="函数内积"><a href="#函数内积" class="headerlink" title="函数内积"></a>函数内积</h3><p>设 $f(x), g(x) \in C[a, b]$，$\rho(x)$ 是 $[a, b]$ 上的权函数，积分<br>$$<br>(f, g) &#x3D; \int_a^b \rho(x) f(x) g(x) , dx<br>$$<br>称为函数 $f(x)$ 与 $g(x)$ 在 $[a, b]$ 上的<strong>内积</strong>。</p>
<h3 id="函数范数与内积"><a href="#函数范数与内积" class="headerlink" title="函数范数与内积"></a>函数范数与内积</h3><blockquote>
<p><strong>向量模（范数）的定义</strong></p>
<p>设向量 $ f \in \mathbb{R}^n $，其模（范数）定义为：<br>$$<br>|| f ||_ 2 &#x3D; \left( \sum_{k&#x3D;1}^{n} f_k^2 \right)^{\frac{1}{2}}<br>$$<br>将此定义推广到任何内积空间中，就有以下定义。</p>
<hr>
<p>设函数 $ f(x) \in C[a, b] $，定义量<br>$$<br>|| f ||_2 &#x3D; \sqrt{ \int_a^b \rho(x) f^2(x) , dx } &#x3D; \sqrt{ (f, f) }<br>$$<br>$$<br>|| f ||_2^2&#x3D;(f, f)<br>$$</p>
<p>称为函数 $ f(x) $ 的<strong>欧氏范数</strong>。</p>
</blockquote>
<blockquote>
<p><strong>定理</strong>  </p>
<p>对任何 $ f, g \in C[a, b] $，下列结论成立：  </p>
<ol>
<li><strong>柯西-许瓦兹不等式</strong>：</li>
</ol>
<p>$$<br>|(f, g)| \leq ||f||_2 ||g||_2 \<br> 或 \quad |(f, g)|^2 \leq (f,f)(g,g)<br>$$</p>
<ol start="2">
<li><strong>三角不等式</strong>：</li>
</ol>
<p>$$<br>||f + g||_2 \leq ||f||_2 + ||g||_2<br>$$</p>
<ol start="3">
<li><strong>平行四边形定律</strong>：</li>
</ol>
<p>$$<br>||f + g||_2^2 + ||f - g||_2^2 &#x3D; 2 \left( ||f||_2^2 + ||g||_2^2 \right)<br>$$</p>
</blockquote>
<h3 id="线性无关相关概念与定理"><a href="#线性无关相关概念与定理" class="headerlink" title="线性无关相关概念与定理"></a>线性无关相关概念与定理</h3><p>设集合 $ S $ 是数域 $ P $ 上的线性空间，元素 $ x_1, x_2, \dots, x_n \in S $。如果存在不全为零的数 $ \alpha_1, \alpha_2, \dots, \alpha_n \in P $，使得<br>$$<br>\alpha_1 x_1 + \alpha_2 x_2 + \dots + \alpha_n x_n &#x3D; 0 \quad (1.1)<br>$$<br>则称 $ x_1, x_2, \dots, x_n $ <strong>线性相关</strong>。否则，若等式 (1.1) 只对<br>$$<br>\alpha_1 &#x3D; \alpha_2 &#x3D; \dots &#x3D; \alpha_n &#x3D; 0<br>$$<br>成立，则称 $ x_1, x_2, \dots, x_n $ <strong>线性无关</strong>。</p>
<hr>
<p><strong>基的定义</strong>  </p>
<p>若线性空间 $ S $ 是由 $ n $ 个线性无关元素 $ x_1, x_2, \dots, x_n $ 生成的，即对任意 $ x \in S $，都有<br>$$<br>x &#x3D; \alpha_1 x_1 + \alpha_2 x_2 + \dots + \alpha_n x_n,<br>$$<br>则 $ x_1, x_2, \dots, x_n $ 称为空间 $ S $ 的一组<strong>基</strong>，记为<br>$$<br>S &#x3D; \text{span}{x_1, x_2, \dots, x_n}.<br>$$<br>其中，系数 $ \alpha_1, \alpha_2, \dots, \alpha_n $ 称为 $ x $ 在基 $ x_1, x_2, \dots, x_n $ 下的<strong>坐标</strong>，记作 $ (\alpha_1, \alpha_2, \dots, \alpha_n) $。</p>
<hr>
<h3 id="无限维线性空间"><a href="#无限维线性空间" class="headerlink" title="无限维线性空间"></a><strong>无限维线性空间</strong></h3><p>如果 $ S $ 中有无限个线性无关元素 $ x_1, x_2, \dots, x_n, \dots $，则称 $ S $ 为<strong>无限维线性空间</strong>。</p>
<blockquote>
<p><strong>定理3</strong> </p>
<p>设 $ X $ 为一个内积空间，$ u_1, u_2, \dots, u_n \in X $，矩阵 $ G $ 定义为：  </p>
<span>
$$
G = \begin{pmatrix}
(u_1, u_1) & (u_2, u_1) & \cdots & (u_n, u_1) \\
(u_1, u_2) & (u_2, u_2) & \cdots & (u_n, u_2) \\
\vdots & \vdots & & \vdots \\
(u_1, u_n) & (u_2, u_n) & \cdots & (u_n, u_n)
\end{pmatrix}
$$
</span>

<p>矩阵 $ G $ 称为<strong>格拉姆(Gram)矩阵</strong>。矩阵 $ G $ 非奇异(<strong>等价与$detG≠0$</strong>)的充分必要条件是 $ u_1, u_2, \dots, u_n $ 线性无关。</p>
</blockquote>
<h2 id="函数的最佳平方逼近"><a href="#函数的最佳平方逼近" class="headerlink" title="函数的最佳平方逼近"></a>函数的最佳平方逼近</h2><p>设函数 $ f(x) \in C[a, b] $，用 $ n $ 次多项式<br>$$<br>s(x) &#x3D; \sum_{k&#x3D;0}^{n} a_k x^k<br>$$<br>作最佳平方逼近，就是要求得以 $ a_0^* , a_1^* , \dots, a_n^*  $ 为系数的多项式<br>$$<br>s^* (x) &#x3D; \sum_{k&#x3D;0}^{n} a_k^*  x^k<br>$$<br>使得<br>$$<br>|| f(x) - s^* (x) ||_2^2 &#x3D; \int_a^b [f(x) - s^* (x)]^2 dx<br>$$</p>
<p>$$<br>&#x3D;\min_{s(x) \in H_n} || f(x) - s(x) ||_2^2<br>$$<br>其中 $ H_n $ 表示所有 $ n $ 次多项式的集合。</p>
<hr>
<p><strong>推广到一般情况</strong></p>
<p>对于给定的权函数 $ \rho(x) $，要求得 $ a_k^* $（$ k &#x3D; 0, 1, \dots, n $）使得<br>$$<br>|| f(x) - s^* (x) ||_2^2 &#x3D; \int_a^b \rho(x) [f(x) - s^* (x)]^2 dx<br>$$</p>
<p>$$<br>&#x3D;\min_{s(x) \in H_n} || f(x) - s(x) ||_2^2<br>$$</p>
<p><strong>进一步推广</strong></p>
<p>$ n $ 次多项式<br>$$<br>s(x) &#x3D; \sum_{k&#x3D;0}^{n} a_k x^k<br>$$<br>是以 $ 1, x, \dots, x^n $ 为基函数的线性组合。</p>
<p>进一步推广可将 $ x^k $ 改为一般的线性无关的连续函数 $ \varphi_k(x) $，全体构成 $ C[a, b] $ 的子空间，即  </p>
<span>
$$
\Phi = \text{span}\{ \varphi_0, \varphi_1, \dots, \varphi_n \}
$$
</span>

<p>最佳平方逼近问题可叙述为：求 $ a_0^* , a_1^* , \dots, a_n^*  $ 使得   </p>
 <span>
$$
|| f(x) - s^* (x) ||_2^2 = || f(x) - \sum_ {k=0}^n a_k  \varphi _k (x) ||_2^2= \min_{s(x) \in \Phi} \| f(x) - s(x) \|_2^2
$$
</span>

<p>其中，$ \Phi &#x3D; \text{span}{ \varphi_0, \varphi_1, \dots, \varphi_n } $ 是由基函数 $ \varphi_k(x) $ 生成的函数空间。</p>
<p><strong>上述问题等价于求解多元函数</strong><br>$$<br>I(a_0, a_1, \dots, a_n) &#x3D; \int_a^b \rho(x) \left| f(x) - \sum_{k&#x3D;0}^n a_k \varphi_k(x) \right|^2 dx<br>$$<br>的最小值问题。</p>
<p>由多元函数极值存在的必要条件可得如下的法方程组：<br>$$<br>\sum_{j&#x3D;0}^{n} (\varphi_j, \varphi_k) a_j &#x3D; (f, \varphi_k), \quad (k &#x3D; 0, 1, \ldots, n)<br>$$</p>
<p>可证明方程组有唯一解 $ a_k &#x3D; a_k^* $（$ k &#x3D; 0, 1, \dots, n $），从而得到</p>
<p>$s^* (x) &#x3D; a_0^*  \varphi_0(x) + \cdots + a_n^*  \varphi_n(x)$</p>
<p>若令<br>$$<br>\delta(x) &#x3D; f(x) - S^* (x),<br>$$</p>
<h3 id="最佳平方逼近的误差"><a href="#最佳平方逼近的误差" class="headerlink" title="最佳平方逼近的误差"></a>最佳平方逼近的误差</h3><span>
$$
\|\delta(x)\|^2_2 = \left( f(x) - S^* (x), f(x) - S^* (x) \right) \\
= (f(x), f(x)) - (S^*(x), f(x)) = \|f(x)\|^2_2 - \sum_{k=0}^n a_k^* (\varphi_k(x), f(x)).
$$
</span>

<p><strong>PS</strong>:根据法方程可得$(S^* (x),\varphi_k)&#x3D;(f,\varphi_k)$,进一步得$(f-S^* (x),\varphi_k)&#x3D;0$，即$(f-S^* ,S^* )&#x3D;0$</p>
<blockquote>
<p>若取基函数<span style="color:#FF0000">（注意区间是$[0, 1]$，如果区间不对，不要乱套希尔伯特矩阵，老实用函数内积解题）  </span><br>$$<br>\varphi_k(x) &#x3D; x^k, \quad \rho(x) &#x3D; 1, \quad f(x) \in C[0, 1],<br>$$<br>则要在 $ H_n $ 中求 $ n $ 次最佳平方逼近多项式<br>$$<br>s^*(x) &#x3D; a_0 + a_1 x + \dots + a_n x^n.<br>$$</p>
<p>此时，内积定义为<br>$$<br>(\varphi_i(x), \varphi_j(x)) &#x3D; \int_0^1 x^{i+j} , dx &#x3D; \frac{1}{i + j + 1},<br>$$<br>而<br>$$<br>(f(x), \varphi_k(x)) &#x3D; \int_0^1 f(x) x^k , dx &#x3D; d_k.<br>$$</p>
<p>用 $ H $ 表示格拉姆矩阵 $ G_n &#x3D; G(1, x, \dots, x^n) $，即  </p>
<span>
$$
H = \begin{pmatrix}
1 & \frac{1}{2} & \cdots & \frac{1}{n+1} \\
\frac{1}{2} & \frac{1}{3} & \cdots & \frac{1}{n+2} \\
\vdots & \vdots & & \vdots \\
\frac{1}{n+1} & \frac{1}{n+2} & \cdots & \frac{1}{2n+1}
\end{pmatrix},
$$
<span>

<p>称 $ H $ 为<strong>希尔伯特(Hilbert)矩阵</strong>。记向量<br>$$<br>a &#x3D; (a_0, a_1, \dots, a_n)^T, \quad d &#x3D; (d_0, d_1, \dots, d_n)^T,<br>$$<br>则线性方程组<br>$$<br>H a &#x3D; d<br>$$<br>的解 $ a_k &#x3D; a_k^* $（$ k &#x3D; 0, 1, \dots, n $）即为所求。</p>
</blockquote>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>求$f(x)&#x3D;\ln x,x\in[1,2]$上的二次最佳平方逼近多项式及平方误差</p>
<p><strong>解</strong></p>
<p><img src="/blog/image/Snipaste_2025-05-31_09-54-07.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-05-31_10-10-39.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-01_09-49-41.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/vnmdisrni.jpg"></p>
<p><img src="/blog/image/Snipaste_2025-06-01_10-38-39.png"></p>
</blockquote>
<h2 id="用正交函数系作最佳平方逼近"><a href="#用正交函数系作最佳平方逼近" class="headerlink" title="用正交函数系作最佳平方逼近"></a>用正交函数系作最佳平方逼近</h2><p>若 ${g_k(x)}(k&#x3D;0,1,\dots,n)$ 是带权 $\rho(x)$ 正交的函数系，即满足：</p>
<p>$$<br>(g_k, g_j) &#x3D; \int_a^b \rho(x) g_k(x) g_j(x) , dx &#x3D; 0 \quad (k \neq j)<br>$$</p>
<p>通过法方程组 $\sum _{k&#x3D;0}^n  (g_k, g_j)a_j &#x3D; (f, g_j)$ 可以独立解得：</p>
<p>$$<br>a_j^* &#x3D; \frac{(f, g_j)}{(g_j, g_j)} &#x3D; \frac{\int_a^b \rho(x) f(x) g_j(x) , dx}{\int_a^b \rho(x) g_j^2(x) , dx} \quad (j&#x3D;0,1,\dots,n)<br>$$</p>
<blockquote>
<p>$a^*_j$与$n$无关</p>
</blockquote>
<h3 id="最佳平方逼近函数"><a href="#最佳平方逼近函数" class="headerlink" title="最佳平方逼近函数"></a>最佳平方逼近函数</h3><p>$$<br>s^* (x) &#x3D; \sum_{j&#x3D;0}^na_j^*  g_j(x) &#x3D; \sum_{j&#x3D;0}^n \frac{(f, g_j)}{(g_j, g_j)} g_j(x)<br>$$</p>
<h3 id="广义Fourier级数"><a href="#广义Fourier级数" class="headerlink" title="广义Fourier级数"></a>广义Fourier级数</h3><p>对于函数 $f(x) \in C[a, b]$ 与正交基函数系 ${g_k(x)}(k&#x3D;0,1,\dots,n)$，按公式逐个计算出 $a_j^*$ 后，可以得到一个级数：</p>
<p>$$<br> a_0^* g_0(x) + a_1^* g_1(x) + \dots + a_n^* g_n(x)<br>$$</p>
<p>这个级数称为 $f(x)$ 对应于基函数系 ${g_k(x)}(k&#x3D;0,1,\dots,n)$的广义Fourier级数。</p>
<p>系数 $ a_k^* $ 为广义Fourier系数，对任意固定的 $ n $，其部分和为：</p>
<p>$$<br>S_n(x) &#x3D; \sum_{k&#x3D;0}^n a_k^* g_k(x)<br>$$</p>
<p>$ S_n(x) $ 称为广义多项式，是所求的最佳平方逼近多项式。</p>
<h3 id="勒让德多项式作为基函数"><a href="#勒让德多项式作为基函数" class="headerlink" title="勒让德多项式作为基函数"></a>勒让德多项式作为基函数</h3><p>当 $ f(x) \in C[-1, 1] $ 时，可以用勒让德多项式 $ {P_k(x)} $ 作为基函数，即<span> $ {g_k(x)} &#x3D; {P_k(x)} $</span>。此时，最佳平方逼近多项式为：</p>
<span>
$$
s_n^*(x) = a_0^* P_0(x) + a_1^* P_1(x) + \dots + a_n^* P_n(x)
$$

</span>

<p>其中，系数 $ a_k^* $ 的计算公式为：<br>$$<br>a_k^* &#x3D; \frac{(P_k, f)}{(P_k, P_k)} &#x3D; \frac{2k+1}{2} \int_{-1}^1 f(x) P_k(x) , dx \quad(k&#x3D;0,1,\cdots,n)<br>$$</p>
<p>则 $ s_n^<em>(x) $ 是使 $ || f(x) - \sum _{k&#x3D;0}^n a_k^</em>  P_k(x) ||_2^2 $ 最小的最佳平方逼近多项式。</p>
<p><strong>此时的平方误差为</strong>：</p>
<span>
$$
\|\delta_n\|_2^2 = \int_{-1}^{1} [f(x)]^2 \, dx - \sum_{k=0}^{n} \frac{2}{2k+1} a_k^{*2}
$$

</span>

<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>求函数 $ f(x) &#x3D; e^x $ 在区间 $[-1, 1]$ 上的三次最佳平方逼近多项式，使用基函数 ${P_0, P_1, P_2, P_3}$。</p>
<ol>
<li><strong>计算内积 $(P_k, f)$：</strong></li>
</ol>
<p>$$<br>(P_0, f) &#x3D; \int_{-1}^{1} e^x , dx &#x3D; e - \frac{1}{e} \approx 2.3504<br>$$</p>
<p>$$<br>(P_1, f) &#x3D; \int_{-1}^{1} x e^x , dx &#x3D; 2e^{-1} \approx 0.7358<br>$$</p>
<p>$$<br>(P_2, f) &#x3D; \int_{-1}^{1} \left( \frac{3}{2} x^2 - \frac{1}{2} \right) e^x , dx \approx 0.02013<br>$$</p>
<p>$$<br>(P_3, f) &#x3D; \int_{-1}^{1} \left( \frac{5}{2} x^3 - \frac{3}{2} x \right) e^x , dx \approx 0.02013<br>$$</p>
<ol start="2">
<li><strong>计算系数</strong> $ a_k^*  $</li>
</ol>
<p>$$<br>a_0^* &#x3D; \frac{(P_0, f)}{2} \approx 1.1752 \<br>a_1^* &#x3D; \frac{3}{2} (P_1, f) \approx 1.1036 \<br>a_2^* &#x3D; \frac{5}{2} (P_2, f) \approx 0.3578 \<br>a_3^* &#x3D; \frac{7}{2} (P_3, f) \approx 0.07046<br>$$</p>
<ol start="3">
<li><strong>得到逼近多项式 $ S_3^*(x) $：</strong></li>
</ol>
<p>$$<br>S_3^*(x) &#x3D; 0.9963 + 0.9979x + 0.5367x^2 + 0.1761x^3<br>$$</p>
<ol start="4">
<li><strong>计算平方误差：</strong></li>
</ol>
<span>
$$
\left|| \delta_3 \right||_2^2 = \left|| e^x - s_3^* (x) \right||_2^2 = \int_{-1}^{1} e^{2x} \, dx - \sum_{k=0}^{3} \frac{2}{2k+1} {a_k^* }^2 = 0.88 \times 10^{-4}
$$

</span>


<p><u>如果所给的区间不是 $[-1, 1]$，而是一般的有限区间 $[a, b]$，可以通过变量置换将其转化为区间 $[-1, 1]$ 上的情形来处理</u>。</p>
<p>变量置换公式</p>
<p>通过以下变量置换公式，将区间 $[a, b]$ 转化为 $[-1, 1]$：</p>
<p>$$<br>x &#x3D; \frac{a + b}{2} + \frac{b - a}{2} t<br>$$</p>
<p>其中：</p>
<ul>
<li>$ x $ 为原区间 $[a, b]$ 上的变量；</li>
<li>$ t $ 为转化后的区间 $[-1, 1]$ 上的变量。</li>
</ul>
<p><strong>例题：求函数 $ f(x) &#x3D; \sqrt{x} $ 在区间 $[0, 1]$ 上的一次最佳平方逼近多项式</strong></p>
<ol>
<li><p><strong>变量变换</strong>：<br>令 $ x &#x3D; \frac{1}{2}(1 + t) $，则 $ t \in [-1, 1] $，且：<br>$$<br>f(x) &#x3D; \sqrt{x} &#x3D; \sqrt{\frac{1}{2}(1 + t)} &#x3D; \frac{1}{\sqrt{2}} \sqrt{1 + t} &#x3D; \varphi(t)<br>$$</p>
</li>
<li><p><strong>求解 $ \varphi(t) $ 的一次最佳平方逼近多项式 $ q_1(t) $</strong>：<br>使用勒让德多项式 $ {P_0, P_1} $ 作为基函数，计算系数 $ a_0 $ 和 $ a_1 $：<br>$$<br>a_0^* &#x3D; \frac{1}{2} (\varphi, P_0) &#x3D; \frac{1}{2} \int_{-1}^{1} \frac{1}{\sqrt{2}} \sqrt{1 + t} \cdot 1 , dt &#x3D; \frac{2}{3} \<br>a_1^* &#x3D; \frac{3}{2} (\varphi, P_1) &#x3D; \frac{3}{2} \int_{-1}^{1} \frac{1}{\sqrt{2}} \sqrt{1 + t} \cdot t , dt &#x3D; \frac{6}{15}<br>$$<br>因此，一次最佳平方逼近多项式为：<br>$$<br>q_1(t) &#x3D; a_0 P_0(t) + a_1 P_1(t) &#x3D; \frac{2}{3} + \frac{6}{15} t<br>$$</p>
</li>
<li><p><strong>将 $ t &#x3D; 2x - 1 $ 代入 $ q_1(t) $</strong>：<br>得到 $ \sqrt{x} $ 在区间 $[0, 1]$ 上的一次最佳平方逼近多项式：<br>$$<br>s_1(x) &#x3D; \frac{2}{3} + \frac{6}{15} (2x - 1) &#x3D; \frac{4}{15} + \frac{12}{15} x<br>$$</p>
</li>
</ol>
</blockquote>
<blockquote>
<p><img src="/blog/image/IMG_0145.jpg"></p>
</blockquote>
<h2 id="正交多项式"><a href="#正交多项式" class="headerlink" title="正交多项式"></a>正交多项式</h2><h3 id="正交函数族"><a href="#正交函数族" class="headerlink" title="正交函数族"></a>正交函数族</h3><p>若 $ f(x), g(x) \in C[a, b] $，$ \rho(x) \in C[a, b] $，且 $ \rho(x) $ 为 $[a, b]$ 上的权函数，且<br>$$<br>(f, g) &#x3D; \int_a^b \rho(x) f(x) g(x) , dx &#x3D; 0<br>$$<br>则称 $ f(x) $ 与 $ g(x) $ 在 $[a, b]$ 上<strong>带权 $ \rho(x) $ 正交</strong>。  </p>
<p>设在 $[a, b]$ 给定函数族 $ {\varphi_n(x)} $，且满足  </p>
<span>
$$
(\varphi_i, \varphi_k) = \int_a^b \rho(x) \varphi_i(x) \varphi_k(x) \, dx = 
\begin{cases} 
0, & i \neq k, \\ 
c_k, & i = k 
\end{cases} \quad (i, k = 0, 1, 2, \dots),
$$
</span>

<p>则称函数族 $ {\varphi_n(x)} $ 为 $[a, b]$ 上带权 $ \rho(x) $ 的正交函数族。<br>特别地，当 $ c_k &#x3D; 1 $ 时，则该函数族称为<strong>标准正交函数族</strong>。  </p>
<hr>
<p>设 $ p_n(x) $ 是 $[a, b]$ 上首项系数 $ a_n \neq 0 $ 的 $ n $ 次多项式，$ \rho(x) $ 为 $[a, b]$ 上的权函数。</p>
<p>若多项式序列 ${p_n(x)}_0^\infty$ 满足正交性，则称 ${p_n(x)}_0^\infty$ 为以 $ \rho(x) $ 为权函数的 $[a, b]$ 上的<strong>正交多项式序列</strong>，并称 $ p_n(x) $ 为以 $ \rho(x) $ 为权函数的 $[a, b]$ 上的 $ n $ 次<strong>正交多项式</strong>。</p>
<h3 id="正交多项式序列"><a href="#正交多项式序列" class="headerlink" title="正交多项式序列"></a>正交多项式序列</h3><p>只要给定 $[a, b]$ 上的权函数 $ \rho(x) $，由 $ {1, x, \dots, x^n, \dots} $，利用逐个正交化手续，可构造<strong>正交多项式</strong>序列：<br>$$<br>P_0(x) &#x3D; 1, \quad P_n(x) &#x3D; x^n - \sum_{j&#x3D;0}^{n-1} \frac{(x^n, P_j)}{(P_j, P_j)} P_j(x), \quad n &#x3D; 1, 2, \dots. \quad (2.3)<br>$$</p>
<h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ol>
<li><p><strong>首项系数为1</strong>：<br>$ P_n(x) $ 的首项系数为 1。  </p>
</li>
<li><p><strong>表示性</strong>：<br>任意 $ Q_n(x) \in H_n $ 均可表示为 $ P_0(x), P_1(x), \dots, P_n(x) $ 的线性组合。  </p>
</li>
<li><p><strong>正交性</strong>：<br>当 $ i \neq j $ 时，$ (P_i, P_j) &#x3D; 0 $，且 $ P_n(x) $ 与任意次数小于 $ n $ 的多项式正交。 </p>
<hr>
<p><strong>递推关系</strong></p>
<p>  设 ${\varphi_n(x)}_{0}^{\infty}$ 是 $[a, b]$ 上带权 $\rho(x)$ 的正交多项式，对 $n \geq 0$ 成立递推关系</p>
<p>$$<br>\varphi_{n+1}(x) &#x3D; (x - \alpha_n) \varphi_n(x) - \beta_n \varphi_{n-1}(x), \quad n &#x3D; 0, 1, \dots<br>$$<br>其中<br>$$<br>\varphi_0(x) &#x3D; 1, \quad \varphi_{-1}(x) &#x3D; 0,<br>$$</p>
<p>$$<br>\alpha_n &#x3D; \frac{(x \varphi_n, \varphi_n)}{(\varphi_n, \varphi_n)}, \quad n &#x3D; 0, 1, \dots,<br>$$</p>
<p>$$<br>\beta_n &#x3D; \frac{(\varphi_n, \varphi_{n})}{(\varphi_{n-1}, \varphi_{n-1})}, \quad n &#x3D; 1, 2, \dots,<br>$$</p>
<p><strong>零点性质</strong>：<br>  设 ${ \varphi_n(x) }^{\infty}_0$ 是 $[a, b]$ 上带权 $\rho(x)$ 的正交多项式，则 $\varphi_n(x)$（$n \geq 1$）在区间 $(a, b)$ 内有 $n$ 个不同的零点。<u>（零点都是实的、单重的）</u></p>
</li>
</ol>
<h2 id="勒让德（Legendre）多项式"><a href="#勒让德（Legendre）多项式" class="headerlink" title="勒让德（Legendre）多项式"></a>勒让德（Legendre）多项式</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>勒让德多项式由 <strong>Rodrigues公式</strong> 定义：<br>$$<br>P_n(x) &#x3D; \frac{1}{2^n n!} \frac{d^n}{dx^n}(x^2-1)^n<br>$$</p>
<p>最高项系数为1的勒让德多项式为<br>$$<br>\widetilde{P}_n(x) &#x3D; \frac{n!}{(2n)!} \cdot \frac{d^n}{dx^n}  (x^2 - 1)^n<br>$$</p>
<ul>
<li>$ P_0(x) &#x3D; 1 $</li>
<li>$ P_1(x) &#x3D; x $</li>
<li>$ P_2(x) &#x3D; \frac{1}{2}(3x^2 - 1)$</li>
<li>$P3(x)&#x3D;\frac{1}{2}(5x^3 - 3x)$</li>
</ul>
<hr>
<h3 id="重要性质"><a href="#重要性质" class="headerlink" title="重要性质"></a>重要性质</h3><h4 id="性质1：正交性"><a href="#性质1：正交性" class="headerlink" title="性质1：正交性"></a>性质1：正交性</h4><p>在区间 $[-1, 1]$ 上满足正交性：<br>$$<br>\int_{-1}^1 P_n(x) P_m(x) , dx &#x3D;<br>\begin{cases}<br>0, &amp; m \neq n \<br>\frac{2}{2n+1}, &amp; m &#x3D; n<br>\end{cases}<br>$$</p>
<h4 id="性质2：奇偶性"><a href="#性质2：奇偶性" class="headerlink" title="性质2：奇偶性"></a>性质2：奇偶性</h4><p>满足奇偶对称性：<br>$$<br>P_n(-x) &#x3D; (-1)^n P_n(x)<br>$$</p>
<h4 id="性质3：最小平方误差"><a href="#性质3：最小平方误差" class="headerlink" title="性质3：最小平方误差"></a>性质3：最小平方误差</h4><p>在所有<strong>最高项系数为1的n次多项式</strong>中，勒让德多项式 $ P_n(x) $ 在 $[-1, 1]$ 上与零的平方误差最小。</p>
<h4 id="性质4：实零点"><a href="#性质4：实零点" class="headerlink" title="性质4：实零点"></a>性质4：实零点</h4><p>$ P_n(x) $ 在区间 $[-1, 1]$ 内有 $ n $ 个不同的实零点（可用反证法证明）。</p>
<h4 id="性质5：递推关系"><a href="#性质5：递推关系" class="headerlink" title="性质5：递推关系"></a>性质5：递推关系</h4><p>当 $ n \geq 1 $ 时，满足递推公式：<br>$$<br>(n+1)P_{n+1}(x) &#x3D; (2n+1)xP_n(x) - nP_{n-1}(x)<br>$$</p>
<h2 id="切比雪夫Chebyshev多项式"><a href="#切比雪夫Chebyshev多项式" class="headerlink" title="切比雪夫Chebyshev多项式"></a>切比雪夫Chebyshev多项式</h2><p>当区间为 $[-1, 1]$，权函数 $\rho(x) &#x3D; \dfrac{1}{\sqrt{1 - x^2}}$ 时，由序列 ${1, x, \cdots, x^n, \cdots}$ 正交化得到的正交多项式就是 Chebyshev 多项式，它可表为：</p>
<p>$$<br>T_n(x) &#x3D; \cos(n \arccos x) \quad |x| \leq 1<br>$$<br>若令 $x &#x3D; \cos\theta$，则 $T_n(x) &#x3D; \cos n\theta$，$0 \leq \theta \leq \pi$。</p>
<h3 id="Chebyshev-多项式重要性质"><a href="#Chebyshev-多项式重要性质" class="headerlink" title="Chebyshev 多项式重要性质"></a>Chebyshev 多项式重要性质</h3><p><strong>性质 1</strong>  </p>
<p>Chebyshev 多项式 ${T_n(x)}$ 在区间 $[-1, 1]$ 上带权 $\rho(x) &#x3D; \dfrac{1}{\sqrt{1 - x^2}}$ 正交，且：</p>
<span>
$$
\int_{-1}^{1} \dfrac{T_n(x)T_m(x)}{\sqrt{1 - x^2}} \, dx = 
\begin{cases} 
0, & n \neq m \\
\dfrac{\pi}{2}, & n = m \neq 0 \\
\pi, & n = m = 0 
\end{cases}
$$

</span>

<p><strong>性质 2 递推关系</strong>  </p>
<span>
$$
\begin{cases}
T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x) & (n = 1, 2, \cdots), \\
T_0(x) = 1, \\
T_1(x) = x.
\end{cases}
$$

</span>

<p>由递推关系可得：</p>
<span>
$$
T_0(x)= 1 \quad \\
T_1(x)= x \quad  \\
T_2(x)= 2x^2 - 1 \quad \\
T_3(x)= 4x^3 - 3x \quad \\
T_4(x) = 8x^4 - 8x^2 + 1 \quad \\
T_5(x) = 16x^5 - 20x^3 + 5x
$$

</span>

<p><strong>性质 3</strong>  </p>
<p>$T_{2k}(x)$ 只含 $x$ 的偶次方，$T_{2k+1}(x)$ 只含 $x$ 的奇次方，这一性质由递推关系可直接得到。</p>
<p><strong>性质 4</strong>  </p>
<p>$T_n(x)$ 在区间 $[-1, 1]$ 上有 $n$ 个零点：</p>
<p>$$x_k &#x3D; \cos \dfrac{2k + 1}{2n}\pi, \quad k &#x3D; 0, 1, \cdots, n - 1$$</p>
<p><strong>性质5</strong></p>
<p>$T_n(x)$的首项$x^n$的系数为$2^{n-1}(n&#x3D;1,2…)$</p>
<h2 id="最小二乘拟合"><a href="#最小二乘拟合" class="headerlink" title="最小二乘拟合"></a>最小二乘拟合</h2><p>对于给定的数据 $(x_i, y_i)$（$i&#x3D;1,2,\ldots,N$），选取线性无关的函数族 $\varphi_0, \varphi_1, \ldots, \varphi_m$ 及权函数 $\omega(x)$，要求在函数类 $\Phi &#x3D; \text{Span}{\varphi_0, \varphi_1, \ldots, \varphi_m}$ 中寻找一个函数</p>
<p>$$<br>\varphi^* (x) &#x3D; a_0^*  \varphi_0 + a_1^*  \varphi_1 + \cdots + a_m^*  \varphi_m \quad （m &lt; N）<br>$$</p>
<p>使</p>
<p>$$<br>I &#x3D; \sum_{i&#x3D;1}^N \omega(x_i) [y_i - \varphi(x_i)]^2<br>$$</p>
<p>达到极小。显然上式是 $m+1$ 个变量 $a_0, a_1, \ldots, a_m$ 的二次函数：</p>
<p>$$<br>I(a_0, a_1, \ldots, a_m) &#x3D; \sum_{i&#x3D;1}^N \omega(x_i) \left[ y_i - \sum_{k&#x3D;0}^m a_k \varphi_k(x_i) \right]^2<br>$$</p>
<p>根据多元函数极值条件<br>$$<br>\frac{1}{2} \frac{\partial I}{\partial a_j} &#x3D; \sum_{i&#x3D;1}^N \omega(x_i) \varphi_j(x_i) \left[ y_i - \sum_{k&#x3D;0}^m a_k \varphi_k(x_i) \right] &#x3D; 0 \quad （j&#x3D;0,1,\ldots,m）<br>$$</p>
<blockquote>
<p><strong>引入内积：</strong></p>
<span>
$$
(f, g) = 
\begin{cases} 
\sum ^{N} _{i=1} \omega(x_i) f(x_i) g(x_i) & \text{离散型} \\
\int_{a}^{b} \rho(x) f(x) g(x) \, dx & \text{连续型}
\end{cases}
$$

</span></blockquote>
<p>方程组：</p>
<p>$$<br>\sum_{i&#x3D;1}^{N} \omega(x_i) \left[ y_i - \sum_{k&#x3D;0}^{m} a_k \varphi_k(x_i) \right] \varphi_j(x_i) &#x3D; 0 \quad (j &#x3D; 0, 1, \ldots, m)<br>$$</p>
<p>可以表示为：</p>
<p>$$<br>a_0 (\varphi_j, \varphi_0) + a_1 (\varphi_j, \varphi_1) + \cdots + a_m (\varphi_j, \varphi_m) &#x3D; (\varphi_j, y)  \quad (j &#x3D; 0, 1, \ldots, m)<br>$$</p>
<p>这个方程组称为<strong>法方程</strong>或<strong>正规方程组</strong>。若用 ${\varphi_0, \varphi_1, \ldots, \varphi_m}$ 构成一个 $N \times (m+1)$ 的矩阵 $A$，即：</p>
<span>
$$
A = 
\begin{bmatrix}
\varphi_0(x_1) & \varphi_1(x_1) & \cdots & \varphi_m(x_1) \\
\varphi_0(x_2) & \varphi_1(x_2) & \cdots & \varphi_m(x_2) \\
\vdots & \vdots & \ddots & \vdots \\
\varphi_0(x_N) & \varphi_1(x_N) & \cdots & \varphi_m(x_N)
\end{bmatrix}
$$

</span>

<p>引入向量：</p>
<p>$$<br>\alpha &#x3D; (a_0, a_1, \ldots, a_m)^T, \quad Y &#x3D; (y_1, y_2, \ldots, y_N)^T<br>$$</p>
<p>法方程组可以写成以下矩阵形式：(权w&#x3D;1)</p>
<p>$$<br>A^T A \alpha &#x3D; A^T Y<br>$$</p>
<p>由于 $\varphi_0, \varphi_1, \ldots, \varphi_m$ 线性无关，法方程组存在唯一解：</p>
<p>$$<br>\alpha &#x3D; (a_0^* , a_1^* , \ldots, a_m^* )^T<br>$$</p>
<p>从而得到函数：</p>
<p>$$<br>\varphi^* (x) &#x3D; a_0^*  \varphi_0 + a_1^*  \varphi_1 + \cdots + a_m^*  \varphi_m<br>$$</p>
<p>最小平方误差为：</p>
<p>$$<br>\delta^2 &#x3D; || y - \varphi^*  ||^2_2 &#x3D; (y - \varphi^* , y - \varphi^* ) &#x3D; || y ||^2_2 - \sum_{j&#x3D;0}^m a_j^*  (\varphi_j, y)<br>$$</p>
<h3 id="代数多项式拟合"><a href="#代数多项式拟合" class="headerlink" title="代数多项式拟合"></a>代数多项式拟合</h3><p>若取基函数 $\varphi_0 &#x3D; 1, \varphi_1 &#x3D; x, \ldots, \varphi_m &#x3D; x^m$，则相应的法方程组为：</p>
<span>
$$
\begin{bmatrix}
\sum_{i=1}^{N} \omega_i & \sum_{i=1}^{N} \omega_i x_i & \cdots & \sum_{i=1}^{N} \omega_i x_i^m \\
\sum_{i=1}^{N} \omega_i x_i & \sum_{i=1}^{N} \omega_i x_i^2 & \cdots & \sum_{i=1}^{N} \omega_i x_i^{m+1} \\
\vdots & \vdots & \ddots & \vdots \\
\sum_{i=1}^{N} \omega_i x_i^m & \sum_{i=1}^{N} \omega_i x_i^{m+1} & \cdots & \sum_{i=1}^{N} \omega_i x_i^{2m}
\end{bmatrix}
\begin{bmatrix}
a_0 \\
a_1 \\
\vdots \\
a_m
\end{bmatrix}
=
\begin{bmatrix}
\sum_{i=1}^{N} \omega_i y_i \\
\sum_{i=1}^{N} \omega_i x_i y_i \\
\vdots \\
\sum_{i=1}^{N} \omega_i x_i^m y_i
\end{bmatrix}
$$

</span>

<p>即<br>$$<br>A^T\omega A\alpha&#x3D;A^T\omega Y<br>$$<br><span><br>$$<br>A &#x3D;<br>\begin{bmatrix}<br>1 &amp; x_1 &amp; \cdots &amp; x_1^m \<br>1 &amp; x_2 &amp; \cdots &amp; x_2^m  \<br>1 &amp; x_3 &amp; \cdots &amp; x_3^m  \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>1 &amp; x_N &amp; \cdots &amp; x_N^m<br>\end{bmatrix}<br>$$</p>
</span>   
$$
\omega =\begin{bmatrix}
\omega_1& &  &  \\
 & \omega _2 &  &   \\
 &  & \omega_3 &   \\
 &  &  & \ddots \\
 &  &  &  & \omega _n
\end{bmatrix}
$$


<p>求出法方程组的解 $a_0, a_1, \ldots, a_m$，即可得到拟合多项式：<br>$$<br>\varphi(x) &#x3D; a_0 + a_1 x + \cdots + a_m x^m<br>$$<br><span style="color:#FF0000">PS:当$n\geq3$时候，求解法方程时将出现系数矩阵为病态的问题</span></p>
<h3 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>已知函数值表（见表3-1），试用二次多项式 $y &#x3D; c_{0} + c_{1}x + c_{2}x^{2}$ 按最小二乘原理拟合这组数据。  </p>
<p>表3-1  </p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>$-2$</th>
<th>$-1$</th>
<th>$0$</th>
<th>$1$</th>
<th>$2$</th>
</tr>
</thead>
<tbody><tr>
<td>$y$</td>
<td>$0$</td>
<td>$1$</td>
<td>$2$</td>
<td>$1$</td>
<td>$0$</td>
</tr>
</tbody></table>
<p><strong>解</strong>：  </p>
<p>系数矩阵为</p>
<span>
$$
A = 
\begin{bmatrix}
1 & -2 & 4 \\
1 & -1 & 1  \\
1 & 0 & 0  \\
1& 1 & 1 \\
1 & 2 & 4
\end{bmatrix}
$$

</span>

<p>计算$A^TA$与$A^Ty$为</p>
<p>步骤略</p>
<p>解方程组$A^T A \alpha &#x3D; A^T y$</p>
<span>
$$
\begin{cases}
5c_0 + 10c_2 = 4 \\  
10c_1 = 0  \\  
10c_0 + 34c_2 = 2  
\end{cases}
$$

</span>
$$
c_0 = \frac{58}{35}, \quad c_1=0, \quad c_2 = -\frac{3}{7}.
$$

<ul>
<li><strong>最终拟合多项式</strong>：<br>$$<br>y &#x3D; \frac{58}{35} - \frac{3}{7}x^2<br>$$</li>
</ul>
</blockquote>
<blockquote>
<p>已知实测数据表：</p>
<table>
<thead>
<tr>
<th>$x_i$</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody><tr>
<td>$y_i$</td>
<td>4</td>
<td>4.5</td>
<td>6</td>
<td>8</td>
<td>8.5</td>
</tr>
<tr>
<td>$\omega_i$</td>
<td>2</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<p>试用最小二乘法求多项式曲线与此数据组拟合。</p>
<p><strong>解</strong>（线性拟合版本）：  </p>
<ol>
<li><strong>构造加权设计矩阵</strong>：<br> 设一次多项式为 $y &#x3D; c_0 + c_1x$，设计矩阵和权重矩阵为：</li>
</ol>
<span>
$$
A = 
\begin{bmatrix}
1 & 1 \\
1 & 2 \\
1 & 3 \\
1 & 4 \\
1 & 5
\end{bmatrix}, \quad
W = 
\begin{bmatrix}
2 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 3 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
$$

</span>

<ol start="2">
<li><p>计算$A^T\omega A$与$A^T\omega y$</p>
</li>
<li><p><strong>计算正规方程</strong>：<br>方程组 $A^T \omega  A C &#x3D; A^T \omega  Y$ 展开为：</p>
</li>
</ol>
<span>

<p>$$<br>\begin{cases}<br>8c_0 + 22c_1 &#x3D; 47 \<br>22c_0 + 74c_1 &#x3D; 145.5<br>\end{cases}<br>$$<br></span></p>
<ol start="4">
<li><strong>解方程</strong>：</li>
</ol>
<ul>
<li>消元得：<br>$$<br>c_0 &#x3D; 2.5648 \quad c_1&#x3D;1.2037<br>$$</li>
<li><strong>最终拟合多项式</strong>：<br>$$<br>y &#x3D; 2.5648 + 1.2037x<br>$$</li>
</ul>
</blockquote>
<blockquote>
<p>已知实测数据</p>
<table>
<thead>
<tr>
<th>$x_i$</th>
<th>1.00</th>
<th>1.25</th>
<th>1.50</th>
<th>1.75</th>
<th>2.00</th>
</tr>
</thead>
<tbody><tr>
<td>$y_i$</td>
<td>5.10</td>
<td>5.79</td>
<td>6.53</td>
<td>7.45</td>
<td>8.46</td>
</tr>
<tr>
<td>$ln y_i$</td>
<td>1.625</td>
<td>1.756</td>
<td>1.876</td>
<td>2.008</td>
<td>2.135</td>
</tr>
</tbody></table>
<p>试求它的最小二乘拟合</p>
<p><strong>解</strong></p>
<ol>
<li>模型设定:</li>
</ol>
<p>设 $y&#x3D;ae^{bx}$，取对数得 $z&#x3D;\ln y&#x3D;c_{0}+c_{1}x$（$c_{0}&#x3D;\ln a,c_{1}&#x3D;b$）。</p>
<ol start="2">
<li>构造矩阵:</li>
</ol>
<p>设计矩阵 $A$:</p>
<span>
$$
A = 
\begin{bmatrix}
1 & 1.00 \\
1 & 1.25 \\
1 & 1.50 \\
1 & 1.75 \\
1 & 2.00
\end{bmatrix}
$$
</span>

<p>观测向量 $Y$:</p>
<span>
$$
Y = 
\begin{bmatrix}
1.625\\
1.756\\
1.876\\
2.008\\
2.135
\end{bmatrix}
$$
</span>

<ol start="3">
<li>计算正规方程组系数:</li>
</ol>
<span>
$$
 A^{T}A=\begin{bmatrix}5&7.5\\7.5&11.875\end{bmatrix} 
$$
</span>

<p>计算</p>
<span>

<p>$$<br>A^{T}Y&#x3D;<br>\begin{bmatrix}<br>9.40\<br>14.418<br>\end{bmatrix}<br>$$</p>
</span>

<ol start="4">
<li>解正规方程组：</li>
</ol>
<span>

<p>$$<br>5c_{0}+7.5c_{1}&#x3D;9.40\<br>7.5c_{0}+11.875c_{1}&#x3D;14.418<br>$$<br></span></p>
<p>解得 $c_{1}&#x3D;0.5088,c_{0}&#x3D;1.1168$。</p>
<ol start="5">
<li>还原参数：</li>
</ol>
<p>$$ a&#x3D;e^{1.1168}\approx 3.055,b&#x3D;0.5088. $$</p>
<p>拟合曲线</p>
<p>$$ y&#x3D;3.055e^{0.5088x} $$</p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-01_15-11-04.png"></p>
<p><img src="/blog/image/cvnbsiuev.jpg"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-01_15-47-00.png"></p>
<p><img src="/blog/image/nvid.jpg"></p>
</blockquote>
<h3 id="用正交多项式拟合"><a href="#用正交多项式拟合" class="headerlink" title="用正交多项式拟合"></a>用正交多项式拟合</h3><p>用最小二乘法得到的法方程，其系数矩阵 $G$ 是病态的。但如果 $\varphi_0(x), \varphi_1(x), \ldots, \varphi_n(x)$ 是关于点集 ${x_i}$（$i &#x3D; 0, 1, \ldots, m$）带权 $\omega(x_i)$（$i &#x3D; 0, 1, \ldots, m$）正交的函数族，即：</p>
<p>$$<br>(\varphi_j, \varphi_k) &#x3D; \sum_{i&#x3D;0}^{m} \omega(x_i) \varphi_j(x_i) \varphi_k(x_i) &#x3D;<br>\begin{cases}<br>0, &amp; j \neq k, \<br>A_k &gt; 0, &amp; j &#x3D; k<br>\end{cases}<br>$$</p>
<p><span style="color:#FF0000"> $a_k^* $ 的表达式为：</span><br>$$<br>a_k^*  &#x3D; \frac{(f, \varphi_k)}{(\varphi_k, \varphi_k)} &#x3D; \frac{\sum_{i&#x3D;0}^{m} \omega(x_i) f(x_i) \varphi_k(x_i)}{\sum_{i&#x3D;0}^{m} \omega(x_i) \varphi_k^2(x_i)}, \quad k &#x3D; 0, 1, \ldots, n<br>$$</p>
<p><span style="color:#FF0000"> 平方误差的表达式为：</span></p>
<span>
$$
\| \delta \|_2^2 = \| f \|_2^2 - \sum_{k=0}^{n} A_k (a_k^* )^2
$$

</span>

<h3 id="正交多项式构造"><a href="#正交多项式构造" class="headerlink" title="正交多项式构造"></a>正交多项式构造</h3><p>根据给定节点 $x_0, x_1, \ldots, x_m$ 及权函数 $\omega(x) &gt; 0$，构造带权正交多项式 ${P_n(x)}$，其中 $n \leq m$，并用递推公式表示 $P_k(x)$。</p>
<p>定义首项系数为 1 的多项式 $P_k(x)$：</p>
<p>$$<br>P_0(x) &#x3D; 1 \<br>P_1(x) &#x3D; (x - \alpha_1)P_0(x) \<br>P_{k+1}(x) &#x3D; (x - \alpha_{k+1}) P_k(x) - \beta_k P_{k-1}(x) \quad k &#x3D; 1, 2, \ldots，n-1<br>$$</p>
<p>根据 $P_k(x)$ 的正交性，得：</p>
<p>$$<br>\alpha_{k+1} &#x3D; \frac{(x P_k, P_k)}{(P_k, P_k)}, \quad k &#x3D; 0, 1, \ldots, n-1<br>$$</p>
<p>$$<br>\beta_k &#x3D; \frac{(P_k, P_k)}{(P_{k-1}, P_{k-1})}, \quad k &#x3D; 1, 2, \ldots, n-1<br>$$</p>
<p>逐步把 $a_k^* P_k(x)$ 累加到 $S(x)$ 中去，最后就可得到所求的拟合曲线</p>
<p>$$<br>y &#x3D; S(x) &#x3D; a_0^* P_0(x) + a_1^* P_1(x) + \cdots + a_n^* P_n(x).<br>$$</p>
<h2 id="最佳一致逼近多项式"><a href="#最佳一致逼近多项式" class="headerlink" title="最佳一致逼近多项式"></a>最佳一致逼近多项式</h2><h3 id="最佳平方逼近"><a href="#最佳平方逼近" class="headerlink" title="最佳平方逼近"></a>最佳平方逼近</h3><p><strong>最佳平方逼近</strong>，即连续型 L-S 逼近，在 $||f||_2 &#x3D; \sqrt{(f, f)}$ 意义下，使得 $||P - y||_2$ 最小。</p>
<h3 id="最佳一致逼近"><a href="#最佳一致逼近" class="headerlink" title="最佳一致逼近"></a>最佳一致逼近</h3><p><strong>最佳一致逼近</strong>（Uniform Approximation），在 $||f||_ \infty &#x3D; \max_{x \in [a, b]} |f(x)|$ 意义下，使得 $||P - y||_\infty$ 最小，也称为 <strong>minimax problem</strong>。</p>
<h3 id="偏差"><a href="#偏差" class="headerlink" title="偏差"></a>偏差</h3><p>设 $ f \in C[a, b] $，$ p_n \in H_n &#x3D; \text{span}{1, x, \cdots, x^n} $，称</p>
<p>$$<br>\Delta(f, p_n) &#x3D; ||f - p_n||_ \infty &#x3D; \max_{a \leq x \leq b} |f(x) - p_n(x)|<br>$$</p>
<p>为 $ p_n $ 与 $ f $ 的<strong>偏差</strong>。</p>
<h3 id="偏差点"><a href="#偏差点" class="headerlink" title="偏差点"></a>偏差点</h3><p>设 $ f \in C[a, b] $，$ p \in H_n $，若存在 $ x_0 \in [a, b] $ 使得</p>
<p>$$<br>|f(x_0) - p(x_0)| &#x3D; \Delta(f, p) &#x3D; \max_{a \leq x \leq b} |f(x) - p(x)| &#x3D; \mu,<br>$$</p>
<p>则称 $ x_0 $ 是 $ p $ 关于 $ f $ 的<strong>偏差点</strong>。</p>
<ul>
<li>若 $ p(x_0) - f(x_0) &#x3D; \mu $，则称 $ x_0 $ 为<strong>正偏差点</strong>；</li>
<li>若 $ p(x_0) - f(x_0) &#x3D; -\mu $，则称 $ x_0 $ 为<strong>负偏差点</strong>。。</li>
</ul>
<h3 id="最小偏差"><a href="#最小偏差" class="headerlink" title="最小偏差"></a>最小偏差</h3><p>若</p>
<p>$$<br>E_n &#x3D; \inf_{p_n \in H_n} \Delta(f, p_n) &#x3D; \min_{p_n \in H_n} \Delta(f, p_n)<br>$$</p>
<p>则称 $ E_n $ 为 $ p_n $ 与 $ f $ 的 <strong>最小偏差</strong>。</p>
<h3 id="最佳一致逼近多项式-1"><a href="#最佳一致逼近多项式-1" class="headerlink" title="最佳一致逼近多项式"></a>最佳一致逼近多项式</h3><p>设 $ f \in C[a, b] $，若存在 $ p_n^* \in H_n $，使<br>$$<br>\Delta(f, p_n^*) &#x3D; E_n &#x3D; \min_{p_n \in H_n} \Delta(f, p_n)<br>$$</p>
<p>则称 $ p_n^* $ 为 $ f $ 在 $[a, b]$ 上的<strong>最佳一致逼近多项式</strong>，简称<strong>最佳逼近多项式</strong>。</p>
<blockquote>
<p><strong>定理：</strong></p>
<p>若 $ p^* (x) \in H_n $ 是 $ f(x) \in C[a, b] $ 的最佳逼近多项式，</p>
<p>则 $ p^*(x) $ 同时存在正、负偏差点。</p>
<p><strong>定理：</strong></p>
<p>若 $ f \in C[a, b] $，则存在 $ p_n^* \in H_n $，使得</p>
<p>$$<br>\Delta(f, p_n^*) &#x3D; E_n &#x3D; \min_{p_n \in H_n} \Delta(f, p_n)<br>$$<br>成立</p>
<p><strong>定理：</strong></p>
<p>$ p_n \in H_n $ 是 $ f \in C[a, b] $ 的最佳逼近多项式的充分必要条件是，在 $[a, b]$ 上至少有 <strong>$ n + 2 $</strong> 个轮流为正负的偏差点，即至少有 $ n + 2 $ 个点 $ a \leq x_1 &lt; x_2 &lt; \dots &lt; x_{n+2} \leq b $，使得</p>
<span>
$$
p_n^*(x_k) - f(x_k) = (-1)^k \sigma || f - p_n^* ||_\infty, \quad \sigma = \pm 1, \quad k = 1, 2, \cdots, n+2
$$

</span>

<p>上述点 ${x_k}_{1}^{n+2}$ 称为 <strong>Chebyshev 交错点组</strong>。</p>
<p><strong>推论1（唯一性定理）：</strong></p>
<p>设 $ f \in C[a, b] $，则在 $ H_n $ 中的最佳逼近多项式是唯一的。</p>
<p><strong>推论 2</strong>：</p>
<p>若 $ f \in C[a, b] $，则其最佳逼近多项式 $ p_n^*(x) \in H_n $ 是 $ f $ 的一个 <strong>Lagrange 插值多项式</strong>。</p>
</blockquote>
<h3 id="最佳一次一致逼近多项式的求法"><a href="#最佳一次一致逼近多项式的求法" class="headerlink" title="最佳一次一致逼近多项式的求法"></a>最佳一次一致逼近多项式的求法</h3><blockquote>
<p><strong>推导过程</strong></p>
<p>$ n &#x3D; 1 $ 时求 $ p_1(x) &#x3D; a_0 + a_1 x $ 的方法</p>
<p>设 $ f \in C^2[a, b] $ 且 $ f’’ $ 在 $[a, b]$ 上不变号，由上面的定理可知，存在点<br>$$<br>a \leq x_1 &lt; x_2 &lt; x_3 \leq b,<br>$$</p>
<p>使得</p>
<p>$$<br>p_1(x_k) - f(x_k) &#x3D; (-1)^k \sigma E_n, \quad k &#x3D; 1, 2, 3; \quad \sigma &#x3D; \pm 1.<br>$$</p>
<p>由于 $ f’’ $不变号，故 $ f’ $ 在 $[a, b]$ 上单调，于是 $ f’(x) - p_1’(x) &#x3D; f’(x) - a_1&#x3D;0 $ 只有一个根 $ x_2 $。因此，$ p_1 $ 对 $ f $ 的另两个偏差点只能在 $[a, b]$ 的端点，故有</p>
<p>$$<br>x_1 &#x3D; a, \quad x_3 &#x3D; b.<br>$$</p>
<p>由此可得</p>
<p>$$<br>p_1(a) - f(a) &#x3D; -\left[ p_1(x_2) - f(x_2) \right] &#x3D; p_1(b) - f(b),<br>$$</p>
<p>或</p>
<p>$$<br>a_0 + a_1 a - f(a) &#x3D; a_0 + a_1 b - f(b)<br>$$</p>
<p>$$<br>a_0 + a_1 a - f(a) &#x3D; -\left[ a_0 + a_1 x_2 - f(x_2) \right]<br>$$</p>
<p>通过上面两个公式可得<span style="color:#FF0000">（记住下面3个公式）</span></p>
<p>$$<br>a_1 &#x3D; \frac{f(b) - f(a)}{b - a}<br>$$</p>
<p>$$<br>a_0 &#x3D; \frac{1}{2} \left[ f(a) + f(x_2) \right] - \frac{a+x_2}{2} a_1\<br>f’(x_2) &#x3D; a_1<br>$$</p>
<p>由此得 $ f $ 在 $[a, b]$ 上的最佳一次逼近多项式</p>
<p>$$<br>p_1(x) &#x3D; a_0 + a_1 x.<br>$$</p>
</blockquote>
<h3 id="例题-3"><a href="#例题-3" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>求函数 $ f(x) &#x3D; \sqrt{x} $ 在区间 $[\frac{1}{4}, 1]$ 上的最佳一次一致逼近多项式。</p>
<ol>
<li>确定二阶导数不变号</li>
</ol>
<p>函数 $ f(x) &#x3D; \sqrt{x} $ 的二阶导数为：</p>
<p>$$<br>f’’(x) &#x3D; -\frac{1}{4} x^{-\frac{3}{2}}<br>$$</p>
<p>在区间 $\left(\frac{1}{4}, 1\right)$ 上，$ f’’(x) $ 不变号。</p>
<ol start="2">
<li>计算多项式系数</li>
</ol>
<p>根据最佳一次逼近多项式的性质，设 $ p_1(x) &#x3D; a_0 + a_1 x $</p>
<p>$$<br>a_1&#x3D;\frac {f(1)-f(\frac{1}{4})}{1-\frac{1}{4}}&#x3D;\frac{2}{3} \quad \<br>f’(x_2) &#x3D; \frac{1}{2\sqrt{x_2}} &#x3D; a_1 \quad \<br>x_2&#x3D;\frac{9}{16} \quad \<br>a_0 &#x3D; \frac{1}{2} \left[ f(a) + f(x_2) \right] - \frac{a+x_2}{2} \frac{f(b) - f(a)}{b - a}&#x3D;\frac{17}{48}<br>$$</p>
<p>最佳一次逼近多项式为：<br>$$<br>p_1(x) &#x3D; \frac{17}{48} + \frac{2}{3} x<br>$$</p>
<p>在区间 $\left[\frac{1}{4}, 1\right]$ 上，最大误差为：<br>$$<br>\max_{\frac{1}{4} \leq x \leq 1} \left| \sqrt{x} - p_1(x) \right| &#x3D; \frac{1}{48}<br>$$</p>
<hr>
<p>求函数 $f(x) &#x3D; \sqrt{1 + x^2}$ 在 $[0,1]$ 上的一次最佳一致逼近多项式，并求其偏差。</p>
<p><strong>解题过程</strong><br>因 $f’(x) &#x3D; x &#x2F; \sqrt{1 + x^2}$，$f’’(x) &#x3D; 1 &#x2F; (1 + x^2)^{3&#x2F;2}$，所以在 $[0, 1]$ 上 $f’’(x)$ 恒为正，</p>
<p>故由公式 $|| f - P_n^*  || _{\infty} &#x3D; \min || f - P_n || _{\infty}$ 知：</p>
<p>$$<br>a_1 &#x3D; \frac{f(1) - f(0)}{1 - 0} &#x3D; \sqrt{2} - 1 \approx 0.4142<br>$$</p>
<p>由 $f’(x_2) &#x3D; x_2 &#x2F; \sqrt{1 + x_2^2} &#x3D; \sqrt{2} - 1$，得：</p>
<p>$$<br>x_2 &#x3D; \left( \frac{\sqrt{2} - 1}{2} \right)^{1&#x2F;2} \approx 0.4551<br>$$</p>
<p>且：</p>
<p>$$<br>f(x_2) &#x3D; \sqrt{1 + x_2^2} \approx 1.0986<br>$$</p>
<p>所以：</p>
<p>$$<br>a_0 &#x3D; \frac{1}{2} \left[ f(0) + f(x_2) \right] - a_1 \cdot \frac{0 + x_2}{2} \approx 0.955<br>$$</p>
<p>于是得到 $f(x) &#x3D; \sqrt{1 + x^2}$ 在 $[0,1]$ 上一次最佳一致逼近多项式：</p>
<p>$$<br>P_1(x) &#x3D; 0.955 + 0.4142x<br>$$</p>
<p>又因区间端点必属于 Chebyshev 交错点组，故：</p>
<p>$$<br>\Delta(f, P_1) &#x3D; \max_{0 \leq x \leq 1} |f(x) - P_1| &#x3D; |f(0) - P_1(0)| &#x3D; |1 - 0.955| &#x3D; 0.045<br>$$</p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-01_09-28-07.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-01_09-33-26.png"></p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析-插值法</title>
    <url>/blog/2025/05/08/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E6%8F%92%E5%80%BC%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文章包含数值分析的插值法部分—————————————————————————————————————————————————————————————————</p>
<h1 id="第二章-插值法"><a href="#第二章-插值法" class="headerlink" title="第二章 插值法"></a>第二章 插值法</h1><h2 id="插值法定义"><a href="#插值法定义" class="headerlink" title="插值法定义"></a>插值法定义</h2><p>设函数 $y &#x3D; f(x)$ 在区间 $[a, b]$ 上有定义，且满足节点排列：<br>$$ a \leq x_0 &lt; x_1 &lt; \cdots &lt; x_n \leq b $$</p>
<p>已知在点 ${x_0, x_1, \ldots, x_n}$ 上的对应函数值 ${y_0, y_1, \ldots, y_n}$。</p>
<p>若存在一简单函数 $p(x)$，满足插值条件：<br>$$ p(x_i) &#x3D; y_i \quad (i &#x3D; 0, 1, 2, \ldots, n) \tag{2.1} $$  （1） </p>
<p>则称：</p>
<ul>
<li>$p(x)$ 为 $f(x)$ 的<strong>插值函数</strong></li>
<li>${x_0, x_1, \ldots, x_n}$ 为<strong>插值节点</strong></li>
<li>包含节点的区间 $[a, b]$ 为<strong>插值区间</strong></li>
<li>式 (1) 为<strong>插值条件</strong></li>
<li>求插值函数的方法称为<strong>插值法</strong></li>
</ul>
<hr>
<h3 id="插值函数分类"><a href="#插值函数分类" class="headerlink" title="插值函数分类"></a>插值函数分类</h3><p>当 $p(x)$ 具有以下形式时：</p>
<ol>
<li><p><strong>多项式插值</strong><br>$$ p(x) &#x3D; a_0 + a_1x + \cdots + a_nx^n \quad (a_i \in \mathbb{R}) \tag{2.2} $$<br>其中多项式次数 $\leq n$</p>
</li>
<li><p><strong>分段插值</strong><br>$p(x)$ 为分段多项式</p>
</li>
<li><p><strong>三角插值</strong><br>$p(x)$ 为三角多项式</p>
</li>
</ol>
<blockquote>
<p><strong>定理</strong>：满足$p(x_i)&#x3D;y_i,i&#x3D;0,\cdots n$ 次数不超过<strong>n</strong>的插值多项式是唯一存在的（证明略）</p>
</blockquote>
<h2 id="拉格朗日插值"><a href="#拉格朗日插值" class="headerlink" title="拉格朗日插值"></a>拉格朗日插值</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>求 <strong>n次多项式</strong>：<br>$$<br>L_n(x) &#x3D; y_0 l_0(x) + y_1 l_1(x) + \cdots + y_n l_n(x)<br>$$<br>满足插值条件：<br>$$<br>L_n(x_i) &#x3D; y_i \quad (i &#x3D; 0,1,2,\ldots,n)<br>$$</p>
<p><strong>约束条件</strong>：</p>
<ul>
<li>无重合节点：当 $i \neq j$ 时，$x_i \neq x_j$</li>
</ul>
<hr>
<h3 id="线性插值特例-n-1"><a href="#线性插值特例-n-1" class="headerlink" title="线性插值特例 ($n&#x3D;1$)"></a>线性插值特例 ($n&#x3D;1$)</h3><p>已知两点 $(x_0, y_0)$ 和 $(x_1, y_1)$，构造一次多项式：<br>$$<br>L_1(x) &#x3D; l_0(x)y_0 + l_1(x)y_1<br>$$</p>
<p><strong>插值条件</strong>：<br>$$<br>\begin{cases}<br>L_1(x_0) &#x3D; y_0 \<br>L_1(x_1) &#x3D; y_1<br>\end{cases}<br>$$</p>
<p><strong>几何意义</strong>：$L_1(x)$ 是过点 $(x_0, y_0)$ 和 $(x_1, y_1)$ 的直线</p>
<p><strong>插值公式</strong><br>$$<br>L_1(x) &#x3D; \frac{x - x_1}{x_0 - x_1} y_0 + \frac{x - x_0}{x_1 - x_0}y_1<br>$$</p>
<p>$$<br>\frac{x - x_1}{x_0 - x_1}与\frac{x - x_0}{x_1 - x_0}称为拉氏基函数<br>$$</p>
<p>等价于点斜式：<br>$$<br>L_1(x) &#x3D; y_0 + \frac{y_1 - y_0}{x_1 - x_0}(x - x_0)<br>$$</p>
<p><strong>公式说明</strong></p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>$l_i(x)$</td>
<td>拉格朗日基函数，满足 $l_i(x_j) &#x3D; \delta_{ij}$</td>
</tr>
<tr>
<td>$\delta_{ij}$</td>
<td>克罗内克函数，当 $i&#x3D;j$ 时为1，否则为0</td>
</tr>
<tr>
<td>$x_i$</td>
<td>互不相同的插值节点</td>
</tr>
</tbody></table>
<h3 id="n-geq-1-时的插值公式"><a href="#n-geq-1-时的插值公式" class="headerlink" title="$n \geq 1$时的插值公式"></a>$n \geq 1$时的插值公式</h3><p><strong>目标</strong>：希望找到$l_i(x_j)$，满足下式：<br>$$<br>l_i(x_j) &#x3D; \delta_{ij} &#x3D; \begin{cases}<br>1 &amp; i &#x3D; j \<br>0 &amp; i \neq j<br>\end{cases} \quad (i,j&#x3D;0,1,\dots,n)<br>$$</p>
<p><strong>然后令</strong>：<br>$$<br>L_n(x) &#x3D; \sum_{i&#x3D;0}^n l_i(x) y_i \quad \text{显然满足} \quad L_n(x_i) &#x3D; y_i<br>$$</p>
<ol>
<li><p><strong>零点分析</strong>：<br>每个基函数 $l_i(x)$ 在 $n$ 个节点处取零值：<br>$$<br>l_i(x_j) &#x3D; 0 \quad (j \neq i)<br>$$<br>即多项式可表示为：<br>$$<br>l_i(x) &#x3D; C_i \prod_{\substack{j&#x3D;0 \ j \neq i}}^n (x - x_j)<br>$$</p>
</li>
<li><p><strong>归一化条件</strong>：<br>通过 $l_i(x_i) &#x3D; 1$ 确定常数 $C_i$：<br>$$<br>C_i &#x3D; \frac{1}{\prod_{\substack{j&#x3D;0 \ j \neq i}}^n (x_i - x_j)}<br>$$</p>
</li>
<li><p><strong>最终基函数表达式</strong></p>
</li>
</ol>
<p>$$<br>l_i(x) &#x3D; \prod_{\substack{j&#x3D;0 \ j \neq i}}^n \frac{x - x_j}{x_i - x_j}<br>$$</p>
<ol start="4">
<li><strong>插值多项式合成</strong></li>
</ol>
<p>$$<br>L_n(x)&#x3D; \sum_{i&#x3D;0}^n l_i(x) y_i&#x3D; \sum_{i&#x3D;0}^n \left[ \prod_{\substack{j&#x3D;0 \ j \neq i}}^n \frac{x - x_j}{x_i - x_j} \right] y_i &#x3D; \sum_{i&#x3D;0}^{n}  \frac{\omega_{n+1}(x)}{(x - x_i)\omega’_{n+1}(x_i)} y_i<br>$$</p>
<p>$$<br>\omega_{n+1}(x) &#x3D; (x - x_0)(x - x_1)\cdots(x - x_n)<br>$$</p>
<p>$$<br>\omega_{n+1}’(x_i) &#x3D; (x_i - x_0)\cdots(x_i - x_{i-1})(x_i - x_{i+1})\cdots(x_i - x_n)<br>$$</p>
<blockquote>
<p>$$<br>\sum_{i&#x3D;0}^n l_i(x) &#x3D; 1 \quad \text{（特别地，当所有 $y_i&#x3D;1$ 时 $L_n(x)&#x3D;1$）}<br>$$</p>
</blockquote>
<hr>
<h3 id="一点零次插值、线性插值、抛物插值公式"><a href="#一点零次插值、线性插值、抛物插值公式" class="headerlink" title="一点零次插值、线性插值、抛物插值公式"></a>一点零次插值、线性插值、抛物插值公式</h3><ol>
<li><strong>一点零次插值</strong></li>
</ol>
<p><strong>条件</strong>：仅1个节点 $(x_0, y_0)$  </p>
<p><strong>多项式：</strong><br>$$<br>L_n(x) &#x3D; y_0<br>$$</p>
<hr>
<ol start="2">
<li><strong>两点一次插值（线性插值）</strong></li>
</ol>
<p><strong>条件</strong>：2个节点 $(x_0, y_0)$ 和 $(x_1, y_1)$  </p>
<p><strong>多项式</strong>：<br>$$<br>L_1(x) &#x3D; \frac{x - x_1}{x_0 - x_1} y_0 + \frac{x - x_0}{x_1 - x_0} y_1<br>$$</p>
<p><strong>等价形式</strong>：<br>$$<br>L_1(x) &#x3D; y_0 + \frac{y_1 - y_0}{x_1 - x_0}(x - x_0)<br>$$</p>
<hr>
<ol start="3">
<li><strong>三点二次插值（抛物插值）</strong></li>
</ol>
<p><strong>条件</strong>：3个节点 $(x_0, y_0)$，$(x_1, y_1)$，$(x_2, y_2)$<br><strong>多项式</strong>：<br>$$<br>L_2(x) &#x3D; \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)} y_0 + \frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} y_1 + \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)} y_2<br>$$</p>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>给定数据表</p>
<table>
<thead>
<tr>
<th align="center">$x_i$</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$y_i$</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center">14</td>
</tr>
</tbody></table>
<p>求三次拉格朗日插值多项式 $L_3(x)$.</p>
<p><strong>解：</strong> 取 $n&#x3D;3$ 并代入数据表值得<br>$$<br>L_3(x) &#x3D; 0 \cdot l_0(x) + 1 \cdot l_1(x) + 5 \cdot l_2(x) + 14 \cdot l_3(x)<br>$$</p>
<p>$$<br>&#x3D; 0 + 1 \cdot \frac{x(x-2)(x-3)}{1 \cdot (-1) \cdot (-2)} + 5 \cdot \frac{x(x-1)(x-3)}{2 \cdot 1 \cdot (-1)} + 14 \cdot \frac{x(x-1)(x-2)}{3 \cdot 2 \cdot 1}<br>$$</p>
<p>$$<br>&#x3D; 0 + 1 \cdot \frac{x(x-2)(x-3)}{2} + 5 \cdot \frac{x(x-1)(x-3)}{-2} + 14 \cdot \frac{x(x-1)(x-2)}{6}<br>$$</p>
<p>$$<br>&#x3D; \frac{x(2x^2 + 3x + 1)}{6}<br>$$</p>
<p>$$<br>&#x3D; \frac{1}{6} x(x+1)(2x+1)<br>$$</p>
<blockquote>
<p><span style="color:#FF0000">根据插值条件进行验算</span>$L_n(x_i) &#x3D; y_i \quad (i &#x3D; 0,1,2,\ldots,n)$</p>
</blockquote>
<hr>
<p>已知由数据 $(0,0), (0.5,y), (1,3), (2,2) $构造出的三次插值多项式 $P_3(x)$的 $x^3$的系数是 6，试确定数据$y$ </p>
<p><strong>解</strong></p>
<p>利用 Lagrange 插值多项式：</p>
<p>$$<br>P_3(x) &#x3D; L_3(x) &#x3D; f(x_0)l_0(x) + f(x_1)l_1(x) + f(x_2)l_2(x) + f(x_3)l_3(x)<br>$$</p>
<p>由基函数的表达形式可知 $x^3$的系数为：</p>
<p>$$<br>\frac{f(x_0)}{(x_0 - x_1)(x_0 - x_2)(x_0 - x_3)} +<br>\frac{f(x_1)}{(x_1 - x_0)(x_1 - x_2)(x_1 - x_3)} +<br>\frac{f(x_2)}{(x_2 - x_0)(x_2 - x_1)(x_2 - x_3)} +<br>\frac{f(x_3)}{(x_3 - x_0)(x_3 - x_1)(x_3 - x_2)}<br>$$</p>
<p>将有关数据代入上述式得：</p>
<p>$$<br>6 &#x3D; \frac{0}{0.5 \times (-0.5) \times (-1.5)} +<br>\frac{y}{(0.5 - 0)(0.5 - 1)(0.5 - 2)} +<br>\frac{3}{(1 - 0)(1 - 0.5)(1 - 2)} +<br>\frac{2}{(2 - 0)(2 - 0.5)(2 - 1)}<br>$$</p>
<p>解得：</p>
<p>$$<br>y &#x3D; 4.25<br>$$</p>
</blockquote>
<h3 id="插值余项与误差估计"><a href="#插值余项与误差估计" class="headerlink" title="插值余项与误差估计"></a>插值余项与误差估计</h3><p><strong>条件</strong>：</p>
<ol>
<li>函数 $f^{(n)}(x)$ 在区间 $[a, b]$ 上连续</li>
<li>$f^{(n+1)}(x)$ 在 $(a, b)$ 内存在</li>
<li>$L_n(x)$ 是满足插值条件的 $n$ 次多项式，插值节点为 $a \leq x_0 &lt; x_1 &lt; \cdots &lt; x_n \leq b $ <span style="color:#FF0000">($n+1$个)</span></li>
</ol>
<p><strong>结论</strong>：<br>对任意 $x \in [a,b]$，插值余项满足：<br>$$<br>R_n(x) &#x3D; f(x) - L_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{j&#x3D;0}^n (x - x_j) \quad<br>$$<br>其中 $\xi \in (a, b)$，且 $\xi$ 的值依赖于 $x$</p>
<h4 id="误差上界估计"><a href="#误差上界估计" class="headerlink" title="误差上界估计"></a><strong>误差上界估计</strong></h4><p>若记 $\max_{x \in [a,b]} |f^{(n+1)}(x)| &#x3D; M_{n+1}$，则余项绝对误差满足：<br>$$<br>|R_n(x)| \leq \frac{M_{n+1}}{(n+1)!} \cdot |\omega_{n+1}(x)| \quad<br>$$<br>其中 $\omega_{n+1}(x) &#x3D; \prod_{j&#x3D;0}^n (x - x_j)$ 为节点多项式</p>
<blockquote>
<p>$$<br>\omega_{n+1}(x) &#x3D; (x - x_0)(x - x_1)\cdots(x - x_n)<br>$$</p>
<p>$$<br>\omega_{n+1}’(x_i) &#x3D; (x_i - x_0)\cdots(x_i - x_{i-1})(x_i - x_{i+1})\cdots(x_i - x_n)<br>$$</p>
<p>$$<br>L_n(x) &#x3D; \sum_{i&#x3D;0}^{n}  \frac{\omega_{n+1}(x)}{(x - x_i)\omega’_{n+1}(x_i)}y_i<br>$$</p>
</blockquote>
<ul>
<li>节点多项式 $\omega_{n+1}(x)$ 是(n+1)个线性因子的乘积</li>
<li>导数 $\omega’_{n+1}(x_i)$ 计算时排除$(x_i - x_i)$项</li>
<li>基函数构造 $\frac{\omega_{n+1}(x)}{(x - x_i)}$ 确保在$x&#x3D;x_i$时取值为1</li>
</ul>
<p><strong>n&#x3D;1时，线性插值余项</strong><br>$$<br>R_1(x) &#x3D; \frac{1}{2} f’’(\xi) \omega_2(x) &#x3D; \frac{1}{2} f’’(\xi) (x - x_0)(x - x_1), \quad \xi \in [x_0, x_1]<br>$$</p>
<p><strong>n&#x3D;2时，抛物插值余项</strong><br>$$<br>R_2(x) &#x3D; \frac{1}{6} f’’’(\xi) (x - x_0)(x - x_1)(x - x_2), \quad \xi \in [x_0, x_2]<br>$$</p>
<blockquote>
<p><strong>例题</strong></p>
<p>已知 $\sin 0.32 &#x3D; 0.314567$, $\sin 0.34 &#x3D; 0.333487$, $\sin 0.36 &#x3D; 0.352274$, 用线性插值计算和抛物插值计算 $\sin 0.3367$ 的值，并估计误差。</p>
<p><strong>解：</strong><br>$$<br>L_1(x) &#x3D; \frac{x - x_1}{x_0 - x_1} y_0 + \frac{x - x_0}{x_1 - x_0} y_1<br>$$</p>
<p>$$<br>\sin 0.3367 \approx L_1(0.3367) &#x3D;0.330365<br>$$</p>
<p>$$<br>|R_1(x)| \leq \frac{M_2}{2} |(x - x_0)(x - x_1)|,<br>$$</p>
<p>$$<br>M_2 &#x3D; \max_{x_0 \leq x \leq x_1} |f’’(x)| &#x3D; \sin x_1 \leq 0.3335,<br>$$</p>
<p>$$<br>|R_1(0.3367)| \leq \frac{1}{2} \times 0.3335 \times 0.0167 \times 0.0033 \leq 9.2 \times 10^{-6}<br>$$</p>
<hr>
<p>$$<br>L_2(x) &#x3D; y_0 \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)} + y_1 \frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} + y_2 \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)}<br>$$</p>
<p>$$<br>\sin 0.3367 \approx L_2(0.3367) &#x3D; \cdots &#x3D; 0.330365.<br>$$</p>
<p>$$<br>|R_2(x)| \leq \frac{M_3}{6} |(x - x_0)(x - x_1)(x - x_2)|, \quad M_3 \leq \cos(x_0) &lt; 0.828,<br>$$</p>
<p>$$<br>|R_2(0.3367)| \leq \frac{1}{6} \times 0.828 \times 0.0167 \times 0.0033 \times 0.0233 \leq 1.78 \times 10^{-7}.<br>$$</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>已知 $f(4) &#x3D; 2$, $f(9) &#x3D; 3$，用线性插值计算 $f(6)$，并估计误差。</p>
<p><strong>解：</strong><br>已知插值节点 $x_0 &#x3D; 4$, $x_1 &#x3D; 9$，两个插值基函数分别为</p>
<p>$$<br>l_0(x) &#x3D; \frac{x - x_1}{x_0 - x_1} &#x3D; -\frac{1}{5} (x - 9),<br>$$</p>
<p>$$<br>l_1(x) &#x3D; \frac{x - x_0}{x_1 - x_0} &#x3D; \frac{1}{5} (x - 4).<br>$$</p>
<p>故有</p>
<p>$$<br>L_1 &#x3D; l_0(x) y_0 + l_1(x) y_1 &#x3D; -\frac{2}{5} (x - 9) + \frac{3}{5} (x - 4) &#x3D; \frac{x}{5} + \frac{6}{5}.<br>$$</p>
<p>因此，计算得</p>
<p>$$<br>f(6) \approx L_1(6) &#x3D; \frac{6}{5} + \frac{6}{5} &#x3D; 2.4.<br>$$</p>
<p><strong>误差为</strong></p>
<p>$$<br>R_1(6) &#x3D; \frac{f’’(\xi)}{2!} (6 - 4)(6 - 9) &#x3D; -3 f’’(\xi).<br>$$</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>设 $y &#x3D; \ln x$，且有函数表</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>0.40</th>
<th>0.50</th>
<th>0.70</th>
<th>0.80</th>
</tr>
</thead>
<tbody><tr>
<td>$\ln x$</td>
<td>-0.916291</td>
<td>-0.693147</td>
<td>-0.356675</td>
<td>-0.223144</td>
</tr>
</tbody></table>
<p>试计算 $f(0.6) &#x3D; \ln 0.6$ 的近似值，并估计误差。</p>
<hr>
<p>解：</p>
<p>(1) 取插值节点：$x_1 &#x3D; 0.50$, $x_2 &#x3D; 0.70$，做线性插值**（内插式）**</p>
<p>$$<br>f(0.6) \approx L_1(0.6) &#x3D; \left[ y_1 \frac{x - x_2}{x_1 - x_2} + y_2 \frac{x - x_1}{x_2 - x_1} \right]_{x&#x3D;0.6} &#x3D; -0.524911<br>$$</p>
<p>误差：</p>
<p>$$<br>R_1(0.6) &#x3D; f(0.6) - L_1(0.6) &#x3D; \frac{f^{(2)}(\xi)}{2!} (0.6 - 0.5)(0.6 - 0.7) &#x3D; 0.01 \times \frac{1}{\xi^2} \quad (0.5 \leq \xi \leq 0.7)<br>$$</p>
<p>因此，$100&#x2F;49 &lt; 1&#x2F;\xi^2 &lt; 100&#x2F;25$，故 $0.01 &lt; R_1(x) &lt; 0.02$。</p>
<hr>
<p>(2) 取插值节点：$x_1 &#x3D; 0.50$, $x_2 &#x3D; 0.70$, $x_3 &#x3D; 0.80$，做拉格朗日插值**（内插式）**</p>
<p>$$<br>\ln 0.6 \approx L_2(0.6) &#x3D; [y_1 l_1(x) + y_2 l_2(x) + y_3 l_3(x)]_{x&#x3D;0.6} &#x3D; -0.513343<br>$$</p>
<p>误差：</p>
<p>$$<br>R_2(0.6) &#x3D; \frac{f^{(3)}(\xi)}{3!} (0.6 - 0.5)(0.6 - 0.7)(0.6 - 0.8) &#x3D; \frac{2}{3} \times 10^{-3} \times \frac{1}{\xi^3}, \quad x_1 \leq \xi \leq x_3<br>$$</p>
<p>$$<br>1.3 \times 10^{-3} &lt; R_2(0.6) &#x3D; f(0.6) - L_2(0.6) &lt; 5.34 \times 10^{-3}<br>$$</p>
<p>$ f(0.6) &#x3D; \ln 0.6$ 的真值为 $-0.510826$。</p>
<p>因此，拉格朗日插值更精确。</p>
</blockquote>
<h2 id="差商与牛顿插值"><a href="#差商与牛顿插值" class="headerlink" title="差商与牛顿插值"></a>差商与牛顿插值</h2><h3 id="差商及其性质"><a href="#差商及其性质" class="headerlink" title="差商及其性质"></a>差商及其性质</h3><h4 id="差商（均差）的定义"><a href="#差商（均差）的定义" class="headerlink" title="差商（均差）的定义"></a>差商（均差）的定义</h4><p><strong>1阶差商</strong><br>$$<br>f[x_i, x_j] &#x3D; \frac{f(x_i) - f(x_j)}{x_i - x_j} \quad (i \neq j, x_i \neq x_j)<br>$$<br><strong>2阶差商</strong><br>$$<br>f[x_i, x_j, x_k] &#x3D; \frac{f[x_i, x_j] - f[x_j, x_k]}{x_i - x_k} \quad (i \neq k)<br>$$<br><strong>$k+1$阶差商</strong>（$k+2$个点）<br>$$<br>f[x_0, …, x_{k+1}] &#x3D; \frac{f[x_0, x_1, …, x_k] - f[x_1, …, x_k, x_{k+1}]}{x_0 - x_{k+1}}<br>&#x3D; \frac{f[x_0, …, x_{k-1}, x_k] - f[x_0, …, x_{k-1}, x_{k+1}]}{x_k - x_{k+1}}<br>$$</p>
<blockquote>
<p>k阶差商必须由k+1个节点构成，k个节点是构造不出k阶差商的。</p>
<p>差商的值与$x_i$顺序无关的</p>
</blockquote>
<h4 id="差商性质"><a href="#差商性质" class="headerlink" title="差商性质"></a>差商性质</h4><ol>
<li><p><strong>k阶差商的线性组合</strong><br>k阶差商可以表示为函数值 $ f(x_0), f(x_1), \ldots, f(x_k) $ 的线性组合，即<br>$$<br>f[x_0, x_1, \ldots, x_k] &#x3D; \sum_{j&#x3D;0}^k \frac{f(x_j)}{(x_j - x_0) \cdots (x_j - x_{j-1})(x_j - x_{j+1}) \cdots (x_j - x_k)}（用数学归纳法证明）<br>$$</p>
</li>
<li><p><strong>对称性</strong><br>差商具有对称性，即<br>$$<br>f[x_0, x_1, \ldots, x_k] &#x3D; f[x_1, x_0, x_2, \ldots, x_k] &#x3D; \cdots &#x3D; f[x_1, \ldots, x_k, x_0]<br>$$</p>
</li>
<li><p><strong>与导数的关系</strong><br>若函数 $ f(x) $ 在区间 $[a, b]$ 上有 $ n $ 阶导数，且节点 $ x_i \in [a, b] $（$ i &#x3D; 0, 1, \ldots, n $），则 $ n $ 阶差商与 $ n $ 阶导数有如下关系式：<br>$$<br>f[x_0, x_1, \ldots, x_n] &#x3D; \frac{f^{(n)}(\xi)}{n!}<br>$$<br>其中 $ \xi \in [a, b] $。</p>
</li>
<li><p><strong>多项式性质</strong><br>若 $ f(x) $ 是 $ n $ 次多项式，则其 $ k $ 阶差商 $ f[x_0, x_1, \ldots, x_{k-1}, x] $ 当 $ k \leq n $ 时是一个 $ n-k $ 次多项式，而当 $ k &gt; n $ 时恒为零。</p>
</li>
</ol>
<h4 id="差商表"><a href="#差商表" class="headerlink" title="差商表"></a>差商表</h4><table>
<thead>
<tr>
<th align="center">$ x_i $</th>
<th align="center">$ f(x_i) $</th>
<th align="center">一阶差商</th>
<th align="center">二阶差商</th>
<th align="center">三阶差商</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$ x_0 $</td>
<td align="center">$ f(x_0) $</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_1 $</td>
<td align="center">$ f(x_1) $</td>
<td align="center">$ f[x_0, x_1] $</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_2 $</td>
<td align="center">$ f(x_2) $</td>
<td align="center">$ f[x_1, x_2] $</td>
<td align="center">$ f[x_0, x_1, x_2] $</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_3 $</td>
<td align="center">$ f(x_3) $</td>
<td align="center">$ f[x_2, x_3] $</td>
<td align="center">$ f[x_1, x_2, x_3] $</td>
<td align="center">$ f[x_0, x_1, x_2, x_3] $</td>
</tr>
</tbody></table>
<h3 id="牛顿插值"><a href="#牛顿插值" class="headerlink" title="牛顿插值"></a>牛顿插值</h3><p>Newton插值是通过选取特殊的基函数来实现的，这时，取</p>
<p>$$<br>\varphi_0(x) &#x3D; 1<br>$$</p>
<p>$$<br>\varphi_{i+1}(x) &#x3D; (x - x_i)\varphi_i(x), \quad i &#x3D; 0, 1, \ldots, n - 1<br>$$</p>
<p>作为Newton插值的以 $ x_0, x_1, \ldots, x_n $ 为节点的基函数，而次数不超过 $ n $ 的多项式 $ N_n(x) $ 可表示为</p>
<p>$$<br>N_n(x) &#x3D; c_0 + c_1(x - x_0) + c_2(x - x_0)(x - x_1) + \cdots + c_n(x - x_0)(x - x_1)\cdots(x - x_{n-1})<br>$$</p>
<p>其中 $ c_0, c_1, \ldots, c_n $ 是待定系数。<br>$$<br>&#x3D; f(x_0) + f[x_0, x_1](x - x_0) + \cdots + f[x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})<br>$$</p>
<p><em><strong>下面推导待定系数：</strong></em><br>$$<br>f(x_0)&#x3D;N_n(x_0)&#x3D;c_0<br>$$</p>
<p>$$<br>f(x_1) &#x3D; N_n(x_1) &#x3D; c_0 + c_1(x_1 - x_0)&#x3D; f(x_0) + c_1(x_1 - x_0)<br>$$</p>
<p>$$<br>c_1 &#x3D; \frac{f(x_1) - f(x_0)}{x_1 - x_0} &#x3D; f[x_0, x_1]<br>$$</p>
<p>通过插值条件运用数学归纳法可以求得<br>$$<br>c_k &#x3D; f[x_0, x_1, \ldots, x_k]<br>$$</p>
<p>因此，得到满足插值条件的 $ n $ 次插值多项式：<br>$$<br>N_n(x)&#x3D; f(x_0) + f[x_0, x_1](x - x_0) + \cdots + f[x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})<br>$$</p>
<p><em><strong>余项的推导</strong></em><br>$$<br>f(x) &#x3D; f(x_0) + (x - x_0)f[x, x_0] \quad \text{(1)}<br>$$</p>
<p>$$<br>f[x, x_0] &#x3D; f[x_0, x_1] + (x - x_1)f[x, x_0, x_1] \quad \text{(2)}<br>$$</p>
<p>$$<br>\vdots<br>$$</p>
<p>$$<br>f[x, x_0, \ldots, x_{n-1}] &#x3D; f[x_0, \ldots, x_n] + (x - x_n)f[x, x_0, \ldots, x_n] \quad \text{(n-1)}<br>$$</p>
<p>$$<br>\text{(1)} + (x - x_0) \times \text{(2)} + \cdots + (x - x_0)\cdots(x - x_{n-1}) \times \text{(n-1)}<br>$$</p>
<p>$$<br>\Rightarrow f(x) &#x3D; f(x_0) + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1) + \cdots + f[x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1}) + f[x, x_0, \cdots, x_n](x - x_0)\cdots(x - x_{n-1})(x - x_n)<br>$$</p>
<p><strong>因此，余项公式为</strong>：</p>
<blockquote>
<p>$$<br>R_n(x)&#x3D;f[x, x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})(x - x_n)&#x3D;f[x, x_0, \ldots, x_n]\omega_{n+1}(x)<br>$$</p>
<p>$$<br>\omega_{n+1}(x) &#x3D; (x - x_0)(x - x_1)\cdots(x - x_n) \<br>c_i &#x3D; f[x_0, \ldots, x_i]<br>$$</p>
</blockquote>
<blockquote>
<p><strong>例1</strong></p>
<p>设当 $x_i &#x3D; 1, 2, 3, 4, 5$ 时, $f(x_i) &#x3D; 1, 4, 7, 8, 6$。求四次牛顿插值多项式。</p>
<table>
<thead>
<tr>
<th>k</th>
<th>$x_k$</th>
<th>$f(x_k)$</th>
<th>一阶差商</th>
<th>二阶差商</th>
<th>三阶差商</th>
<th>四阶差商</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>4</td>
<td>3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>7</td>
<td>3</td>
<td>0</td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>8</td>
<td>1</td>
<td>-1</td>
<td>-1&#x2F;3</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>6</td>
<td>-2</td>
<td>-3&#x2F;2</td>
<td>-1&#x2F;6</td>
<td>1&#x2F;24</td>
</tr>
</tbody></table>
<p>$$<br>N_4(x) &#x3D; 1 + (x - 1) \cdot 3 + (x - 1)(x - 2) \cdot 0 + (x - 1)(x - 2)(x - 3) \cdot \left(-\frac{1}{3}\right) + (x - 1)(x - 2)(x - 3)(x - 4) \cdot \frac{1}{24}<br>$$</p>
<p>$$<br>&#x3D; \frac{1}{24} x^4 - \frac{9}{12} x^3 + \frac{83}{24} x^2 - \frac{33}{12} x + 1<br>$$</p>
<blockquote>
<p>提示：</p>
<ol>
<li>根据差商表计算更高阶的差商时，遵循相近作差的原则。比如计算三阶差商$- \frac{1}{6}$时候，直接用前一阶差商的-1和-3&#x2F;2作差，然后三阶差商需要4个点，即从该列开始往前数4个点,序号差别最大的作差（本例就是$x_4-x_1$），两个差值作除法就是新差商</li>
<li>注意4次牛顿插值，反应到多项式就是4次多项式。组合牛顿插值的时候几阶差商乘的就是几阶多项式</li>
</ol>
</blockquote>
<p><strong>例2</strong></p>
<p>给定 $f(x)$ 的函数表，求四次牛顿插值值多项式，计算 $f(0.596)$ 的近似值，并估计误差。</p>
<p>得出差商表，得到</p>
<p>$$<br>N_4(x) &#x3D; 0.41075 + 1.116(x - 0.4) + 0.28(x - 0.4)(x - 0.55) + 0.19733(x - 0.4)(x - 0.55)(x - 0.65) + 0.03134(x - 0.4)(x - 0.55)(x - 0.65)(x - 0.8)<br>$$</p>
<p>$$<br>f(0.596) \approx N_4(0.596) &#x3D; 0.63192,<br>$$</p>
<p>误差：</p>
<p>$$<br>R_4(x) &#x3D; (x - x_0)(x - x_1) \cdots (x - x_4) f[x,x_0, x_1, \cdots, x_4],<br>$$</p>
<p>$$<br>|R_4(x)| \approx |f[x_0, x_1, \cdots, x_5] \omega_5(0.596)| \leq 3.63 \times 10^{-9}.<br>$$</p>
<p>因此 $x &#x3D; 0.596$ 和 $f(x) \approx 0.63192$，得到 $f[x_0, \cdots, x_4]$ 的近似值。</p>
</blockquote>
<p><strong>注：</strong></p>
<p>由唯一性可知 $ N_n(x) \equiv L_n(x) $，只是算法不同，故其余项也相同，即</p>
<p>$$<br>f[x, x_0, \ldots, x_n] \omega_{n+1}(x) &#x3D; \frac{f^{(n+1)}(\xi_x)}{(n+1)!} \omega_{n+1}(x)<br>$$</p>
<p>则</p>
<p>$$<br>f[x_0, \ldots, x_k] &#x3D; \frac{f^{(k)}(\xi)}{k!}, \quad \xi \in (x_{\min}, x_{\max})<br>$$</p>
<blockquote>
<p><strong>证明（不用掌握）：</strong></p>
<p>$$ f[x_0, x_1, \ldots, x_k] &#x3D; \frac{f^{(k)}(\xi)}{k!}, \quad \xi \in (x_{\min}, x_{\max}) $$</p>
<hr>
<p>数学归纳法推导</p>
<p><span style="color:#FF0000">基例验证（$ k&#x3D;1 $）</span></p>
<p><strong>命题</strong>：对任意两节点 $ x_0, x_1 $，一阶差商满足：<br>$$ f[x_0, x_1] &#x3D; \frac{f’(\xi)}{1!}, \quad \xi \in (x_0, x_1) $$</p>
<p><strong>推导步骤</strong>：</p>
<ol>
<li><strong>差商定义</strong>：</li>
</ol>
<p>$$<br> f[x_0, x_1] &#x3D; \frac{f(x_1) - f(x_0)}{x_1 - x_0}<br>$$</p>
<ol start="2">
<li><strong>微分中值定理</strong>：存在 $ \xi \in (x_0, x_1) $，使得：</li>
</ol>
<p>$$<br> \frac{f(x_1) - f(x_0)}{x_1 - x_0} &#x3D; f’(\xi)<br>$$</p>
<ol start="3">
<li><strong>结论</strong>：</li>
</ol>
<p>$$<br> f[x_0, x_1] &#x3D; \frac{f’(\xi)}{1!} \quad \text{（基例成立）}<br>$$</p>
<hr>
<p><span style="color:#FF0000">归纳假设（假设 $ k&#x3D;m $ 时成立）</span></p>
<p>假设对任意 $ m+1 $ 个节点 $ x_0, x_1, \ldots, x_m $，有：<br>$$<br>f[x_0, x_1, \ldots, x_m] &#x3D; \frac{f^{(m)}(\eta)}{m!}, \quad \eta \in (x_{\min}, x_{\max})<br>$$</p>
<hr>
<p><span style="color:#FF0000">归纳步骤（证明 $ k&#x3D;m+1 $ 时成立）</span></p>
<p><strong>目标</strong>：对任意 $ m+2 $ 个节点 $ x_0, x_1, \ldots, x_{m+1} $，证明：<br>$$<br>f[x_0, x_1, \ldots, x_{m+1}] &#x3D; \frac{f^{(m+1)}(\xi)}{(m+1)!}, \quad \xi \in (x_{\min}, x_{\max})<br>$$</p>
<p><strong>推导过程</strong>：</p>
<ol>
<li><strong>差商递归关系</strong>：</li>
</ol>
<p>$$<br> f[x_0, \ldots, x_{m+1}] &#x3D; \frac{f[x_1, \ldots, x_{m+1}] - f[x_0, \ldots, x_m]}{x_{m+1} - x_0}<br>$$</p>
<ol start="2">
<li><strong>应用归纳假设</strong>：</li>
</ol>
<ul>
<li><p>对 $ f[x_1, \ldots, x_{m+1}] $：<br>$$<br>f[x_1, \ldots, x_{m+1}] &#x3D; \frac{f^{(m)}(\eta_1)}{m!}, \quad \eta_1 \in (x_1, x_{m+1})<br>$$</p>
</li>
<li><p>对 $ f[x_0, \ldots, x_m] $：<br>$$<br>f[x_0, \ldots, x_m] &#x3D; \frac{f^{(m)}(\eta_2)}{m!}, \quad \eta_2 \in (x_0, x_m)<br>$$</p>
</li>
</ul>
<ol start="3">
<li><strong>构造辅助函数</strong>：<br> 定义 $ g(x) &#x3D; f^{(m)}(x) $，则：</li>
</ol>
<p>$$<br> f[x_0, \ldots, x_{m+1}] &#x3D; \frac{g(\eta_1) - g(\eta_2)}{(x_{m+1} - x_0) \cdot m!}<br>$$</p>
<ol start="4">
<li><strong>广义微分中值定理</strong>：<br> 存在 $ \xi \in (\eta_2, \eta_1) \subseteq (x_{\min}, x_{\max}) $，使得：</li>
</ol>
<p>$$<br> \frac{g(\eta_1) - g(\eta_2)}{\eta_1 - \eta_2} &#x3D; g’(\xi) &#x3D; f^{(m+1)}(\xi)<br>$$</p>
<ol start="5">
<li><strong>结合节点间距</strong>：<br> 由于 $ \eta_1 - \eta_2 \leq x_{m+1} - x_0 $，整理得：</li>
</ol>
<p>$$<br> f[x_0, \ldots, x_{m+1}] &#x3D; \frac{f^{(m+1)}(\xi)}{(m+1)!}<br>$$</p>
<hr>
<p><span style="color:#FF0000">归纳结论</span></p>
<p>对所有 $ k \geq 1 $，公式成立：<br>$$<br>\boxed{f[x_0, x_1, \ldots, x_k] &#x3D; \frac{f^{(k)}(\xi)}{k!}, \quad \xi \in (x_{\min}, x_{\max})}<br>$$</p>
<p>关键符号说明</p>
<table>
<thead>
<tr>
<th>符号</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>$ f[x_0, \ldots, x_k] $</td>
<td>$ k $ 阶差商，节点 $ x_0, \ldots, x_k $ 处的函数变化率</td>
</tr>
<tr>
<td>$ f^{(k)}(\xi) $</td>
<td>函数 $ f $ 在区间内的 $ k $ 阶导数</td>
</tr>
<tr>
<td>$ \xi $</td>
<td>区间内的某点，由中值定理保证存在</td>
</tr>
</tbody></table>
</blockquote>
<h4 id="差分形式的牛顿插值公式"><a href="#差分形式的牛顿插值公式" class="headerlink" title="差分形式的牛顿插值公式"></a>差分形式的牛顿插值公式</h4><p><strong>节点等距分布条件</strong>：<br>当节点满足等距分布时：<br>$$ x_i &#x3D; x_0 + ih \quad (i&#x3D;0,\ldots,n) $$</p>
<hr>
<p><strong>向前差分</strong><br>$$<br>\Delta f_i &#x3D; f_{i+1} - f_i<br>$$</p>
<p>$$<br>\Delta^k f_i &#x3D; \Delta(\Delta^{k-1}f_i) &#x3D; \Delta^{k-1}f_{i+1} - \Delta^{k-1}f_i<br>$$</p>
<hr>
<p><strong>向后差分</strong><br>$$<br>\nabla f_i &#x3D; f_i - f_{i-1}<br>$$</p>
<p>$$<br>\nabla^k f_i &#x3D; \nabla(\nabla^{k-1}f_i) &#x3D; \nabla^{k-1}f_i - \nabla^{k-1}f_{i-1}<br>$$</p>
<hr>
<p><strong>中心差分</strong><br>$$<br>\delta f_i &#x3D; f_{i+\frac{1}{2}} - f_{i-\frac{1}{2}} \quad \text{其中} \quad f_{i\pm\frac{1}{2}} &#x3D; f\left(x_i \pm \frac{h}{2}\right)<br>$$</p>
<p>$$<br>\delta^k f_i &#x3D; \delta^{k-1}f_{i+\frac{1}{2}} - \delta^{k-1}f_{i-\frac{1}{2}}<br>$$</p>
<hr>
<p><strong>差分的重要性质：</strong></p>
<ol>
<li><p>差分可由函数值计算<br>$$<br>\Delta^n f_k &#x3D; \sum_{j&#x3D;0}^n (-1)^{j} \binom{n}{j} f_{n+k-j} \<br>\nabla^n f_k &#x3D; \sum_{j&#x3D;0}^n (-1)^{n-j} \binom{n}{j} f_{k+j-n}<br>$$<br>其中：</p>
<ul>
<li><p>$$<br>\binom{n}{j} &#x3D; \frac{n(n-1)\cdots(n-j+1)}{j!}<br>$$</p>
<p>是二项式系数。</p>
</li>
</ul>
</li>
<li><p>函数值可由差分值算出<br>$$<br>f_{n+k} &#x3D; \sum_{j&#x3D;0}^n \binom{n}{j} \Delta^j f_k<br>$$</p>
</li>
<li><p>差商和差分的关系</p>
</li>
</ol>
<p>$$<br>f[x_k, x_{k+1}, \ldots, x_{k+m}] &#x3D; \frac{1}{m! h^m} \Delta^m f_k<br>$$</p>
<p>$$<br>f[x_k, x_{k-1}, \ldots, x_{k-m}] &#x3D; \frac{1}{m! h^m} \nabla^m f_k<br>$$</p>
<ol start="4">
<li>差分与导数的关系<br>$$<br>\Delta^n f_k &#x3D; h^n f^{(n)}(\xi), \quad \xi \in (x_k, x_{k+n})<br>$$</li>
</ol>
<p><strong>牛顿公式：</strong><br>$$<br>N_n(x) &#x3D; f(x_0) + f[x_0, x_1](x - x_0) + \cdots + f[x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})<br>$$</p>
<p><span style="color:rgb(255, 53, 116)">牛顿前插公式：</span><br>设 $ x &#x3D; x_0 + th $（$ 0 \leq t \leq 1 $），则<br>$$<br>N_n(x) &#x3D; N_n(x_0 + th) &#x3D; \sum_{k&#x3D;0}^{n} \binom{t}{k} \Delta^k f(x_0)<br>$$<br>$$<br>&#x3D; f_0 + t\Delta f_0 + \frac{t(t - 1)}{2!}\Delta^2 f_0 + \dots + \frac{t(t - 1)\dots(t - n + 1)}{n!}\Delta^n f_0<br>$$</p>
<p>余项：<br>$$<br>R_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} t(t-1)\cdots(t-n) h^{n+1}, \quad \xi \in (x_0, x_n)<br>$$</p>
<p><span style="color:rgb(255, 53, 116)">牛顿后插公式：</span><br>将节点顺序倒置：<br>$$<br>N_n(x) &#x3D; f(x_n) + f[x_n, x_{n-1}](x - x_n) + \cdots + f[x_n, \ldots, x_0](x - x_n)\cdots(x - x_1)<br>$$<br>设 $ x &#x3D; x_n + th $（$ -1 \leq t \leq 0 $），则<br>$$<br>N_n(x) &#x3D; N_n(x_n + th) &#x3D; \sum_{k&#x3D;0}^{n} (-1)^k \binom{-t}{k} \nabla^k f(x_n)<br>$$<br>$$<br>&#x3D; f_n + t\nabla f_n + \frac{t(t + 1)}{2!}\nabla^2 f_n + \dots + \frac{t(t + 1)\dots(t + n - 1)}{n!}\nabla^n f_n<br>$$</p>
<p>余项：<br>$$<br>R_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} t(t+1)\cdots(t+n) h^{n+1}, \quad \xi \in (x_0, x_n)<br>$$</p>
<p>注：一般当 $ x $ 靠近 $ x_0 $ 时用前插，靠近 $ x_n $ 时用后插，故两种公式亦称为表初公式和表末公式。</p>
<p><strong>差分表</strong></p>
<p><img src="/blog/image/Snipaste_2025-03-12_16-09-19.png"></p>
<p><strong>例题</strong></p>
<blockquote>
<p>给出 $f(x) &#x3D; \cos x$ 在 $x_k &#x3D; kh, k &#x3D; 0, 1, 2, 3, 4, 5, h &#x3D; 0.1$ 时的函数值，试用 4 次牛顿前插公式计算 $f(0.048)$ 的近似值，并估计误差。</p>
<p><strong>解：</strong> 先构造差商表并用牛顿前插公式求 $f(0.048)$ 的近似值。</p>
<p><strong>差商表</strong></p>
<table>
<thead>
<tr>
<th>$x_k$</th>
<th>$f(x_k)$</th>
<th>$\Delta f$</th>
<th>$\Delta^2 f$</th>
<th>$\Delta^3 f$</th>
<th>$\Delta^4 f$</th>
<th>$\Delta^5 f$</th>
</tr>
</thead>
<tbody><tr>
<td>0.00</td>
<td>1.00000</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>-0.00500</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>0.10</td>
<td>0.99500</td>
<td></td>
<td>-0.00993</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>-0.01493</td>
<td></td>
<td>0.00013</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0.20</td>
<td>0.98007</td>
<td></td>
<td>-0.00980</td>
<td></td>
<td>0.00012</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>-0.02473</td>
<td></td>
<td>0.00025</td>
<td></td>
<td>-0.00002</td>
</tr>
<tr>
<td>0.30</td>
<td>0.95534</td>
<td></td>
<td>-0.00955</td>
<td></td>
<td>0.00010</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>-0.03428</td>
<td></td>
<td>0.00035</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0.40</td>
<td>0.92106</td>
<td></td>
<td>-0.00920</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>-0.04348</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>0.50</td>
<td>0.87758</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>取 $x &#x3D; 0.048, h &#x3D; 0.1, t &#x3D; \frac{x - 0}{h} &#x3D; 0.48$，得</p>
<p>$$<br>N_4(0.048) &#x3D; 1.00000 + 0.48 \times (-0.00500) + \frac{(0.48)(0.48-1)}{2} \times (-0.00993) + \frac{(0.48)(0.48-1)(0.48-2)}{6} \times (0.00013)<br>$$</p>
<p>$$</p>
<ul>
<li>\frac{(0.48)(0.48-1)(0.48-2)(0.48-3)}{24} \times (0.00012)<br>$$</li>
</ul>
<p>$$<br>&#x3D; 0.99885 \approx \cos 0.048,<br>$$</p>
<p>误差估计为：</p>
<p>$$<br>|R_4(0.048)| \leq \frac{M_5}{5!} |t(t-1)(t-2)(t-3)(t-4)| h^5 \leq 1.3433 \times 10^{-7},<br>$$</p>
<p>其中 $M_5 &#x3D; |\sin 0.5| \leq 0.479$。</p>
<hr>
<p>给出 $f(x) &#x3D; \cos x$ 在 $x_k &#x3D; kh, k &#x3D; 0, 1, 2, 3, 4, 5,6； h &#x3D; 0.1$ 时的函数值，用 4 次牛顿后插公式计算 $f(0.566)$ 的近似值，并估计误差。</p>
<p>做差商表</p>
<table>
<thead>
<tr>
<th align="right">$k$</th>
<th align="center">$x_k$</th>
<th align="center">$f(x_k)$</th>
<th align="center">$\nabla f $</th>
<th align="center">$\nabla^2 f $</th>
<th align="center">$\nabla^3 f$</th>
<th align="center">$\nabla^4 f$</th>
<th align="center">$\nabla^5 f$</th>
<th align="center">$\nabla^6 f$</th>
</tr>
</thead>
<tbody><tr>
<td align="right"><strong>6</strong></td>
<td align="center">0.6</td>
<td align="center">0.8253356</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0522470</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>5</strong></td>
<td align="center">0.5</td>
<td align="center">0.8775826</td>
<td align="center"></td>
<td align="center">−0.0087687</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0434783</td>
<td align="center"></td>
<td align="center">0.0004340</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>4</strong></td>
<td align="center">0.4</td>
<td align="center">0.9210609</td>
<td align="center"></td>
<td align="center">−0.0092027</td>
<td align="center"></td>
<td align="center">0.0000912</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0342756</td>
<td align="center"></td>
<td align="center">0.0003428</td>
<td align="center"></td>
<td align="center">−0.0000046</td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>3</strong></td>
<td align="center">0.3</td>
<td align="center">0.9553365</td>
<td align="center"></td>
<td align="center">−0.0095455</td>
<td align="center"></td>
<td align="center">0.0000958</td>
<td align="center"></td>
<td align="center">−0.0000027</td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0247301</td>
<td align="center"></td>
<td align="center">0.0002470</td>
<td align="center"></td>
<td align="center">−0.0000019</td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>2</strong></td>
<td align="center">0.2</td>
<td align="center">0.9800666</td>
<td align="center"></td>
<td align="center">−0.0097925</td>
<td align="center"></td>
<td align="center">0.0000977</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0149376</td>
<td align="center"></td>
<td align="center">0.0001493</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>1</strong></td>
<td align="center">0.1</td>
<td align="center">0.9950042</td>
<td align="center"></td>
<td align="center">−0.0099418</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">−0.0049958</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="right"><strong>0</strong></td>
<td align="center">0.0</td>
<td align="center">1.0000000</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>取 $x &#x3D; 0.566, h &#x3D; 0.1, t &#x3D; \frac{x - 0.6}{h} &#x3D; -0.34$，得<br>$$<br>N_4(x)&#x3D; f_6 + t\nabla f_6 + \frac{t(t + 1)}{2!}\nabla^2 f_6 + \frac{t(t + 1)(t+2)}{3!}\nabla^3 f_6 +\frac{t(t + 1)(t+2)(t+3)}{4!}\nabla^4 f_6<br>$$</p>
<p>$$<br>&#x3D;0.84405\approx \cos 0.566<br>$$</p>
<p>$$<br>R_4(0.566) \leq \frac{| \sin 0.6 |}{5!} \cdot | -0.34 \cdot (-0.34 + 1) \cdots (-0.48 + 4) | \cdot (0.1)^5 \leq 1.7064 \times 10^{-7}.<br>$$</p>
<hr>
<p>给定数据表如下：</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>0.2</th>
<th>0.4</th>
<th>0.6</th>
<th>0.8</th>
<th>1.0</th>
<th>1.2</th>
</tr>
</thead>
<tbody><tr>
<td>$f(x)$</td>
<td>21</td>
<td>25</td>
<td>23</td>
<td>20</td>
<td>21</td>
<td>24</td>
</tr>
</tbody></table>
<p>(1) 用三次插值多项式计算 $f(0.7)$ 的近似值；</p>
<p>(2) 用二次插值多项式计算 $f(0.95)$ 的近似值；</p>
<p><strong>解</strong></p>
<p><strong>备注：由于节点等距，可用差分形式的牛顿插值公式</strong></p>
<p>先造差分表如下表</p>
<table>
<thead>
<tr>
<th>$y_i$</th>
<th>$\Delta y_i$</th>
<th>$\Delta^2 y_i$</th>
<th>$\Delta^3 y_i$</th>
<th>$\Delta^4 y_i$</th>
<th>$\Delta^5 y_i$</th>
</tr>
</thead>
<tbody><tr>
<td>21</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>4</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>25</td>
<td></td>
<td>-6</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>-2</td>
<td></td>
<td>5</td>
<td></td>
<td></td>
</tr>
<tr>
<td>23</td>
<td></td>
<td>-1</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td></td>
<td>-3</td>
<td></td>
<td>5</td>
<td></td>
<td>-7</td>
</tr>
<tr>
<td>20</td>
<td></td>
<td>4</td>
<td></td>
<td>-7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>1</td>
<td></td>
<td>-2</td>
<td></td>
<td></td>
</tr>
<tr>
<td>21</td>
<td></td>
<td>2</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>3</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>24</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<hr>
<p>(1) 选取 $x_1 &#x3D; 0.4,\ x_2 &#x3D; 0.6,\ x_3 &#x3D; 0.8,\ x_4 &#x3D; 1.0$ 为节点，构造三次向前 Newton 插值多项式：</p>
<p>$$<br>N_3(x_1 + th) &#x3D; y_1 + \Delta y_1 t + \frac{\Delta^2 y_1}{2!} t(t - 1) + \frac{\Delta^3 y_1}{3!} t(t - 1)(t - 2)<br>$$</p>
<p>将 $x_1$ 和 $h$ 代入上式，得：</p>
<p>$$<br>N_3(0.4 + 0.2t) &#x3D; 25 - 2t - \frac{1}{2}t(t - 1) + \frac{5}{6}t(t - 1)(t - 2)<br>$$</p>
<p>由 $0.4 + 0.2t &#x3D; 0.7$ 解得 $t &#x3D; 1.5$，所以：</p>
<p>$$<br>f(0.7) \approx N_3(0.7) &#x3D; 21.3125<br>$$</p>
<hr>
<p>(2) 选 $x_3 &#x3D; 0.8,\ x_4 &#x3D; 1.0,\ x_5 &#x3D; 1.2$ 为节点，构造二次向前 Newton 插值式：</p>
<p>$$<br>N_2(x_3 + th) &#x3D; y_3 + \Delta y_3 t + \frac{\Delta^2 y_3}{2!} t(t - 1)<br>$$</p>
<p>将 $x_3$ 和 $h$ 代入上式，得：</p>
<p>$$<br>N_2(0.8 + 0.2t) &#x3D; 20 + t + t(t - 1)<br>$$</p>
<p>由 $0.8 + 0.2t &#x3D; 0.95$ 解得 $t &#x3D; 0.75$，所以：</p>
<p>$$<br>f(0.95) \approx N_2(0.95) &#x3D; 20.5625<br>$$</p>
</blockquote>
<blockquote>
<ol start="2">
<li>给出 $f(x) &#x3D; \ln x$ 数值表</li>
</ol>
<table>
<thead>
<tr>
<th>$x$</th>
<th>0.4</th>
<th>0.5</th>
<th>0.6</th>
</tr>
</thead>
<tbody><tr>
<td>$\ln x$</td>
<td>-0.916291</td>
<td>-0.693147</td>
<td>-0.510826</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>$x$</th>
<th>0.7</th>
<th>0.8</th>
</tr>
</thead>
<tbody><tr>
<td>$\ln x$</td>
<td>-0.356675</td>
<td>-0.223144</td>
</tr>
</tbody></table>
<hr>
<p>用线性插值及二次插值计算 $\ln 0.54$ 的近似值。</p>
<h4 id="解"><a href="#解" class="headerlink" title="解"></a>解</h4><p>根据插值误差估计式选距离 $0.54$ 较近的点为插值节点，并建立差商表：</p>
<p>$$<br>\begin{aligned}<br>x_0 &amp;&#x3D; 0.5,\quad f(x_0) &#x3D; -0.693147 \<br>x_1 &amp;&#x3D; 0.6,\quad f(x_1) &#x3D; -0.510826 \<br>x_2 &amp;&#x3D; 0.4,\quad f(x_2) &#x3D; -0.916291<br>\end{aligned}<br>$$</p>
<p>差商计算如下：</p>
<p>$$<br>f[x_0, x_1] &#x3D; \frac{f(x_1) - f(x_0)}{x_1 - x_0} &#x3D; \frac{-0.510826 + 0.693147}{0.6 - 0.5} &#x3D; 1.823210<br>$$</p>
<p>$$<br>f[x_1, x_2] &#x3D; \frac{f(x_2) - f(x_1)}{x_2 - x_1} &#x3D; \frac{-0.916291 + 0.510826}{0.4 - 0.6} &#x3D; 2.027325<br>$$</p>
<p>$$<br>f[x_0, x_1, x_2] &#x3D; \frac{f[x_1, x_2] - f[x_0, x_1]}{x_2 - x_0} &#x3D; \frac{2.027325 - 1.823210}{0.4 - 0.5} &#x3D; -0.204115<br>$$</p>
<hr>
<p>写出 Newton 插值多项式：</p>
<p>$$<br>N_1(x) &#x3D; -0.693147 + 1.823210(x - 0.5)<br>$$</p>
<p>$$<br>N_2(x) &#x3D; N_1(x) + (-0.204115)(x - 0.5)(x - 0.6)<br>$$</p>
<p>计算近似值：</p>
<p><strong>一阶插值：</strong></p>
<p>$$<br>N_1(0.54) &#x3D; -0.693147 + 1.823210 \times (0.54 - 0.5) \<br>\approx -0.620219<br>$$</p>
<p><strong>二阶插值：</strong><br>$$<br>N_2(0.54) &#x3D; N_1(0.54) + (-0.204115) \times (0.54 - 0.5)(0.54 - 0.6) \<br>\approx -0.616839<br>$$</p>
</blockquote>
<h2 id="埃尔米特插值"><a href="#埃尔米特插值" class="headerlink" title="埃尔米特插值"></a>埃尔米特插值</h2><p><span style="color:blue">不仅要求函数值重合，而且要求若干阶导数也重合，这种插值问题称为埃尔米特插值问题。</span></p>
<h3 id="两个典型的埃尔米特插值多项式"><a href="#两个典型的埃尔米特插值多项式" class="headerlink" title="两个典型的埃尔米特插值多项式"></a><span style="color:#FF0000">两个典型的埃尔米特插值多项式</span></h3><ol>
<li><h4 id="二点三次埃尔米特插值多项式"><a href="#二点三次埃尔米特插值多项式" class="headerlink" title="二点三次埃尔米特插值多项式"></a>二点三次埃尔米特插值多项式</h4><p>**问题描述：**给定区间 $[x_0, x_1]$ 两端点的函数值与导数值：</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>$x_0$</th>
<th>$x_1$</th>
</tr>
</thead>
<tbody><tr>
<td>$f(x)$</td>
<td>$y_0$</td>
<td>$y_1$</td>
</tr>
<tr>
<td>$f’(x)$</td>
<td>$m_0$</td>
<td>$m_1$</td>
</tr>
</tbody></table>
<p>要求构造三次多项式 $H_3(x)$，满足：<br>$$<br>\begin{cases}<br>H_3(x_0) &#x3D; y_0, &amp; H_3(x_1) &#x3D; y_1 \<br>H_3’(x_0) &#x3D; m_0, &amp; H_3’(x_1) &#x3D; m_1<br>\end{cases}<br>$$</p>
<hr>
<p><strong>解法形式</strong></p>
<p>设 $H_3(x)$ 为：<br>$$<br>H_3(x) &#x3D; \alpha_0(x)y_0 + \alpha_1(x)y_1 + \beta_0(x)m_0 + \beta_1(x)m_1<br>$$<br>其中 $\alpha_i(x)$ 和 $\beta_i(x)$ 为基函数（<u>三次式</u>），满足以下条件：</p>
<ol>
<li><p><strong>插值条件</strong>：</p>
<ul>
<li>$\alpha_i(x_j) &#x3D; \delta_{ij}$（$\delta_{ij}$ 为克罗内克函数）</li>
<li>$\alpha’_i(x_j) &#x3D; 0$</li>
<li>$\beta_i(x_j) &#x3D; 0$</li>
<li>$ \beta’_i(x_j) &#x3D; \delta _{ij}$</li>
</ul>
</li>
<li><p><strong>基函数构造</strong>：<br>$$<br>\alpha_i(x) &#x3D; (a_i x + b_i) l_i^2(x), \quad \beta_i(x) &#x3D; c_i(x - x_i) l_i^2(x)<br>$$<br>其中 $l_i(x) &#x3D; \frac{x - x_j}{x_i - x_j}$（$j \neq i$）为拉格朗日基函数。</p>
</li>
</ol>
<hr>
<p><strong>基函数推导</strong></p>
<p>$\alpha_0(x)$ 的构造</p>
<p>通过条件 $\alpha_0(x_0) &#x3D; 1$ 和 $\alpha’_0(x_0) &#x3D; 0$，解得：<br>$$<br>\begin{cases}<br>a_0 &#x3D; -\dfrac{2}{x_0 - x_1}, \<br>b_0 &#x3D; 1 + \dfrac{2x_0}{x_0 - x_1}<br>\end{cases}<br>$$<br>最终形式为：<br>$$<br>\alpha_0(x) &#x3D; \left(1 - 2\dfrac{x - x_0}{x_0 - x_1}\right)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2 \<br>\alpha_1(x) &#x3D; \left(1 - 2\dfrac{x - x_1}{x_1 - x_0}\right)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<p>$\beta_i(x)$ 的构造<br>$$<br>\beta_0(x) &#x3D; (x - x_0)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2, \quad \beta_1(x) &#x3D; (x - x_1)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<hr>
<p><strong>最终表达式</strong><br>$$<br>H_3(x) &#x3D; y_0\left(1 - 2\dfrac{x - x_0}{x_0 -x_1}\right)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2<br>$$</p>
</li>
</ol>
<p>$$<br>+y_1\left(1 - 2\dfrac{x - x_1}{x_1 - x_0}\right)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<p>$$<br>+m_0(x - x_0)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2 + m_1(x - x_1)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<blockquote>
<p>$$<br>\sum_{i&#x3D;0}^1 \alpha_i(x) &#x3D; 1 \quad \text{（当 $f(x) &#x3D; 1$ 时）}<br>$$</p>
</blockquote>
<blockquote>
<p><strong>余项为：</strong><br>$$<br>R_3(x)&#x3D;\frac{1}{4!}f^{(4)}(\xi)(x-x_0)^2(x-x_1)^2\<br>\xi \in(x_0,x_1)<br>$$</p>
</blockquote>
<ol start="2">
<li><h4 id="三点三次带一个导数值的插值多项式"><a href="#三点三次带一个导数值的插值多项式" class="headerlink" title="三点三次带一个导数值的插值多项式"></a>三点三次带一个导数值的插值多项式</h4></li>
</ol>
<p><strong>问题描述</strong></p>
<p>给定函数表如下：</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>$x_0$</th>
<th>$x_1$</th>
<th>$x_2$</th>
</tr>
</thead>
<tbody><tr>
<td>$f(x)$</td>
<td>$y_0$</td>
<td>$y_1$</td>
<td>$y_2$</td>
</tr>
<tr>
<td>$f’(x)$</td>
<td></td>
<td>$m_1$</td>
<td></td>
</tr>
</tbody></table>
<p>要求构造三次多项式 $H_3(x)$，满足：<br>$$<br>\begin{cases}<br>H_3(x_i) &#x3D; y_i, &amp; i &#x3D; 0, 1, 2 \<br>H_3’(x_1) &#x3D; m_1<br>\end{cases}<br>$$</p>
<p><strong>解法形式</strong></p>
<p>利用满足插值条件的 Newton 插值多项式，设：<br>$$<br>H_3(x) &#x3D; y_0 + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1) + k(x - x_0)(x - x_1)(x - x_2)<br>$$<br>其中 $k$ 为待定系数。</p>
<p><strong>待定系数求解</strong></p>
<p>通过导数条件 $H_3’(x_1) &#x3D; m_1$ 确定 $k$：<br>$$<br>H_3’(x_1) &#x3D; f[x_0, x_1] + f[x_0, x_1, x_2](x_1 - x_0) + k(x_1 - x_0)(x_1 - x_2) &#x3D; m_1<br>$$<br>解得：<br>$$<br>k &#x3D; \frac{m_1 - f[x_0, x_1] - f[x_0, x_1, x_2](x_1 - x_0)}{(x_1 - x_0)(x_1 - x_2)}<br>$$</p>
<p><strong>最终表达式</strong></p>
<p>将 $k$ 代入后，$H_3(x)$ 的完整形式为：<br>$$<br>H_3(x) &#x3D; y_0 + f[x_0, x_1](x - x_0) + f[x_0, x_1, x_2](x - x_0)(x - x_1) \<br>+\frac{m_1 - f[x_0, x_1] - f[x_0, x_1, x_2](x_1 - x_0)}{(x_1 - x_0)(x_1 - x_2)} (x - x_0)(x - x_1)(x - x_2)<br>$$</p>
<blockquote>
<p>余项为：<br>$$<br>R(x)&#x3D;\frac{1}{4!}f^{(4)}(\xi)(x-x_0)(x-x_1)^2(x-x_2)\<br>\xi \in(x_0,x_2)<br>$$</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>若$f(x)$在$[a,b]$上有三阶连续导数，试求满足条件</p>
<p>$$H(x_0) &#x3D; f(x_0), H(x_1) &#x3D; f(x_1), H’(x_0) &#x3D; f’(x_0)$$</p>
<p>的插值多项式及其余项。</p>
<p><strong>解</strong><br>$$<br>H_2(x) &#x3D; f(x_0) + (x - x_0) f[x_0, x_1] + A(x - x_0)(x - x_1)<br>$$</p>
<p>再由条件$H’(x_0) &#x3D; f’(x_0)$，可得</p>
<p>$$<br>A &#x3D; \frac{f[x_0, x_1] - f’(x_0)}{x_1 - x_0}.<br>$$<br>构造补函数$g(t) &#x3D; f(t) - H(t) - K(x)(t - x_0)^2 (t - x_1)$，得余项</p>
<p>$$<br>R(x) &#x3D; f(x) - H(x) &#x3D; \frac{f^{(3)}(\xi)}{6} (x - x_0)^2 (x - x_1)<br>$$<br>PS:余项公式有以下规律</p>
<ol>
<li><p>余项公式的阶数要比插值多项式多一阶，此项$ (x - x_0)^2 (x - x_1)$依赖题目条件：提供函数和导数条件的为2次项，其余为1次项</p>
</li>
<li><p>$\frac{f^{(3)}(\xi)}{6}$此项与拉格朗日余项$R_n(x)$中的$\frac{f^{(n+1)}(\xi)}{(n+1)!}$一致保持</p>
</li>
</ol>
</blockquote>
<blockquote>
<p>  <strong>例题</strong></p>
<p>  给定$f(x) &#x3D; x^{3&#x2F;2}, x_0 &#x3D; \frac{1}{4}, x_1 &#x3D; 1, x_2 &#x3D; \frac{9}{4}$，试求$f(x)$在$\left[\frac{1}{4}, \frac{9}{4}\right]$上的三次插值多项式$P(x)$，使它满足$P(x_i) &#x3D; f(x_i) \ (i &#x3D; 0, 1, 2), P’(x_1) &#x3D; f’(x_1)$，并写出余项表达式。</p>
<p>  <strong>解</strong> </p>
<p>  由所给节点可求出<br>  $$<br>  f_0 &#x3D; f\left(\frac{1}{4}\right) &#x3D; \frac{1}{8}, f_1 &#x3D; f(1) &#x3D; 1, f_2 &#x3D; f\left(\frac{9}{4}\right) &#x3D; \frac{27}{8},<br>  $$</p>
<p>  $$<br>  f[x_0, x_1] &#x3D; \frac{7}{6}, f[x_0, x_1, x_2] &#x3D; \frac{11}{30}.<br>  $$<br>  故可令<br>  $$<br>  P(x) &#x3D;f_0+f[x_0, x_1] (x-x_0)+f[x_0, x_1, x_2] (x-x_0)(x-x_1)+A(x-x_0)(x-x_1)(x-x_2)<br>  $$</p>
<p>  $$<br>  &#x3D; \frac{1}{8} + \frac{7}{6} \left( x - \frac{1}{4} \right) + \frac{11}{30} \left( x - \frac{1}{4} \right) \left( x - 1 \right) + A \left( x - \frac{1}{4} \right) \left( x - 1 \right) \left( x - \frac{9}{4} \right).<br>  $$</p>
<p>  再由条件$P’(1) &#x3D; f’(1) &#x3D; \frac{3}{2}$可得</p>
<p>  $$A &#x3D; - \frac{14}{225}$$</p>
<p>  于是所求的三次插值多项式为</p>
<p>  $$<br>  P(x) &#x3D; \frac{1}{8} + \frac{7}{6} \left( x - \frac{1}{4} \right) + \frac{11}{30} \left( x - \frac{1}{4} \right) \left( x - 1 \right) - \frac{14}{225} \left( x - \frac{1}{4} \right) \left( x - 1 \right) \left( x - \frac{9}{4} \right)<br>  $$</p>
<p>  余项为</p>
<p>  $$<br>  R(x) &#x3D; f(x) - P(x) &#x3D; \frac{f^{(4)}(\xi)}{4!} \left( x - \frac{1}{4} \right) \left( x - 1 \right)^2 \left( x - \frac{9}{4} \right),<br>  $$</p>
<p>  其中$\xi \in \left[ \frac{1}{4}, \frac{9}{4} \right]$。</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>求一个次数不高于 4 次的多项式 $P(x)$，使它满足：<br>$$<br>P(0) &#x3D; P’(0) &#x3D; 0,\quad P(1) &#x3D; P’(1) &#x3D; 1,\quad P’(2) &#x3D; 1<br>$$</p>
<hr>
<h3 id="解-1"><a href="#解-1" class="headerlink" title="解"></a>解</h3><p>满足 $H_3(0) &#x3D; H_3’(0) &#x3D; 0,\ H_3(1) &#x3D; H_3’(1) &#x3D; 1$ 的 Hermite 插值多项式为（其中 $x_0 &#x3D; 0,\ x_1 &#x3D; 1$）：</p>
<p>$$<br>H_3(x) &#x3D; \sum_{j&#x3D;0}^{1} \left[ H_3(x_j)\alpha_j(x) + H_3’(x_j)\beta_j(x) \right]<br>$$</p>
<p>其中：</p>
<p>$$<br>\alpha_0(x) &#x3D; \left[1 - 2\frac{x - 0}{1 - 0}\right] \left( \frac{x - 1}{0 - 1} \right)^2 \<br>&#x3D; (1 - 2x)(1 - x)^2<br>$$</p>
<p>$$<br>\beta_0(x) &#x3D; (x - 0)\left( \frac{x - 1}{0 - 1} \right)^2 &#x3D; x(1 - x)^2<br>$$</p>
<p>$$<br>\alpha_1(x) &#x3D; \left[1 - 2\frac{x - 1}{0 - 1}\right] \left( \frac{x - 0}{1 - 0} \right)^2 &#x3D; (2x - 1)x^2<br>$$</p>
<p>$$<br>\beta_1(x) &#x3D; (x - 1) \left( \frac{x - 0}{1 - 0} \right)^2 &#x3D; (x - 1)x^2<br>$$</p>
<p>代入得：</p>
<p>$$<br>H_3(x) &#x3D; [1 - 2x](1 - x)^2 + (x - 1)(x^2) &#x3D; 2x^2 - x^3<br>$$</p>
<p>设：</p>
<p>$$<br>P(x) &#x3D; H_3(x) + Ax^2(x - 1)^2<br>$$</p>
<p>令 $P(2) &#x3D; 1$，代入得：</p>
<p>$$<br>P(2) &#x3D; 2 \cdot 4 - 8 + A \cdot 4 \cdot 1 &#x3D; 0 + 4A &#x3D; 1 \Rightarrow A &#x3D; \frac{1}{4}<br>$$</p>
<p>所以：</p>
<p>$$<br>P(x) &#x3D; 2x^2 - x^3 + \frac{1}{4}x^2(x - 1)^2<br>&#x3D; \frac{1}{4}x^2(x - 3)^2<br>$$</p>
</blockquote>
<h3 id="一般埃尔米特插值多项式"><a href="#一般埃尔米特插值多项式" class="headerlink" title="一般埃尔米特插值多项式"></a>一般埃尔米特插值多项式</h3><p><strong>问题描述</strong></p>
<p>已知节点 $x_0, x_1, \ldots, x_n$ 处的函数值 $y_0, y_1, \ldots, y_n$ 和导数值 $y’_0, y’_1, \ldots, y’_n$</p>
<p>要求构造次数为 $2n+1$ 的多项式$H_{2n+1}(x)$（这样的Hermite 插值唯一），满足：<br>$$<br>\begin{cases}<br>H_{2n+1}(x_i) &#x3D; y_i, \<br>H’_{2n+1}(x_i) &#x3D; y’_i<br>\end{cases}<br>\quad (i &#x3D; 0, 1, \ldots, n)<br>$$</p>
<p><strong>解法形式</strong></p>
<p>设多项式为：<br>$$<br>H_{2n+1}(x) &#x3D; \sum_{i&#x3D;0}^n y_i \alpha_i(x) + \sum_{i&#x3D;0}^n y’_i \beta_i(x)<br>$$</p>
<p>其中基函数 $\alpha_i(x)$ 和 $\beta_j(x)$ 满足：<br>$$<br>\alpha_i(x_j) &#x3D; \delta_{ij} \quad \alpha’_i(x_j) &#x3D; 0 ;<br>$$</p>
<p>$$<br>\beta_i(x_j) &#x3D; 0 \quad \beta^{‘} _i(x_j) &#x3D; \delta _{ij}<br>$$</p>
<blockquote>
<p>$\alpha_i(x)$ 和 $\beta_i(x)$ 均为 $2n+1$ 次多项式。</p>
</blockquote>
<p><strong>基函数构造</strong></p>
<p><u>$\alpha_i(x)$ 的构造</u></p>
<ol>
<li><p><strong>零点性质</strong>：$\alpha_i(x)$ 在 $x_0, x_1, \ldots, x_n$ 处有二重零点（除 $x_i$ 外）。</p>
</li>
<li><p><strong>形式假设</strong>：<br>$$<br>\alpha_i(x) &#x3D; [A_ix + B_i] l_i^2(x)<br>$$<br>其中 $l_i(x) &#x3D; \prod_{\substack{\ i \neq i}} \dfrac{x - x_j}{x_i - x_j}$ 为拉格朗日基函数。</p>
</li>
<li><p><strong>条件求解</strong>：</p>
<ul>
<li>$\alpha_i(x_i) &#x3D; 1 \Rightarrow B_i &#x3D; 1$</li>
<li>$\alpha’_i(x_i) &#x3D; 0 \Rightarrow A_i &#x3D; -2 l_i’(x_i)$</li>
</ul>
<p>最终形式为：<br>$$<br>\alpha_i(x) &#x3D; \left[ 1 - 2 l_i’(x_i)(x - x_i) \right] l_i^2(x)<br>$$</p>
</li>
</ol>
<p><u>$\beta_i(x)$ 的构造</u></p>
<ol>
<li><p><strong>零点性质</strong>：$\beta_i(x)$ 在 $x_0, x_1, \ldots, x_n$ 处有二重零点（除 $x_i$ 外）。</p>
</li>
<li><p><strong>形式假设</strong>：<br>$$<br>\beta_i(x) &#x3D; C_i (x - x_i) l_i^2(x)<br>$$</p>
</li>
<li><p><strong>条件求解</strong>：</p>
<ul>
<li>$\beta’_i(x_i) &#x3D; 1 \Rightarrow C_i &#x3D; 1$</li>
</ul>
<p>最终形式为：<br>$$<br>\beta_i(x) &#x3D; (x - x_i) l_i^2(x)<br>$$</p>
</li>
</ol>
<blockquote>
<p><span style="color:blue"><strong>余项分析</strong></span></p>
<p>设区间 $[a, b]$ 满足 $a &#x3D; x_0 &lt; x_1 &lt; \cdots &lt; x_n &#x3D; b$，且 $f \in C^{2n}&gt;[a, b]$，则插值余项为：<br>$$<br>R_n(x) &#x3D; \frac{f^{(2n+2)}(\xi)}{(2n+2)!} \left[ \prod_{i&#x3D;0}^n (x - x_i) \right]^2<br>$$<br>其中 $\xi \in (a, b)$。</p>
</blockquote>
<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><h2 id="分段低次插值"><a href="#分段低次插值" class="headerlink" title="分段低次插值"></a>分段低次插值</h2><h3 id="分段线性插值"><a href="#分段线性插值" class="headerlink" title="分段线性插值"></a>分段线性插值</h3><p><strong>定义</strong></p>
<p>设已知节点 $a&lt;x_0 &lt; x_1 &lt; \cdots &lt; x_n &#x3D; b$ 处的函数值为 $f_0, f_1, \ldots, f_n$，记区间宽度：<br>$$<br>h_k &#x3D; x_{k+1} - x_k, \quad h &#x3D; \max_{k} h_k<br>$$<br>分段线性插值通过折线段连接插值点逼近 $f(x)$，构造折线函数 $I_h(x)$ 满足：</p>
<ol>
<li><strong>连续性</strong>：$I_h(x) \in C[a, b]$</li>
<li><strong>插值条件</strong>：$I_h(x_k) &#x3D; f_k \quad (k &#x3D; 0, 1, \ldots, n)$</li>
<li><strong>分段线性</strong>：在每段区间 $[x_k, x_{k+1}]$ 上，$I_h(x)$ 为线性函数。</li>
</ol>
<p><strong>分段线性插值函数可表示为：</strong><br>$$<br>I_h(x) &#x3D; \sum_{k&#x3D;0}^n f_k l_k(x)<br>$$<br>其中 $l_k(x)$ 为分段线性基函数。</p>
<p><strong>基函数定义</strong></p>
<p>基函数 $l_k(x)$ 在区间内的表达式为：<br>$$<br>l_k(x) &#x3D;<br>\begin{cases}<br>\dfrac{x - x_{k-1}}{x_k - x_{k-1}}, &amp; x \in [x_{k-1}, x_k] \quad (k \neq 0) \<br>\dfrac{x - x_{k+1}}{x_k - x_{k+1}}, &amp; x \in [x_k, x_{k+1}] \quad (k \neq n) \<br>0, &amp; x \notin [x_{k-1}, x_{k+1}]<br>\end{cases}<br>$$</p>
<p><strong>区间分段表达式</strong></p>
<p>左半区间 $[x_{k-1}, x_k]$：<br>$$<br>I_h(x) &#x3D; \dfrac{x - x_{k-1}}{x_k - x_{k-1}} f_k + \dfrac{x - x_k}{x_{k-1} - x_k} f_{k-1}<br>$$</p>
<p>右半区间 $[x_k, x_{k+1}]$：<br>$$<br>I_h(x) &#x3D; \dfrac{x - x_{k+1}}{x_k - x_{k+1}} f_k + \dfrac{x - x_k}{x_{k+1} - x_k} f_{k+1}<br>$$</p>
<p><strong>收敛性与性质</strong></p>
<ol>
<li><p><strong>一致收敛性</strong>：当 $h \to 0$ 时，$I_h(x)$ 在 $[a, b]$ 上一致收敛到 $f(x)$。</p>
</li>
<li><p><strong>光滑性缺失</strong>：分段线性插值函数仅连续（$C^0$），但不可导（失去原函数的光滑性）。</p>
<blockquote>
<p><strong><span style="color:blue">插值误差</span></strong><br>$$<br>\max_{x_k \leq x \leq x_{k+1}} |f(x) - I_h(x)| \leq \frac{M_2}{2} \max_{x_k \leq x \leq x_{k+1}} |(x - x_k)(x - x_{k+1})|<br>$$<br>或<br>$$<br>\max_{a \leq x \leq b} |f(x) - I_h(x)| \leq \frac{M_2}{8} h^2<br>$$<br>其中<br>$$<br>M_2 &#x3D; \max_{a \leq x \leq b} |f’’(x)|<br>$$</p>
</blockquote>
</li>
</ol>
<h3 id="分段三次-Hermite-插值"><a href="#分段三次-Hermite-插值" class="headerlink" title="分段三次 Hermite 插值"></a>分段三次 Hermite 插值</h3><p><u><strong>问题描述</strong></u></p>
<p>在节点 $x_0 &lt; x_1 &lt; \cdots &lt; x_n$ 上已知函数值 $f_k$ 和导数值 $f’_k &#x3D; m_k$，构造分段插值多项式函数 $I_h(x)$ 满足：</p>
<ol>
<li><p><strong>光滑性</strong>：$I_h \in C^1[a, b]$</p>
</li>
<li><p><strong>插值条件</strong>：<br>$$<br>I_h(x_k) &#x3D; f_k, \quad I’_h(x_k) &#x3D; f’_k \quad (k &#x3D; 0, 1, \ldots, n)<br>$$</p>
</li>
<li><p><strong>分段三次多项式</strong>：在每段区间 $[x_k, x_{k+1}]$ 上，$I_h(x)$ 为三次多项式。</p>
</li>
</ol>
<p><u><strong>全局表达式</strong></u></p>
<p>插值函数可表示为：<br>$$<br>I_h(x) &#x3D; \sum_{k&#x3D;0}^n \left[ f(x_k) \alpha_k(x) + f’(x_k) \beta_k(x) \right]<br>$$</p>
<p><u><strong>区间局部表达式</strong></u></p>
<p>在区间 $[x_k, x_{k+1}]$ 上的具体形式为：<br>$$<br>I_h(x) &#x3D; \left( \dfrac{x - x_{k+1}}{x_k - x_{k+1}} \right)^2 \left( 1 + 2 \dfrac{x - x_k}{x_{k+1} - x_k} \right) f_k<br>+\left( \dfrac{x - x_k}{x_{k+1} - x_k} \right)^2 \left( 1 + 2 \dfrac{x - x_{k+1}}{x_k - x_{k+1}} \right) f_{k+1}<br>$$</p>
<p>$$<br>+\left( \dfrac{x - x_{k+1}}{x_k - x_{k+1}}  \right)^2 (x - x_k) f’ _k<br>$$</p>
<p>$$<br>+\left( \dfrac{x - x_k}{x_{k+1} - x_k}  \right)^2 (x - x_{k+1}) f’ _{k+1}<br>$$</p>
<p><u><strong>基函数定义</strong></u></p>
<p>$\alpha_k(x)$ 的分段表达式<br>$$<br>\alpha_k(x) &#x3D;<br>\begin{cases}<br>\left(\dfrac{x - x_{k-1}}{x_k - x_{k-1}} \right)^2 \left( 1 + 2 \dfrac{x - x_k}{x_{k-1} - x_k} \right), &amp; x \in [x_{k-1}, x_k] \quad (k \neq 0) \<br>\left(\dfrac{x - x_{k+1}}{x_k - x_{k+1}} \right)^2 \left( 1 + 2 \dfrac{x - x_k}{x_{k+1} - x_k} \right), &amp; x \in [x_k, x_{k+1}] \quad (k \neq n) \<br>0, &amp; \text{其他区间}<br>\end{cases}<br>$$</p>
<p>$\beta_k(x)$ 的分段表达式<br>$$<br>\beta_k(x) &#x3D;<br>\begin{cases}<br>\left( \dfrac{x - x_{k-1}}{x_k - x_{k-1}} \right)^2 (x - x_k), &amp; x \in [x_{k-1}, x_k] \quad (k \neq 0) \<br>\left( \dfrac{x - x_{k+1}}{x_k - x_{k+1}} \right)^2 (x - x_k), &amp; x \in [x_k, x_{k+1}] \quad (k \neq n) \<br>0, &amp; \text{其他区间}<br>\end{cases}<br>$$</p>
<blockquote>
<p><strong>误差估计：</strong><br>$$<br>|f(x) - I_h(x)| \leq \frac{1}{384}h_k^4 \max_{x_k \leq x \leq x_{k+1}} |f^{(4)}(x)| \<br>x\in[x_k,x_{k+1}] \<br>h_k&#x3D;x_{k+1}-x_k<br>$$</p>
<p>设函数满足：</p>
<ul>
<li>$ f \in C^4[a,b] $</li>
<li>$ I_h(x) $ 是 $ f(x) $ 在节点</li>
</ul>
<p>$$<br>a &#x3D; x_0 &lt; x_1 &lt; \cdots &lt; x_n &#x3D; b<br>$$</p>
<p>上的分段三次埃尔米特插值多项式</p>
<p>则有全局误差估计：<br>$$<br>\max_{a \leq x \leq b} |f(x) - I_h(x)| \leq \frac{h^4}{384} \max_{a \leq x \leq b} |f^{(4)}(x)| \<br>h&#x3D;\max_{0 \leq k \leq n-1}(x_{k+1}-x_k)<br>$$</p>
</blockquote>
<blockquote>
<p><span style="color:blue">$C^k$表示函数有K阶连续导数；$C^0$表述函数连续，没有要求可导</span></p>
</blockquote>
<h2 id="样条插值"><a href="#样条插值" class="headerlink" title="样条插值"></a>样条插值</h2><h3 id="样条插值的概念"><a href="#样条插值的概念" class="headerlink" title="样条插值的概念"></a>样条插值的概念</h3><p>对于给定节点 $a&#x3D;x_0&lt;x_1&lt;\cdots&lt;x_n&#x3D;b$，若存在函数 $s(x)$ 满足：  </p>
<ol>
<li>在每个小区间 $\left[x_j, x_{j+1}\right]$ 是一个次数不超过 3 次的多项式；  </li>
<li>在每一个内节点上具有直到二阶的连续导数，<br>则称 $s(x)$ 是节点 $x_0, x_1,\cdots, x_n$ 上的三次样条函数。</li>
</ol>
<ol start="3">
<li><p>若在节点上给定函数值 $f\left(x_j\right)&#x3D;y_j(j&#x3D;0,\cdots, n)$，并满足  </p>
<p>$s\left(x_j\right)&#x3D;y_j, j&#x3D;0,\cdots, n$  </p>
<p>则称 $s(x)$ 是三次样条插值函数。</p>
</li>
</ol>
<h3 id="三次样条插值函数-s-x-的确定"><a href="#三次样条插值函数-s-x-的确定" class="headerlink" title="三次样条插值函数 $s(x)$ 的确定"></a>三次样条插值函数 $s(x)$ 的确定</h3><span>
$$
s(x)=\left\{\begin{array}{c} 
s_1(x), & x_0\leq x\leq x_1, \\
\ldots \\
s_n(x), & x_{n-1}\leq x\leq x_n.
\end{array}\right.
$$
</span>

<p>在每个 $\left[x_j, x_{j+1}\right]$ 上要确定 4 个待定系数，共 $4n$ 个参数。因二阶导数连续，故在内节点 $x_j$ 上满足连续性条件：<br>$$<br>\begin{gathered}<br>s\left(x_j-0\right)&#x3D;s\left(x_j+0\right), \quad s^{\prime}\left(x_j-0\right)&#x3D;s^{\prime}\left(x_j+0\right), \<br>s^{\prime\prime}\left(x_j-0\right)&#x3D;s^{\prime\prime}\left(x_j+0\right), \quad (j&#x3D;1,\cdots, n-1)<br>\end{gathered}<br>$$</p>
<p>再加上插值条件，共 $4n-2$ 个条件。还需 2 个条件，通常在两个端点加上边界条件。</p>
<h3 id="常见三种边界条件"><a href="#常见三种边界条件" class="headerlink" title="常见三种边界条件"></a>常见三种边界条件</h3><ol>
<li><p><strong>第一种边界条件</strong>(已知两端的<strong>一阶</strong>导数值)<br>$$<br>s^{\prime}\left(x_0\right)&#x3D;y_0^{\prime}\<br>s^{\prime}\left(x_n\right)&#x3D;y_n^{\prime}<br>$$</p>
</li>
<li><p><strong>第二种边界条件</strong>：(已知两端的<strong>二阶</strong>导数值)<br>$$<br>s^{\prime\prime}\left(x_0\right)&#x3D;y_0^{\prime\prime} \s^{\prime\prime}\left(x_n\right)&#x3D;y_n^{\prime\prime}<br>$$</p>
<p>特别地，<strong>自然边界条件</strong>：$s^{\prime\prime}\left(x_0\right)&#x3D;0, \quad s^{\prime\prime}\left(x_n\right)&#x3D;0$。  </p>
</li>
<li><p><strong>第三种边界条件（周期边界条件）</strong>($f(x)$以$x_n-x_0$为周期的周期函数)<br>$$<br>s^{\prime}\left(x_0+0\right)&#x3D;s^{\prime}\left(x_n-0\right)\<br>s^{\prime\prime}\left(x_0+0\right)&#x3D;s^{\prime\prime}\left(x_n-0\right)<br>$$</p>
<p><em>注意</em>：因插值条件 $y_0&#x3D;y_n$，故 $s\left(x_0+0\right)&#x3D;s\left(x_n-0\right)$ 已经成立。</p>
</li>
</ol>
<h3 id="三次样条插值函数的建立"><a href="#三次样条插值函数的建立" class="headerlink" title="三次样条插值函数的建立"></a>三次样条插值函数的建立</h3><p>求三次样条插值函数常用<strong>三弯矩法</strong>和<strong>三转角法</strong>。</p>
<p><strong>三转角法</strong></p>
<p>假定 $s^{\prime}\left(x_j\right)&#x3D;m_j(j&#x3D;0,\cdots, n)$，根据分段三次埃尔米特插值多项式，<br>$$<br>s(x)&#x3D;\sum_{j&#x3D;0}^n\left[f_j\alpha_j(x)+m_j\beta_j(x)\right]<br>$$</p>
<p>由插值条件、连续性条件和边界条件，可得关于 $m_j$ 的三对角方程组，求出 $m_j$，得到三次样条插值函数。</p>
<p><strong>三弯矩法</strong></p>
<p>令<br>$$<br>s^{\prime\prime}\left(x_j\right)&#x3D;M_j, \quad j&#x3D;0,\cdots, n,<br>$$</p>
<p>$$<br>\quad h_j&#x3D;x_{j+1}-x_j<br>$$</p>
<p>则<br>$$<br>s^{\prime\prime}(x)&#x3D;\frac{x_{j+1}-x}{h_j} M_{j}+\frac{x-x_j}{h_j} M_{j+1}, \quad x\in\left[x_j, x_{j+1}\right]<br>$$</p>
<p>对$s’’(x)$积分两次并利用$s\left(x_{j+1}\right)&#x3D;y_{j+1} \quad s\left(x_{j+1}\right)&#x3D;y_{j+1}$</p>
<span>
$$
\begin{aligned}
s^{\prime}(x) &= -\frac{\left(x_{j+1}-x\right)^{2}}{2 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{2}}{2 h_{j}} M_{j+1} + c_{1}, \\
s(x) &= \frac{\left(x_{j+1}-x\right)^{3}}{6 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{3}}{6 h_{j}} M_{j+1} + c_{1} x + c_{2}, \\
s\left(x_{j}\right) &= \frac{1}{6} h_{j}^{2} M_{j} + c_{1} x_{j} + c_{2} = y_{j}, \\
s\left(x_{j+1}\right) &= \frac{1}{6} h_{j}^{2} M_{j+1} + c_{1} x_{j+1} + c_{2} = y_{j+1}, \\
c_{1} &= \frac{y_{j+1}-y_{j}}{h_{j}} - \frac{1}{6} h_{j}\left(M_{j+1}-M_{j}\right), \\
c_{2} &= \frac{y_{j} x_{j+1} - y_{j+1} x_{j}}{h_{j}} - \frac{1}{6} h_{j}\left(x_{j+1} M_{j} - x_{j} M_{j+1}\right).
\end{aligned}
$$
</span>
$$
s(x) = \frac{\left(x_{j+1}-x\right)^{3}}{6 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{3}}{6 h_{j}} M_{j+1} + \left(y_{j}-\frac{M_{j} h_{j}^{2}}{6}\right)\frac{x_{j+1}-x}{h_{j}} + \left(y_{j+1}-\frac{M_{j+1} h_{j}^{2}}{6}\right)\frac{x-x_{j}}{h_{j}}
$$

<p>$$<br>s^{\prime}(x) &#x3D; -\frac{\left(x_{j+1}-x\right)^2}{2 h_j} M_{j} + \frac{\left(x-x_j\right)^2}{2 h_j} M_{j+1} + \frac{y_{j+1}-y_j}{h_j} - \frac{M_{j+1}-M_{j}}{6} h_{j}.<br>$$</p>
<p>为了求 $M_0,\cdots, M_n$，要用导数连续条件：$s^{\prime}\left(x_j+0\right)&#x3D;s^{\prime}\left(x_j-0\right)$。</p>
<span>
$$
\begin{align*}
s^{\prime}\left(x_{j}+0\right) &= -\frac{h_{j}}{3} M_{j} - \frac{h_{j}}{6} M_{j+1} + \frac{y_{j+1}-y_{j}}{h_{j}}, \\
s^{\prime}\left(x_{j+1}-0\right) &= \frac{h_{j}}{6} M_{j} + \frac{h_{j}}{3} M_{j+1} + \frac{y_{j+1}-y_{j}}{h_{j}}, \\
s^{\prime}\left(x_{j}-0\right) &= \frac{h_{j-1}}{6} M_{j-1} + \frac{h_{j-1}}{3} M_{j} + \frac{y_{j-1}-y_{j-1}}{h_{j-1}}. \\
\frac{h_{j-1}}{6} M_{j-1} + \frac{h_{j-1}+h_{j}}{3} M_{j} + \frac{h_{j}}{6} M_{j+1} &= \frac{y_{j}-y_{j-1}}{h_{j-1}} - \frac{y_{j+1}-y_{j}}{h_{j}}, \quad j=1,\cdots, n-1,
\end{align*}
$$
</span>
$$
\mu_{j} M_{j-1} + 2 M_{j} + \lambda_{j} M_{j+1} = d_{j}, \quad j=1,\cdots, n-1,
$$

<p>解得<br>$$<br>d_{j}&#x3D;6 f\left[x_{j-1}, x_{j}, x_{j+1}\right]<br>$$</p>
<p>$$<br>\lambda_{j}&#x3D; \frac{h_j}{h_{j-1}+h_j}<br>$$</p>
<p>$$<br>\mu_j &#x3D; \frac{h_{j-1}}{h_{j-1}+h_j}<br>$$</p>
<h4 id="第一边界条件"><a href="#第一边界条件" class="headerlink" title="第一边界条件"></a>第一边界条件</h4><span>
$$
\begin{bmatrix}
2 & \lambda_0 & & & \\
\mu_1 & 2 & \lambda_1 & & \\
 & \ddots & \ddots & \ddots & \\
 & & \mu_{n-1} & 2 & \lambda_{n-1} \\
 & & & \mu_{n} & 2
\end{bmatrix}
\begin{bmatrix}
M_0 \\
M_1 \\
\vdots \\
M_{n-1} \\
M_n
\end{bmatrix}
=
\begin{bmatrix}
d_0 \\
d_1 \\
\vdots \\
d_{n-1} \\
d_n
\end{bmatrix}
$$
</span>

<blockquote>
<p>$$<br>\lambda_0 &#x3D; 1\<br>\mu_n &#x3D; 1\<br>\quad h_j&#x3D;x_{j+1}-x_j<br>$$<br>$$<br>d_0 &#x3D; \frac{6}{h_0} \left( f[x_0, x_1] - f’_0 \right)<br>$$</p>
<p>$$<br>d_j &#x3D; 6 \frac{f[x_j, x_{j+1}] - f[x_{j-1}, x_j]}{h_{j-1} + h_j} &#x3D; 6 f[x_{j-1}, x_j, x_{j+1}], \quad j &#x3D; 1, 2, \dots, n-1<br>$$</p>
<p>$$<br>d_n &#x3D; \frac{6}{h_{n-1}} \left( f’_n - f[x _{n-1}, x_n] \right)<br>$$</p>
<p>$$<br>\lambda_{j}&#x3D; \frac{h_j}{h_{j-1}+h_j}\<br>\mu_j &#x3D; \frac{h_{j-1}}{h_{j-1}+h_j}<br>$$</p>
<p>$$<br>s(x) &#x3D; \frac{\left(x_{j+1}-x\right)^{3}}{6 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{3}}{6 h_{j}} M_{j+1} + \left(y_{j}-\frac{M_{j} h_{j}^{2}}{6}\right)\frac{x_{j+1}-x}{h_{j}} + \left(y_{j+1}-\frac{M_{j+1} h_{j}^{2}}{6}\right)\frac{x-x_{j}}{h_{j}}<br>$$</p>
</blockquote>
<p><strong>第二边界条件矩阵方程</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">2 &amp; \lambda_1 &amp; &amp; \\</span><br><span class="line">\mu_2 &amp; 2 &amp; \lambda_2 &amp; \\</span><br><span class="line"> &amp; \ddots &amp; \ddots &amp; \ddots \\</span><br><span class="line"> &amp; &amp; \mu_&#123;n-1&#125; &amp; 2</span><br><span class="line">\end&#123;bmatrix&#125;</span><br><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">M_1 \\</span><br><span class="line">M_2 \\</span><br><span class="line">\vdots \\</span><br><span class="line">M_&#123;n-1&#125;</span><br><span class="line">\end&#123;bmatrix&#125;</span><br><span class="line">=</span><br><span class="line">\begin&#123;bmatrix&#125;</span><br><span class="line">d_1 - \mu_1 f&#x27;&#x27;_0 \\</span><br><span class="line">d_2 \\</span><br><span class="line">\vdots \\</span><br><span class="line">d_&#123;n-1&#125; - \lambda_&#123;n-1&#125; f&#x27;&#x27;_n</span><br><span class="line">\end&#123;bmatrix&#125;</span><br></pre></td></tr></table></figure>



<p><img src="/blog/image/Snipaste_2025-05-14_14-45-25.png"></p>
<p>边界条件约束：</p>
<span>
$$
\begin{cases}
M_0 = f''_0 \\
M_n = f''_n
\end{cases}
$$

</span>

<p><strong>第三边界条件（周期边界条件）矩阵方程</strong></p>
<span>
$$
\begin{bmatrix}
2 & \lambda_1 & & & \mu_1 \\
\mu_2 & 2 & \lambda_2 & & \\
 & \ddots & \ddots & \ddots & \\
 & & \mu_{n-1} & 2 & \lambda_{n-1} \\
\lambda_n & & & \mu_n & 2
\end{bmatrix}
\begin{bmatrix}
M_1 \\
M_2 \\
\vdots \\
M_{n-1} \\
M_n
\end{bmatrix}
=
\begin{bmatrix}
d_1 \\
d_2 \\
\vdots \\
d_{n-1} \\
d_n
\end{bmatrix}
$$



</span>

<p>特殊约束条件</p>
<span>
$$
\begin{cases}
x_0 = x_n \quad (\text{周期条件}) \\
M_0 = M_n \quad (\text{弯矩周期约束}) \\
\mu_n M_{n-1} + 2M_n + \lambda_n M_1 = d_n \quad (\text{闭环方程})
\end{cases}
$$

</span>

<p>参数定义</p>
<span>
$$
\begin{aligned}
\mu_n &= \frac{h_{n-1}}{h_{n-1} + h_0} \quad (\text{末节点弯矩传递系数}) \\
\lambda_n &= \frac{h_0}{h_{n-1} + h_0} \quad (\text{首节点弯矩传递系数}) \\
d_n &= 6f[x_{n-1}, x_n, x_1] \quad (\text{三阶差商计算})
\end{aligned}
$$

</span>

<h3 id="误差界与收敛性"><a href="#误差界与收敛性" class="headerlink" title="误差界与收敛性"></a>误差界与收敛性</h3><p> 设 $f(x) \in C^4[a,b]$，$S(x)$ 满足第一或第二边界条件，<br>令 $h &#x3D; \max\limits_{0 \leq i \leq n-1} h_i$，其中 $h_i &#x3D; x_{i+1} - x_i$，则有估计式：<br>$$<br>\max_{a \leq x \leq b} \left| f^{(k)}(x) - s^{(k)}(x) \right| \leq C_k \left( \max_{a \leq x \leq b} \left| f^{(4)}(x) \right| \right) h^{4-k}<br>$$<br>其中常数项系数为：<br>$$<br>\begin{cases}<br>C_0 &#x3D; \dfrac{5}{384} \<br>C_1 &#x3D; \dfrac{1}{24} \<br>C_2 &#x3D; \dfrac{3}{8}<br>\end{cases} \quad (k&#x3D;0,1,2)<br>$$</p>
<h3 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>给定数据表</p>
<table>
<thead>
<tr>
<th>$x_j$</th>
<th>$y_j$</th>
</tr>
</thead>
<tbody><tr>
<td>0.25</td>
<td>0.5000</td>
</tr>
<tr>
<td>0.30</td>
<td>0.5477</td>
</tr>
<tr>
<td>0.39</td>
<td>0.6245</td>
</tr>
<tr>
<td>0.45</td>
<td>0.6708</td>
</tr>
<tr>
<td>0.53</td>
<td>0.7280</td>
</tr>
</tbody></table>
<p>试求三次样条插值$S(x)$,并满足条件</p>
<ol>
<li>$S’(0.25) &#x3D; 1.0000$，$S’(0.53) &#x3D; 0.6868$</li>
<li>$S’’(0.25) &#x3D; S’’(0.53) &#x3D; 0$</li>
</ol>
<p><strong>解</strong></p>
<p><code>5个点，n=4,5阶方程组</code></p>
<p>计算区间宽度 $h_i$</p>
<span>
$$
\begin{aligned}
h_0 &= 0.30 - 0.25 = 0.05 \\
h_1 &= 0.39 - 0.30 = 0.09 \\
h_2 &= 0.45 - 0.39 = 0.06 \\
h_3 &= 0.53 - 0.45 = 0.08
\end{aligned}
$$

</span>

<p>计算系数 $\mu_i$ 和 $\lambda_i$<br>$$<br>\lambda_{j}&#x3D; \frac{h_j}{h_{j-1}+h_j}\<br>\mu_j &#x3D; \frac{h_{j-1}}{h_{j-1}+h_j}<br>$$</p>
<p>$$<br>\mu_1 &#x3D; \frac{5}{14},\quad \lambda_1 &#x3D; \frac{9}{14} \<br>\mu_2 &#x3D; \frac{3}{5},\quad \lambda_2 &#x3D; \frac{2}{5} \<br>\mu_3 &#x3D; \frac{3}{7},\quad \lambda_3 &#x3D; \frac{4}{7} \<br>\mu_4 &#x3D; 1,\quad \lambda_0 &#x3D; 1<br>$$</p>
<p>建立差商表</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>$f(x)$</th>
<th>一阶差商</th>
<th>二阶差商</th>
</tr>
</thead>
<tbody><tr>
<td>0.25</td>
<td>0.5000</td>
<td></td>
<td></td>
</tr>
<tr>
<td>0.30</td>
<td>0.5477</td>
<td>0.954</td>
<td></td>
</tr>
<tr>
<td>0.39</td>
<td>0.6245</td>
<td>0.8533</td>
<td>-0.7193</td>
</tr>
<tr>
<td>0.45</td>
<td>0.6708</td>
<td>0.7717</td>
<td>-0.5440</td>
</tr>
<tr>
<td>0.53</td>
<td>0.7280</td>
<td>0.7150</td>
<td>-0.4050</td>
</tr>
</tbody></table>
<p>$$<br>d_0 &#x3D; \frac{6}{h_0} ( f[x_0, x_1] - f’_0 )&#x3D;6(-0.92)<br>$$</p>
<p>$$<br>d_n &#x3D; \frac{6}{h_{n-1}} ( f’_n - f[x _{n-1}, x_n] )&#x3D;6(-0.3525)<br>$$</p>
<p>一阶导数边界条件弯距方程组</p>
<span>
$$
\begin{bmatrix}
2       & 1        & 0        & 0        & 0        \\
\frac{5}{14} & 2       & \frac{9}{14} & 0        & 0        \\
0       & \frac{3}{5} & 2       & \frac{2}{5} & 0        \\
0       & 0        & \frac{3}{7} & 2       & \frac{4}{7} \\
0       & 0        & 0        & 1        & 2
\end{bmatrix}
\begin{bmatrix}
M_0 \\ M_1 \\ M_2 \\ M_3 \\ M_4
\end{bmatrix}
= 6 \times
\begin{bmatrix}
-0.9200 \\ -0.7193 \\ -0.5440 \\ -0.4050 \\ -0.3525
\end{bmatrix}
$$

<span>

<p>追赶法解得：<br>$$<br>M_0 &#x3D; -2.0278 \quad M_1 &#x3D; -1.4643 \quad M_2 &#x3D; -1.0313 \quad<br>M_3 &#x3D; -0.8072 \quad M_4 &#x3D; -0.6539<br>$$</p>
<span>
$$
S(x) =
\begin{cases} 
1.8783x^3 - 2.4227x^2 + 1.8591x + 0.1573, & x \in [0.25, 0.30] \\
0.8019x^3 - 1.4538x^2 + 1.5685x + 0.1863, & x \in [0.30, 0.39] \\
0.6225x^3 - 1.2440x^2 + 1.4866x + 0.1970, & x \in [0.39, 0.45] \\
0.3194x^3 - 0.8348x^2 + 1.3025x + 0.2246, & x \in [0.45, 0.53]
\end{cases}
$$

</span>



<p>系数矩阵与右端项：</p>
<span>
$$
\begin{bmatrix}
2 & \frac{9}{14} & 0 \\
\frac{3}{5} & 2 & \frac{2}{5} \\
0 & \frac{3}{7} & 2
\end{bmatrix}
\begin{bmatrix}
M_1 \\ M_2 \\ M_3
\end{bmatrix}
= 6
\begin{bmatrix}
-0.7193 \\ -0.5440 \\ -0.4050
\end{bmatrix}
$$

</span>

<p><strong>(写系数矩阵的时候直接在一阶导数边界条件的系数矩阵上 上下左右各划掉一行或者一列即可)</strong></p>
<p>追赶法解得：<br>$$<br>M_0 &#x3D; 0,\quad M_1 &#x3D; -1.8809,\quad M_2 &#x3D; -0.8616,\quad M_3 &#x3D; -1.0314,\quad M_4 &#x3D; 0<br>$$</p>
<span>
$$
S(x) =
\begin{cases} 
-6.2697x^3 + 4.7023x^2 - 0.2059x + 0.3555, & x \in [0.25, 0.30] \\
1.8876x^3 - 2.6390x^2 + 1.9966x + 0.1353, & x \in [0.30, 0.39] \\
-0.4689x^3 + 0.1178x^2 + 0.9213x + 0.2751, & x \in [0.39, 0.45] \\
2.1467x^3 - 3.4132x^2 + 2.5103x + 0.0367, & x \in [0.45, 0.53]
\end{cases}
$$
</span></blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析-常微分方程数值解</title>
    <url>/blog/2025/04/23/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此部分包含常微分方程的数值解部分———————————————————————————————————————————————————————————–</p>
<h1 id="第五章-常微分方程数值解"><a href="#第五章-常微分方程数值解" class="headerlink" title="第五章 常微分方程数值解"></a>第五章 常微分方程数值解</h1><h2 id="记忆内容汇总"><a href="#记忆内容汇总" class="headerlink" title="记忆内容汇总"></a>记忆内容汇总</h2><blockquote>
<p><strong>欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n)<br>$$<br><strong>改进欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_n + h f(x_n, y_n)) \right]<br>$$</p>
<p><strong>四阶经典R-K方法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} (K_1 + 2K_2 + 2K_3 + K_4)<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_1)<br>$$</p>
<p>$$<br>K_3 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_2)<br>$$</p>
<p>$$<br>K_4 &#x3D; f(x_n + h, y_n + h K_3)<br>$$</p>
<p><strong>稳定区间</strong></p>
<ol>
<li>欧拉法</li>
</ol>
  <div>

<p>$$<br>  E(h\lambda)&#x3D;1+h\lambda \<br>  -2 &lt; \lambda h &lt; 0<br>$$</p>
  </div>

<ol start="2">
<li>改进欧拉法</li>
</ol>
  <div>

<p>$$<br>  E(h\lambda)&#x3D;1 + h\lambda + \frac{(h\lambda)^2}{2} \<br>  -2 &lt; h\lambda &lt; 0<br>$$</p>
  </div>

<ol start="3">
<li>4阶经典龙格库塔方法<br>$$<br>  E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!} + \frac{(h\lambda)^4}{4!}.<br>$$</li>
</ol>
<p>$$<br>  -2.78 &lt; h\lambda &lt; 0<br>$$</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>考虑一阶常微分方程的初值问题 &#x2F;* Initial-Value Problem *&#x2F;:</p>
<span>
$$
\begin{cases}
\frac{dy}{dx} = f(x, y), & x \in [a, b] \\
y(a) = y_0
\end{cases}
$$

</span>

<p>只要 $f(x, y)$ 在 $[a, b] \times \mathbb{R}^1$ 上连续，且关于 $y$ 满足 Lipschitz 条件，即存在与 $x, y$ 无关的常数 $L$ 使得<br>$$<br>|f(x, y_1) - f(x, y_2)| \leq L |y_1 - y_2|<br>$$</p>
<p>对任意定义在 $[a, b]$ 上的 $y_1(x)$ 和 $y_2(x)$ 都成立，则上述 IVP (一阶常微分方程的初值问题)存在唯一解。</p>
<ul>
<li>本章的任务：计算出解函数 $y(x)$ 在一系列节点 $a &#x3D; x_0 &lt; x_1 &lt; \dots &lt; x_n &#x3D; b$ 处的近似值。</li>
</ul>
<p>$$<br>y_n \approx y(x_n) \quad (n &#x3D; 1, \dots, N)<br>$$</p>
<h2 id="建立常微分方程数值方法的基本思想"><a href="#建立常微分方程数值方法的基本思想" class="headerlink" title="建立常微分方程数值方法的基本思想"></a>建立常微分方程数值方法的基本思想</h2><p>微分方程数值解法，其实是求出方程的解 $y(x)$ 在一系列离散点上的近似值。则微分方程数值解的基本思想是：求解区间和方程离散化。</p>
<h3 id="求解区间离散化"><a href="#求解区间离散化" class="headerlink" title="求解区间离散化"></a>求解区间离散化</h3><p>将求解区间 $[a, b]$ 离散化，是在 $[a, b]$ 上插入一系列的分点 ${x_k}$ 使得<br>$$<br>a &#x3D; x_0 &lt; x_1 &lt; \dots &lt; x_n &lt; \dots &lt; x_N &#x3D; b<br>$$</p>
<ul>
<li><p>记 $h_n &#x3D; x_{n+1} - x_n$ ($n &#x3D; 0, 1, \dots, N-1$) 称为步长，一般取 $h_n &#x3D; h$（常数）</p>
</li>
<li><p>节点为 $x_n &#x3D; x_0 + nh$ ($n &#x3D; 0, 1, 2, \dots, N$)</p>
</li>
<li><p>$h &#x3D; \frac{b - a}{N}$ 为等步长节点。</p>
</li>
</ul>
<hr>
<h3 id="微分方程离散化"><a href="#微分方程离散化" class="headerlink" title="微分方程离散化"></a>微分方程离散化</h3><p>将微分方程离散化，通常有以下几种方法：</p>
<ol>
<li><p><strong>差商逼近法</strong></p>
<p>即是用适当的差商逼近导数值。</p>
</li>
<li><p><strong>数值积分法</strong></p>
<p>基本思想是先将问题转化为积分类方程</p>
<p>$$<br>y(x_m) - y(x_n) &#x3D; \int_{x_n}^{x_m} f(x, y(x)) dx \quad (y(x_0) &#x3D; y_0)<br>$$</p>
<p>然后将式子右端采用第四章介绍的数值积分离散化，从而获得初值问题的一个离散差分格式。</p>
</li>
<li><p><strong>Taylor 展开法</strong></p>
</li>
</ol>
<blockquote>
<p><strong>例题</strong></p>
<p>用二阶 Taylor 展开法求初值问题<br>$$<br>\begin{cases}<br>y’ &#x3D; x^2 + y^2 \<br>y(1) &#x3D; 1<br>\end{cases}<br>$$</p>
<p>求其在 $x &#x3D; 1.5$ 时的近似值（取步长 $h &#x3D; 0.25$，小数点后至少保留 5 位）。</p>
<hr>
<p><strong>解题过程</strong><br>二阶 Taylor 展开公式为：<br>$$<br>y(x_{n+1}) &#x3D; y(x_n) + y’(x_n) h + \frac{y’’(x_n)}{2!} h^2 + O(h^3)<br>$$</p>
<p>已知：</p>
<p>$$<br>y’ &#x3D; x^2 + y^2,\quad y’’ &#x3D; 2x + 2y \cdot y’ &#x3D; 2x + 2y(x^2 + y^2)<br>$$</p>
<p>代入上式，并略去高阶项 $O(h^3)$，则求解公式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h(x_n^2 + y_n^2) + \frac{h^2}{2} \left[ 2x_n + 2y_n(x_n^2 + y_n^2) \right]<br>$$</p>
<p>由 $y(1) &#x3D; y_0 &#x3D; 1$，计算得：</p>
<p>$$<br>y(1.25) \approx y_1 &#x3D; 1.6875 ;\<br>y(1.50) \approx y_2 &#x3D; 3.333298<br>$$</p>
</blockquote>
<h2 id="欧拉方法"><a href="#欧拉方法" class="headerlink" title="欧拉方法"></a>欧拉方法</h2><h3 id="欧拉公式"><a href="#欧拉公式" class="headerlink" title="欧拉公式"></a>欧拉公式</h3><p>向前差商近似导数  →  $y’(x_0) \approx \frac{y(x_1) - y(x_0)}{h}$</p>
<p>记为</p>
<p>$$<br>y(x_1) \approx y(x_0) + h y’(x_0) &#x3D; y_0 + h f(x_0, y_0)<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n) \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p><strong>原理图形</strong></p>
<p><img src="/blog/image/Snipaste_2025-05-20_14-47-05.png"></p>
<h2 id="隐式欧拉法"><a href="#隐式欧拉法" class="headerlink" title="隐式欧拉法"></a>隐式欧拉法</h2><p>向后差商近似导数  →  $y’(x_1) \approx \frac{y(x_1) - y(x_0)}{h}$</p>
<p>记为</p>
<p>$$<br>y(x_1) \approx y_0 + h f(x_1, y(x_1))<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1}) \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p>由于未知数 $y_{n+1}$ 同时出现在等式的两边，不能直接得到，故称为<strong>隐式欧拉公式</strong>，而前者称为<strong>显式欧拉公式</strong>。</p>
<p>一般先用显式计算一个初值，再递代求解。即</p>
<p>$$<br>y_{n+1}^{(0)} &#x3D; y_n + h f(x_n, y_n)<br>$$</p>
<p>$$<br>y_{n+1}^{(k+1)} &#x3D; y_n + h f(x_{n+1}, y_{n+1}^{(k)}) \quad k &#x3D; 0, 1, 2, \dots<br>$$</p>
<p>如果迭代过程收敛，则步后 $y_{n+1}^{(k+1)}$ 就可以作为 $y_{n+1}$，从而进行下一步的计算。</p>
<h2 id="梯形公式"><a href="#梯形公式" class="headerlink" title="梯形公式"></a>梯形公式</h2><p>显、隐式两种算法的平均<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_{n+1}) \right] \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<hr>
<h2 id="两步欧拉公式"><a href="#两步欧拉公式" class="headerlink" title="两步欧拉公式"></a>两步欧拉公式</h2><p>中心差商近似导数  →  $y’(x_1) \approx \frac{y(x_2) - y(x_0)}{2h}$</p>
<p>$$<br>y(x_2) \approx y(x_0) + 2h f(x_1, y(x_1))<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_{n-1} + 2h f(x_n, y_n) \quad n &#x3D; 1, \dots, N-1<br>$$</p>
<hr>
<blockquote>
<p>需要 2 个初值 $y_0$ 和 $y_1$ 来启动递推，这样的算法称为两步法 &#x2F;* double-step method <em>&#x2F;，而前面的三种算法都是单步法 &#x2F;</em> single-step method *&#x2F;。</p>
</blockquote>
<h2 id="改进欧拉法"><a href="#改进欧拉法" class="headerlink" title="改进欧拉法"></a>改进欧拉法</h2><p>Step 1: 先用显式欧拉公式作预测，算出 $\bar{y}_{n+1} &#x3D; y_n + h f(x_n, y_n)$</p>
<p>Step 2: 再将 $\bar y_{n+1}$ 代入隐式梯形公式的右边作校正，得到<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, \bar y_{n+1}) \right]<br>$$</p>
<p>递推公式为</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_n + h f(x_n, y_n)) \right] \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p><strong>换一种表示方法</strong><span style="color:#FF0000">（考试记忆这个）</span></p>
<p>$y_p &#x3D; y_n + h f(x_n, y_n)$，$y_c &#x3D; y_n + h f(x_{n+1}, y_p)$，因此有<br>$$<br>y_{n+1} &#x3D; \frac{1}{2} (y_p + y_c)<br>$$</p>
<blockquote>
<p>此法也称为<strong>预测-校正法</strong> &#x2F;* predictor-corrector method *&#x2F;。可以证明该算法具有 <strong>2 阶精度</strong>，同时可以看到它是个单步递推格式，比隐式公式的解求过程简单。后面将看到，它的稳定性高于显式欧拉法。</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p>用梯形法和改进的欧拉法求解初值问题</p>
<p>$$<br>\begin{cases}<br>y’ &#x3D; x + y, \quad 0 \leq x \leq 0.5 \<br>y(0) &#x3D; 1<br>\end{cases}<br>$$</p>
<p>取步长 $h &#x3D; 0.1$，并与准确解 $y &#x3D; -x - 1 + 2e^x$ 比较。</p>
<hr>
<p><strong>解题过程</strong></p>
<p>梯形法计算公式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{1}{2}h \left[ x_n + y_n + x_{n+1} + y_{n+1} \right]<br>$$</p>
<p>解得：</p>
<p>$$<br>y_{n+1} &#x3D; \frac{1}{1 - h&#x2F;2} \left[ \left(1 + \frac{h}{2} \right) y_n + \frac{h}{2} (x_n + x_{n+1}) \right], \quad (n &#x3D; 0,1,\cdots,4)<br>$$</p>
<p><span style="color:#FF0000">（这里需要记住梯形法计算时等式右边的$y_{n+1}$需要移项后计算）</span></p>
<p>改进的欧拉法为：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2}[f(x_n,y_n)+f(x_{n+1},y_n+hf(x_n,y_n))]<br>$$</p>
<p>即：</p>
<p>$$<br>y_{n+1} &#x3D; (1+h+\frac{h^2}{2})y_n+(\frac{h}{2}+\frac{h^2}{2})x_n+\frac{h}{2}x_{n+1}<br>$$</p>
<p>代入 $h &#x3D; 0.1, y_0 &#x3D; 1$ 代入上述两种方法计算，结果见下表：</p>
<table>
<thead>
<tr>
<th>n</th>
<th>$x_n$</th>
<th>梯形法 $y_n$</th>
<th>$y(x_n) - y_n$</th>
<th>n</th>
<th>$x_n$</th>
<th>改进欧拉法 $y_n$</th>
<th>$y(x_n) - y_n$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.1</td>
<td>1.110 526 316</td>
<td>0.184 479 × 10⁻³</td>
<td>0</td>
<td>0.1</td>
<td>1.11 000 000</td>
<td>0.341 836 × 10⁻³</td>
</tr>
<tr>
<td>1</td>
<td>0.2</td>
<td>1.243 213 296</td>
<td>0.407 779 × 10⁻³</td>
<td>1</td>
<td>0.2</td>
<td>1.242 050</td>
<td>0.755 516 × 10⁻³</td>
</tr>
<tr>
<td>2</td>
<td>0.3</td>
<td>1.400 393 643</td>
<td>0.676 027 × 10⁻³</td>
<td>2</td>
<td>0.3</td>
<td>1.398 465 250</td>
<td>1.252 365 × 10⁻³</td>
</tr>
<tr>
<td>3</td>
<td>0.4</td>
<td>1.584 645 606</td>
<td>0.996210 × 10⁻³</td>
<td>3</td>
<td>0.4</td>
<td>1.581804101</td>
<td>1.845 294 × 10⁻³</td>
</tr>
<tr>
<td>4</td>
<td>0.5</td>
<td>1.798 818 827</td>
<td>1.376285 × 10⁻³</td>
<td>4</td>
<td>0.5</td>
<td>1.794893532</td>
<td>2.549 009 × 10⁻³</td>
</tr>
</tbody></table>
<hr>
<p><strong>结论</strong><br>可以看出，就本题而言，梯形法比改进的欧拉法更精确。</p>
</blockquote>
<h2 id="局部截断误差和方法的阶"><a href="#局部截断误差和方法的阶" class="headerlink" title="局部截断误差和方法的阶"></a>局部截断误差和方法的阶</h2><p>初值问题的单步法可用一般形式表示为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h \varphi(x_n, y_n, y_{n+1}, h)<br>$$</p>
<p>其中，$\varphi$ 称为增量函数。</p>
<ul>
<li>若 $\varphi$ 包含 $y_{n+1}$ 时，方法是<strong>隐式</strong>的</li>
<li>若 $\varphi$ 不包含 $y_{n+1}$ 时，方法是<strong>显式</strong>的</li>
</ul>
<p>例如</p>
<ul>
<li><p>(显示)欧拉法有 $\varphi(x_n, y_n, h) &#x3D; f(x_n, y_n)$，</p>
</li>
<li><p>隐式欧拉法有 $\varphi(x_n, y_n, y_{n+1},h) &#x3D; f(x_{n+1}, y_{n+1})$</p>
</li>
</ul>
<p>从 $x_0$ 开始计算，如果考虑每一步产生的误差，直到 $x_n$ 则有误差<br>$$<br>e_n &#x3D; y(x_n) - y_n<br>$$</p>
<p>称为该方法在 $x_n$ 的<strong>整体截断误差</strong></p>
<p>分析和求得整体截断误差是复杂的。为此，我们只考虑从 $x_n$ 到 $x_{n+1}$ 的局部情况，并假设 $x_n$ 之前的计算没有误差，即$y(x_n)&#x3D;y_n$</p>
<p><strong>定义</strong></p>
<p>设 $y(x)$ 是初值问题的准确解，称</p>
<p>$$<br>T_{n+1} &#x3D;y(x_{n+1}) - y_{n+1}&#x3D; y(x_{n+1}) - y(x_n) - h \varphi(x_n, y(x_n),y(x_{n+1}) ,h)<br>$$</p>
<p>为单步法的<strong>局部截断误差</strong>。</p>
<p><strong>定义</strong></p>
<blockquote>
<p>若某算法的局部截断误差为 $O(h^{p+1})$，则该算法有 $p$ 阶精度。</p>
</blockquote>
<blockquote>
<span>
$$
\begin{aligned}
f(x + \Delta x, y + \Delta y) &= f(x, y) \\
&\quad + \Delta x \cdot f_x + \Delta y \cdot f_y \\
&\quad + \frac{1}{2} \left( \Delta x^{2} f_{xx} + 2 \Delta x \Delta y f_{xy} + \Delta y^{2} f_{yy} \right) \\
&\quad + \frac{1}{6} \left( \Delta x^{3} f_{xxx} + 3 \Delta x^{2} \Delta y f_{xxy} + 3 \Delta x \Delta y^{2} f_{xyy} + \Delta y^{3} f_{yyy} \right) \\
&\quad + \frac{1}{24} \left( \Delta x^{4} f_{xxxx} + 4 \Delta x^{3} \Delta y f_{xxxy} + 6 \Delta x^{2} \Delta y^{2} f_{xxyy} + 4 \Delta x \Delta y^{3} f_{xyyy} + \Delta y^{4} f_{yyyy} \right) \\
&\quad + O(\Delta x^{5}, \Delta y^{5})
\end{aligned}
$$


</span>

</blockquote>
<h3 id="欧拉法的局部截断误差"><a href="#欧拉法的局部截断误差" class="headerlink" title="欧拉法的局部截断误差"></a>欧拉法的局部截断误差</h3><p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1}   \<br>&#x3D; [y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3)] - [y_n + h f(x_n, y_n)] \<br>$$</p>
<p>$$<br>\text {其中} \quad y_n&#x3D;y(x_n) \quad  f(x_n, y_n)&#x3D;y’(x_n) \<br>$$</p>
<p>$$<br>T_{n+1}&#x3D;\frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>欧拉法具有 1 阶精度。</strong></p>
<h3 id="隐式欧拉法的局部截断误差"><a href="#隐式欧拉法的局部截断误差" class="headerlink" title="隐式欧拉法的局部截断误差"></a>隐式欧拉法的局部截断误差</h3><p>求隐式欧拉式 $y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1})$ 的局部截断误差。<br>$$<br>T_{n+1} &#x3D; y(x_{n+1})-y_{n+1} \<br>&#x3D;y(x_{n+1}) - y(x_n) - h f(x_{n+1}, y_{n+1}) \<br>&#x3D;y(x_{n+1}) - y(x_n) - hy’(x_{n+1}) \<br>&#x3D; h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3) - h[y’(x_n) + h y’’(x_n) + O(h^2)] \<br>&#x3D; -\frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>具有 1 阶精度。</strong></p>
<hr>
<h3 id="梯形公式的局部截断误差"><a href="#梯形公式的局部截断误差" class="headerlink" title="梯形公式的局部截断误差"></a>梯形公式的局部截断误差</h3><p>梯形公式 $y_{n+1} &#x3D; y_n + \frac{h}{2}[f(x_n, y_n) + f(x_{n+1}, y_{n+1})]$ 的局部截断误差。<br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y(x_n) - \frac{h}{2}[y’(x_n) + y’(x_{n+1})] \<br>&#x3D; h y’(x_n) + \frac{h^2}{2} y’’(x_n) + \frac{h^3}{3!} y^{(3)}(x_n) - \frac{h}{2}[y’(x_n) + y’(x_n) + hy’’(x_n) + \frac{h^2}{2} y^{(3)}(x_n) + O(h^4)] \<br>&#x3D; -\frac{h^3}{12} y^{(3)}(x_n) + O(h^4)<br>$$</p>
<p><strong>具有 2 阶精度。</strong></p>
<h3 id="改进欧拉法的局部截断误差"><a href="#改进欧拉法的局部截断误差" class="headerlink" title="改进欧拉法的局部截断误差"></a>改进欧拉法的局部截断误差</h3><p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) -  y_{n+1} &#x3D; O(h^3)<br>$$</p>
<p> $ y(x_{n+1}) $精确解在 $ x_n $ 处展开至三阶项：</p>
<span>
$$
\begin{aligned}
y(x_{n+1}) &= y(x_n) + h y'(x_n) + \frac{h^2}{2} y''(x_n) + \frac{h^3}{6} y'''(x_n) + O(h^4) \\
&= y(x_{n+1}) + h f + \frac{h^2}{2}(f_x + f f_y) + \frac{h^3}{6}(f_{xx} + 2f_{xy}f + f_{yy}f^2 + f_y f_x + f_y^2 f) + O(h^4)
\end{aligned}
$$

</span>



<p>预测-校正步骤：<br>$$<br>y_{n+1} &#x3D; y_n + h (f+f(x_n+h,y_n+hf))<br>$$</p>
<p>对 $f(x_n + h, y_n + h f)$ 进行二元泰勒展开（至二阶项）：<br>$$<br>f(x_n + h, y_n + h f) &#x3D; f + h f_x + h f f_y + \frac{h^2}{2}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + O(h^3)<br>$$</p>
<p>代入得数值解：<br>$$<br>y_{n+1} &#x3D; y_n + h f + \frac{h^2}{2}(f_x + f f_y) + \frac{h^3}{4}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + O(h^4)<br>$$</p>
<span>
$$
\begin{aligned}
T_{n+1} &= y(x_{n+1}) - y_{n+1} \\
&= \left[ \frac{h^3}{6}(f_{xx} + 2 f_{xy} f + f_{yy} f^2 + f_y f_x + f_y^2 f) \right] \\
&\quad - \left[ \frac{h^3}{4}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) \right] + O(h^4) \\
&= -\frac{h^3}{12}(f_{xx} + 2 f_{xy} f + f_{yy} f^2) + \frac{h^3}{6}(f_y f_x + f_y^2 f) + O(h^4)
\end{aligned}
$$

</span>

<p><strong>即两步欧拉公式具有 2 阶精度。</strong></p>
<h3 id="方法比较表"><a href="#方法比较表" class="headerlink" title="方法比较表"></a>方法比较表</h3><table>
<thead>
<tr>
<th>方法</th>
<th>局部截断误差</th>
<th>精度（阶）</th>
</tr>
</thead>
<tbody><tr>
<td>显式欧拉法</td>
<td>$\frac{h^2}{2} y’’(x_n) + O(h^3)$</td>
<td>1</td>
</tr>
<tr>
<td>隐式欧拉法</td>
<td>$-\frac{h^2}{2} y’’(x_n) + O(h^3)$</td>
<td>1</td>
</tr>
<tr>
<td>梯形公式</td>
<td>$-\frac{h^3}{12} y^{(3)}(x_n) + O(h^4)$</td>
<td>2</td>
</tr>
<tr>
<td>改进欧拉法</td>
<td>$O(h^3)$</td>
<td>2</td>
</tr>
</tbody></table>
<h2 id="龙格-库塔法"><a href="#龙格-库塔法" class="headerlink" title="龙格 - 库塔法"></a>龙格 - 库塔法</h2><h3 id="龙格-库塔法的基本思想"><a href="#龙格-库塔法的基本思想" class="headerlink" title="龙格 - 库塔法的基本思想"></a>龙格 - 库塔法的基本思想</h3><ul>
<li>建立高精度的单步逆推公式。</li>
</ul>
<p>单步逆推法的基本思想是从 $(x_n, y_n)$ 点出发，以某一斜率沿直线达到 $(x_{n+1}, y_{n+1})$ 点。欧拉法及其各种变形所能达到的最高精度为2阶。</p>
<p>考虑改进的欧拉法，可以将其改写为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + h \left[ \frac{1}{2} K_1 + \frac{1}{2} K_2 \right]<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + h, y_n + h K_1)<br>$$</p>
<p>当然，$K_1, K_2$ 是在点 $x_n, x_{n+1}$ 处的斜率。以上公式用到了两个点的斜率的加权平均，它为构造算法提供了新的途径。<strong>Runge-Kutta方法就是这种思想的体现和发展</strong>。</p>
<p><strong>将改进欧拉法推广为</strong><br>$$<br>y_{n+1} &#x3D; y_n + h[\lambda_1 K_1 + \lambda_2 K_2]<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + ph, y_n + phK_1)<br>$$</p>
<p>首先希望能够确定系数 $\lambda_1, \lambda_2, p$，使得到的算法公式有2阶精度，即在 $y_n &#x3D; y(x_n)$ 的前提假设下，使得</p>
<p>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; O(h^3)<br>$$</p>
<p><strong>Step 1</strong>: 将 $K_2$ 在 $(x_n, y_n)$ 点作 Taylor 展开<br>$$<br>K_2 &#x3D; f(x_n + ph, y_n + phK_1)<br>$$</p>
<blockquote>
<span>
$$
\begin{aligned}
f(x + \Delta x, y + \Delta y) &= f(x, y) \\
&\quad + \Delta x \cdot f_x + \Delta y \cdot f_y \\
&\quad + \frac{1}{2} \left( \Delta x^{2} f_{xx} + 2 \Delta x \Delta y f_{xy} + \Delta y^{2} f_{yy} \right) \\
&\quad + \frac{1}{6} \left( \Delta x^{3} f_{xxx} + 3 \Delta x^{2} \Delta y f_{xxy} + 3 \Delta x \Delta y^{2} f_{xyy} + \Delta y^{3} f_{yyy} \right) \\
&\quad + \frac{1}{24} \left( \Delta x^{4} f_{xxxx} + 4 \Delta x^{3} \Delta y f_{xxxy} + 6 \Delta x^{2} \Delta y^{2} f_{xxyy} + 4 \Delta x \Delta y^{3} f_{xyyy} + \Delta y^{4} f_{yyyy} \right) \\
&\quad + O(\Delta x^{5}, \Delta y^{5})
\end{aligned}
$$

</span>

</blockquote>
<p>$$<br>&#x3D; f(x_n, y_n) + phf_x(x_n, y_n) + phK_1 f_y(x_n, y_n) + O(h^2)<br>$$</p>
<blockquote>
<p>$$<br>y’’(x) &#x3D; \frac{d}{dx} f(x, y)&#x3D; f_x(x, y) + f_y(x, y) \frac{dy}{dx}&#x3D; f_x(x, y) + f_y(x, y) f(x, y)<br>$$</p>
</blockquote>
<p>$$<br>&#x3D; y’(x_n) + ph y’’(x_n) + O(h^2)<br>$$</p>
<p><strong>Step 2</strong>: 将 $K_2$ 代入第1式，得到<br>$$<br>y_{n+1} &#x3D; y_n + h \left( \lambda_1 y’(x_n) + \lambda_2 \left[ y’(x_n) + ph y’’(x_n) + O(h^2) \right] \right)<br>$$</p>
<p>$$<br>&#x3D; y_n + (\lambda_1 + \lambda_2) h y’(x_n) + \lambda_2 ph^2 y’’(x_n) + O(h^3)<br>$$</p>
<p><strong>Step 3</strong>: 将 $y_{n+1}$ 与 $y(x_{n+1})$ 在 $x_n$ 点的泰勒展开比较<br>$$<br>y_{n+1} &#x3D; y_n + (\lambda_1 + \lambda_2) h y’(x_n) + \lambda_2 ph^2 y’’(x_n) + O(h^3)<br>$$</p>
<p>$$<br>y(x_{n+1}) &#x3D; y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + O(h^3)<br>$$</p>
<p>要求 $T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; O(h^3)$，则必须有：</p>
<p>$$<br>\lambda_1 + \lambda_2 &#x3D; 1, \quad \lambda_2 p &#x3D; \frac{1}{2}<br>$$</p>
<p><strong>这里有3个未知数，2个方程</strong>。</p>
<p>存在无穷多个解。所有满足上述的格式系统称为2阶龙格-库塔格式。注意到，$p &#x3D; 1, \lambda_1 &#x3D; \lambda_2 &#x3D; \frac{1}{2}$ 就是改进的欧拉法。</p>
<h3 id="Runge-Kutta方法的一般形式"><a href="#Runge-Kutta方法的一般形式" class="headerlink" title="Runge-Kutta方法的一般形式"></a>Runge-Kutta方法的一般形式</h3><p>$$<br>y_{n+1} &#x3D; y_n + h \sum_{i&#x3D;1}^{L} \lambda_i k_i<br>$$</p>
<p>$$<br>k_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>k_2 &#x3D; f(x_n + c_2 h, y_n + c_2 h k_1)<br>$$</p>
<p>$$<br>k_3 &#x3D; f(x_n + c_3 h, y_n + c_3 h (a_{31} k_1 + a_{32} k_2))<br>$$</p>
<p>$$<br>\vdots<br>$$</p>
<p>$$<br>k_i &#x3D; f(x_n + c_i h, y_n + c_i h \sum_{j&#x3D;1}^{i-1} a_{ij} k_j) \quad i &#x3D; 2, 3, \dots, L<br>$$</p>
<p>其中，$\sum_{i&#x3D;1}^{L} \lambda_i &#x3D; 1, \quad c_i \leq 1, \quad \sum_{j&#x3D;1}^{i-1} a_{ij} &#x3D; 1$ 均为待定系数，确定这些系数的步骤与前面相似。</p>
<h3 id="二阶中点格式"><a href="#二阶中点格式" class="headerlink" title="二阶中点格式"></a>二阶中点格式</h3><p>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + h K_2 \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left( x_n + \frac{h}{2},\ y_n + \frac{h}{2} K_1 \right), \quad (n &#x3D; 0, 1, 2, \cdots)<br>\end{cases}<br>$$</p>
<h3 id="二阶休恩格式"><a href="#二阶休恩格式" class="headerlink" title="二阶休恩格式"></a>二阶休恩格式</h3><p>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + \frac{h}{4} \left( K_1 + 3K_2 \right) \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left( x_n + \frac{2}{3}h,\ y_n + \frac{2}{3}h K_1 \right), \quad (n &#x3D; 0, 1, 2, \cdots)<br>\end{cases}<br>$$</p>
<h3 id="四级4阶经典龙格-库塔法"><a href="#四级4阶经典龙格-库塔法" class="headerlink" title="四级4阶经典龙格-库塔法"></a>四级4阶经典龙格-库塔法</h3><p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} (K_1 + 2K_2 + 2K_3 + K_4)<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_1)<br>$$</p>
<p>$$<br>K_3 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_2)<br>$$</p>
<p>$$<br>K_4 &#x3D; f(x_n + h, y_n + h K_3)<br>$$</p>
<blockquote>
<p><strong>例题</strong><br>$$<br>y’&#x3D;y-\frac {2x}{y} \quad(0&lt;x&lt;1) \<br>y(0)&#x3D;1<br>$$<br><strong>解</strong>：对于本题，经典的四阶 Runge-Kutta 方法具有以下形式：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} \left( k_1 + 2k_2 + 2k_3 + k_4 \right)<br>$$</p>
<p>$$<br>k_1 &#x3D; y_n - \frac{2x_n}{y_n}<br>$$</p>
<p>$$<br>k_2 &#x3D; y_n + \frac{h}{2} k_1 - \frac{2x_n + h}{y_n + \frac{h}{2} k_1}<br>$$</p>
<p>$$<br>k_3 &#x3D; y_n + \frac{h}{2} k_2 - \frac{2x_n + h}{y_n + \frac{h}{2} k_2}<br>$$</p>
<p>$$<br>k_4 &#x3D; y_n + h k_3 - \frac{2(x_n + h)}{y_n + h k_3}<br>$$</p>
<p>这里，我们取步长 $h&#x3D;0.2$，下面是计算结果（符号的意义同前）：</p>
<table>
<thead>
<tr>
<th>$X_n$</th>
<th>$y_n$</th>
<th>$y(x_n)$</th>
</tr>
</thead>
<tbody><tr>
<td>0.2</td>
<td>1.1832</td>
<td>1.1832</td>
</tr>
<tr>
<td>0.4</td>
<td>1.3417</td>
<td>1.3416</td>
</tr>
<tr>
<td>0.6</td>
<td>1.4833</td>
<td>1.4832</td>
</tr>
<tr>
<td>0.8</td>
<td>1.6125</td>
<td>1.6125</td>
</tr>
<tr>
<td>1.0</td>
<td>1.7321</td>
<td>1.7321</td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<p><strong>注</strong>:<br>龙格-库塔法的主要运算是在计算 $K_i$ 的值，即计算 $f$ 的值。Butcher 于 1965 年给出了计算量与可达到的最高精度阶数的关系：</p>
<table>
<thead>
<tr>
<th>每步须计算 $K_i$ 的个数</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>$n \geq 8$</th>
</tr>
</thead>
<tbody><tr>
<td>可达到的最高精度</td>
<td>$O(h^2)$</td>
<td>$O(h^3)$</td>
<td>$O(h^4)$</td>
<td>$O(h^4)$</td>
<td>$O(h^5)$</td>
<td>$O(h^6)$</td>
<td>$O(h^{n-2})$</td>
</tr>
</tbody></table>
<p>由于龙格-库塔法的导出基于泰勒展开，故精度主要受解函数的光滑性影响。对于光滑性不太好的解，最好采用低阶方法而将步长 $h$ 取小。</p>
</blockquote>
<blockquote>
<p><strong>【题 1】（北京理工大学 2006 年）</strong></p>
<p><strong>考查初值问题</strong></p>
<span>
$$
\begin{cases}
y' = x^4, \quad x > 0 \\
y(0) = 1
\end{cases} \quad \text{①}
$$

</span>

<p>其准确解为 $y(x) &#x3D; 1 + \frac{x^5}{5}$。记 $x_i &#x3D; ih$, $i &#x3D; 0, 1, 2, \cdots$，设 ${y_i}_{i&#x3D;0}^\infty$ 为用经典 Runge-Kutta 公式所得近似解，证明：<br>$$<br>y(x_i) - y_i &#x3D; -\frac{x_i}{120}h^4, \quad i &#x3D; 0, 1, 2, \cdots \quad \text{②}<br>$$</p>
<hr>
<p><strong>解题过程</strong></p>
<p>求解 ① 的 Runge-Kutta 公式为：</p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + \frac{h}{6}(K_1 + 2K_2 + 2K_3 + K_4) \\
K_1 = f(x_i, y_i) = x_i^4 \\
K_2 = f\left(x_i + \frac{h}{2},\ y_i + \frac{1}{2}hK_1\right) = \left(x_i + \frac{h}{2} \right)^4 \\
K_3 = f\left(x_i + \frac{h}{2},\ y_i + \frac{1}{2}hK_2\right) = \left(x_i + \frac{h}{2} \right)^4 \\
K_4 = f(x_i + h, y_i + hK_3) = (x_i + h)^4 \\
y_0 = 1
\end{cases}
$$

</span>

<p>因此：<br>$$<br>y_{i+1} &#x3D; y_i + \frac{h}{6} \left[ x_i^4 + 2\left(x_i + \frac{h}{2}\right)^4 + 2\left(x_i + \frac{h}{2}\right)^4 + (x_i + h)^4 \right]<br>$$</p>
<blockquote>
<p>$$<br>(a + b)^n &#x3D; \sum_{k&#x3D;0}^{n} C_n^k a^{n-k} b^k<br>$$</p>
<p>$$<br>(a + b)^4 &#x3D; a^4 + 4a^3b + 6a^2b^2 + 4ab^3 + b^4<br>$$</p>
</blockquote>
<p>展开得：</p>
<p>$$<br>&#x3D; y_i + h \left(x_i^4 + 2x_i^3 h + 2x_i^2 h^2 + x_i h^3 + \frac{5}{24} h^4 \right) \quad \text{③}<br>$$</p>
<hr>
<p>另一方面：</p>
<p>$$<br>y(x_{i+1}) &#x3D; 1 + \frac{1}{5}x_{i+1}^5 &#x3D; 1 + \frac{1}{5}(x_i + h)^5<br>$$</p>
<p>展开：</p>
<p>$$<br>&#x3D; 1 + \frac{1}{5} \left[ x_i^5 + 5x_i^4 h + 10x_i^3 h^2 + 10x_i^2 h^3 + 5x_i h^4 + h^5 \right] \<br>&#x3D; y(x_i) + x_i^4 h + 2x_i^3 h^2 + 2x_i^2 h^3 + x_i h^4 + \frac{1}{5} h^5 \quad \text{④}<br>$$</p>
<hr>
<p>将③和④相减，得：</p>
<p>$$<br>y(x_{i+1}) - y_{i+1} &#x3D; y(x_i) - y_i + \frac{1}{5}h^5 - \frac{5}{24}h^5 \<br>&#x3D; y(x_i) - y_i - \frac{1}{120}h^5<br>$$</p>
<span>
$$
\begin{cases}
y(x_i) - y_i  = y(x_{i-1}) - y_{i-1} - \frac{1}{120}h^5 \\
y(x_{i-1}) - y_{i-1}=y(x_{i-2}) - y_{i-2}- \frac{1}{120}h^5\\
\vdots \vdots  \\
 y(x_{1}) - y_{1}= y(x_{0}) - y_{0}- \frac{1}{120}h^5
\end{cases}
$$

</span>

<p>上式相加整理得：<br>$$<br>y(x_i) - y_i &#x3D; - \frac{1}{120}h^5 \cdot i &#x3D; -\frac{x_i}{120}h^4<br>$$</p>
<p>因此最终结果为：</p>
<p>$$<br>\boxed{y(x_i) - y_i &#x3D; -\frac{x_i}{120}h^4}, \quad i &#x3D; 0, 1, 2, \cdots<br>$$</p>
</blockquote>
<h2 id="收敛性与稳定性"><a href="#收敛性与稳定性" class="headerlink" title="收敛性与稳定性"></a>收敛性与稳定性</h2><h3 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a>收敛性</h3><p><strong>定义</strong><br>若某算法对于任意固定的 $x &#x3D; x_n &#x3D; x_0 + n h$，当 $h \to 0$（同时 $n \to \infty$）时有 $y_n \to y(x_n)$，则称该算法是<strong>收敛</strong>的。</p>
<p><strong>例</strong>: 就初值问题<br>$$<br>y’ &#x3D; \lambda y<br>$$</p>
<p>$$<br>y(0) &#x3D; y_0<br>$$</p>
<p>考察欧拉显式格式的收敛性.</p>
<p><strong>解</strong>: 该问题的精确解为<br>$$<br>y(x) &#x3D; y_0 e^{\lambda x}<br>$$</p>
<p>欧拉公式为<br>$$<br>y_{n+1} &#x3D; y_n + h \lambda y_n &#x3D; (1 + \lambda h) y_n<br>\Rightarrow y_n &#x3D; (1 + \lambda h)^n y_0<br>$$</p>
<p>对于任意固定的 $x &#x3D; x_n &#x3D; n h$，有<br>$$<br>y_n &#x3D; y_0 (1 + \lambda h)^n &#x3D; y_0 \left[(1 + \lambda h)^{\frac{1}{\lambda h}}\right]^{\lambda x_n}<br>\Rightarrow y_0 e^{\lambda x_n} &#x3D; y(x_n) \checkmark<br>$$<br><strong>定理</strong><br>对于一个 $p$ 阶的显式单步法，若满足以下条件：</p>
<ol>
<li>增量函数 $\Phi$ 关于 $y$ 满足 Lipschitz 条件，即存在常数 $L_\varphi &gt; 0$，使得<br>$$<br>|\varphi(x, y, h) - \varphi(x, \bar{y}, h)| \leq L_\varphi |y - \bar{y}|, \quad \forall y, \bar{y} \in \mathbb{R}<br>$$</li>
<li>微分方程的初值是准确的，<br>则该方法收敛，其<strong>整体</strong>截断误差为：<br>$$<br>|e_n| &#x3D; |y(x_n) - y_n| &#x3D; O(h^p).<br>$$</li>
</ol>
<p><strong>注</strong>:</p>
<ol>
<li>判定显式单步格式的收敛性，归结为验证增量函数 $\Phi$ 是否满足 Lipschitz 条件。</li>
<li><strong>单步格式的整体截断误差</strong>差由<strong>初值误差</strong>及<strong>局部截断误差</strong>决定，整体截断误差比局部截断误差的阶数<strong>低一阶</strong>。</li>
<li>要构造高精度的计算方法，只需设计提高局部截断误差的阶即可。</li>
</ol>
<h3 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h3><p><strong>定义</strong><br>若某算法在计算过程中任一步产生的误差在以后的计算中都<strong>逐步衰减</strong>，则称该算法是<strong>绝对稳定的</strong> 。</p>
<p>一般分析时为简便起见，只考虑<strong>试验方程</strong>：</p>
<p>$$<br>y’ &#x3D; \lambda y \quad \text{Re}(\lambda) &lt; 0<br>$$</p>
<p>若得到的解<br>$y_{n+1} &#x3D; E(h\lambda) y_n$，满足 $|E(h\lambda)| &lt; 1$，则称该方法是<strong>绝对稳定</strong>的。<br>在 $\mu &#x3D; h\lambda$ 平面上，使 $|E(h\lambda)| &lt; 1$ 的区域称为<strong>绝对稳定域</strong>，<br>它与实轴的交称为<strong>绝对稳定区间</strong>。<span style="color:blue">（求$\lambda h$的取值范围，即$h$的取值范围）</span></p>
<blockquote>
<p><strong>一阶线性微分方程的通解</strong></p>
<p>一阶线性微分方程的标准形式为：</p>
<p>$$<br>\frac{dy}{dx} + P(x)y &#x3D; Q(x)<br>$$</p>
<p>其中，$ P(x) $ 和 $ Q(x) $ 是已知函数。</p>
<p>$$<br>y &#x3D; e^{-\int P(x) dx} \left( \int Q(x) e^{\int P(x) dx} dx + C \right)<br>$$</p>
</blockquote>
<hr>
<h4 id="欧拉法"><a href="#欧拉法" class="headerlink" title="欧拉法"></a>欧拉法</h4><p><strong>例：</strong> </p>
<p>对<strong>欧拉法</strong>有<br>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n) &#x3D; y_n + \lambda h y_n &#x3D; (1 + \lambda h) y_n,<br>$$<br>$$<br>\Rightarrow \text{稳定区间为 } -2 &lt; \lambda h &lt; 0。<br>$$</p>
<p>当 $\lambda &#x3D; -100$ 时，$0 &lt; h &lt; \frac{2}{100} &#x3D; 0.02$，<br>例如 $h &#x3D; 0.025$ 不稳定，$h &#x3D; 0.005$ 稳定</p>
<hr>
<h4 id="隐式欧拉法-1"><a href="#隐式欧拉法-1" class="headerlink" title="隐式欧拉法"></a>隐式欧拉法</h4><p><strong>例：</strong> </p>
<p>考察隐式欧拉法<br>$$<br>y_{i+1} &#x3D; y_i + h\lambda y_{i+1}<br>$$</p>
<p>解得：<br>$$<br>y_{i+1} &#x3D; \left(\frac{1}{1 - \lambda h}\right) y_i<br>$$</p>
<p>可见绝对稳定区域为：<br>$$<br>|1 - \lambda h| &gt; 1<br>$$</p>
<p>绝对稳定区间为 $-\infty &lt; \lambda h &lt; 0$。</p>
<p>当 $\lambda &lt; 0$ 时，$0 &lt; h &lt; \infty$，即对任何步长稳定。</p>
<blockquote>
<p><strong>注：</strong> 一般来说，隐式欧拉法的绝对稳定性比同阶的显式法的好。</p>
</blockquote>
<hr>
<h4 id="改进欧拉法-1"><a href="#改进欧拉法-1" class="headerlink" title="改进欧拉法"></a>改进欧拉法</h4><p><strong>例</strong></p>
<p>改进欧拉法（预测—校正，即二阶 $R-K$ 法）：<br>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + h \left( \frac{k_1}{2} + \frac{k_2}{2} \right), \<br>k_1 &#x3D; f(x_n, y_n) &#x3D; \lambda y_n, \<br>k_2 &#x3D; f(x_n + h, y_n + h k_1) &#x3D; \lambda (y_n + h \lambda y_n),<br>\end{cases}<br>$$</p>
<p>即：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h\lambda}{2} \left( y_n + (y_n + h\lambda y_n) \right)<br>&#x3D; \left( 1 + h\lambda + \frac{(h\lambda)^2}{2} \right) y_n.<br>$$</p>
<p>故：</p>
<p>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2}.<br>$$</p>
<p>$$<br>\left| 1 + h\lambda + \frac{(h\lambda)^2}{2} \right| &lt; 1<br>\Leftrightarrow -2 &lt; 2 + 2h\lambda + (h\lambda)^2 &lt; 2<br>$$</p>
<p>$$<br>\Leftrightarrow -2 &lt; 1 + (1 + h\lambda)^2 &lt; 2<br>\Leftrightarrow |1 + h\lambda| &lt; 1 \Leftrightarrow -2 &lt; h\lambda &lt; 0.<br>$$</p>
<hr>
<h4 id="梯形方法"><a href="#梯形方法" class="headerlink" title="梯形方法"></a>梯形方法</h4><p><strong>例</strong></p>
<p>梯形方法：对模型方程 $y’ &#x3D; \lambda y$ 使用梯形法（隐式中点法）</p>
<p>其更新格式为：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_{n+1}) \right]<br>$$</p>
<p>代入模型方程得：</p>
<p>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ \lambda y_n + \lambda y_{n+1} \right]<br>&#x3D; y_n + \frac{h\lambda}{2} (y_n + y_{n+1})<br>$$</p>
<p>将 $y_{n+1}$ 移项整理：</p>
<p>$$<br>y_{n+1} - \frac{h\lambda}{2} y_{n+1} &#x3D; y_n + \frac{h\lambda}{2} y_n<br>\Rightarrow \left( 1 - \frac{h\lambda}{2} \right) y_{n+1} &#x3D; \left( 1 + \frac{h\lambda}{2} \right) y_n<br>$$</p>
<p>因此，得到递推公式：</p>
<p>$$<br>y_{n+1} &#x3D; \frac{1 + \frac{h\lambda}{2}}{1 - \frac{h\lambda}{2}} y_n<br>$$</p>
<p>于是</p>
<p>$$<br>E(h\lambda) &#x3D; \frac{1 + \frac{h\lambda}{2}}{1 - \frac{h\lambda}{2}}<br>$$</p>
<p>只要 $\operatorname{Re}(\lambda) &lt; 0$，则：</p>
<p>$$<br>\left|E(h\lambda)\right| &lt; 1<br>$$</p>
<ul>
<li>绝对稳定域为 $\mu &#x3D; h\lambda$ 的左半平面， </li>
<li>绝对稳定区间为 $-\infty &lt; \lambda h &lt; 0$，即 $0 &lt; h &lt; \infty$ 时梯形法均是稳定的。</li>
</ul>
<hr>
<h4 id="三阶、四阶-R-K-法"><a href="#三阶、四阶-R-K-法" class="headerlink" title="三阶、四阶 $R-K$ 法"></a>三阶、四阶 $R-K$ 法</h4><p><strong>例</strong></p>
<p>三阶、四阶 $R-K$ 法分别有：<br>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!},<br>$$</p>
<p>$$<br>E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!} + \frac{(h\lambda)^4}{4!}.<br>$$</p>
<p>由 $|E(h\lambda)| &lt; 1$，当 $\lambda$ 为实数时，得绝对稳定区间分别为：</p>
<p><span style="color:blue">三阶显式 $R-K$ 法：$-2.51 &lt; h\lambda &lt; 0$，即 $0 &lt; h &lt; -2.51 &#x2F; \lambda$</span></p>
<p><span style="color:blue">四阶显式 $R-K$ 法：$-2.78 &lt; h\lambda &lt; 0$，即 $0 &lt; h &lt; -2.78 &#x2F; \lambda$</span></p>
<hr>
<h4 id="中点公式"><a href="#中点公式" class="headerlink" title="中点公式"></a>中点公式</h4><p>证明中点公式<br>$$<br>\begin{cases}<br>y_{n+1} &#x3D; y_n + hK_2 \<br>K_1 &#x3D; f(x_n, y_n) \<br>K_2 &#x3D; f\left(x_n + \frac{h}{2}, y_n + \frac{h}{2}K_1\right)<br>\end{cases}<br>$$</p>
<p>是二阶的，并求其绝对稳定区间。</p>
<p><strong>分析</strong>　本题考查了中点公式及其绝对稳定区间。</p>
<p><strong>解</strong><br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y(x_n) - h f\left(x_n + \frac{h}{2}, y(x_n) + \frac{h}{2} y’(x_n)\right)<br>$$</p>
<p>$$<br>&#x3D; y(x_n) + h y’(x_n) + \frac{h^2}{2} y’’(x_n) + \frac{1}{3!} h^3 y^{(3)}(x_n) + O(h^4)<br>$$</p>
<p>$$<br>&#x3D; y(x_n) + h ( f(x_n, y(x_n)) + \frac{h}{2} \frac{\partial f(x_n, y(x_n))}{\partial x}<br>$$</p>
<p>$$<br>+\frac{h}{2} y’(x_n) \frac{\partial f(x_n, y(x_n))}{\partial y}<br>$$</p>
<p>$$<br>+\frac{1}{2!} \left[ \frac{h}{2} \right]^2 \frac{\partial^2 f(x_n, y(x_n))}{\partial x^2}<br>$$</p>
<p>$$<br>+\frac{h}{2} \cdot \frac{h}{2} y’(x_n) \frac{\partial^2 f(x_n, y(x_n))}{\partial x \partial y}<br>$$</p>
<p>$$<br>+\left( \frac{h}{2} y’(x_n) \right)^2 \frac{\partial^2 f(x_n, y(x_n))}{\partial y^2} + O(h^3) )<br>$$</p>
<p>$$<br>&#x3D; \frac{h^3}{3!} y^{(3)}(x_n) - \frac{h^3}{8} \left[ \frac{\partial^2 f}{\partial x^2} +2 y’(x) \frac{\partial^2 f}{\partial x \partial y}<br>+(y’(x))^2 \frac{\partial^2 f}{\partial y^2} \right]_{(x_n, y(x_n))} + O(h^4) &#x3D; O(h^3)<br>$$</p>
<p>因此，中点公式是二阶的。</p>
<p>对模型方程 $y’ &#x3D; \lambda y\ ( \operatorname{Re}(\lambda) &lt; 0 )$ 使用中点公式求解，得：</p>
<p>$$<br>y_{n+1} &#x3D; \left[ 1 + \lambda h + \frac{1}{2} (\lambda h)^2 \right] y_n<br>$$</p>
<p>易知，当<br>$$<br>\left| 1 + \lambda h + \frac{1}{2} (\lambda h)^2 \right| &lt;1<br>$$<br>时，中点公式绝对稳定。特别当 $\lambda$ 为实数且 $\lambda &lt; 0$ 时，上不等式的解为：</p>
<p>$$<br>-2 &lt; \lambda h &lt; 0<br>$$</p>
<hr>
<h4 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h4><p> 对于初值问题<br>$$<br>y’ &#x3D; -100(y - x^2) + 2x, \quad y(0) &#x3D; 1.<br>$$</p>
<p>(1) 用欧拉法求解，步长 $h$ 取什么范围的值，才能使计算稳定。  </p>
<p>(2) 若用四阶龙格–库塔方法计算，步长 $h$ 如何选取？<br>(3) 若用梯形公式计算，步长 $h$ 有无限制。</p>
<p><strong>解</strong></p>
<p>(1) 原方程为<br>$$<br>y’ &#x3D; -100y+100x^2+2x<br>$$</p>
<p>稳定性分析主要关注<strong>齐次方程</strong>部分$y’ &#x3D; -100y$</p>
<p>用欧拉法求解题中初值问题，递推公式为<br>$$<br>y_{n+1}&#x3D;y_n+hf(x_n,y_n)&#x3D;y_n+h(-100y_n)&#x3D;(1-100h)y_n<br>$$</p>
<p>故当<br>$$<br>|1 + (-100h)| \leq 1<br>$$</p>
<p>时绝对稳定，即当 $0 &lt; h \leq 0.02$ 时欧拉法绝对稳定。</p>
<hr>
<p>(2) 当 $\lambda h &#x3D; -100h$ 满足不等式</p>
<p>$$<br>\left| 1 + \lambda h + \frac{1}{2}(\lambda h)^2 + \frac{1}{3!}(\lambda h)^3 + \frac{1}{4!}(\lambda h)^4 \right| \leq 1<br>$$</p>
<p>时，四阶龙格–库塔法绝对稳定，也即当 $\lambda h$ 满足</p>
<p>$$<br>-2.785 \leq \lambda h &lt; 0, \quad 0 &lt; h \leq \frac{-2.785}{\lambda} &#x3D; \frac{2.785}{100} &#x3D; 0.02785<br>$$</p>
<p>时绝对稳定。</p>
<p>(3) 对于梯形公式，当 $\lambda h &#x3D; -100h \in (-\infty, 0)$ 时，绝对稳定，<br>此条件 $\forall h \in (0, +\infty)$ 都成立，即梯形法对 $h$ 无限制。</p>
<hr>
<p><strong>例：</strong> 隐式龙格-库塔法  </p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + h[\lambda_1 K_1 + \cdots + \lambda_m K_m] \\
K_j = f\left(x_i + \alpha_j h, y_i + \beta_{j1} h K_1 + \cdots + \beta_{jm} h K_m \right), \quad (j = 1, \ldots, m)
\end{cases}
$$

</span>

<p>其中 <strong>2 阶方法</strong>：</p>
<span>
$$
\begin{cases}
y_{i+1} = y_i + h K_1 \\
K_1 = f\left(x_i + \frac{h}{2}, y_i + \frac{h}{2} K_1\right)
\end{cases}
$$

</span>

<p>该方法的<strong>绝对稳定区域</strong>为图中左侧阴影区域（无条件稳定）。</p>
<p><img src="/blog/image/Snipaste_2025-04-28_15-16-58.png"></p>
<p>而<strong>显式 1～4 阶方法</strong>的绝对稳定区域如下图所示（随阶数增加扩大但仍有限）：</p>
<p><img src="/blog/image/Snipaste_2025-04-28_15-17-09.png"></p>
<p>图示区域说明：</p>
<ul>
<li>$k&#x3D;1$ 到 $k&#x3D;4$ 分别表示显式龙格-库塔法从一阶到四阶的稳定区域</li>
</ul>
<h2 id="线性多步法"><a href="#线性多步法" class="headerlink" title="线性多步法"></a>线性多步法</h2><p>用<strong>若干</strong>节点处的 $y$ 及 $y’$ 值的<strong>线性组合</strong>来近似 $y(x_{n+1})$。其通式可写为：</p>
<p>$$<br>y_{n+1} &#x3D; \alpha_0 y_n + \alpha_1 y_{n-1} + \dots + \alpha_k y_{n-k} + h\left( \beta_{-1} f_{n+1} + \beta_0 f_n + \beta_1 f_{n-1} + \dots + \beta_k f_{n-k} \right)<br>$$</p>
<ul>
<li><p>当$\beta_{-1} \neq 0$时，为隐式公式</p>
</li>
<li><p>当$\beta_{-1} &#x3D; 0$时，为显式公式</p>
</li>
</ul>
<h3 id="基于数值积分的构造法"><a href="#基于数值积分的构造法" class="headerlink" title="基于数值积分的构造法"></a>基于数值积分的构造法</h3><p>将 $y’ &#x3D; f(x, y)$ 在 $[x_n, x_{n+1}]$ 上积分，得到：</p>
<p>$$<br>y(x_{n+1}) - y(x_n) &#x3D; \int_{x_n}^{x_{n+1}} f(x, y(x)) , dx<br>$$</p>
<p>只要<strong>近似地算出右边的积分</strong> $I_n \approx \int_{x_n}^{x_{n+1}} f(x, y(x)) , dx$，则可通过<br>$$<br>y_{n+1} &#x3D; y_n + I_n<br>$$<br>近似 $y(x_{n+1})$。而<strong>选用不同近似式 $I_n$</strong>，可得到不同的计算公式。</p>
<h3 id="亚当姆斯显式公式"><a href="#亚当姆斯显式公式" class="headerlink" title="亚当姆斯显式公式"></a>亚当姆斯显式公式</h3><p>利用 $k+1$ 个节点上的被积函数值 $f_n, f_{n-1}, \ldots, f_{n-k}$ 构造 $k$ 阶牛顿<strong>后插多项式</strong> $N_k(x_n + th)$，$t \in [0,1]$，有：</p>
<p>$$<br>\int_{x_n}^{x_{n+1}} f(x, y(x)) dx &#x3D; \int_0^1 N_k(x_n + th) h , dt + \int_0^1 R_k(x_n + th) h , dt<br>$$</p>
<p>从而得<strong>显式计算公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + h \int_0^1 N_k(x_n + th) , dt<br>$$</p>
<p>局部截断误差为：<br>$$<br>T_{n+1} &#x3D; y(x_{n+1}) - y_{n+1} &#x3D; h \int_0^1 R_k(x_n + th) , dt<br>$$</p>
<hr>
<p><strong>例：</strong> 当 $k &#x3D; 1$ 时，有<br>$$<br>N_1(x_n + th) &#x3D; f_n + t \nabla f_n &#x3D; f_n + t(f_n - f_{n-1})<br>$$</p>
<p>代入得：<br>$$<br>y_{n+1} &#x3D; y_n + h \int_0^1 [f_n + t(f_n - f_{n-1})] dt &#x3D; y_n + \frac{h}{2} (3f_n - f_{n-1})<br>$$</p>
<p>局部截断误差为：<br>$$<br>T_{n+1} &#x3D; h \int_0^1  \frac{d^2}{dx^2} f(\xi_x, y(\xi_x)) \cdot \frac{1}{2!} th(t+1) h , dt &#x3D; \frac{5}{12} h^3 y’’’(\xi_n)<br>$$</p>
<hr>
<p><strong>注：</strong> 一般有<br>$$<br>T_{n+1} &#x3D; B_k h^{k+2} y^{(k+2)} (\xi_n)<br>$$<br>其中 $B_k$ 与 $y_{n+1}$ 计算公式中的系数 $f_n, f_{n-1}, \dots, f_{n-k}$ 各项的系数均可表示得到。</p>
<table>
<thead>
<tr>
<th>k</th>
<th>$f_n$</th>
<th>$f_{n-1}$</th>
<th>$f_{n-2}$</th>
<th>$f_{n-3}$</th>
<th>…</th>
<th>$B_k$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1</td>
<td></td>
<td></td>
<td></td>
<td>…</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>$\frac{3}{2}$</td>
<td>$-\frac{1}{2}$</td>
<td></td>
<td></td>
<td>…</td>
<td>$\frac{1}{2}$</td>
</tr>
<tr>
<td>2</td>
<td>$\frac{23}{12}$</td>
<td>$-\frac{16}{12}$</td>
<td>$\frac{5}{12}$</td>
<td></td>
<td>…</td>
<td>$\frac{5}{12}$</td>
</tr>
<tr>
<td>3</td>
<td>$\frac{55}{24}$</td>
<td>$-\frac{59}{24}$</td>
<td>$\frac{37}{24}$</td>
<td>$-\frac{9}{24}$</td>
<td>…</td>
<td>$\frac{251}{720}$</td>
</tr>
</tbody></table>
<hr>
<p><strong>常用的</strong> $k &#x3D; 3$ <strong>的 4 阶亚当姆斯显式公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{24} \left( 55 f_n - 59 f_{n-1} + 37 f_{n-2} - 9 f_{n-3} \right)<br>$$<br><strong>常用的</strong> $k &#x3D; 3$ <strong>的 4 阶亚当姆斯隐式公式</strong>：<br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{24} \left( 9 f_{n+1} + 19 f_n - 5 f_{n-1} + f_{n-2} \right)<br>$$</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
  </entry>
  <entry>
    <title>数值分析-非线性方程求根</title>
    <url>/blog/2025/03/26/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E6%B1%82%E6%A0%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文章包含非线性方程组求根部分—————————————————————————————————————————————————————-</p>
<h1 id="第七章-非线性方程求根"><a href="#第七章-非线性方程求根" class="headerlink" title="第七章 非线性方程求根"></a>第七章 非线性方程求根</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>求 f(x) &#x3D; 0 的根</strong></p>
<ul>
<li>数学物理中的许多问题常常归结为解函数方程 f(x) &#x3D; 0，方程 f(x) &#x3D; 0 的解 x* 称作它的根，或称为 f(x) 的零点。</li>
<li>设函数 f(x) 在 [a,b] 上连续且 f(a)f(b) &lt; 0，根据连续函数的性质可知方程 f(x) &#x3D; 0 在区间 [a,b] 内一定有实根，这时称 (a,b) 为方程 f(x) &#x3D; 0 的有根区间。</li>
</ul>
<h2 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h2><ul>
<li>二分法的思想是将有根区间折半进行搜索，即对有根区间 $[a, b]$，取中点 $x_1 &#x3D; \frac{a + b}{2}$ 将它分为两半，检查 $f(a)$ 与 $f(x)$ 是否同号，如果确系同号，说明所求的根在 $[x_1, b]$ ；否则根必在 $[a, x_1]$<br>不管出现哪一种情况，新的有根区间仅为原来的一半。</li>
</ul>
<h3 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h3><ul>
<li>第1步产生的 $x_1 &#x3D; \frac{a + b}{2}$ 有误差 $|x_1 - x^*| \leq \frac{b - a}{2}$  </li>
<li>第 $k$ 步产生的 $x_k$ 有误差 $|x_k - x^*| \leq \frac{b - a}{2^k}$</li>
</ul>
<p>对于给定的精度 $\epsilon$，可估计二分法所需的步数 $k$：<br>$$<br>\frac{b - a}{2^k} &lt; \epsilon \Rightarrow k &gt; \left[\frac{\ln(b - a) - \ln \epsilon}{\ln 2}\right]<br>$$</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li>简单</li>
<li>对 $f(x)$ 要求不高（只要连续即可）。</li>
</ol>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li>无法求复根及偶重根。</li>
<li>收敛慢。</li>
</ol>
<blockquote>
<p>注：用二分法求根，最好先给出 $f(x)$ 草图以确定根的大概位置。或用搜索程序，将 $[a, b]$ 分为若干小区间，对每一个满足 $f(a_k) \cdot f(b_k) &lt; 0$ 的区间调用二分法程序，可找出区间 $[a, b]$ 内的多个根，且不必要求 $f(a) \cdot f(b) &lt; 0$。</p>
</blockquote>
<hr>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>求方程 $f(x) &#x3D; x^3 - x - 1 &#x3D; 0$ 在 $[1.0, 1.5]$ 区间内的一个实根，要求准确到小数点后的第2位。</p>
<p><strong>解</strong></p>
<p>二分法过程解题过程见下表：</p>
<p>(这里 $a &#x3D; 1.0$, $f(a) &lt; 0$；  $b &#x3D; 1.5$, $f(b) &gt; 0$)</p>
<table>
<thead>
<tr>
<th>$k$</th>
<th>$a_k$</th>
<th>$b_k$</th>
<th align="center">$x_k$</th>
<th>$f(x_k)$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1.0</td>
<td>1.5</td>
<td align="center">1.25</td>
<td>-</td>
</tr>
<tr>
<td>1</td>
<td>1.25</td>
<td>1.5</td>
<td align="center">1.375</td>
<td>+</td>
</tr>
<tr>
<td>2</td>
<td>1.25</td>
<td>1.375</td>
<td align="center">1.3125</td>
<td>-</td>
</tr>
<tr>
<td>3</td>
<td>1.3125</td>
<td>1.375</td>
<td align="center">1.3438</td>
<td>+</td>
</tr>
<tr>
<td>4</td>
<td>1.3125</td>
<td>1.3438</td>
<td align="center">1.3281</td>
<td>+</td>
</tr>
<tr>
<td>5</td>
<td>1.3125</td>
<td>1.3281</td>
<td align="center">1.3203</td>
<td>-</td>
</tr>
<tr>
<td>6</td>
<td>1.3203</td>
<td>1.3281</td>
<td align="center">1.3242</td>
<td>-</td>
</tr>
</tbody></table>
<h2 id="简单迭代法"><a href="#简单迭代法" class="headerlink" title="简单迭代法"></a>简单迭代法</h2><h3 id="等价变换"><a href="#等价变换" class="headerlink" title="等价变换"></a>等价变换</h3><p>$$<br>f(x) &#x3D; 0 \quad \longleftrightarrow \quad x &#x3D; \varphi(x)<br>$$<br>$$<br>f(x) &#x3D; 0 \text{ 的根} \quad \longleftrightarrow \quad \varphi(x) \text{ 的不动点}<br>$$</p>
<p>从一个初值 $x_0$ 出发，计算 $x_1 &#x3D; \varphi(x_0)$, $x_2 &#x3D; \varphi(x_1)$, …,<br>若 $ {x_k }_{k&#x3D;0}^{\infty}$ 收敛，即存在 $x^* $ 使得<br>$$<br>\lim _{k \to \infty} x_k &#x3D; x^*<br>$$</p>
<p>且 $\varphi$ 连续，则由<br>$$<br>\lim_{k \to \infty} x_{k+1} &#x3D; \lim_{k \to \infty} \varphi(x_k)<br>$$<br>可知 $x^*  &#x3D; \varphi(x^* )$，即 $x^*$ 是 $\varphi$ 的不动点，也就是 $f &#x3D; 0$ 的根。</p>
<blockquote>
<p>迭代法是一种逐次逼近法，其基本思想是将隐式方程归结为一组显式的计算公式，即说，迭代过程实际上是一个逐步显示化的过程。</p>
</blockquote>
<hr>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>设 $f(x) &#x3D; x^3 + 4x^2 - 10 &#x3D; 0$ （此方程在 $[1, 2]$ 中有唯一根），用不同的方法将它变换成等价的方程。</p>
<p><strong>解</strong>：</p>
<p>(1) $x &#x3D; \varphi_1(x) &#x3D; x - x^3 - 4x^2 + 10$<br>(2) $x &#x3D; \varphi_2(x) &#x3D; \left(\frac{10}{x }-4x\right)^{\frac{1}{2}}$<br>(3) $x &#x3D; \varphi_3(x) &#x3D; \frac{1}{2} \left(10 - x^3\right)^{\frac{1}{2}}$<br>(4) $x &#x3D; \varphi_4(x) &#x3D; \left(\frac{10}{4 + x}\right)^{\frac{1}{2}}$<br>(5) $x &#x3D; \varphi_5(x) &#x3D; x - \frac{x^3 + 4x^2 - 10}{3x^2 + 8x}$</p>
<p>对所选取的 $\varphi_i(x)$ ($i&#x3D;1, 2, 3, 4, 5$) 迭代法计算结果列入下表（取初始近似值 $x_0 &#x3D; 1.5$）</p>
<p><img src="/blog/image/Snipaste_2025-04-16_14-40-28.png"></p>
<h2 id="迭代法收敛定理"><a href="#迭代法收敛定理" class="headerlink" title="迭代法收敛定理"></a>迭代法收敛定理</h2><blockquote>
<p><strong>定理1</strong> 如果迭代函数 $\varphi(x) \in C[a,b]$，并且  </p>
<ol>
<li>$\forall x \in [a,b]$，都有 $\varphi(x) \in [a,b]$，  </li>
<li>$\exists 0 \leq \text{常数 } L &lt; 1$，使得 $\forall x,y \in [a,b]$，都有<br>$$<br>  |\varphi(x) - \varphi(y)| \leq L |x - y|;<br>$$</li>
</ol>
<p>那么 $\varphi(x)$ 在 $[a,b]$ 上存在唯一的不动点 $x^*$。</p>
<p><strong>定理2</strong> 考虑方程 $x &#x3D; \varphi(x)$, $\varphi(x) \in C^1[a, b]$，若：</p>
<p>(I) 当 $x \in [a, b]$ 时，$\varphi(x) \in [a, b]$；</p>
<p>(II) 存在$0 \leq L &lt; 1$，使得 $|\varphi’(x)| \leq L &lt; 1$ 对 $\forall x \in [a, b]$ 成立。</p>
<p>则任取 $x_0 \in [a, b]$，由 $x_{k+1} &#x3D; \varphi(x_k)$ 得到的序列 ${x_k}_{k&#x3D;0}^{\infty}$ 收敛于 $\varphi(x)$ 在 $[a, b]$ 上的<strong>唯一</strong>不动点，并且有误差估计式：</p>
<p>$$<br>|x^* - x_k| \leq \frac{1}{1 - L} |x_{k+1} - x_k|<br>$$</p>
<p>$$<br>|x^* - x_k| \leq \frac{L^k}{1 - L} |x_1 - x_0| \quad (k &#x3D; 1, 2, \dots)<br>$$</p>
<p>并且存在极限：</p>
<p>$$<br>\lim_{k \to \infty} \frac{x^* - x_{k+1}}{x^* - x_k} &#x3D; \varphi’(x^*)<br>$$</p>
</blockquote>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><p>求方程 $f(x) &#x3D; x^3 - x - 1 &#x3D; 0$ 在 $x &#x3D; 1.5$ 附近的根，若将方程改写为：</p>
<p>$$ x &#x3D; x^3 - 1 $$</p>
<p>建立迭代公式：</p>
<p>$$ x_{k+1} &#x3D; x_k^3 - 1 $$</p>
<p>这是因为：</p>
<p>$$ \varphi’(x) &#x3D; (x^3 - 1)’ &#x3D; 3x^2 $$</p>
<p>当 $x &gt; 0.7$ 时，均有 $|\varphi’(x)| &gt; 1$，所以该迭代过程是发散的。</p>
<hr>
<p>考虑迭代过程</p>
<p> (a)<br>$$<br>x_{k+1} &#x3D; \varphi_3(x_k) &#x3D; \frac{1}{2} (10 - x_k^3)^{1&#x2F;2}<br>$$</p>
<p>(b)<br>$$<br>x_{k+1} &#x3D; \varphi_4(x_k) &#x3D; \left( \frac{10}{4 + x_k} \right)^{1&#x2F;2}<br>$$<br> 的收敛性，当 $|x_k - x^*| &lt; 10^{-5}$ 时，确定 (b) 中迭代次数 $k$。</p>
<p><strong>解</strong></p>
<p>对于迭代过程 (b)，迭代函数 $\varphi_4(x) &#x3D; \left( \frac{10}{4 + x} \right)^{1&#x2F;2}$ 于<br>$$<br>|\varphi_4’(x)| &#x3D; \left|\frac{-5}{\sqrt{10} (4 + x)^{3&#x2F;2} }\right| \leq \frac{5}{\sqrt{10}(5)^{3&#x2F;2}} &lt; 0.15<br>$$</p>
<p>因此，迭代函数 $\varphi_4(x)$ 在 $[1, 2]$ 上满足定理条件 (II)，故迭代过程 (b) 收敛。</p>
<p>由 $|x^* - x_k| \leq \frac{L^k}{1 - L} |x_1 - x_0| &lt; \epsilon$ （$\epsilon$ 为给定精度要求）</p>
<p>迭代次数 $k$ 应取：（<span style="color:#FF0000">考试时现推即可</span>）</p>
<p>$$<br>k &gt; \frac{\lg \epsilon - \lg \frac{|x_1 - x_0|}{1-L}}{\lg L}<br>$$</p>
<p>由要求 $|x_k - x^*| &lt; 10^{-5}$，应用上述公式，其中 $x_1 &#x3D; 1.3484$ 和 $L_4 &#x3D; 0.15$，$x_0 &#x3D; 1.5$<span style="color:#FF0000">（初值是自己选的）</span></p>
<p>则有：<br>$$<br>k &gt; \frac{\lg 10^{-5} - \lg \frac{(1.5 - 1.3484)}{0.85}}{\lg 0.15} &#x3D; 5.16<br>$$</p>
<p>于是，推得所要求迭代次数 $k &#x3D; 6$。</p>
<p>对于迭代过程 (a)，迭代函数 $\varphi_3(x) &#x3D; \frac{1}{2} (10 - x^3)^{1&#x2F;2}$ 于：<br>$$<br>\varphi_3’(x) &#x3D; \frac{-3x^2}{4\sqrt{10 - x^3}} &lt; 0<br>$$</p>
<p>注意到 $|\varphi_3’(2)| \approx 2.12$，所以在 $[1, 2]$ 上，定理中条件 (II) 不满足。 但当 $x \in [1, 1.5]$ 时，有 $|\varphi_3’(x)| \leq |\varphi_3’(1.5)| &lt; 0.66 &#x3D; L_3$ 迭代函数 $\varphi_3(x)$ 在 $[1, 1.5]$ 上满足定理的条件 (II)，故迭代过程初值限制在 $[1, 1.5]$ 上时，迭代过程收敛。</p>
<p>由要求 $|x_k - x^*| &lt; 10^{-5}$，应用上述公式，其中 $x_1 &#x3D; 1.287$ 和 $L_3 &#x3D; 0.66$，$x_0 &#x3D; 1.5$，则有：<br>$$<br>k &gt; \frac{\lg 10^{-5} - \lg \frac{(1.5 - 1.287)}{1-0.66}}{\lg 0.66} &#x3D; 26.58<br>$$</p>
<p>于是，推得所要求迭代次数 $k &#x3D; 27$。</p>
<blockquote>
<p><strong>注</strong>：此题中 $L_4 &lt; L_3$，可知迭代过程 (b) 比迭代过程 (a) 收敛快。</p>
<p>定理条件<strong>非必要条件</strong>，可将 $[a, b]$ 缩小，定义<strong>局部收敛性</strong>：</p>
<p>若在 $x^* $ 的某 $\delta$ 邻域 $R &#x3D; { x \ | \ |x - x^*| \leq \delta }$ </p>
<p>有 $\varphi \in C^1[a, b]$ 且 $|\varphi’(x^*)| &lt; 1$，则对 $\forall x_0 \in R$ 开始的迭代收敛。即调换初值可得到收敛的结果。</p>
</blockquote>
<p><strong>定义</strong></p>
<p>若存在在 $x^* $ 的某个邻域 $R: |x - x^*| \leq \delta$，使迭代过程</p>
<p>$$<br>x_{k+1} &#x3D; \varphi(x_k)<br>$$</p>
<p>对于任意初值 $x_0 \in R$ 收敛，则称迭代过程 $x_{k+1} &#x3D; \varphi(x_k)$ 在根 $x^*$ 附近具有局部收敛性。</p>
<p><strong>定理</strong></p>
<p>设 $x^* $ 为方程 $x &#x3D; \varphi(x)$ 的根，$\varphi’(x)$ 在 $x^* $ 的邻域连续，且 $|\varphi’(x^*)| &lt; 1$ 则迭代过程</p>
<p>$$<br>x_{k+1} &#x3D; \varphi(x_k)<br>$$</p>
<p>具有局部收敛性。</p>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_14-28-44.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_14-28-59.png"></p>
</blockquote>
<h2 id="迭代法的收敛阶"><a href="#迭代法的收敛阶" class="headerlink" title="迭代法的收敛阶"></a>迭代法的收敛阶</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>设迭代 $x_{k+1} &#x3D; \varphi(x_k)$ 收敛到 $\varphi(x)$ 的不动点 $x^*$。</p>
<p>设 $e_k &#x3D; x_k - x^*$，若</p>
<p>$$<br>\lim_{k \to \infty}  \frac{e_{k+1}}{e_k^p} &#x3D; C<br>$$</p>
<p>则称该迭代为 <strong>$p$ 阶收敛</strong>，其中 $C$ 称为渐近误差常数（$C \neq0$）。</p>
<blockquote>
<ul>
<li>$p &#x3D; 1$ 时称作<strong>线性收敛</strong></li>
<li>$p &gt; 1$ 时称作<strong>超线性收敛</strong></li>
<li>p &#x3D; 2 时称作<strong>平方收敛</strong></li>
</ul>
</blockquote>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><p>设 $x^* $ 为方程 $x &#x3D; \varphi(x)$ 的不动点，若 $\varphi \in C^p(R(x^*))$ 且 $p \geq 2$；</p>
<p>$$<br>\varphi’(x^* ) &#x3D; \dots &#x3D; \varphi^{(p-1)}(x^* ) &#x3D; 0, \quad \varphi^{(p)}(x^* ) \neq 0,<br>$$</p>
<p>则 $x_{k+1} &#x3D; \varphi(x_k)$ 在 $R(x^*)$ 内 $p$ 阶收敛。</p>
<p><strong>证明</strong>：<br>$$<br>x_{k+1} &#x3D; \varphi(x_k) &#x3D; \varphi(x^* ) + \varphi’(x^* ) (x_k - x^* ) + \dots + \frac{\varphi^{(p)}(\xi_k)}{p!} (x_k - x^* )^p<br>$$</p>
<p>其中 $\xi_k \to x^<em>$ as $k \to \infty$，极限值为 $C$。<br>$$<br>\lim <em>{k\rightarrow\infty}\frac{e</em>{k+1}}{e_k^p}&#x3D; \lim <em>{k\rightarrow\infty}\frac{x</em>{k+1}-x^{</em>}}{\left(x_{k}-x^{<em>}\right)^{p}}&#x3D;\frac{\varphi^{(p)}\left(x^{</em>}\right)}{p !}<br>$$</p>
<blockquote>
<p>特别地</p>
<p>当 $0 &lt; |\varphi’(x^ * )| &lt; 1$ 时，迭代法线性收敛；<br>当 $\varphi’(x^ * ) &#x3D; 0$，$\varphi’’(x^ * ) \neq 0$ 时，平方收敛。</p>
</blockquote>
<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_10-09-04.png"></p>
</blockquote>
<h2 id="埃特金（Aitken）算法"><a href="#埃特金（Aitken）算法" class="headerlink" title="埃特金（Aitken）算法"></a>埃特金（Aitken）算法</h2><p>设 $x_k$ 是一个线性收敛序列，其极限为 $x^* $，误差 $e_k &#x3D; x^* - x_k$，若：</p>
<p>$$<br>\lim_{k \to \infty} \left| \frac{e_{k+1}}{e_k} \right| &#x3D; c \quad (0 &lt; c &lt; 1)<br>$$</p>
<p>因此，当 $k$ 充分大时：</p>
<p>$$<br>\frac{x^* - x_{k+1}}{x^* - x_{k+2}} \approx \frac{x^* - x_k}{x^* - x_{k+1}}<br>$$</p>
<p>由此得：</p>
<p>$$<br>x^* \approx x_{k+1} - \frac{(x_{k+2} - x_{k+1})^2}{x_{k+2} - 2x_{k+1} + x_k}&#x3D; x_k - \frac{(x_{k+1} - x_k)^2}{x_k - 2x_{k+1} + x_{k+2}}<br>$$</p>
<p>以上式右端得到的结果作为新的改进值，记为：</p>
<p>$$<br>\overline x_{k+1} &#x3D; x_k - \frac{(x_{k+1} - x_k)^2}{x_k - 2x_{k+1} + x_{k+2}}<br>$$</p>
<p>得到新序列 ${ \overline{x}_k }$，较原序列 ${ x_k }$ 更快的收敛到 $x^*$。</p>
<p><strong>可以证明</strong><br>$$<br>\lim_{k \to \infty} \frac{\overline x_{k+1} - x^* }{x_k - x^* } &#x3D; 0<br>$$</p>
<p>它表明序列 ${ \overline{x}_k }$的收敛速度比 ${ x_k }$ 的收敛速度快。</p>
<p><strong>埃特金（Aitken）算法</strong></p>
<ul>
<li><p>迭代：$\overline x_{k+1} &#x3D; \varphi(x_k) $</p>
</li>
<li><p>重新迭代：$ \tilde x_{k+1} &#x3D; \varphi(\overline{x}_{k+1}) $</p>
</li>
<li><p>改进：<br>$$<br> x_{k+1} &#x3D; x_k - \frac{ (\overline x_{k+1} - x_k)^2}{x_k - 2 \overline x_{k+1} + \tilde x_{k+1}}<br>$$</p>
</li>
</ul>
<h2 id="斯蒂芬森迭代"><a href="#斯蒂芬森迭代" class="headerlink" title="斯蒂芬森迭代"></a>斯蒂芬森迭代</h2><ul>
<li><p>埃特金方法不管原序列 ${x_k}$ 是怎样产生的，对 ${x_k}$ 进行加速计算，得到序列 ${ \tilde{x}_k }$，如果把埃特金加速技巧与不动点迭代结合，则可得到如下的迭代法：<br>$$<br>y_k &#x3D; \varphi(x_k), \quad z_k &#x3D; \varphi(y_k)<br>$$</p>
<p>$$<br>x_{k+1} &#x3D; x_k - \frac{(y_k - x_k)^2}{z_k - 2y_k + x_k} \quad (k &#x3D; 0, 1, \cdots) \qquad (*)<br>$$</p>
<p><span style="color:#FF0000">称为斯蒂芬森 (Steffensen) 迭代法</span></p>
<p>它可以这样理解，我们要求$x &#x3D; \varphi(x)$ 的根 $x^*$</p>
<p>令</p>
<p> $\epsilon(x) &#x3D; \varphi(x) - x $</p>
<p>$ \epsilon(x^* ) &#x3D; \varphi(x^* ) - x^*  &#x3D; 0 $</p>
<p> 已知 $x^* $ 的近似值 $x_k$ 及 $y_k$，其误差分别为：<br>$$<br>\epsilon(y_k) &#x3D; \varphi(y_k) - y_k &#x3D; z_k - y_k<br>$$</p>
<p>$$<br>\epsilon(x_k) &#x3D; \varphi(x_k) - x_k &#x3D; y_k - x_k<br>$$</p>
<p>误差的“外推到零”</p>
<p>即过 $(x_k, \epsilon(x_k))$ 和 $(y_k, \epsilon(y_k))$ 两点做线性插值函数，它与 $x$ 轴交点就是 $(*)$ 中的 $x_{k+1}$。</p>
<p>即方程：</p>
<p>$$<br>\epsilon(x_k) + \frac{\epsilon(y_k) - \epsilon(x_k)}{y_k - x_k}(x - x_k) &#x3D; 0<br>$$</p>
<p>的解：<br>$$<br>x &#x3D; x_k - \frac{\varepsilon(x_k)}{\varepsilon(y_k) - \varepsilon(x_k)} (y_k - x_k) &#x3D; x_k - \frac{(y_k - x_k)^2}{z_k - 2y_k + x_k} &#x3D; x_{k+1}<br>$$<br>实际上 $(*)$ 是将不动点迭代法计算两步合并为一步得到的，可以写成另一种不动点迭代：<br>$$<br>x_{k+1} &#x3D; \psi(x_k) \quad (k &#x3D; 0, 1, \cdots)<br>$$</p>
<p>其中：</p>
<p>$$<br>\psi(x) &#x3D; x - \frac{[\varphi(x) - x]^2}{\varphi(\varphi(x)) - 2\varphi(x) + x}<br>$$</p>
<p>对于不动点迭代：</p>
<p>$$<br>x_{k+1} &#x3D; \psi(x_k) \quad (k &#x3D; 0, 1, \cdots)<br>$$</p>
<p>具有以下局部收敛性定理：</p>
<blockquote>
<p>若 $x^* $ 为迭代函数 $\psi(x)$ 的不动点，则 $x^* $ 为 $\varphi(x)$ 的不动点。</p>
<p>反之，若 $x^* $ 为 $\varphi(x)$ 的不动点，设$\varphi’(x) $存在，且 $\varphi’(x^* ) \neq 1$，则 $x^* $ 是 $\psi(x)$ 的不动点，且斯蒂芬森 (Steffensen) 迭代法是 2 阶收敛的。</p>
</blockquote>
</li>
</ul>
<p><strong>示例：</strong></p>
<p>求方程 $3x^2 - e^x &#x3D; 0$ 在 $[3, 4]$ 中的解。</p>
<p>解：由方程得 $e^x &#x3D; 3x^2$，取对数得<br>$$<br>x &#x3D; \ln 3x^2 &#x3D; 2 \ln x + \ln 3 &#x3D; \varphi(x)<br>$$</p>
<p>若构造迭代法：</p>
<p>$$<br>x_{k+1} &#x3D; 2 \ln x_k + \ln 3<br>$$</p>
<p>由于</p>
<p>$$<br>\varphi’(x) &#x3D; \frac{2}{x}, \quad \max_{3 \leq x \leq 4} |\varphi’(x)| \leq \frac{2}{3} &lt; 1,<br>$$</p>
<p>且当$x \in [3,4]$时，$\varphi(x) \in [3,4]$</p>
<p>故知此迭代法收敛，若取 $x_0 &#x3D; 3.5$ 迭代 16 次得 $x_{16} &#x3D; 3.73307$，有六位有效数字。</p>
<p>若用斯蒂芬森加速法进行加速，计算结果列入表中：</p>
<table>
<thead>
<tr>
<th>$k$</th>
<th>$x_k$</th>
<th>$y_k$</th>
<th>$z_k$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>3.5</td>
<td>3.60414</td>
<td>3.66202</td>
</tr>
<tr>
<td>1</td>
<td>3.73444</td>
<td>3.73381</td>
<td>3.73447</td>
</tr>
<tr>
<td>2</td>
<td>3.73307</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h2><h3 id="牛顿迭代法"><a href="#牛顿迭代法" class="headerlink" title="牛顿迭代法"></a>牛顿迭代法</h3><p>牛顿迭代法是一种特殊的不动点迭代法，其计算公式为：</p>
<p>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \cdots<br>$$</p>
<p>其迭代函数为：</p>
<p>$$<br>\varphi(x) &#x3D; x - \frac{f(x)}{f’(x)}<br>$$</p>
<p><strong>牛顿迭代法的收敛速度</strong></p>
<p>当 $f(x^* ) &#x3D; 0, f’(x^* ) \neq 0$ 时，容易证明，$\varphi’(x^* ) &#x3D; 0, \varphi’’(x^* ) &#x3D;  \frac{f’’(x^* )}{f’(x^* )}$，由定理 7.4 知，牛顿迭代法是平方收敛的，且</p>
<p>$$<br>\lim_{k \to \infty} \frac{e_{k+1}}{e_k^2} &#x3D; \frac{f’’(x^* )}{2f’(x^* )}<br>$$</p>
<p>其中，$e_k &#x3D; x_k - x^*$ 为误差。</p>
<h3 id="简化牛顿法"><a href="#简化牛顿法" class="headerlink" title="简化牛顿法"></a>简化牛顿法</h3><p><strong>构造迭代公式</strong><br>$$<br>x_{k+1} &#x3D; x_k - C f(x_k), \quad C \neq 0, \quad k &#x3D; 0, 1, 2, \dots<br>$$</p>
<p>当 $|g’(x) |&#x3D; |1 - C f’(x)| &lt; 1$，即 $0 &lt; C f’(x) &lt; 2$ 时，公式局部收敛。</p>
<p><strong>简化牛顿法</strong><br>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k)}{f’(x_0)}<br>$$</p>
<h3 id="牛顿下山法："><a href="#牛顿下山法：" class="headerlink" title="牛顿下山法："></a>牛顿下山法：</h3><p>$$<br>x_{k+1} &#x3D; x_k - \lambda \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \dots<br>$$</p>
<p>其中下山因子 $\lambda &#x3D; 1$，逐次减半直至满足 $|f(x_{k+1})| &lt; |f(x_k)|$。</p>
<hr>
<p><strong>示例</strong></p>
<p>求解 $x^3 - x - 1 &#x3D; 0$ 在 1.5 附近的根 $x^*$。</p>
<p>解：</p>
<ul>
<li><p>第一列牛顿法 $x_0 &#x3D; 1.5$</p>
</li>
<li><p>第二列牛顿法$x_0 &#x3D; 0.6$，</p>
</li>
<li><p>牛顿下山法 $x_0 &#x3D; 0.6$，$\lambda &#x3D; 1$, 经过 16 次迭代得到$\lambda &#x3D; 1&#x2F;32$,此时$x_1&#x3D;1.140625,f(x_1)&#x3D;-0.656643,f(x_0)&#x3D;-1.384$,显然有$|f(x_1)|&lt;|f(x_0)|$,接下来由$x_1$计算$x_2,x_3$时，$\lambda &#x3D; 1$</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>$k$</th>
<th>$x_k$</th>
<th>$x_k$</th>
<th>$x_k$</th>
<th>$f(x_k)$</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1.5</td>
<td>0.6</td>
<td>0.6</td>
<td>-1.384</td>
</tr>
<tr>
<td>1</td>
<td>1.34783</td>
<td>17.9</td>
<td>1.140625</td>
<td>-0.656643</td>
</tr>
<tr>
<td>2</td>
<td>1.32520</td>
<td>发散</td>
<td>1.36181</td>
<td>0.1866</td>
</tr>
<tr>
<td>3</td>
<td>1.32472</td>
<td></td>
<td>1.32628</td>
<td>0.00667</td>
</tr>
<tr>
<td>4</td>
<td>1.32472</td>
<td></td>
<td>1.32472</td>
<td>0.0000086</td>
</tr>
</tbody></table>
<h3 id="牛顿法的重根情形"><a href="#牛顿法的重根情形" class="headerlink" title="牛顿法的重根情形"></a>牛顿法的重根情形</h3><p><strong>方法1</strong>（知道重数）<br>$$<br>x_{k+1} &#x3D; x_k - m \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \dots<br>$$<br><strong>方法2</strong><br>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k) f’(x_k)}{[f’(x_k)]^2 - f(x_k) f’’(x_k)}, \quad (k &#x3D; 0, 1, 2, \dots)<br>$$</p>
<h2 id="弦截法"><a href="#弦截法" class="headerlink" title="弦截法"></a>弦截法</h2><p>$$<br>x_{k+1} &#x3D; x_k -  \frac{f(x_k)}{f(x_k)-f(x_{k-1})} (x_k-x_{k-1}), \quad k &#x3D;  1, 2, \dots<br>$$</p>
<p>弦截法具有超线性收敛，且收敛阶 $p&#x3D;1.618$</p>
<h2 id="抛物线法"><a href="#抛物线法" class="headerlink" title="抛物线法"></a>抛物线法</h2><p>以 $x_k, x_{k-1}$ 和 $x_{k-2}$ 为插值节点，得到插值函数</p>
<p>$$<br>p_2(x) &#x3D; f(x_k) + f[x_k, x_{k-1}](x - x_k) + f[x_k, x_{k-1}, x_{k-2}](x - x_k)(x - x_{k-1})<br>$$</p>
<p>令 $p_2(x) &#x3D; 0$，得到两个零点：</p>
<p>$$<br>x_{k+1} &#x3D; x_k - \frac{2 f(x_k)}{\omega \pm \sqrt{\omega - 4 f(x_k)f[x_k, x_{k-1}, x_{k-2}]}}<br>$$</p>
<p>式中 $\omega &#x3D; f[x_k, x_{k-1}] + f[x_k, x_{k-1}, x_{k-2}](x_k - x_{k-1})$，</p>
<p>$$<br>\Rightarrow x_{k+1} &#x3D; x_k - \frac{2 f(x_k)}{\omega + \text{sgn}(\omega) \sqrt{\omega - 4 f(x_k)  f[x_k, x_{k-1}, x_{k-2}]}}<br>$$</p>
<p>插值线法按阶 $p &#x3D; 1.840$ 收敛到 $x^*$。</p>
<h2 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h2><blockquote>
<p>（15 分）用下列方法求 $f(x)&#x3D;x^{3}-\dfrac{x}{9}-\dfrac{2}{9}$ 在 $x_{0}&#x3D;0.5$ 附近的根，根的准确值是 $x^{\ast}&#x3D;0.66666\ldots$。要求计算第 2 步：  </p>
<ol>
<li>牛顿法；  </li>
<li>弦截法，$x_{0}&#x3D;0.5,;x_{1}&#x3D;0.6$</li>
</ol>
<p><strong>解答</strong>  </p>
<ul>
<li>牛顿法</li>
</ul>
<p>牛顿迭代公式  </p>
<p>$$<br>x_{k+1}&#x3D;x_{k}-\frac{f(x_{k})}{f’(x_{k})},<br>\qquad<br>f’(x)&#x3D;3x^{2}-\frac{1}{9}.<br>$$</p>
<table>
<thead>
<tr>
<th>步</th>
<th>$x_k$</th>
<th>$f(x_k)$</th>
<th>$f’(x_k)$</th>
<th>$x_{k+1}$</th>
</tr>
</thead>
<tbody><tr>
<td>初值</td>
<td>$x_0 &#x3D; 0.500000$</td>
<td>$-0.1527778$</td>
<td>$0.6388889$</td>
<td>—</td>
</tr>
<tr>
<td>第 1 步</td>
<td>$x_0$</td>
<td>$-0.1527778$</td>
<td>$-0.1527778$</td>
<td>$x_1 &#x3D; 0.739130$</td>
</tr>
<tr>
<td>第 2 步</td>
<td>$x_1$</td>
<td>$0.0994493$</td>
<td>$1.527553$</td>
<td>$x_2 &#x3D; 0.674039$</td>
</tr>
</tbody></table>
<ul>
<li>弦截法</li>
</ul>
<p>弦截迭代公式  </p>
<p>$$<br>x_{k+1}&#x3D;x_{k}-f(x_{k}),<br>\frac{x_{k}-x_{k-1}}{f(x_{k})-f(x_{k-1})}.<br>$$</p>
<table>
<thead>
<tr>
<th>步</th>
<th>$x_{k-1}$</th>
<th>$x_{k}$</th>
<th>$f(x_{k-1})$</th>
<th>$f(x_{k})$</th>
<th>$x_{k+1}$</th>
</tr>
</thead>
<tbody><tr>
<td>初值</td>
<td>$x_0 &#x3D; 0.500000$</td>
<td>$x_1 &#x3D; 0.600000$</td>
<td>$-0.1527778$</td>
<td>$-0.0728889$</td>
<td>—</td>
</tr>
<tr>
<td>第 1 步</td>
<td>$x_0$</td>
<td>$x_1$</td>
<td>$0.1527778$</td>
<td>$-0.0728889$</td>
<td>$x_2 &#x3D; 0.691238$</td>
</tr>
<tr>
<td>第 2 步</td>
<td>$x_1$</td>
<td>$x_2$</td>
<td>$-0.0728889$</td>
<td>$0.0312537$</td>
<td>$x_3 &#x3D; 0.663857$</td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_10-19-37.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_10-19-46.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_10-36-48.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_11-25-59.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_11-26-06.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_11-26-26.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_14-50-34.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_15-28-31.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_15-28-49.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-11_15-28-59.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-11_16-05-13.png"></p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
  </entry>
  <entry>
    <title>数值分析-QR分解</title>
    <url>/blog/2025/06/09/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-QR%E5%88%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="QR分解"><a href="#QR分解" class="headerlink" title="QR分解"></a>QR分解</h1><h2 id="例题1"><a href="#例题1" class="headerlink" title="例题1"></a>例题1</h2><p><img src="/blog/image/Snipaste_2025-06-09_18-39-23.png"></p>
<h2 id="例题2"><a href="#例题2" class="headerlink" title="例题2"></a>例题2</h2><p><img src="/blog/image/Snipaste_2025-06-09_19-07-12.png"></p>
<h2 id="例题3"><a href="#例题3" class="headerlink" title="例题3"></a>例题3</h2><p><img src="/blog/image/Snipaste_2025-06-10_09-32-14.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-10_09-32-30.png"></p>
<h1 id="约化为对称三对角阵"><a href="#约化为对称三对角阵" class="headerlink" title="约化为对称三对角阵"></a>约化为对称三对角阵</h1><h2 id="例题1-1"><a href="#例题1-1" class="headerlink" title="例题1"></a>例题1</h2><p><img src="/blog/image/Snipaste_2025-06-09_20-19-03.png"></p>
<h2 id="例题2-1"><a href="#例题2-1" class="headerlink" title="例题2"></a>例题2</h2><p><img src="/blog/image/Snipaste_2025-06-09_20-19-16.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-09_20-19-24.png"></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
  </entry>
  <entry>
    <title>数值分析-误差</title>
    <url>/blog/2025/04/30/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E8%AF%AF%E5%B7%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文章包含数值分析的误差部分—————————————————————————————————————————————————————————————————-</p>
<p><span style="color:blue">$C^p[a,b]$表示具有$p$阶连续导数的函数空间；$C^0$表述函数连续，没有要求可导</span></p>
<h1 id="第一章-误差"><a href="#第一章-误差" class="headerlink" title="第一章 误差"></a>第一章 误差</h1><h2 id="误差的度量方式"><a href="#误差的度量方式" class="headerlink" title="误差的度量方式"></a>误差的度量方式</h2><ul>
<li><p>设 $x$ 为准确值，$x^* $ 为 $x$ 的一个近似值，称  $$e^* &#x3D; x^* - x$$  为<strong>绝对误差</strong>，简称为<strong>误差</strong>。</p>
</li>
<li><p>对于一般情形</p>
</li>
</ul>
<p>$$<br>| x^*  - x | ≤ ε^*<br>$$</p>
<p>$ε^* $为<strong>绝对误差限</strong> </p>
<ul>
<li><p><strong>相对误差</strong>的公式表示为：  $$e_r^* &#x3D; \frac{e^* }{x}$$，实际中一般取$$e_r^* &#x3D; \frac{e^* }{x^* }$$</p>
</li>
<li><p>$x$ 的<strong>相对误差上限</strong>定义为$\varepsilon_r^* &#x3D; \frac{\varepsilon^* }{|x^* |}$</p>
</li>
</ul>
<h2 id="有效数字"><a href="#有效数字" class="headerlink" title="有效数字"></a>有效数字</h2><h3 id="有效数字的定义"><a href="#有效数字的定义" class="headerlink" title="有效数字的定义"></a>有效数字的定义</h3><p>若近似值 $ x^* $ 的误差限是某一位的半个单位，该位到 $ x $ 的第一位非零数字共有 $ n $ 位，则 $ x $ 有 $ n $ 位有效数字。  </p>
<p><strong>示例</strong><br>圆周率 $ \pi &#x3D; 3.14159265 \dots $  </p>
<ul>
<li>按四舍五入原则，若取四位小数，则 $ \pi \approx 3.1416 $；  </li>
<li>取五位小数，则 $ \pi \approx 3.14159 $。</li>
</ul>
<p>它们的绝对误差不超过末位数的半个单位，即：  </p>
<ul>
<li>$$| \pi - 3.1416 | \leq \frac{1}{2} \times 10^{-4}$$  五位有效数值  </li>
<li>$$| \pi - 3.14159 | \leq \frac{1}{2} \times 10^{-5}$$  六位有效数值</li>
</ul>
<blockquote>
<p>如果是四舍五入的数字，可以直接从后往前数有几位就行了</p>
</blockquote>
<p><strong>科学计数法</strong></p>
<p>用科学计数法，记 $ x^* &#x3D; \pm 0.a_1 a_2 \cdots a_n \times 10^m $（其中 $ a_1 \neq 0 $）。若 $ |x - x^* | \leq 0.5 \times 10^{m-n} $（即 $ a_n $ 的截取按四舍五入规则），则称 $ x^* $ 为有 <strong>$ n $</strong> 位有效数字，精确到 <strong>$ 10^{m-n} $</strong>。</p>
<h3 id="有效数字与相对误差的关系"><a href="#有效数字与相对误差的关系" class="headerlink" title="有效数字与相对误差的关系"></a>有效数字与相对误差的关系</h3><p><strong>有效数字 ⇒ 相对误差限</strong></p>
<p> 已知 $ x^* $ 有 $ n $ 位有效数字，则其相对误差限为<br>$$<br>\varepsilon_r *  &#x3D; \left| \frac{\varepsilon^* }{x^* } \right| &#x3D; \frac{0.5 \times 10^{m-n}}{0.a_1 a_2 \cdots a_n \times 10^m} &#x3D; \frac{10^{-n}}{2 \times 0.a_1 \cdots}  \leq \frac{1}{2a_1} \times 10^{-n+1}<br>$$<br><strong>相对误差限 ⇒ 有效数字</strong></p>
<p> 已知 $ x^* $ 的相对误差限若满足<br>$$<br>\varepsilon_r * \leq \frac{1}{2(a_1 + 1)} \times 10^{-n+1}<br>$$<br>则<br>$$<br>|x - x^* | \leq \varepsilon_r^ *   \cdot |x^* | &#x3D; \frac{10^{-n+1}}{2(a_1 + 1)} \times 0.a_1 a_2 \cdots \times 10^m<br>&lt; \frac{10^{-n+1}}{2(a_1 + 1)} \cdot (a_1 + 1) \times 10^{m-1} &#x3D; 0.5 \times 10^{m-n}<br>$$<br>可见 $ x^* $ 至少有 $ n $ 位有效数字。</p>
<h2 id="求函数值和算术运算的误差估计"><a href="#求函数值和算术运算的误差估计" class="headerlink" title="求函数值和算术运算的误差估计"></a>求函数值和算术运算的误差估计</h2><p>设多元函数 $ A &#x3D; f(x_1, x_2, \cdots, x_n) $，$ x_1^* , x_2^* , \cdots, x_n^*  $ 为 $ x_1, x_2, \cdots, x_n $ 的近似值。 则 $ A $ 的近似值 $ A^* $：$ A^* &#x3D; f(x_1^* , x_2^* , \cdots, x_n^* ) $。 </p>
<p>函数值 $ A^* $ 的绝对误差： $$ A - A^*  &#x3D; f(x_1, \cdots, x_n) - f(x_1^* , \cdots, x_n^* ) $$ </p>
<p>在点 $ x &#x3D; (x_1, x_2, \cdots, x_n) $ 的 Taylor 展开式，设 $ |x_i - x_i^* | $ ($ i &#x3D; 1, 2, \cdots, n $) 都很小</p>
<p>略去高阶项：<br>$$<br>A - A^* &#x3D; f(x_1, \cdots, x_n) - f(x_1^* , \cdots, x_n^* ) \approx \sum_{j&#x3D;1}^n \frac{\partial f(x)}{\partial x_j} (x_j - x_j^* )<br>$$<br>或<br>$$<br>e(A) \approx \sum_{j&#x3D;1}^n \frac{\partial f(x)}{\partial x_j} e(x_j)<br>$$</p>
<p>$$<br>|e(A)| \leq \sum_{j&#x3D;1}^n \left| \frac{\partial f(x)}{\partial x_j} \right| |e(x_j)|<br>$$</p>
<p><strong>一元函数时：</strong><br>$$<br>e^* (x)&#x3D;x^*-x<br>$$</p>
<p>$$<br>e^* (A)&#x3D;f(x^* )-f(x)&#x3D; f’(\xi)(x^* -x)<br>$$</p>
<h2 id="病态问题与条件数"><a href="#病态问题与条件数" class="headerlink" title="病态问题与条件数"></a>病态问题与条件数</h2><p>$$<br> | e_r(y) | &#x3D; \left| \frac{e(y)}{f(x^* )} \right| &#x3D; \left| \frac{f(x) - f(x^* )}{f(x^* )} \right|<br>$$</p>
<p>$$<br> &#x3D; \left| \frac{f(x) - f(x^* )}{x - x^* } \cdot \frac{x}{f(x)} \cdot \frac{x - x^* }{x} \right|<br>$$</p>
<p>$$<br> \approx \left| \frac{x \cdot f’(x)}{f(x)} \right| \cdot \left| \frac{x - x^*}{x} \right| &#x3D; \left| \frac{x \cdot f’(x)}{f(x)} \right| \cdot | e_r(x) |<br>$$</p>
<p>$| \frac{x \cdot f’(x)}{f(x)} |$为条件数，条件数很大时，初始数据的微小误差可能引起结果 $ A $ 的很大误差。</p>
<p>对数学问题而言，如果输入数据有微小扰动，引起输出数据（即数学问题的解）有很大扰动，则称数学问题是病态问题，否则称为良态问题。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析-线性方程的解法</title>
    <url>/blog/2025/03/26/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90-%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84%E7%9A%84%E8%A7%A3%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>此文章包含线性方程组的解法部分—————————————————————————————————————————————————————-</p>
<h1 id="线性方程组的解法"><a href="#线性方程组的解法" class="headerlink" title="线性方程组的解法"></a>线性方程组的解法</h1><h2 id="记忆内容汇总"><a href="#记忆内容汇总" class="headerlink" title="记忆内容汇总"></a>记忆内容汇总</h2><blockquote>
<p><strong>常用矩阵范数</strong>(<strong>下面的$x$都指的是向量</strong>)</p>
<ol>
<li><strong>Frobenius范数</strong></li>
</ol>
<p>$$<br>||A||_F &#x3D; \sqrt {\sum _{i&#x3D;1}^n  \sum _{j&#x3D;1}^n |a _{ij}|^2}<br>$$</p>
<p>对于方阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $x \in \mathbb{R}^n$ 有：</p>
<p>$$<br>||Ax||_2 \leq ||A||_F \cdot ||x||_2<br>$$</p>
<ol start="2">
<li><strong>算子范数（Operator Norm）</strong></li>
</ol>
<p>矩阵范数与向量范数的<strong>相容性</strong>（<em>consistent</em>）</p>
<p>$$<br>||A|| _p &#x3D; \max _{x \neq 0} \frac{||Ax|| _p}{||x|| _p} &#x3D; \max _{||x|| _p&#x3D;1} ||Ax|| _p<br>$$</p>
<p>进一步：</p>
<p>$$<br>||Ax||_p \leq ||A||_p ||x||_p<br>$$</p>
<blockquote>
<p><strong>行和范数（∞-范数）</strong><br>$$<br>||A|| _\infty &#x3D; \max _{1 \leq i \leq n} \sum _{j&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>列和范数（1-范数）</strong></p>
<p>$$<br>||A||_1 &#x3D; \max _{1 \leq j \leq n} \sum _{i&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>谱范数（2-范数）</strong></p>
</blockquote>
<blockquote>
<p>$$<br>||A||_2 &#x3D; \sqrt{\lambda _{\max}(A^T A)}<br>$$</p>
<p>矩阵$A^T A$的最大特征根</p>
</blockquote>
<p><strong>矩阵谱半径定义</strong></p>
<p>设矩阵 $A \in \mathbb{C}^{n \times n}$ 的特征根为 $\lambda_1, \lambda_2, \ldots, \lambda_n$，则矩阵 $A$ 的<strong>谱半径</strong>（<em>spectral radius</em>）定义为：</p>
<p>$$<br>\rho(A) &#x3D; \max_{1 \leq i \leq n} |\lambda_i|<br>$$</p>
</blockquote>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/Snipaste_2025-06-07_15-31-27.png"></p>
</blockquote>
<h2 id="向量与矩阵范数"><a href="#向量与矩阵范数" class="headerlink" title="向量与矩阵范数"></a>向量与矩阵范数</h2><h3 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h3><p>我们用 $\mathbb{R}^n$ 表示 $n$ 维实向量的空间。</p>
<p>定义</p>
<blockquote>
<p>hexo显示有误，下面 |.| 皆为范数 ||.||</p>
</blockquote>
<p>如果向量 $X \in \mathbb{R}^n$ 的某个实值函数 $N(X) &#x3D; ||X||$ 满足以下条件：</p>
<ol>
<li><p><strong>正定性</strong>：<br>$$<br>||x|| \geq 0，\quad \text{当且仅当} \ x &#x3D; 0 \ \text{时，} \ ||x|| &#x3D; 0<br>$$</p>
</li>
<li><p><strong>齐次性</strong>：<br>$$<br>|| \alpha x || &#x3D; |\alpha| \cdot ||x||，\quad \alpha \in \mathbb{R}<br>$$</p>
</li>
<li><p><strong>三角不等式</strong>：<br>$$<br>||x + y|| \leq ||x|| + ||y||，\quad x, y \in S<br>$$</p>
</li>
</ol>
<p><u>则称 $N(X)$ 是向量 $X$ 的范数。</u></p>
<blockquote>
<ol>
<li><p><strong>∞-范数（最大范数）</strong>：<br>$$<br>||x|| _ \infty &#x3D; \max_{1 \leq i \leq n} |x_i|<br>$$</p>
</li>
<li><p><strong>1-范数</strong>：<br>$$<br>||x|| _ 1 &#x3D; \sum_{i&#x3D;1}^n |x_i|<br>$$</p>
</li>
<li><p><strong>2-范数</strong>：<br>$$<br>||x|| _ 2 &#x3D; \left( \sum_{i&#x3D;1}^n x_i^2 \right)^{1&#x2F;2}<br>$$</p>
</li>
<li><p><strong>p-范数（推广范数）</strong></p>
</li>
</ol>
<p>$$<br>|X|_p &#x3D; \left( \sum _{i&#x3D;1}^n |x_i|^p \right)^{1&#x2F;p}<br>$$</p>
<ol start="2">
<li>计算示例</li>
</ol>
<p>对向量 $X &#x3D; (1, -2, 3)$：</p>
<p>$$<br>||X||_1 &#x3D; |1| + |-2| + |3| &#x3D; 6<br>$$</p>
<p>$$<br>||X||_\infty &#x3D; \max(|1|, |-2|, |3|) &#x3D; 3<br>$$</p>
<p>$$<br>||X||_2 &#x3D; \sqrt{1^2 + (-2)^2 + 3^2} &#x3D; \sqrt{14}<br>$$</p>
</blockquote>
<hr>
<p><strong>一些定义和定理：</strong></p>
<p><strong>定义</strong>：向量序列 ${X^{(k)}}$ 收敛于向量 $X^*$ 是指对每一个 $1 \leq i \leq n$ 都有</p>
<p>$$<br>\lim_{k \to \infty} x_i^{(k)} &#x3D; x_i^*<br>$$</p>
<p>可以理解为</p>
<p>$$<br>||X^{(k)} - X^*||_\infty \to 0 \quad<br>$$</p>
<p><strong>定义</strong>：若存在常数 $C &gt; 0$，使得对任意 $X \in \mathbb{R}^n$ 满足<br>$$<br>||X||_A \leq C ||X||_B,<br>$$</p>
<p>则称范数 $||\cdot||_A$ 比范数 $||\cdot||_A$ <strong>强</strong></p>
<p><strong>定义</strong>：若 $||\cdot||_A$ 比 $||\cdot||_A$ 强，同时 $||\cdot||_B$ 也比 $||\cdot||_A$ 强，即存在常数 $C_1, C_2 &gt; 0$ 使得<br>$$<br>C_1 ||\cdot||_B \leq ||\cdot||_A \leq C_2 ||\cdot||_B<br>$$</p>
<p>则称 $||\cdot||_A$ 和 $||\cdot||_B$ <strong>等价</strong>。</p>
<p><strong>定理</strong><br>$$<br>\mathbb{R}^n \text{上一切范数都等价。}<br>$$</p>
<p><strong>定理：</strong></p>
<p>$$<br>\lim_{k \to \infty} X^{(k)} &#x3D; X^* \quad \Leftrightarrow \quad |X^{(k)} - X^*| \to 0 \quad (k \to \infty)<br>$$</p>
<hr>
<h3 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h3><p><strong>定义</strong></p>
<p>矩阵范数 $||\cdot||$ 对任意矩阵 $A, B \in \mathbb{R}^{m \times n}$ 满足以下条件：</p>
<ol>
<li><p><strong>正定性</strong>（<em>positive definite</em>）</p>
<p>$$<br>|A| \geq 0；\quad |A| &#x3D; 0 \Leftrightarrow A &#x3D; 0<br>$$</p>
</li>
<li><p><strong>齐次性</strong>（<em>homogeneous</em>）</p>
<p>$$<br>|\alpha A| &#x3D; |\alpha| \cdot |A| \quad \text{对任意} \ \alpha \in \mathbb{C}<br>$$</p>
</li>
<li><p><strong>三角不等式</strong>（<em>triangle inequality</em>）</p>
<p>$$<br>|A + B| \leq |A| + |B|<br>$$</p>
</li>
<li><p><strong>相容性</strong>（<em>consistent</em>，当$m &#x3D; n$时）</p>
<p>$$<br>|AB| \leq |A| \cdot |B|<br>$$</p>
</li>
</ol>
<blockquote>
<p><strong>常用矩阵范数</strong>(<strong>下面的$x$都指的是向量</strong>)</p>
<ol>
<li><strong>Frobenius范数</strong></li>
</ol>
<p>$$<br>||A||_F &#x3D; \sqrt {\sum _{i&#x3D;1}^n  \sum _{j&#x3D;1}^n |a _{ij}|^2}<br>$$</p>
<p>对于方阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $x \in \mathbb{R}^n$ 有：</p>
<p>$$<br>||Ax||_2 \leq ||A||_F \cdot ||x||_2<br>$$</p>
<ol start="2">
<li><strong>算子范数（Operator Norm）</strong></li>
</ol>
<p>矩阵范数与向量范数的<strong>相容性</strong>（<em>consistent</em>）</p>
<p>$$<br>||A|| _p &#x3D; \max _{x \neq 0} \frac{||Ax|| _p}{||x|| _p} &#x3D; \max _{||x|| _p&#x3D;1} ||Ax|| _p<br>$$</p>
<p>进一步：</p>
<p>$$<br>||Ax||_p \leq ||A||_p ||x||_p<br>$$</p>
<blockquote>
<p><strong>特别有</strong></p>
</blockquote>
<blockquote>
<p><strong>行和范数（∞-范数）</strong></p>
<p>$$<br>||A|| _\infty &#x3D; \max _{1 \leq i \leq n} \sum _{j&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>列和范数（1-范数）</strong></p>
<p>$$<br>||A||_1 &#x3D; \max _{1 \leq j \leq n} \sum _{i&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>谱范数（2-范数）</strong></p>
</blockquote>
<blockquote>
<p>$$<br>||A||_2 &#x3D; \sqrt{\lambda _{\max}(A^T A)}<br>$$</p>
<p>矩阵$A^T A$的最大特征根</p>
</blockquote>
<p><strong>矩阵谱半径定义</strong></p>
<p>设矩阵 $A \in \mathbb{C}^{n \times n}$ 的特征根为 $\lambda_1, \lambda_2, \ldots, \lambda_n$，则矩阵 $A$ 的<strong>谱半径</strong>（<em>spectral radius</em>）定义为：</p>
<p>$$<br>\rho(A) &#x3D; \max_{1 \leq i \leq n} |\lambda_i|<br>$$</p>
</blockquote>
<p><strong>一些定理</strong></p>
<ol>
<li>对于任意算子范数  $||\cdot||$  ，有：</li>
</ol>
<p>$$<br>\rho(A) \leq ||A||<br>$$</p>
<ol start="2">
<li><p>若$A$对称，则有</p>
<p>$$<br>||A||_2 &#x3D; \rho(A)<br>$$</p>
</li>
<li><p>若矩阵$B$对某个算子范数满足$||B|| &lt; 1$，则必有：</p>
<ol>
<li>$I \pm B$ 可逆；</li>
<li>$||(I \pm B)^{-1}|| \leq \dfrac{1}{1 - ||B||}$</li>
</ol>
</li>
</ol>
<h2 id="高斯消元法"><a href="#高斯消元法" class="headerlink" title="高斯消元法"></a>高斯消元法</h2><p><strong>定理</strong> </p>
<p>设矩阵 $A$ 为 $n$ 阶非奇异矩阵（可逆方阵），则可通过高斯消去法（包括交换两行的初等变换）将方程组 $A\mathbf{x} &#x3D; \mathbf{b}$ 化为<strong>三角形方程组</strong>。</p>
<p><strong>引理</strong> </p>
<p>约化过程中主元素 $a_{ii}^{(i)} \neq 0$（$i&#x3D;1,2,\ldots,k$）的充要条件是矩阵 $A$ 的顺序主子式满足：<br>$$<br>D_i \neq 0 \quad (i&#x3D;1,2,\ldots,k)<br>$$</p>
<p>特别地，一阶主子式：</p>
<p>$$<br>D_1 &#x3D; a_{11} \neq 0<br>$$</p>
<p><strong>顺序主子式定义如下：</strong></p>
<span>
$$
A_k = \begin{pmatrix} a_{11} & \cdots & a_{1k} \\\ \vdots & \ddots & \vdots \\\ a_{k1} & \cdots & a_{kk} \end{pmatrix}, \quad D_k = \det(A_k)
$$
</span>

<p><strong>推论</strong></p>
<p>如果矩阵 $A$ 的顺序主子式 $D_k \neq 0$（$k&#x3D;1,2,\ldots,n-1$），则：</p>
<p>$$<br>a_{11}^{(1)} &#x3D; D_1<br>$$</p>
<p>$$<br>a_{kk}^{(k)} &#x3D; \frac{D_k}{D_{k-1}} \quad (k&#x3D;2,\ldots,n)<br>$$</p>
<p><strong>定理</strong></p>
<p>若 $A$ 的所有顺序主子式均满足：</p>
<p>$$<br>D_k \neq 0<br>$$</p>
<p>则高斯消元无需换行即可进行到底，得到唯一解。</p>
<blockquote>
<p>高斯消去法的计算过程略</p>
</blockquote>
<p><strong>高斯法的问题</strong></p>
<ol>
<li><p><strong>主元素为零</strong>：</p>
<p>$$<br>a_{kk}^{(k)} &#x3D; 0 \quad \text{消去过程中出现，导致消去法无法进行}<br>$$</p>
</li>
<li><p><strong>小主元素问题</strong>：</p>
<ul>
<li><p>即使 $a_{kk}^{(k)} \neq 0$ 但绝对值很小时：</p>
<ul>
<li>导致其他元素数量级严重增长</li>
<li>引发舍入误差扩散</li>
<li>最终使计算解不可靠</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="高斯列主元消去法"><a href="#高斯列主元消去法" class="headerlink" title="高斯列主元消去法"></a>高斯列主元消去法</h2><p>设方程组的增广矩阵为：</p>
<span>
$$
B = \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} & b_1 \\\ a_{21} & a_{22} & \cdots & a_{2n} & b_2 \\\ \vdots & \vdots & \ddots & \vdots & \vdots \\\ a_{n1} & a_{n2} & \cdots & a_{nn} & b_n \end{bmatrix}
$$
</span>

<p>在矩阵 $A$ 的<span style="color:#FF0000">第一列</span>选取绝对值最大的元素：</p>
<p>$$<br>|a_{i_1,1}| &#x3D; \max_{1 \leq i \leq n} |a_{i1}| \neq 0<br>$$</p>
<p>交换矩阵 $B$ 的第1行与第$i_1$行，经第一次消元计算得：</p>
<p>$$<br>(A|b) \rightarrow (A^{(2)}|b^{(2)})<br>$$</p>
<p>设已完成第$k-1$步的选主元素、交换两行及消元计算，$(A|b)$约化为：</p>
<span>
$$
(A^{(k)}|b^{(k)}) = \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1k} & \cdots & a_{1n} & b_1 \\\ & a_{22} & \cdots & a_{2k} & \cdots & a_{2n} & b_2 \\\ & & \ddots & \vdots & \ddots & \vdots & \vdots \\\ & & & a_{kk} & \cdots & a_{kn} & b_k \\\ & & & \vdots & \ddots & \vdots & \vdots \\\ & & & a_{nk} & \cdots & a_{nn} & b_n \end{bmatrix}
$$
</span>

<p>在$A^{(k)}$右下角子矩阵的第1列选取主元素：</p>
<p>$$<br>|a_{i_k,k}| &#x3D; \max_{k \leq i \leq n} |a_{i,k}| \neq 0<br>$$</p>
<p>消元后三角矩阵</p>
<span>
$$
\begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\\ & a_{22} & \cdots & a_{2n} \\\ & & \ddots & \vdots \\\ & & & a_{nn} \end{bmatrix} \begin{bmatrix} x_1 \\\ x_2 \\\ \vdots \\\ x_n \end{bmatrix} = \begin{bmatrix} b_1 \\\ b_2 \\\ \vdots \\\ b_n \end{bmatrix} 
$$
</span>

<p>回代求解公式</p>
<span>
$$
 x_n = \dfrac{b_n}{a_{nn}} \qquad\\
 x_i = \left(b_i - \sum\limits_{j=i+1}^{n} a_{ij} x_j\right) \bigg/ a_{ii} \quad (i = n-1, \ldots, 2, 1)
$$
</span>

<h2 id="矩阵三角分解法"><a href="#矩阵三角分解法" class="headerlink" title="矩阵三角分解法"></a>矩阵三角分解法</h2><p><strong>定理</strong> </p>
<p>设$A$为$n$阶矩阵，如果$A$的顺序主子式$|D_i| \neq 0$ $(i &#x3D; 1,2,\cdots,n-1)$</p>
<p>则$A$的$LU$分解唯一</p>
<p><strong>（其中$L$为单位下三角阵，U为上三角矩阵）</strong></p>
<h3 id="道立特分解法（Doolittle-Factorization）"><a href="#道立特分解法（Doolittle-Factorization）" class="headerlink" title="道立特分解法（Doolittle Factorization）"></a>道立特分解法（Doolittle Factorization）</h3><p>通过比较法直接导出L和U的计算公式。</p>
<p><img src="/blog/image/Snipaste_2025-04-07_20-28-30.png"></p>
<p><strong>方法备注：</strong></p>
<ol>
<li><span style="color:#FF0000">L的对角线元素为1，U的第一行元素$u_{1j}&#x3D;a_{1j}$</span></li>
<li>然后求L的第一列元素，随后求U的第二列，然后L，随后U，交替往复。<strong>（瞪眼法）</strong></li>
</ol>
<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><blockquote>
<span>
$$
A=\begin{bmatrix}1&1&1\\0&4&-1\\2&-2&1\end{bmatrix}=\begin{bmatrix}1&0&0\\0&1&0\\2&-1&1\end{bmatrix}\begin{bmatrix}1&1&1\\0&4&-1\\0&0&-2\end{bmatrix}=LU
$$
</span></blockquote>
<blockquote>
<p>设</p>
<span>
$$
A = \begin{bmatrix} 2 & 1 & 1 \\ 2 & 3 & 2 \\ 2 & 3 & 4 \end{bmatrix}, \quad b = \begin{bmatrix} 4 \\ 7 \\ 9 \end{bmatrix}
$$
</span>



<p>将 $A$ 作 LU 分解，求解 $AX &#x3D; b$。</p>
<p><strong>解：</strong></p>
<span>
$$
LU = 
\begin{bmatrix}
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 
\end{bmatrix}
\begin{bmatrix}
2 & 1 & 1 \\
0 & 2 & 1 \\
0 & 0 & 2
\end{bmatrix}
$$

</span>
$$
Ly = b \Rightarrow y = \begin{bmatrix} 4 \\ 3 \\ 2 \end{bmatrix}, \quad
UX = y \Rightarrow X = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}.
$$</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-07_10-31-16.png"></p>
</blockquote>
<h3 id="平方根法（Choleski’s-Method）"><a href="#平方根法（Choleski’s-Method）" class="headerlink" title="平方根法（Choleski’s Method）"></a>平方根法（Choleski’s Method）</h3><blockquote>
<p><strong>对称矩阵</strong></p>
<p>一个矩阵 $A &#x3D; (a_{ij})_{n \times n}$ 称为<strong>对称阵</strong>，如果满足：</p>
<p>$a_{ij} &#x3D; a_{ji}$</p>
<p><strong>正定矩阵</strong></p>
<p>一个矩阵 $A$ 称为<strong>正定阵</strong>，如果对任意非零向量 $\vec{x} \neq \vec{0}$，满足： $\vec{x}^T A \vec{x} &gt; 0$</p>
<p><strong>对称正定矩阵的性质</strong></p>
<ol>
<li><p><strong>逆矩阵性质</strong> $A^{-1}$ 仍为对称正定矩阵，且其主对角元满足： $a_{ii} &gt; 0 \quad (i&#x3D;1,2,\cdots,n)$</p>
</li>
<li><p><strong>主子阵性质</strong><br>&#x20;$A$ 的任意<strong>顺序主子阵</strong>（leading principal submatrices） $A_k$ （ $k&#x3D;1,2,\cdots,n$ ）均为对称正定矩阵。</p>
</li>
<li><p><strong>特征值性质</strong><br>&#x20;$A$ 的所有特征值 $\lambda_i$ 均为正数： $\lambda_i &gt; 0 \quad (i&#x3D;1,2,\cdots,n)$</p>
</li>
<li><p><strong>主子式性质</strong> </p>
<p>$A$ 的全部顺序主子式满足： $\det(A_k) &gt; 0 \quad (k&#x3D;1,2,\cdots,n)$ 特别地，矩阵行列式可表示为： $\det(A) &#x3D; \prod_{i&#x3D;1}^n \lambda_i$</p>
</li>
</ol>
</blockquote>
<hr>
<p>设<strong>对称正定</strong>矩阵$A$的LU分解结果为：<br>$$<br>A &#x3D; LU<br>$$<br>其中：</p>
<ul>
<li><p>$L$为<strong>单位下三角阵</strong>（主对角线元素为1）</p>
</li>
<li><p>$U$为<strong>上三角阵</strong>，可进一步分解为对角阵乘积：</p>
<p><img src="/blog/image/Snipaste_2025-04-21_09-49-01.png"></p>
</li>
</ul>
<p>由对称性$A &#x3D; A^T$，有$L&#x3D;\tilde{U}^T$， 故$A &#x3D; LDL^T$</p>
<p>取对角阵的平方根：</p>
<p>$$<br>D^{1&#x2F;2} &#x3D; \mathrm{diag}\left( \sqrt{u_{11}}, \sqrt{u_{22}}, \dots, \sqrt{u_{nn}} \right)<br>$$</p>
<p>定义新的下三角阵： $\tilde{L} &#x3D; LD^{1&#x2F;2}$ 则矩阵可表示为： $A &#x3D; \tilde{L}\tilde{L}^T$</p>
<p><strong>定理</strong> </p>
<p>设矩阵$A \in \mathbb{R}^{n \times n}$对称正定，则存在<strong>非奇异下三角阵</strong>$L$满足： $A &#x3D; LL^T$ 若进一步限定$L$的主对角元素满足： $l_{ii} &gt; 0 \quad (i&#x3D;1,2,\dots,n)$ 则该分解<strong>唯一存在</strong>。</p>
<hr>
<h3 id="追赶法"><a href="#追赶法" class="headerlink" title="追赶法"></a>追赶法</h3><span>
$$
A=\begin{bmatrix}b_1&c_1\\a_2&b_2&c_2\\&\ddots&\ddots&\ddots\\&&a_{n-1}&b_{n-1}&c_{n-1}\\&&&a_n&b_n\end{bmatrix}=\begin{bmatrix}\alpha_1\\r_2&\alpha_2\\&\ddots&\ddots\\&&r_n&\alpha_n\end{bmatrix}\begin{bmatrix}1&\beta_1\\&1&\ddots\\&&\ddots&\beta_{n-1}\\&&&1\end{bmatrix}
$$
</span>

<p>并且满足</p>
<ol>
<li><p>$a_i \ne 0\ (i &#x3D; 2, 3, \dots, n),\ c_i \ne 0\ (i &#x3D; 1, 2, \dots, n - 1);$</p>
</li>
<li><p>$|b_1| &gt; |c_1|,\ |b_i| \ge |a_i| + |c_i|\ (i &#x3D; 2, 3, \dots, n - 1),\ |b_n| &gt; |a_n|.$</p>
</li>
</ol>
<p>$$<br>\boxed{<br>\text{条件1保证方程组不能降阶，条件2保证三角分解可做到底。}<br>}<br>$$</p>
<p>$$<br>r_i&#x3D;a_i<br>$$</p>
<p>$$<br>\beta_1&#x3D;\frac{c_1}{b_1}<br>$$</p>
<p>$$<br>\beta_i&#x3D;\frac{c_i}{b_i-a_i \beta_{i-1}}<br>$$</p>
<p>$$<br>\alpha_1&#x3D;b_{1}\quad \<br>\alpha_{i}&#x3D;b_{i}-a_{i}\beta_{i-1}<br>$$</p>
<hr>
<blockquote>
<p><strong>解题过程</strong></p>
<ol>
<li><p><strong>方程组分解</strong>： 原方程组$AX &#x3D; f$分解为两个三角方程组：</p>
</li>
<li><p><strong>计算 ${\beta_i}$ 的递推关系</strong>：</p>
</li>
<li><p><strong>计算 ${\alpha_i}$ 和${r_i}$的递推关系</strong>：</p>
</li>
<li><p><strong>解下三角方程组 $Ly &#x3D; f$</strong>：</p>
</li>
<li><p><strong>解上三角方程组 $Ux &#x3D; y$</strong>：</p>
</li>
</ol>
<p><strong>例题</strong></p>
<p><img src="/blog/image/shuzhifenxi1.jpg"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-07_11-03-13.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-07_15-09-52.png"></p>
</blockquote>
<p><strong>定理</strong></p>
<blockquote>
<p><strong>对角占优矩阵（Diagonally Dominant Matrix）</strong></p>
<p>对于$n$阶矩阵$A &#x3D; (a_{ij})$，若其<strong>每一行</strong>满足：<br>$$<br>|a_{ii}| \geq \sum_{\substack{j&#x3D;1 \ j \neq i}}^{n} |a_{ij}| \quad (i&#x3D;1,2,\dots,n)<br>$$</p>
<p>则称$A$为<strong>行对角占优矩阵</strong>。</p>
<p>若其<strong>每一列</strong>满足：<br>$$<br>|a_{jj}| \geq \sum_{\substack{i&#x3D;1 \ i \neq j}}^{n} |a_{ij}| \quad (j&#x3D;1,2,\dots,n)<br>$$</p>
<p>则称$A$为<strong>列对角占优矩阵</strong>。</p>
<p><u>上面两个条件满足其一就是对角占优矩阵</u></p>
<hr>
<p><strong>严格对角占优矩阵（Strictly Diagonally Dominant Matrix）</strong></p>
<p>将上述不等式中的”≥”改为严格”&gt;”：</p>
</blockquote>
<p>若$A$为<strong>对角占优</strong>（diagonally dominant）的三对角阵，且满足：</p>
<ol>
<li><p>首尾行条件：$|b_1| &gt; |c_1| &gt; 0$   $|b_n| &gt; |a_n| &gt; 0$</p>
</li>
<li><p>非零条件：$a_i \neq 0 $  $c_i \neq 0 $</p>
<p>则追赶法可解以$A$为系数矩阵的方程组。</p>
</li>
</ol>
<p><strong>注</strong><br>当$A$是<strong>严格对角占优阵</strong>时（即满足严格不等式 $|b_i| &gt; |a_i| + |c_i|$），不要求三对角线上所有元素非零（允许$a_i&#x3D;0$或$c_i&#x3D;0$的特殊情况存在）。</p>
<hr>
<h2 id="线性方程组的误差分析"><a href="#线性方程组的误差分析" class="headerlink" title="线性方程组的误差分析"></a>线性方程组的误差分析</h2><h3 id="情形1：矩阵-A-精确，右端项-vec-b-存在误差"><a href="#情形1：矩阵-A-精确，右端项-vec-b-存在误差" class="headerlink" title="情形1：矩阵$A$精确，右端项$\vec{b}$存在误差"></a>情形1：矩阵$A$精确，右端项$\vec{b}$存在误差</h3><p>设$\vec{b}$有扰动$\delta\vec{b}$，对应解的扰动为$\delta\vec{x}$，满足：</p>
<p>$$<br>A(\vec{x} + \delta\vec{x}) &#x3D; \vec{b} + \delta\vec{b}<br>$$</p>
<ol>
<li><p><strong>扰动解表达式</strong> $\delta\vec{x} &#x3D; A^{-1}\delta\vec{b}$</p>
</li>
<li><p><strong>范数不等式</strong> $|\delta\vec{x}| \leq |A^{-1}| \cdot |\delta\vec{b}|$</p>
</li>
<li><p><strong>原始解范数关系</strong> $|\vec{b}| &#x3D; |A\vec{x}| \leq |A| \cdot |\vec{x}| \implies \frac{1}{|\vec{x}|} \leq \frac{|A|}{|\vec{b}|}$</p>
</li>
<li><p><strong>相对误差界</strong> $\frac{|\delta\vec{x}|}{|\vec{x}|} \leq |A| \cdot |A^{-1}| \cdot \frac{|\delta\vec{b}|}{|\vec{b}|}$</p>
</li>
</ol>
<h3 id="情形2：矩阵-A-存在误差-delta-A"><a href="#情形2：矩阵-A-存在误差-delta-A" class="headerlink" title="情形2：矩阵$A$存在误差$\delta A$"></a>情形2：矩阵$A$存在误差$\delta A$</h3><p>设矩阵有扰动$\delta A$，解的扰动满足：</p>
<p>$$<br>(A + \delta A)(\vec{x} + \delta\vec{x}) &#x3D; \vec{b}<br>$$</p>
<p>推导过程略</p>
<p>$$<br>\frac{|\delta \bar{x}|}{|\bar{x}|} \leq \frac{|A^{-1}| \cdot |\delta A|}{1 - |A^{-1}| \cdot |\delta A|} &#x3D; \frac{|A| \cdot |A^{-1}| \cdot \frac{|\delta A|}{|A|}}{1 - |A| \cdot |A^{-1}| \cdot \frac{|\delta A|}{|A|}}<br>$$</p>
<hr>
<h3 id="条件数"><a href="#条件数" class="headerlink" title="条件数"></a>条件数</h3><p>矩阵$A$的条件数定义为：</p>
<p>$$<br>\text{cond}(A) &#x3D; |A| \cdot |A^{-1}|<br>$$</p>
<p><strong>核心结论</strong></p>
<p><strong>条件数与病态性关系</strong>：</p>
<p>$\text{cond}(A) \text{ 越大} \implies A \text{ 越病态} \implies \text{解算结果越难准确}$</p>
<p>$cond(A)$的大小与$||.||$的取法有关，但相对大小一致</p>
<p><strong>常用条件数定义</strong></p>
<p><em>一般矩阵条件数</em></p>
<span>
$$
 \begin{cases}
 \text{cond}(A)_1 \\
 \text{cond}(A)_\infty \\
 \text{cond} (A)_2 = \sqrt{\frac{\lambda_{\max}(A^T A)}{\lambda_{\min}(A^T A)}} 
 \end{cases} 
$$
</span>

<p><em>对称矩阵的特殊情形</em></p>
<p>当$A$为对称矩阵时： $\text{cond}(A)_2 &#x3D; \frac{\max|\lambda|}{\min|\lambda|}$</p>
<p><strong>条件数性质</strong></p>
<p>□ 若$A$可逆，则$\text{cond}(A)_p \geq 1$；</p>
<p> □ 若$A$可逆且$\alpha \in \mathbb{R}$，则$\text{cond}(\alpha A) &#x3D; \text{cond}(A)$；</p>
<p>□若$A$正交，则$\text{cond}(A)_2 &#x3D; 1$；</p>
<p>□ 若$A$可逆且$R$正交，则： $\text{cond}(RA)_2 &#x3D; \text{cond}(AR)_2 &#x3D; \text{cond}(A)_2$</p>
<hr>
<h3 id="近似解的误差估计及改善"><a href="#近似解的误差估计及改善" class="headerlink" title="近似解的误差估计及改善"></a>近似解的误差估计及改善</h3><p>设 $A\vec{x} &#x3D; \vec{b}$ 的近似解为 $\vec{x}^*$，则：</p>
<ol>
<li>残差向量：$\vec{r} &#x3D; \vec{b} - A\vec{x}^* \neq \vec{0}$</li>
<li>误差上界：</li>
</ol>
<p>$$<br>\frac{|\vec{x} - \vec{x}^*|}{|\vec{x}|} \leq \text{cond}(A) \cdot \frac{|\vec{r}|}{|\vec{b}|}<br>$$</p>
<p><strong>改善方法</strong></p>
<p><strong>Step 1</strong> 求初始近似解： $A\vec{x}_1 &#x3D; \vec{b} \quad \Rightarrow \quad \vec{x}_1$</p>
<p><strong>Step 2</strong> 计算残差： $\vec{r}_1 &#x3D; \vec{b} - A\vec{x}_1$</p>
<p><strong>Step 3</strong> 解校正方程： $A\vec{d}_1 &#x3D; \vec{r}_1 \quad \Rightarrow \quad \vec{d}_1$</p>
<p><strong>Step 4</strong> 更新解： $\vec{x}_2 &#x3D; \vec{x}_1 + \vec{d}_1$</p>
<p>若 $\vec{d}_1$ 可精确解得：</p>
<p>$$<br>\vec{x}_2 &#x3D; \vec{x}_1 + A^{-1}(\vec{b} - A\vec{x}_1) &#x3D; A^{-1}\vec{b}<br>$$</p>
<p>此时 $\vec{x}_2$ 即为精确解。</p>
<p><strong>经验表明</strong>： 若$A$不是非常病态（例如：$ε \cdot \text{cond}(A)_∞ &lt; 1$），则如此迭代可达到机器精度； 但若$A$病态，则此算法也不能改进。</p>
<h2 id="解线性方程的迭代法"><a href="#解线性方程的迭代法" class="headerlink" title="解线性方程的迭代法"></a>解线性方程的迭代法</h2><p>方程组改写形式</p>
<p>$$<br>A \bar{x} &#x3D; \bar{b} \quad \Rightarrow \quad \bar{x} &#x3D; B \bar{x} + \bar{f}<br>$$</p>
<p>建立迭代</p>
<p>$$<br>\bar{x}^{(k+1)} &#x3D; B \bar{x}^{(k)} + \bar{f}<br>$$</p>
<p>从初值$\bar{x}^{(0)}$得到${\bar{x}^{(k)}}$</p>
<h3 id="Jacobi-雅可比-迭代法"><a href="#Jacobi-雅可比-迭代法" class="headerlink" title="Jacobi(雅可比)迭代法"></a>Jacobi(雅可比)迭代法</h3><p>线性方程组标准形式</p>
<span>
$$
\begin{cases} 
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1 \\\ 
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2 \\\
\vdots \quad \vdots \quad \ddots \quad \vdots \\\
a_{n1}x_1 + a_{n2}x_2 + \cdots + a_{nn}x_n = b_n 
\end{cases}
$$
</span>

<p><strong>条件</strong>：$a_{ii} \neq 0$（主对角元非零）</p>
<p><strong>Jacobi迭代公式（分量形式）</strong></p>
<p>第i分量迭代式</p>
<p>$$<br>x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left( b_i - \sum_{\substack{j&#x3D;1 \ j \neq i}}^{n} a_{ij}x_j^{(k)} \right)<br>$$</p>
<ol>
<li>第一分量：$x_1 &#x3D; \frac{1}{a_{11}}(-a_{12}x_2 - \cdots - a_{1n}x_n + b_1)$</li>
<li>第二分量：$x_2 &#x3D; \frac{1}{a_{22}}(-a_{21}x_1 - \cdots - a_{2n}x_n + b_2)$</li>
<li>第n分量：$x_n &#x3D; \frac{1}{a_{nn}}(-a_{n1}x_1 - \cdots - a_{nn-1}x_{n-1} + b_n)$</li>
</ol>
<p><strong>Jacobi迭代的矩阵形式</strong></p>
<p><strong>矩阵分解形式</strong></p>
<p><img src="/blog/image/Snipaste_2025-04-06_16-16-19.png"></p>
<p>$$<br>A\vec{x} &#x3D; \vec{b} \Leftrightarrow (D + L + U)\vec{x} &#x3D; \vec{b}<br>$$</p>
<span>
$$
\begin{gathered}
\boldsymbol{L}=\begin{bmatrix}0\\a_{21}&0\\\vdots&\ddots\\\vdots&&\ddots\\a_{n-1}&\cdots&\cdots&a_{n,n-1}&0\end{bmatrix}
U=\begin{bmatrix}
0&a_{12}&\cdots&a_{1n}\\&\ddots&\ddots&\vdots\\&&\ddots&a_{n-1,n}\\
&&&0
\end{bmatrix}
\quad
\boldsymbol{D}=\begin{bmatrix}a_{11}\\&a_{22}\\&&\ddots\\&&&\ddots\\&&&&a_{nn}\end{bmatrix}\quad\end{gathered}
$$

</span>


<ul>
<li><p><strong>对角阵</strong>$D$： </p>
</li>
<li><p><strong>严格下三角</strong>$L$：</p>
</li>
<li><p><strong>严格上三角</strong>$U$：</p>
</li>
</ul>
<p><strong>迭代推导过程</strong></p>
<span>
$$
\begin{cases} D\vec{x} = -(L + U)\vec{x} + \vec{b} \\\ \vec{x} = -D^{-1}(L + U)\vec{x} + D^{-1}\vec{b} \\\ \vec{x}^{(k+1)} = -D^{-1}(L + U)\vec{x}^{(k)} + D^{-1}\vec{b} \end{cases}
$$
</span>

<p><span style="color:#FF0000">Jacobi迭代阵</span><br>$$<br> B_J&#x3D;-D^{-1}(L + U)<br>$$</p>
<h3 id="Gauss-Seidel迭代法"><a href="#Gauss-Seidel迭代法" class="headerlink" title="Gauss-Seidel迭代法"></a>Gauss-Seidel迭代法</h3><p><strong>迭代公式</strong></p>
<ol>
<li>第1分量： $x_1^{(k+1)} &#x3D; \frac{1}{a_{11}} \left( -a_{12}x_2^{(k)} - a_{13}x_3^{(k)} - \cdots - a_{1n}x_n^{(k)} + b_1 \right)$</li>
<li>第2分量： $x_2^{(k+1)} &#x3D; \frac{1}{a_{22}} \left( -a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} - \cdots - a_{2n}x_n^{(k)} + b_2 \right)$</li>
<li>第3分量： $x_3^{(k+1)} &#x3D; \frac{1}{a_{33}} \left( -a_{31}x_1^{(k+1)} - a_{32}x_2^{(k+1)} - \cdots - a_{3n}x_n^{(k)} + b_3 \right)$</li>
<li>第n分量： $x_n^{(k+1)} &#x3D; \frac{1}{a_{nn}} \left( -a_{n1}x_1^{(k+1)} - \cdots - a_{n,n-1}x_{n-1}^{(k+1)} + b_n \right)$</li>
</ol>
<p>通用形式</p>
<p>$x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left( b_i - \sum_{j&#x3D;1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j&#x3D;i+1}^n a_{ij}x_j^{(k)} \right)$</p>
<p><strong>矩阵形式</strong></p>
<p>矩阵分解</p>
<p>$A &#x3D; D + L + U$ <strong>迭代公式推导</strong></p>
<ol>
<li>原始形式： $x^{(k+1)} &#x3D; -D^{-1}(Lx^{(k+1)} + Ux^{(k)}) + D^{-1}b$</li>
<li>等价变形： $(D + L)x^{(k+1)} &#x3D; -Ux^{(k)} + b$</li>
<li>标准形式： $x^{(k+1)} &#x3D; -(D + L)^{-1}Ux^{(k)} + (D + L)^{-1}b$</li>
</ol>
<p><span style="color:#FF0000">Gauss-Seidel迭代阵</span><br>$$<br>B &#x3D; -(D + L)^{-1}U<br>$$</p>
<hr>
<p><strong>收敛性说明</strong></p>
<blockquote>
<p><strong>注</strong>：两种方法都存在收敛性问题。<br>有例子表明：</p>
<ul>
<li>Gauss-Seidel法收敛时，Jacobi法可能不收敛</li>
<li>Jacobi法收敛时，Gauss-Seidel法也可能不收敛</li>
</ul>
</blockquote>
<h3 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/Snipaste_2025-06-07_16-51-36.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-07_16-51-42.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_10-29-46.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_10-50-29.png"></p>
</blockquote>
<h2 id="迭代法的收敛性"><a href="#迭代法的收敛性" class="headerlink" title="迭代法的收敛性"></a>迭代法的收敛性</h2><h3 id="递推公式与收敛条件"><a href="#递推公式与收敛条件" class="headerlink" title="递推公式与收敛条件"></a>递推公式与收敛条件</h3><ol>
<li><strong>递推公式</strong>：</li>
</ol>
<p>$$<br>  \vec x^{(k+1)} &#x3D; B\vec x^{(k)} +\vec f<br>$$</p>
<ol start="2">
<li><strong>收敛条件推导</strong>：</li>
</ol>
<p>$$<br>e^{(k+1)} &#x3D; x^{(k+1)} - x^*<br>&#x3D; (Bx^{(k)} + f) - (Bx^* + f)<br>&#x3D; B(x^{(k)} - x^*)<br>&#x3D; Be^{(k)}<br>$$</p>
<p>进一步可得：</p>
<p>$$<br>e^{(k)} &#x3D; B^k e^{(0)}<br>$$</p>
<p><strong>定理</strong>：<br>设方程 $x &#x3D; Bx + f$ 存在唯一解，则从任意初始值 $x^{(0)}$ 出发，迭代格式<br>$$<br>x^{(k+1)} &#x3D; Bx^{(k)} + f<br>$$</p>
<p>收敛的充要条件是 $B^k \to 0$（当 $k \to \infty$ 时）。</p>
<p><strong>矩阵序列收敛定义</strong>：<br>设 </p>
<p>$A &#x3D; (a_{ij})_{n \times n}$</p>
<p>$A_k &#x3D; (a_{ij}^{(k)})_{n \times n} \in \mathbb{R}^{n \times n}$</p>
<p>则<br>$$<br>\lim_{k \to \infty} A_k &#x3D; A<br>$$</p>
<p>定义为对所有 $1 \leq i, j \leq n$，满足</p>
<p>$$<br>\lim_{k \to \infty} a_{ij}^{(k)} &#x3D; a_{ij}<br>$$</p>
<p>等价于对任何算子范数有$||A_k-A||\to 0 \quad as \quad k\to \infty$</p>
<p><strong>定理：</strong><br>$$<br>B^k \to0\Leftrightarrow \rho(B)&lt;1<br>$$</p>
<p><strong>迭代算法收敛条件</strong></p>
<p>$$<br>\text{迭代从任意向量出发收敛 } \Leftrightarrow B^k \to 0 \quad (k \to \infty) \Leftrightarrow \rho(B) &lt; 1<br>$$</p>
<p><strong>定理</strong></p>
<p>设有方程组</p>
<p>$$<br>x &#x3D; Bx + f<br>$$</p>
<p>对于任意初始向量 $x^{(0)}$ 及任意 $f$，解此方程组的迭代法</p>
<p>$$<br>x^{(k+1)} &#x3D; Bx^{(k)} + f<br>$$</p>
<p>收敛的充要条件是</p>
<p>$$<br>\rho(B) &lt; 1<br>$$</p>
<p>当$\rho(B) &lt; 1$时，迭代过程收敛，且$\rho(B) $越小，迭代收敛越快。</p>
<hr>
<p>注意到 $\vec{e}^{(k+1)} &#x3D; \vec{x}^{(k+1)} - \vec{x}^* &#x3D; B(\vec{x}^{(k)} - \vec{x}^*) &#x3D; B\vec{e}^{(k)} &#x3D; B^{k+1}\vec{e}^{(0)}$</p>
<p>则 $||\vec{e}^k|| &#x3D; ||B^k\vec{e}^{(0)}|| \leq ||B^k|| ||\vec{e}^{(0)}|| \leq ||B||^k||\vec{e}^{(0)}||$<br>$$<br>||\vec{e}^k|| \approx (\rho(B))^k||\vec{e}^{(0)}||<br>$$</p>
<p><strong>定义</strong></p>
<p>称 $R(B) &#x3D; -\ln \rho(B)$ 为迭代法的<span style="color:#FF0000">收敛速度</span></p>
<hr>
<p><strong>定理（充分条件）</strong></p>
<p>若存在一个矩阵范数使得 $|B| &#x3D; q &lt; 1$，则迭代收敛，且有下列误差估计：</p>
<p>$$<br>|\vec{x}^* - \vec{x}^{(k)}| \leq \frac{q}{1-q} |\vec{x}^{(k)} - \vec{x}^{(k-1)}|<br>$$</p>
<p>$$<br>|\vec{x}^* - \vec{x}^{(k)}| \leq \frac{q^k}{1-q} |\vec{x}^{(1)} - \vec{x}^{(0)}|<br>$$</p>
<p><strong>注</strong>：因 $\rho(B) \leq |B| &lt; 1$，故收敛性得证。</p>
<hr>
<p><strong>定理（充分条件）：</strong></p>
<p>若A为严格对角占优阵，则解$A \vec x&#x3D; \vec b$的Jacobi和Gauss-Seidel迭代均收敛。</p>
<hr>
<h3 id="例题-3"><a href="#例题-3" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p>已知方程组</p>
<span>
$$
\begin{bmatrix} 1 & -2 \\\ -0.32 & 1 \end{bmatrix} 
\begin{bmatrix} x_1 \\\ x_2 \end{bmatrix} = \begin{bmatrix} b_1 \\\ b_2 \end{bmatrix}
$$
</span>

<p>考察解此方程组的Jacobi迭代法是否收敛，它的渐近收敛速度为多少。</p>
<p><strong>解</strong></p>
<p>方程组的Jacobi迭代阵<br>$$<br>B &#x3D; \begin{bmatrix} 0 &amp; 2 \\ 0.32 &amp; 0 \end{bmatrix}<br>$$</p>
<p>$$<br>|\lambda I - B| &#x3D; \begin{vmatrix} \lambda &amp; -2 \\ -0.32 &amp; \lambda \end{vmatrix} &#x3D; 0<br>$$</p>
<p>$\lambda_1 &#x3D; -0.8, \lambda_2 &#x3D; 0.8$</p>
<ul>
<li><p>因 $\rho(B) &#x3D; 0.8$ 故方程组的Jacobi迭代收敛。</p>
</li>
<li><p>其渐近收敛速度 $R(B) &#x3D; -\ln \rho(B) &#x3D; -\ln 0.8 &#x3D; 0.223$</p>
</li>
</ul>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_14-32-52.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_14-42-52.png"></p>
</blockquote>
<h2 id="松弛法"><a href="#松弛法" class="headerlink" title="松弛法"></a>松弛法</h2><p><strong>基本迭代公式</strong><br>$$<br>x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left[ b_i - \sum_{j&#x3D;1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j&#x3D;i+1}^n a_{ij}x_j^{(k)} \right]<br>$$</p>
<p><strong>残差形式表示</strong></p>
<p>$$<br>&#x3D; x_i^{(k)} + \frac{r_i^{(k+1)}}{a_{ii}}<br>$$</p>
<p>其中残差$r_i^{(k+1)}$定义为：</p>
<p>$$<br>r_i^{(k+1)} &#x3D; b_i - \sum_{j&lt;i} a_{ij}x_j^{(k+1)} - \sum_{j \geq i} a_{ij}x_j^{(k)}<br>$$</p>
<p>令</p>
<p>$$<br>x_i^{(k+1)} &#x3D; x_i^{(k)} + \omega \frac{r_i^{(k+1)}}{a_{ii}}<br>$$</p>
<p>$$<br>&#x3D;x_i^{(k)} + \frac{\omega }{a_{ii}}\left [b_i - \sum_{j&lt;i} a_{ij}x_j^{(k+1)} - \sum_{j \geq i} a_{ij}x_j^{(k)} \right ]<br>$$</p>
<p>选取合适的$\omega$来加速收敛，这就是<u>松弛法</u>。</p>
<ol>
<li><strong>低松弛法</strong> (Under-Relaxation methods)： $0 &lt; \omega &lt; 1$</li>
<li><strong>Gauss-Seidel法</strong>： $\omega &#x3D; 1$</li>
<li><strong>超松弛法</strong> (SOR&#x2F;Successive Over-Relaxation methods)： $\omega &gt; 1$</li>
</ol>
<p><strong>矩阵形式公式</strong></p>
<ol>
<li><strong>基本形式</strong>：</li>
</ol>
<p>$$<br>  \vec{x}^{(k+1)} &#x3D; x_i^{(k)} + \omega \frac{r_i^{(k+1)}}{a_{ii}}<br>  &#x3D; (1 - \omega) \vec{x}^{(k)} + \omega D^{-1} \left[ -L \vec{x}^{(k+1)} - U \vec{x}^{(k)} + \vec{b} \right]<br>$$</p>
<ol start="2">
<li><strong>标准迭代形式</strong>：</li>
</ol>
<p>$$<br>\vec{x}^{(k+1)}<br>&#x3D; (D + \omega L)^{-1} \left[ (1 - \omega) D - \omega U \right] \vec{x}^{(k)} + (D + \omega L)^{-1} \omega \vec{b} \<br>$$</p>
<p>$$<br>H_{\omega}<br>&#x3D;(D + \omega L)^{-1} \left[ (1 - \omega) D - \omega U \right]<br>$$</p>
<p><strong>定理</strong>：设$A$可逆，且$a_{ii} \neq 0$，则松弛法从任意$\vec{x}^{(0)}$出发对某个$\omega$收敛的充要条件为： $\rho(H_\omega) &lt; 1$ 其中<br>$$<br>H_\omega &#x3D; (D + \omega L)^{-1} \left[ (1 - \omega) D - \omega U \right]<br>$$</p>
<p>为迭代矩阵</p>
<hr>
<p><strong>定理</strong>（必要条件）</p>
<p>设$A$可逆，且$a_{ii} \neq 0$，则松弛法从任意$\vec{x}^{(0)}$出发对某个$\omega$收敛$\Rightarrow 0&lt; \omega&lt;2 $</p>
<hr>
<p><strong>定理（Ostrowski-Reich充分条件）</strong></p>
<p><strong>设</strong> $A$ 为对称正定矩阵，且松弛因子满足 $0 &lt; \omega &lt; 2$，<br><strong>则</strong> 松弛法从任意初始向量 $\vec{x}^{(0)}$ 出发均收敛。</p>
<hr>
<p><strong>定理</strong></p>
<p><strong>设</strong> $A$ 为对称正定三对角矩阵，则：</p>
<ol>
<li>谱半径关系：</li>
</ol>
<p>$$<br>\rho(B_{G-S}) &#x3D; [\rho(B_J)]^2 &lt; 1<br>$$</p>
<ol start="2">
<li>SOR最佳松弛因子为</li>
</ol>
<p>$$<br>\omega&#x3D;\frac{2}{1 + \sqrt{1 - [\rho(B_J)]^2}}<br>$$</p>
<ol start="3">
<li>此时收敛速度</li>
</ol>
<p>$$<br>\rho(H_ \omega) &#x3D; \omega - 1<br>$$</p>
<h3 id="例题-4"><a href="#例题-4" class="headerlink" title="例题"></a>例题</h3><blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_15-03-59.png"></p>
</blockquote>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-06-09_15-14-08.png"></p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
  </entry>
  <entry>
    <title>机电一体化分析与建模（1-4章）</title>
    <url>/blog/2025/05/12/%E6%9C%BA%E7%94%B5%E4%B8%80%E4%BD%93%E5%8C%96%E5%88%86%E6%9E%90%E4%B8%8E%E5%BB%BA%E6%A8%A1%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第二章12 16题<br>第三章3 7 8<br>第四章8 11<br>第五章19<br>第六章9</p>
<p>不定项选择题（20分）</p>
<p>简答题（20分，5题）</p>
<p>计算题（20分，4题）</p>
<p>设计题（20分，2题）</p>
<p>综合题（20分，2题）</p>
<h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><ol>
<li><p><strong>机电系统</strong>：是机械电子系统的简称，是由<strong>机械系统</strong>和<strong>电气系统</strong>组成的，其核心是<strong>控制系统。</strong></p>
</li>
<li><p>机电控制系统一般由7个部分组成：</p>
</li>
</ol>
<p><img src="/blog/image/Snipaste_2025-06-28_08-40-57.png"></p>
<p><strong>放大器</strong>：是将比较得出的偏差信号进行放大，用来推动<strong>执行器</strong>去控制被控对象。</p>
<p><strong>被控对象</strong>：是控制系统要操纵的对象。</p>
<p><strong>机电控制系统的执行器</strong>：也称为执行元件或执行装置。</p>
<ol start="3">
<li>根据<strong>使用能量的不同</strong>，可以将<strong>执行装置</strong>大体分为<u>电气式</u>、<u>液压式</u>、<u>气动式</u></li>
</ol>
<p><strong>液压式执行装置</strong>：</p>
<p>a)    优点：液压驱动装置具有<u>重量轻、惯性小、快速性好</u>等优点；</p>
<p>b)   缺点：液压元件<u>易漏油</u>，会<u>污染环境</u>，也有可能<u>引起火灾</u>；液压系统<u>易受环境温度变化的影响</u></p>
<p><strong>气动执行装置：</strong></p>
<p>a)    优点：是<u>动作迅速、反应快、维护简单、成本低</u>，同时由于空气黏度很小，压力损失小，节能高效，适用于<u>远距离输送</u>；<u>工作环境适应性好</u></p>
<p>b)   缺点：由于空气可压缩性较大。负载变化时系统的动作稳定性较差，也不易获得较大输出力或力矩，同时需要对气源中杂质和水分进行处理，排气时噪声较大。</p>
<ol start="4">
<li><p><strong>机电控制系统的基本要求</strong>：<u>稳定性、快速性、准确性</u></p>
<ul>
<li><p><u>稳定性</u>是保证控制系统正常工作的先决条件。</p>
</li>
<li><p>稳定系统：被控量偏离期望值的偏差 <strong>随时间增长逐渐减小或趋于零</strong>，过渡过程的振荡 <strong>逐渐减弱</strong>，最终能达到平衡状态（<span style="color:#FF0000">偏差减小，震荡减弱</span>）</p>
</li>
<li><p>不稳定系统：被控量偏离期望值的偏差 <strong>随时间增长而发散</strong>，过渡过程的振荡 <strong>逐步增强</strong>，导致被控量失控（）</p>
</li>
<li><p><strong>稳态误差</strong>：被控量的<u>稳态值</u>与<u>期望值</u>之间会有误差存在，称之为稳态误差。</p>
</li>
</ul>
</li>
<li><p><strong>机电控制系统控制方式的分类</strong>：一般可以分为<u>开环控制</u>、<u>闭环控制</u>和<u>复合控制</u>。</p>
</li>
<li><p><strong>复合控制方式</strong>：是把<u>偏差控制</u>与按<u>扰动控制</u>结合起来的控制方式</p>
</li>
<li><p><strong>开环控制系统与闭环控制系统不同的地方是</strong>：开环控制系统不需要被控对象的<u>反馈信号</u>，他的控制器直接根据<u>给定信号</u>去控制被控对象工作。</p>
</li>
</ol>
<h1 id="第二章-自动控制系统基本知识"><a href="#第二章-自动控制系统基本知识" class="headerlink" title="第二章 自动控制系统基本知识"></a>第二章 自动控制系统基本知识</h1><ol>
<li><p><strong>控制系统的组成</strong>：由<u>给定单元</u>、<u>控制单元</u>、<u>执行单元</u>、<u>被控对象</u>、<u>测量单元</u>等五大部分组成。</p>
<p><img src="/blog/image/Snipaste_2025-06-28_09-32-30.png"></p>
</li>
<li><p><strong>控制系统的分类：</strong></p>
<ul>
<li>按<strong>系统输入信号</strong>的特点分类：<u>定值控制系统</u>、<u>随动控制系统</u>、<u>程序控制系统</u>。</li>
<li>按<strong>系统信号的传递</strong>特点分类：<u>开环控制系统</u>、<u>闭环控制系统</u>、<u>复合控制系统</u>。</li>
<li>按<strong>系统的变量</strong>特点分类：<u>连续控制系统</u>、<u>离散控制系统</u>。</li>
</ul>
</li>
<li><p><strong>建立系统数学模型的方法</strong>：</p>
</li>
</ol>
<p>（1）分析计算法（<strong>解析法</strong>）</p>
<p>（2）<strong>实验测定法</strong></p>
<ol start="4">
<li><p><strong>传递函数</strong>定义为：在零初始条件下，线性定常系统的输出量的拉普拉斯变换式与输入量的拉普拉斯变换式之比  </p>
</li>
<li><p><strong>恒值系统与随动系统</strong>：它们的特征方程和通解是相同的，所不同的是它们的边界条件和特解。研究恒值系统和随动系统不仅在方法上基本相同，而且运动方程也很相似。（特解代表系统强制运动，通解代表系统自然运动）</p>
</li>
<li><p><strong>几个典型环节的传递函数</strong></p>
<ul>
<li><p><strong>比例环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_09-57-05.png"></p>
</li>
<li><p><strong>惯性环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-00-48.png"></p>
</li>
<li><p><strong>积分环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-00-58.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-17.png"></p>
</li>
<li><p><strong>振荡环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-10.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-24.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-29.png"></p>
</li>
<li><p><strong>实际微分环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-38.png"></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-43.png"></p>
</li>
<li><p><strong>延迟环节</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-50.png"></p>
</li>
</ul>
</li>
</ol>
<p><img src="/blog/image/Snipaste_2025-06-28_10-01-54.png"></p>
<h2 id="控制器的控制规律及响应特性（PID）"><a href="#控制器的控制规律及响应特性（PID）" class="headerlink" title="控制器的控制规律及响应特性（PID）"></a>控制器的控制规律及响应特性（PID）</h2><p><strong>1. 比例控制（P）</strong></p>
<p><u><strong>工作原理</strong></u></p>
<p>控制器输出与输入信号 <strong>成比例关系</strong>，数学表达式：</p>
<p>$$<br>y(t) &#x3D; Kx(t) \quad \text{或} \quad \Delta y &#x3D; K\Delta x<br>$$</p>
<p>（$K$ 为比例放大系数，$\Delta$ 表示信号变化量）</p>
<p><u><strong>特性</strong></u></p>
<ul>
<li><p><strong>余差特性</strong>：过渡过程结束后，被控量的稳定值与给定值存在 <strong>余差</strong>（偏差无法完全消除）。</p>
</li>
<li><p><strong>响应特性</strong>：比例系数 $K$ 越大，响应越快；$K$ 越小，响应越慢</p>
</li>
</ul>
<p><u><strong>性能</strong></u></p>
<ul>
<li><p><strong>优点</strong>：结构简单，响应快速</p>
</li>
<li><p><strong>缺点</strong>：无法消除稳态误差（余差），仅适用于对稳态精度要求不高的场景。</p>
</li>
</ul>
<blockquote>
<p>加快响应，<strong>但无法消除余差</strong></p>
</blockquote>
<hr>
<p>   <strong>2. 比例积分控制（PI）</strong></p>
<p><strong>工作原理</strong></p>
<p>   输出为 <strong>比例作用 + 积分作用</strong>，数学表达式：</p>
<p>$$<br>   y(t) &#x3D; K\left[ x(t) + \frac{1}{T_i} \int x(t)dt \right]<br>$$</p>
<p>   （$T_i$ 为积分时间，积分部分累积历史偏差，逐步消除余差）</p>
<p><strong>特性</strong></p>
<ul>
<li><p><strong>余差特性</strong>：积分作用可 <strong>理论上消除余差</strong>（稳态误差为零）。</p>
</li>
<li><p><strong>积分特性</strong>：$T_i$ 越小，积分速度越快、作用越强；但 $T_i$ 过小会导致系统振荡加剧，甚至失稳（积分作用与稳定性存在矛盾）。</p>
</li>
</ul>
<p><strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：消除稳态误差，提高控制精度；继承比例控制的快速性。</p>
</li>
<li><p><strong>缺点</strong>：积分作用会降低系统稳定性（需合理设置 $T_i$），过渡过程可能更振荡或变慢。</p>
<blockquote>
<p><strong>消除稳态误差，积分作用会降低系统稳定性</strong></p>
</blockquote>
<hr>
</li>
</ul>
<p>   <strong>3. 比例微分控制（PD）</strong></p>
<p>   <strong>工作原理</strong></p>
<p>   输出为 <strong>比例作用 + 微分作用</strong>，数学表达式：</p>
<p>$$<br>   y(t) &#x3D; K\left[ x(t) + T_d \frac{dx(t)}{dt} \right]<br>$$</p>
<p>   （$T_d$ 为微分时间，微分部分反映信号变化率，实现 “超前控制”）</p>
<p>   <strong>特性</strong></p>
<ul>
<li><p><strong>超前特性</strong>：微分作用可 <strong>预见偏差变化趋势</strong>（如偏差增大时提前抑制），改善动态响应。</p>
</li>
<li><p><strong>微分特性</strong>：$T_d$ 越大，微分作用越强，超调越小；但 $T_d$ 过大易引发被控量剧烈振荡；$T_d$ 过小则控制效果不明显。</p>
</li>
</ul>
<p>   <strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：抑制超调，改善动态响应（超前控制）</p>
</li>
<li><p><strong>缺点</strong>：对高频噪声敏感</p>
<blockquote>
<p>抑制超调，改善动态响应;微分作用过强会引发被控量剧烈振荡</p>
</blockquote>
<hr>
</li>
</ul>
<p>   <strong>4. 比例积分微分控制（PID）</strong></p>
<p>   <strong>工作原理</strong></p>
<p>   输出为 <strong>比例 + 积分 + 微分作用</strong>，数学表达式：</p>
<p>$$<br>y(t) &#x3D; K\left[ x(t) + \frac{1}{T_i} \int x(t)dt + T_d \frac{dx(t)}{dt} \right]<br>$$</p>
<p>   <strong>特性</strong></p>
<ul>
<li><p><strong>协同特性</strong>：综合三者优势，兼顾 <strong>快速性（P）、稳定性（D）、精度（I）</strong>。</p>
</li>
<li><p><strong>参数特性</strong>：参数整定复杂（需平衡 $K$、$T_i$、$T_d$），但适配范围广（尤其高精度控制）。</p>
</li>
</ul>
<p>   <strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：兼具快速响应、消除余差、抑制振荡的能力，适用于<strong>高精度复杂控制</strong>场景</p>
</li>
<li><p><strong>缺点</strong>：参数调试难度大</p>
</li>
</ul>
<ol start="7">
<li><p><strong>控制系统的控制质量指标</strong>：<u>衰减率</u>、<u>余差</u>、<u>最大偏差</u>、<u>过渡过程时间</u></p>
</li>
<li><p>**稳定性：**当自控系统处于平衡状时，由于受到内部或外部的扰动，被调量偏离原有的平衡值，当扰动过后，经过足够的时间，系统仍能够回到原有的平衡工作状态，即被调量回到原有平衡值上，则系统是稳定的，否则，系统是不稳定的</p>
</li>
<li><p><strong>误差</strong>是描述自动控制系统精度的指标，反映了系统在<strong>跟随输入信号</strong>和<strong>抑制干扰信号</strong>整个过程的精度。 所以误差有动态误差和稳态误差两种。</p>
</li>
</ol>
<ul>
<li><p><strong>动态误差</strong>描述系统的误差随时间变化的过程</p>
</li>
<li><p><strong>稳态误差</strong>（也称静态误差或余差）反映动态过程在时间趋于无穷大时，系统到达稳态时的误差**(过渡过程结束后，被控量稳态值与期望值的偏差)**</p>
</li>
</ul>
<h1 id="第三章-机电系统中的传感器技术"><a href="#第三章-机电系统中的传感器技术" class="headerlink" title="第三章 机电系统中的传感器技术"></a>第三章 机电系统中的传感器技术</h1><ol>
<li><strong>传感器的组成</strong>：传感器一般由<u>敏感元件</u>、<u>转换元件</u>、<u>基本转换电路</u>三部分组成</li>
</ol>
<p><img src="/blog/image/Snipaste_2025-06-28_14-53-18.png"></p>
<ol start="2">
<li><strong>传感器的分类</strong>：</li>
</ol>
<p>按<strong>输入量</strong>分类：<u>物理量传感器</u>、<u>化学量传感器</u>、<u>生物量传感器</u>三大类；</p>
<p>按<strong>输出信号形式</strong>分类：<u>模拟式</u>、<u>开关式</u>、<u>数字式</u>；</p>
<p>按<strong>转换原理</strong>分类：<u>结构型</u>、<u>物性型</u>、<u>复合型</u>；</p>
<ol start="3">
<li><p><strong>传感器的基本特性</strong>：静态特性、动态特性</p>
<ul>
<li><strong>静态特性</strong>：灵敏度、线性度、迟滞性、重复性、分辨力以及零漂等  </li>
<li><strong>动态特性</strong>：传感器要检测的输入信号是随时间而变化的，传感器的特性应能<strong>跟踪</strong>输入信号的变化，才能获得准确的输出信号</li>
</ul>
</li>
<li><p><strong>电学式压力传感器</strong>：</p>
<ul>
<li><p><strong>电阻应变片式压力传感器</strong> ：靠电阻值来度量压变和压力的，所以必需考虑电阻丝的温度效应</p>
</li>
<li><p><strong>电容式压力传感器</strong>：采用变电容测量原理，将由被测压力引起的<u>弹性元件的位移变形</u>转变为<u>电容的变化</u>，测出电容量便可知道被测压力的大小。<br>$$<br>C &#x3D; \frac{\varepsilon A}{d}<br>$$</p>
</li>
<li><p><strong>压阻式压力传感器</strong>：  压阻式压力传感器是基于半导体材料（单晶硅）的<strong>压阻效应</strong>（<u>固体受力后电阻率发生变化的现象</u>  ）原理制成的传感器  </p>
<p>特点：灵敏度高，频率响应高；测量范围宽；精度高，工作可靠；易于微小型化  </p>
</li>
<li><p><strong>压电式压力传感器</strong>  ：压电传感器主要是利用<strong>压电效应</strong>制造而成的</p>
<p><strong>压电效应</strong> ：某些晶体介质，当沿着一定方向受到机械力作用发生变形时，就产生了<strong>极化效应</strong>，而在其某些表面上会产生电荷；当机械力撤掉之后，又会重新回到不带电的状态，此现象称为“压电效应  “<br>$$<br>p &#x3D; \frac{Q}{kS} \tag{3-4}<br>$$<br>$Q$ 为电荷量，$k$ 为压电常数，$S$ 为作用面积，$p$ 为压力。通过测量电荷量可知被测压力大小。</p>
</li>
<li><p><strong>差动变压器式压力传感器</strong>  :由弹性敏感元件和差动变压器构成的压力传感器。 它的弹性敏感元件作为受力机构，把<strong>被测压力转换成位移</strong>，再用差动变压器把位移转换为与被测压力成一定关系的电信号</p>
</li>
</ul>
</li>
<li><p><strong>位移传感器</strong>：<u>电感式位移传感器</u>、<u>电容式位移传感器</u>、电阻式位移传感器、<u>光栅位移传感器</u>、光电式位移传感器、超声波式位移传感器、霍尔式位移传感器等。  </p>
</li>
<li><p><strong>电感式位移传感器</strong>：</p>
<ul>
<li><p><strong>电涡流式位移传感器</strong>：电涡流式位移传感器是利用<strong>电涡流原理</strong>设计而成的，它可以实现静态和动态地、非接触、高线性度、高分辨率地<strong>测量金属表面与传感器探头之间的距离及其变化</strong>  </p>
</li>
<li><p><strong>差动变压器式位移传感器</strong></p>
<p>差动变压器式位移传感器是利用<strong>线圈的互感作用</strong>将<strong>位移转换成感应电势的变化</strong>。</p>
<ul>
<li><p>传感器主要由线圈、铁心和活动衔铁三个部分组成，如图3.10（a）（b）所示。</p>
</li>
<li><p>线圈包括一个初级线圈和两个反接的次级线圈，当线圈输入交流激励电压时，次级线圈将产生感应电动势$e_1$和$e_2$。由于两个次级线圈极性反接，因此传感器的输出电压为两者之差，即$e_y&#x3D;e_1-e_2$</p>
</li>
<li><p>活动衔铁能改变线圈之间的耦合程度。输出ey的大小随活动衔铁的位置而改变。当活动衔铁的位置居中时，即e1&#x3D;e2，ey&#x3D;0；当活动衔铁向上移时，即e1&gt;e2，ey&gt;0;当活动衔铁向下移时，即e1&lt;e2，ey&lt;0。活动衔铁的位置往复变化，其输出电压也随之变化，输出特性如图3.10（c）所示。</p>
</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-06-23_15-51-57.png"></p>
</li>
</ul>
</li>
<li><p><strong>光栅式位移传感器</strong></p>
<ul>
<li>光栅的特点是<strong>测量精度高</strong>（可达±１μｍ）、<strong>响应速度快</strong>和<strong>量程范围大</strong>等。 用于精密机械的位移测量  </li>
<li>光栅传感器工作的基础是<strong>莫尔条纹</strong>  </li>
<li>光栅传感器可以根据<u>莫尔条纹移动量和移动方</u>向判定<u>光栅的位移量和位移的方向</u></li>
</ul>
</li>
<li><p><strong>速度传感器</strong>：测速发电机、电涡轮式转速传感器  、霍尔转速传感器   、光电式转速传感器  </p>
<ul>
<li>光电法测转速分透射式和反射式两种</li>
</ul>
</li>
<li><p><strong>温度传感器</strong>：热电偶、热敏电阻、热电阻</p>
</li>
<li><p><strong>热电偶冷端补偿</strong>（温度补偿）的3种方法：<u>延长导线法、机械调零法、补偿电桥法</u></p>
<blockquote>
<p><strong>说明热电偶的工作原理。当热端与冷端之间距离较远时，采用什么冷端补偿方式较好？</strong></p>
<p>热电偶的工作原理是<strong>基于物体的热电效应</strong></p>
<p>（即不同导体或半导体材料连接形成回路时，在两个接点处温度不同会产生热电动势，从而测量温度。）</p>
<p><strong>当热端与冷端之间的距离较远时：</strong></p>
<ul>
<li>需要使用<strong>补偿导线</strong>来延长热电偶的冷端，使之远离测量点</li>
<li>注意<strong>导线的型号、极性、以及接点的温度</strong>。</li>
</ul>
</blockquote>
</li>
<li><p><strong>热敏电阻</strong>：一般把<u>金属氧化物陶瓷半导体</u>材料经成形、烧结等工艺制成的测温元件叫做热敏电阻</p>
<ul>
<li><p>热敏电阻是<strong>中低温区</strong>最常用的一种温度检测器  </p>
</li>
<li><p><strong>分类</strong>：</p>
<p><strong>根据温度系数正负</strong>：PTC热敏电阻（电阻温度系数为正）、NTC热敏电阻（电阻温度系数为负）。</p>
<p><strong>NTC</strong>热敏电阻<strong>根据不同的用途</strong>：负指数型NTC（电阻值与温度之间呈负指数关系，用于测量宽度较宽的温度测量）、突变型NTC（当温度上升到某一设定值时，其电阻值突然下降，多作电路保护）</p>
<p><strong>PTC</strong>热敏电阻：突变型PTC（温度范围较窄，一般用于恒温加热控制或温度开关）、线性型PTC（可用于温度补偿或温度测量）。</p>
</li>
</ul>
</li>
<li><p><strong>热电阻</strong>:把金<u>属导体</u>如铜、镍、铂制成的测温电阻称为热电阻。  </p>
<ul>
<li>热电阻是利用物质在温度变化时本身电阻也随着发生变化的特性来测量温度的</li>
</ul>
</li>
<li><p><strong>热电阻传感器的测量电路</strong><br>热电阻传感器的测量电路一般使用电桥电路，由于工业用热电阻安装在生产现场，离控制室较远，因此热电阻的引线对测量结果有较大影响。为此，热电阻内部引线方式有<strong>二线制、三线制和四线制三种</strong>。</p>
</li>
</ol>
<p>​      <img src="/blog/image/IMG_20250328_095737_%E7%9C%8B%E5%9B%BE%E7%8E%8B.jpg"></p>
<blockquote>
<p><strong>两线制</strong></p>
<p><span style="color:#FF0000">电路结构</span></p>
<ul>
<li><p>采用 <strong>电桥电路</strong> 测量热电阻 $  R_t  $：电源 $  E_s  $ 供电，桥臂含固定电阻 $  R_1 \quad R_2  $、可调电阻 $  R_3  $，中间串联微安表 $  \mu A  $ 检测平衡。</p>
</li>
<li><p>热电阻 $  R_t  $ 通过 <strong>两根引线</strong> 接入电桥，引线自身存在电阻 $  r  $（图中虚线框内两侧的 $  r  $），即 <strong>引线电阻会串联在热电阻回路中</strong>。</p>
</li>
</ul>
<p><span style="color:#FF0000">优缺点</span></p>
<ul>
<li>这种引线方式简单、费用低，但是引线电阻以及引线电阻的变化会带来附加误差。</li>
<li>两线制适于引线不长，精度要求较低的场合。</li>
</ul>
</blockquote>
<p><img src="/blog/image/Snipaste_2025-06-29_10-12-28.png"></p>
<blockquote>
<p><strong>三线制</strong></p>
<p>热电阻的一端与一根导线相接，另一端同时接两根导线。</p>
<p><span style="color:#FF0000">工作原理</span></p>
<p>惠斯通电桥</p>
<p><img src="/blog/image/Snipaste_2025-06-29_11-00-42.png"></p>
<p>图中热电阻 $  R_t  $ 的三根导线，粗细相同，长度相等，阻值都是 $  r  $。其中一根串联在电桥的电源上，对电桥的平衡与否毫无影响。另外两根分别串联在电桥的相邻两臂里，使相邻两臂的阻值都增加同样大的阻值 $  r  $。</p>
<p><strong>当电桥平衡时，可写出下列关系，即</strong><br>$$<br>(R_t + r)R_2 &#x3D; (R_3 + r)R_1<br>$$</p>
<p>由此可以得出</p>
<p>$$<br>R_t &#x3D; \frac{(R_3 + r)R_1 - rR_2}{R_2} &#x3D; \frac{R_3R_1}{R_2} + \frac{R_1r}{R_2} - r<br>$$</p>
<p>设计电桥时如满足 $  R_1 &#x3D; R_2  $，则上式等号右边含有 $  r  $ 的两项完全消去，就和 $  r&#x3D;0  $ 的电桥平衡公式完全一样了。这种情况下，导线电阻 $  r  $ 对热电阻的测量毫无影响。但必须注意，只有在左右对称的电桥（即 $  R_1 &#x3D; R_2  $ 的电桥），且只有在平衡状态下才是如此。</p>
<p><img src="/blog/image/IMG_20250328_095926.jpg"></p>
<p><strong>为什么使用三线制？有什么作用？</strong></p>
<p>由于热电阻的电阻值较小，因此在热电阻与测量仪表之间引线过长会引起测量误差。所以此时引线电阻及其随长度和温度的变化就不能忽略不计。<span style="color:#FF0000">为了消除和减小引线电阻对测量精度的影响</span>，通常采用三线制连接法  </p>
<ul>
<li>减少引线电阻误差，提高测量精度</li>
<li>适用于长距离测温</li>
</ul>
</blockquote>
<blockquote>
<p><strong>四线制</strong></p>
<p><span style="color:#FF0000">工作原理</span></p>
<ol>
<li><strong>电流激励回路</strong></li>
</ol>
<ul>
<li>恒流源（如 1mA）通过两根导线向热电阻提供稳定电流 I。</li>
<li>引线电阻（$r_1 \quad r_4$）的压降被恒流源的高输出阻抗克服，不影响电流大小。</li>
</ul>
<ol start="2">
<li><strong>电压测量回路</strong></li>
</ol>
<ul>
<li><p>高阻抗电压表（输入阻抗 &gt;10 MΩ）通过另两根导线直接测量热电阻两端电压 U。</p>
</li>
<li><p>因测量回路电流趋近于零（I≈0），引线电阻（$r_2 \quad r_3$）的压降 IR≈0</p>
<p>故<br>$$<br>R_t&#x3D;\frac{U}{I}<br>$$<br><img src="/blog/image/IMG_20250328_095932.jpg"></p>
<p><strong>为什么使用四线制？有什么作用？</strong></p>
<p><span style="color:#FF0000">为了消除和减小引线电阻对测量精度的影响</span></p>
<ul>
<li>消除引线电阻误差，提高测量精度</li>
<li>适用于长距离与高精度测量</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="第四章-电路及接口设计"><a href="#第四章-电路及接口设计" class="headerlink" title="第四章 电路及接口设计"></a>第四章 电路及接口设计</h1><h2 id="运算放大器电路设计"><a href="#运算放大器电路设计" class="headerlink" title="运算放大器电路设计"></a>运算放大器电路设计</h2><h3 id="“理想”运算放大器"><a href="#“理想”运算放大器" class="headerlink" title="“理想”运算放大器"></a>“理想”运算放大器</h3><p>运算放大器的<strong>理想化条件</strong>通常有以下几点：</p>
<ol>
<li><p><strong>开环电压放大倍数（$A_{uo} \to \infty$）</strong>：</p>
<ul>
<li><p>理想运算放大器要求它的开环增益（即没有任何反馈的增益）无限大。</p>
<ul>
<li>运算放大器的<strong>开环增益</strong>就是输入信号与输出信号之比，通常是一个非常大的数值，理想情况下无穷大。</li>
</ul>
<p>开环增益的表达式为：<br>$$<br>A_{u_o}&#x3D;\frac{u_0}{u_d}<br>$$</p>
<p>其中：</p>
<ul>
<li><p>$u_d$：输入电压信号（即运算放大器的正输入和负输入之间的电压差）</p>
</li>
<li><p>$u_o$：输出电压信号</p>
<blockquote>
<p><strong>虚短</strong><br>$$<br>u_d&#x3D;\frac {u_0}{A_{u0}}<br>$$<br>由于$A_{U0} \to \infty$且$u_0$为有限值，则$u_d&#x3D;0$<br>$$<br>u_+&#x3D;u_{-}<br>$$</p>
</blockquote>
</li>
</ul>
</li>
<li><p>开环增益越大，意味着即使输入信号很小，输出信号也会被放大得非常明显。</p>
</li>
</ul>
</li>
<li><p><strong>开环输入电阻（$r_{id} \to \infty$）</strong>：</p>
<ul>
<li><p>理想的运算放大器要求其输入电阻无限大。这意味着输入端几乎不消耗电流，所有的输入电流都被输入端的电路系统吸收，不影响放大器的输入信号。</p>
<blockquote>
<p><strong>虚断</strong><br>$$<br>i_+&#x3D;i_{-}&#x3D;0<br>$$</p>
</blockquote>
</li>
<li><p>在实际运算放大器中，输入电阻是非常高的（通常达到几兆欧），但由于技术限制不能无限大。</p>
</li>
</ul>
</li>
<li><p><strong>开环输出电阻（$r_o \to 0$）</strong>：</p>
<ul>
<li>理想化运算放大器的输出电阻要求为零。这意味着理想放大器在输出端没有任何“阻抗”，输出信号不会受到负载影响，也不会因为负载电阻而减少功率。</li>
<li>实际上，运算放大器的输出电阻是有限的（但非常小，通常在几欧姆至几十欧姆之间）。</li>
</ul>
</li>
<li><p><strong>共模抑制比（$K_{CMRR} \to \infty$）</strong>：</p>
<ul>
<li>共模抑制比（CMRR, Common-Mode Rejection Ratio）是一个衡量运算放大器对共模信号（即两输入端同时接收到的相同信号）的抑制能力的参数。理想情况下，运算放大器应该能够完全抑制共模信号，CMRR趋近于无穷大。</li>
<li>实际上，运算放大器对于共模信号的抑制是有限的，但好的运算放大器具有非常高的共模抑制比。</li>
</ul>
</li>
</ol>
<blockquote>
<p>由于实际运算放大器的技术指标接近理想化条件，所以用理想运算放大器分析电路能够简化问题的复杂度</p>
</blockquote>
<h3 id="运算放大器的电压传输特性"><a href="#运算放大器的电压传输特性" class="headerlink" title="运算放大器的电压传输特性"></a>运算放大器的电压传输特性</h3><ul>
<li>设输入电压 $u_d &#x3D; u_+ - u_-$，其中 $u_+$ 和 $u_-$ 分别为运算放大器的两个输入端电压。</li>
<li>输出电压 $u_o$ 和输入 $u_d$ 之间的传输特性曲线如下图所示。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-12_20-44-27.png"></p>
<ul>
<li>近似特性和实际特性分别用不同的曲线表示：<ul>
<li>近似特性：线性区域为主，开始接近饱和时，曲线逐渐饱和。</li>
<li>实际特性：表现出一定的饱和电压，出现非线性区域。</li>
</ul>
</li>
</ul>
<ol>
<li><strong>线性工作区</strong>：<ul>
<li>$|u_d| &lt; U_{ds}$，在此区域，输出电压 $u_o &#x3D; A u_d$，即输出与输入呈线性关系。</li>
</ul>
</li>
<li><strong>正向饱和区</strong>：<ul>
<li>$u_d &gt; U_{ds}$，在此区域，输出电压达到最大饱和值 $u_o &#x3D; U_{sat}$</li>
</ul>
</li>
<li><strong>负向饱和区</strong>：<ul>
<li>$u_d &lt; -U_{ds}$，在此区域，输出电压达到最小饱和值 $u_o &#x3D; - U_{sat}$</li>
</ul>
</li>
</ol>
<blockquote>
<ul>
<li><strong>实际表现</strong>：<span style="color:#FF0000">工作在开环状态的运放</span>，任何微小的输入电压差 <code>(u_+ - u_- ≠ 0)</code> 都会使输出瞬间饱和（达到正电源电压 <code>+V_sat</code> 或负电源电压 <code>-V_sat</code>），无法进行线性放大。输出仅有两种状态：</li>
</ul>
<p>$$<br>u_o&#x3D;<br>+V_{sat}\quad if \quad u_+&gt;u_-<br>$$</p>
<p>$$<br>u_o&#x3D;-V_{sat} \quad if \quad u_+&lt;u_- \<br>$$</p>
<ul>
<li><strong>用途</strong>：<span style="color:#FF0000">构成电压比较器。</span></li>
</ul>
</blockquote>
<h3 id="反向比例器"><a href="#反向比例器" class="headerlink" title="反向比例器"></a>反向比例器</h3><p><strong><span style="color:#FF0000">反相端接输入，同相端接地</span></strong></p>
<p>电路图示意图</p>
<p><img src="/blog/image/1746757641996_%E7%9C%8B%E5%9B%BE%E7%8E%8B.jpg" alt="反向比例器电路图"></p>
<ul>
<li><p><strong>虚短</strong>：$u_+ &#x3D; u_- &#x3D; 0$</p>
</li>
<li><p><strong>电流分析</strong>：</p>
<p>$$<br>i_1 &#x3D; \frac{u_i}{R_1}, \quad i_2 &#x3D; \frac{-u_o}{R_f}<br>$$</p>
</li>
<li><p><strong>虚断</strong>：$i_- &#x3D; 0$, 所以 $i_2 &#x3D; i_1$</p>
</li>
</ul>
<p>因此，</p>
<p>$$<br>u_o &#x3D; -\frac{R_f}{R_1} u_i<br>$$</p>
<p><span style="color:#FF0000">（直接记忆）</span></p>
<ol>
<li><p>当 $R_1$ 和 $R_f$ 确定后，为使 $u_o$ 不超过饱和电压（即保证工作在线性区），对 $u_i$ 有一定限制。<span style="color:#FF0000">（在脉宽调制式功率放大级那块有用到饱和的例子）</span></p>
</li>
<li><p>运放不工作在开环状态（极不稳定，振荡在饱和区），都工作在闭环状态，输出电压由外电路决定。</p>
</li>
</ol>
<h3 id="加法器"><a href="#加法器" class="headerlink" title="加法器"></a>加法器</h3><ul>
<li>电路图示意图</li>
</ul>
<p><img src="/blog/image/1747877382020_%E7%9C%8B%E5%9B%BE%E7%8E%8B.jpg" alt="加法器电路图"></p>
<ul>
<li><strong>电路分析</strong></li>
</ul>
<p><strong>虚短</strong>（$u^- &#x3D; u^+$）<br><strong>虚断</strong>（$i^- &#x3D; 0$）</p>
<p>所以：</p>
<p>$$<br>\frac{u_{i1}}{R_1} + \frac{u_{i2}}{R_2} + \frac{u_{i3}}{R_3} &#x3D; \frac{-u_o}{R_f}<br>$$</p>
<p>进一步解得：</p>
<p>$$<br>u_o &#x3D; - R_f \left( \frac{u_{i1}}{R_1} + \frac{u_{i2}}{R_2} + \frac{u_{i3}}{R_3} \right)<br>$$</p>
<ul>
<li><strong>特殊情况</strong></li>
</ul>
<p>如果：$R_1 &#x3D; R_2 &#x3D; R_3 &#x3D; R_f$，则：</p>
<p>$$<br>u_o &#x3D; - (u_1 + u_2 + u_3)<br>$$</p>
<blockquote>
<p>式中负号说明输出电压和输入电压反相。</p>
</blockquote>
<ul>
<li><strong>比例加法器</strong></li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-22_09-32-28.png"><br>$$<br>y &#x3D; a_1 x_1 + a_2 x_2 + a_3 x_3<br>$$</p>
<p>符号如右图：</p>
<p>其中：</p>
<ul>
<li>$a_1 &#x3D; \frac{R_f}{R_1}$</li>
<li>$a_2 &#x3D; \frac{R_f}{R_2}$</li>
<li>$a_3 &#x3D; \frac{R_f}{R_3}$</li>
</ul>
<h3 id="减法器-加法器"><a href="#减法器-加法器" class="headerlink" title="减法器&#x2F;加法器"></a>减法器&#x2F;加法器</h3><ul>
<li>电路图示意图</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-22_09-39-47.png" alt="减法器电路图"></p>
<ul>
<li>电路分析</li>
</ul>
<p>对节点 1、2 分别列出节点电压方程：（并注意规则 1，$i^+ &#x3D; i^- &#x3D; 0$）</p>
<p>由虚短知：$U_{n1}&#x3D;U_{n2}$</p>
<p>由虚断知：$i_{+}&#x3D;i_{-}$<br>$$<br>\frac{U_{1}-U_{n1}}{R_{1}}&#x3D;\frac{U_{n1}-U_{o}}{R_{2}}<br>$$</p>
<p>$$<br>\frac{U_{2}-U_{n2}}{R_{1}}&#x3D;\frac{U_{n2}}{R_{2}}<br>$$</p>
<p>整理得<br>$$<br>\left( \frac{1}{R_1} + \frac{1}{R_2} \right) u_{n1} - \frac{u_1}{R_1} - \frac{u_0}{R_2} &#x3D; 0 \\<br>\left( \frac{1}{R_1} + \frac{1}{R_2} \right) u_{n2} - \frac{u_2}{R_1} &#x3D; 0<br>$$</p>
<p>得</p>
<p>$$<br>\frac{u_1}{R_1} + \frac{u_0}{R_2} &#x3D; \frac{u_2}{R_1}<br>$$</p>
<p>整理后解得：</p>
<p>$$<br>u_0 &#x3D; \frac{R_2}{R_1} (u_2 - u_1)<br>$$</p>
<blockquote>
<p><img src="/blog/image/Snipaste_2025-07-05_14-44-17.png"></p>
<p><strong>两个要点</strong></p>
<ul>
<li>$\frac{R_f}{R_s}$</li>
<li>同相端电压之和-反相端电压之和</li>
</ul>
</blockquote>
<h3 id="积分器"><a href="#积分器" class="headerlink" title="积分器"></a>积分器</h3><ul>
<li>电路图示意图</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-22_09-52-15.png" alt="微分器电路图"></p>
<ul>
<li>电路分析</li>
</ul>
<p>由虚短和虚断知：</p>
<p>$$<br>u^- &#x3D; 0, \quad i^- &#x3D; 0<br>$$</p>
<p>$$<br>\frac {u_i}{R}&#x3D;-C \frac{du_0}{dt}<br>$$</p>
<p>最终可得输出电压表达式：</p>
<p>$$<br>u_0 &#x3D; - \frac {1}{RC }\int u_idt<br>$$</p>
<h3 id="电感-电容的电流与电压关系"><a href="#电感-电容的电流与电压关系" class="headerlink" title="电感&#x2F;电容的电流与电压关系"></a>电感&#x2F;电容的电流与电压关系</h3><blockquote>
<ul>
<li><p>电感<br>$$<br>i(t) &#x3D; \frac{1}{L} \int u(t) dt \<br>u(t)&#x3D;L\frac{di(t)}{dt}<br>$$</p>
</li>
<li><p>电容</p>
</li>
</ul>
<p>$$<br>i(t) &#x3D; C \frac{du(t)}{dt} \<br>u(t) &#x3D; \frac{1}{C} \int i(t) dt<br>$$</p>
</blockquote>
<h3 id="微分器"><a href="#微分器" class="headerlink" title="微分器"></a>微分器</h3><ul>
<li>电路图示意图</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-22_10-03-07.png" alt="微分器电路图"></p>
<ul>
<li>电路分析</li>
</ul>
<p>由虚短和虚断知：</p>
<p>$$<br>u^- &#x3D; 0, \quad i^- &#x3D; 0<br>$$</p>
<p>$$<br>C \frac{du_i}{dt} &#x3D; \frac{- u_0}{R}<br>$$</p>
<p>最终可得输出电压表达式：</p>
<p>$$<br>u_0 &#x3D; -RC \frac{du_i}{dt}<br>$$</p>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><p>图所示为两级比例运算放大电路，求 $u_o$ 与 $u_i$ 的关系。</p>
<ul>
<li>电路图示意图</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-22_10-07-09.png" alt="两级比例运放电路图"></p>
<p>第一极放大器输出：</p>
<p>$$<br>u_{o1} &#x3D; -\frac{R_f}{R_1} u_i<br>$$</p>
<p>第二极运放输出：</p>
<p>$$<br>u_{o2} &#x3D; -\frac{2R}{R} u_{o1}<br>$$</p>
<p>代入 $u_{o1}$ 得：</p>
<p>$$<br>u_{o2} &#x3D; -2 u_{o1}  &#x3D; \frac{2R_f}{R_1} u_i<br>$$</p>
<p>最终输出：</p>
<p>$$<br>u_o &#x3D; u_{o2} - u_{o1}&#x3D; \frac{3R_f}{R_1} u_i<br>$$</p>
<hr>
<p>如图所示，$A_1$、$A_2$ 为理想运算放大器，参数如电路图所示。<br>输入：$U_{i1} &#x3D; 1.1, \text{V}$，$U_{i2} &#x3D; 1, \text{V}$</p>
<p><strong>试求：</strong> 接入 $U_{i1} &#x3D; 1.1, \text{V}$，$U_{i2} &#x3D; 1, \text{V}$ 后，输出电压 $U_o$ 由 $0, \text{V}$ 上升到 $10, \text{V}$ 所需的时间</p>
<p><strong>电路图</strong></p>
<p><img src="/blog/image/Snipaste_2025-05-22_10-34-00.png" alt="积分电路图"></p>
<p><span style="color:#FF0000">（减法器+积分器）</span></p>
<ul>
<li>电路分析推导：</li>
</ul>
<p>中间运放 $A_1$ ：<br>$$<br>\frac {u_{i1}-u_1}{R_1}&#x3D;\frac {u_1-u_{o1}}{R_f}<br>$$</p>
<p>$$<br>\frac {u_{i2}-u_1}{R_2}&#x3D;\frac {u_1}{R_3}<br>$$</p>
<p>中间运放 $A_2$ ：<br>$$<br>\frac {u_{o1}}{R_4}&#x3D;-C \frac {du_0}{dt}<br>$$</p>
<p>$$<br>U_{o1} &#x3D; \frac{R_3}{R_2 + R_3} \cdot \frac{R_1 + R_f}{R_1} U_{i2} - \frac{R_f}{R_1} U_{i1}&#x3D;0.2 \text{V}<br>$$</p>
<p>$$<br>U_o &#x3D; -\frac{1}{R_4 C} \int_0^t U_{o1} , dt &#x3D; 10t\text{V} \cdot \text{s}^{-1}<br>$$</p>
<p>$$<br>t &#x3D; \frac{U_o}{10 \text{V&#x2F;s}} &#x3D; \frac{10, \text{V}}{10 \text{V&#x2F;s}} &#x3D; 1\text{s}<br>$$</p>
<p><strong>$U_o$ 从 0 V 上升到 10 V 需要 1 秒钟。</strong></p>
<p><strong>电容单位换算规则</strong></p>
<blockquote>
<p>$$<br>1mF &#x3D; 10^{-3}F\<br>$$</p>
<p>$$<br>1 \mu F &#x3D; 10^{-6}F \<br>$$</p>
<p>$$<br>1nF&#x3D; 10^{-9}F \<br>$$</p>
<p>$$<br>1pF &#x3D; 10^{-12}F\<br>$$</p>
</blockquote>
<p><strong>题目描述：</strong></p>
<p>下图所示的电路中，设运算放大器 $A_1$，$D$、$D_z$ 均为理想元件，其中 $D_z &#x3D; 5,\text{V}$。  并设电路的初始状态为零。<br>当 $t &#x3D; 0$ 时，开关 $S$ 置于位置“1”；<br>当 $t &#x3D; 2,\text{s}$ 时，突然转换到位置“2”。</p>
<p>试绘出输出电压 $U_o$ 的波形，并求出输出电压过零时间 $t_1$ 和开始限制时间 $t_2$。</p>
<p><strong>电路图</strong></p>
<p><img src="/blog/image/Snipaste_2025-05-22_10-53-31.png" alt="积分电路与开关控制"></p>
<blockquote>
<p>根据电容两端电压判断电流走向</p>
<ul>
<li>0-2-5 S：左零右负，电流向右，D截止</li>
<li>5-7.5 S：左零右正，电流向左，$D_Z$截止，直到反向导通</li>
</ul>
</blockquote>
<ul>
<li>解题过程：</li>
</ul>
<p><strong>1. 阶段一：$0 &lt; t &lt; 2,\text{s}$，开关在位置 “1”</strong></p>
<p>$$<br>U_o &#x3D; -\frac{1}{RC} \int_0^t U_i, dt &#x3D; -3t<br>$$</p>
<p>当 $t &#x3D; 2,\text{s}$ 时：</p>
<p>$$<br>U_o &#x3D; -6\text{V}<br>$$</p>
<p><strong>2. 阶段二：$2,\text{s} &lt; t &lt; t_1$，开关切换到位置 “2”</strong></p>
<p>此时电压源变为 $2,\text{V}$，且考虑初值 $U_o(2) &#x3D; -6,\text{V}$，积分器继续作用：</p>
<p>$$<br>U_o &#x3D; -6-\frac{1}{RC} \int_2^t U_i  dt &#x3D; 2(t - 2) - 6<br>$$</p>
<p>令 $U_o &#x3D; 0$，解得过零时间：</p>
<p>$$<br>t_1 &#x3D; 5\text{s}<br>$$</p>
<p><strong>3. 阶段三：积分到 $U_o &#x3D; 5,\text{V}$（钳位限制）</strong></p>
<p>继续积分：</p>
<p>$$<br>U_o &#x3D; 2(t - 2) - 6 &#x3D; 5<br>$$</p>
<p>解得限制开始时间：</p>
<p>$$<br>t_2 &#x3D; 7.5\text{s}<br>$$</p>
<p>输出电压 $U_o$ 的波形图：</p>
<ul>
<li>$t&#x3D;0$ 到 $2,\text{s}$：$U_o$ 线性下降到 $-6\text{V}$</li>
<li>$t&#x3D;2,\text{s}$ 到 $5,\text{s}$：$U_o$ 上升到 $0\text{V}$</li>
<li>$t&#x3D;5,\text{s}$ 到 $7.5,\text{s}$：$U_o$ 上升到 $5\text{V}$</li>
<li>$t\ge 7.5,\text{s}$：钳位，输出恒定 $5\text{V}$</li>
</ul>
<p><img src="/blog/image/IMG_0117.jpg"></p>
<p>结论：</p>
<ul>
<li><strong>过零时间</strong>：$t_1 &#x3D; 5\text{s}$</li>
<li><strong>开始限制时间</strong>：$t_2 &#x3D; 7.5\text{s}$</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-07-07_08-01-56.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_08-51-43.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_10-17-13.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_10-17-23.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_10-17-30.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_10-17-36.png"></p>
<p><img src="/blog/image/Snipaste_2025-08-01_09-39-21.png"></p>
<h2 id="比较环节、比例、积分、微分等运放电路"><a href="#比较环节、比例、积分、微分等运放电路" class="headerlink" title="比较环节、比例、积分、微分等运放电路"></a>比较环节、比例、积分、微分等运放电路</h2><p><img src="/blog/image/Snipaste_2025-07-07_11-11-21.png"></p>
<p>根据温度控制实验，试根据运放放大电路构建PI调节方式的温度控制电路，要求包括输入信号与反馈信号的<strong>比较环节控制电路</strong>，偏差信号的<strong>PI调节电路</strong>和<strong>信号增益放大电路</strong>？</p>
<p><img src="/blog/image/%E5%9B%BE%E7%89%871.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-07_11-11-34.png"></p>
<h2 id="高性能放大电路"><a href="#高性能放大电路" class="headerlink" title="高性能放大电路"></a>高性能放大电路</h2><p><img src="/blog/image/1231.jpg"></p>
<p><img src="/blog/image/1233.jpg"></p>
<p><img src="/blog/image/1234.jpg"></p>
<p><img src="/blog/image/1232.jpg"></p>
<h2 id="基本桥路放大器"><a href="#基本桥路放大器" class="headerlink" title="基本桥路放大器"></a>基本桥路放大器</h2><p>图4.14为基本桥路放大器</p>
<ul>
<li>用$R+\Delta R$代表<strong>传感器</strong>，</li>
<li>$R$为规定的参考状态下传感器的阻值，</li>
<li>$\Delta R$为偏离参考状态时传感器阻值的变量。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-23_16-15-41.png"></p>
<h3 id="图4-14a（线性输出）"><a href="#图4-14a（线性输出）" class="headerlink" title="图4.14a（线性输出）"></a>图4.14a（线性输出）</h3><p>观察到<br>$$<br>u_+&#x3D;\frac{R}{R+R}U_R&#x3D;u_-<br>$$</p>
<div>

<p>$$<br>\frac{U_R-U_R&#x2F;2}{R}&#x3D; \frac{U_R&#x2F;2-U_0}{R+\Delta R}  \<br>U_o &#x3D; -\frac{\Delta R}{2R} U_R<br>$$</p>
</div>



<h3 id="图4-14b（非线性输出）"><a href="#图4-14b（非线性输出）" class="headerlink" title="图4.14b（非线性输出）"></a>图4.14b（非线性输出）</h3><div>

<p>$$<br>u_+&#x3D;\frac{R+\Delta R}{2R+ \Delta R}U_R&#x3D;u_- \<br>U_R-\frac{R+\Delta R}{2R+ \Delta R}U_R&#x3D;\frac{R+\Delta R}{2R+ \Delta R}U_R-U_0  \<br>U_o &#x3D;  \frac{\Delta R}{2R + \Delta R}U_R<br>$$</p>
</div>



<h3 id="两种电路结构对比"><a href="#两种电路结构对比" class="headerlink" title="两种电路结构对比"></a>两种电路结构对比</h3><table>
<thead>
<tr>
<th><strong>特征</strong></th>
<th><strong>图4.14a（传感器置于反馈支路）</strong></th>
<th><strong>图4.14b（传感器接地）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>电路结构</strong></td>
<td>传感器作为反馈电阻</td>
<td>传感器接地，与固定电阻组成分压电路</td>
</tr>
<tr>
<td><strong>输出电压公式</strong></td>
<td>$U_o &#x3D; -\frac{\Delta R}{2R} U_R$</td>
<td>$ U_o &#x3D;  \frac{\Delta R}{2R + \Delta R}U_R  $</td>
</tr>
<tr>
<td><strong>线性性</strong></td>
<td>随传感器电阻的增加，输出电压减小；$R$ 与 $U_o$ 成线性关系</td>
<td>非线性关系</td>
</tr>
</tbody></table>
<h3 id="关键设计优化"><a href="#关键设计优化" class="headerlink" title="关键设计优化"></a>关键设计优化</h3><p>运放负载能力保护（针对图4.14a）</p>
<ol>
<li><strong>问题</strong>：</li>
</ol>
<p>由于传感器的电流由参考电压$U_R$供给，因此图（ａ）电路流经传感器的电流受运放负载能力的限制，<span style="color:#FF0000">反馈电流 $I &#x3D; \frac{U_R&#x2F;2}{R}$ 可能超过运放最大输出电流 $I_{\text{max}}$。</span></p>
<p><strong>而图(ｂ）电路则不受此限制</strong>  </p>
<p><strong>解决方案</strong>：将反相输入端两臂电阻 $R$ 同时增大 $m$ 倍（即 $R \rightarrow mR$）：</p>
<ul>
<li>调整后电流：$I’ &#x3D; \frac{U_R&#x2F;2}{mR}$</li>
</ul>
<h2 id="三端固定式集成稳压电源"><a href="#三端固定式集成稳压电源" class="headerlink" title="三端固定式集成稳压电源"></a>三端固定式集成稳压电源</h2><h3 id="集成稳压电源的性能指标"><a href="#集成稳压电源的性能指标" class="headerlink" title="集成稳压电源的性能指标"></a>集成稳压电源的性能指标</h3><ul>
<li><p>最大输出电流</p>
</li>
<li><p>输出电压</p>
</li>
<li><p>纹波电压</p>
</li>
<li><p>稳压系数</p>
</li>
<li><p>输出电阻</p>
</li>
</ul>
<p><strong>三端固定式稳压集成电源的产品分类</strong></p>
<ul>
<li><p><strong>CW7800系列</strong>：输出电压为<strong>正极性</strong></p>
</li>
<li><p><strong>CW7900系列</strong>：输出电压为<strong>负极性</strong></p>
</li>
<li><p><strong>输出共 7 个档次电压</strong>：</p>
</li>
</ul>
<p>$$<br>5\text{V},\ 6\text{V},\ 9\text{V},\ 12\text{V},\ 15\text{V},\ 18\text{V},\ 24\text{V}<br>$$</p>
<ul>
<li><strong>输出电流分为 3 个档次</strong>：</li>
</ul>
<p>$$<br>\text{H}:\ 1.5\text{A},\quad \text{L}:\ 0.1\text{A},\quad \text{M}:\ 0.5\text{A}<br>$$</p>
<hr>
<ul>
<li><p><strong>LM78L05</strong>：输出电压 $+5\text{V}$，最大输出电流 $0.1\text{A}$</p>
</li>
<li><p><strong>CW7915</strong>：输出电压 $-15\text{V}$，最大输出电流 $1.5\text{A}$</p>
</li>
</ul>
<h3 id="两种稳压电源的典型应用电路"><a href="#两种稳压电源的典型应用电路" class="headerlink" title="两种稳压电源的典型应用电路"></a>两种稳压电源的典型应用电路</h3><p><img src="/blog/image/1748049757448.jpg"></p>
<ul>
<li><p>其中输入端电容$ C_i$用以<strong>旁路高频干扰脉冲及改善纹波</strong>。</p>
</li>
<li><p>输出端所接电容$C_0$起<strong>改善瞬态响应特性、减小高频输出阻抗</strong>的作用。</p>
</li>
<li><p>一般在输出端无需接入大电解电容器。</p>
</li>
</ul>
<blockquote>
<p><strong>78XX:1入，2出，3地</strong></p>
<p><strong>79XX:1地，2出，3入</strong></p>
<p>（两者都按照电平从高到低排列的）</p>
</blockquote>
<h2 id="集成稳压器"><a href="#集成稳压器" class="headerlink" title="集成稳压器"></a>集成稳压器</h2><p>图 4.19 所示为集成稳压器的实际应用电路。</p>
<ul>
<li>该电路使用 CW78XX 系列三端稳压器，将市电交流电压变换为稳定的直流输出，常用于嵌入式系统、小型电子设备供电。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-05-24_10-09-19.png"></p>
<p><strong>电路结构说明</strong></p>
<ul>
<li><strong>T</strong>：变压器，将 220V 交流电降压；</li>
<li><strong>整流桥</strong>：由四个二极管组成的桥式整流器，将交流电转换为脉动直流；</li>
<li><strong>C</strong>：滤波电容，作用是平滑整流输出的电压；</li>
<li><strong>$C_i$</strong>：输入旁路电容，减少输入纹波；</li>
<li><strong>CW78XX</strong>：三端固定输出电压的集成稳压器，如 7805、7812 等；</li>
<li><strong>$C_o$</strong>：输出端电容，用于改善负载瞬变响应；</li>
<li><strong>$R_3$</strong>：负载电阻，模拟实际用电器负载。</li>
</ul>
<hr>
<p><strong>稳压器正常工作时的输入电压范围</strong></p>
<p>为了确保稳压器输出稳定电压，其输入电压 $U_i$ 必须满足以下范围：</p>
<span>
$$
U_{omax} + (U_i - U_o) _{min} \leq U_i \leq U_{omin} + (U_i - U_o) _{max}
$$

</span>

<p>其中：</p>
<ul>
<li>$U_{omax}$：最大输出电压；</li>
<li>$U_{omin}$：最小输出电压；</li>
<li>$(U_i - U_o)_{min}$：最小输入输出电压差，一般为 2V 左右；</li>
<li>$(U_i - U_o)_{max}$：最大允许输入输出压差，通常由功耗决定。</li>
</ul>
<p><strong>说明</strong>：</p>
<ul>
<li>若 $U_i$ 过低，会导致输出掉压；</li>
<li>若 $U_i$ 过高，会造成稳压器功耗增加，可能烧毁芯片。</li>
</ul>
<hr>
<p><strong>最大输出电流限制</strong></p>
<p>稳压器内部设有限流保护，输出电流需满足：</p>
<p>$$<br>I_{cm} &lt; I_{omax}<br>$$</p>
<p>其中：</p>
<ul>
<li>$I_{cm}$：负载实际工作电流；</li>
<li>$I_{omax}$：稳压器规格书规定的最大输出电流，通常为 1A 或 1.5A。</li>
</ul>
<h2 id="改变输出电压极性的应用"><a href="#改变输出电压极性的应用" class="headerlink" title="改变输出电压极性的应用"></a>改变输出电压极性的应用</h2><p><img src="/blog/image/Snipaste_2025-07-05_19-40-40.png"></p>
<ul>
<li>7800：将输出端接地，接地端电位下降为<strong>负电平</strong>，成为<strong>负电压输出端</strong></li>
<li>7900：将输出端接地，接地端电位上升为<strong>正电平</strong>，成为<strong>正电压输出端</strong></li>
</ul>
<blockquote>
<p><span style="color:blue">输出端接地，接地端电位变化，成为新的输出端</span></p>
</blockquote>
<h2 id="输出电压连续可调的应用"><a href="#输出电压连续可调的应用" class="headerlink" title="输出电压连续可调的应用"></a>输出电压连续可调的应用</h2><p><img src="/blog/image/Snipaste_2025-07-05_20-45-47.png"></p>
<p><strong>图 4.21(a)：正极性连续可调电源（CW7805）</strong></p>
<ul>
<li>使用 CW7805 提供 5V 稳压基准；</li>
<li>通过电位器 $R_w$ 调节其地引脚的等效参考电位；</li>
<li>输出电压范围为：<strong>5V ~15V 连续可调</strong>；</li>
<li>输出电流为 <strong>1A</strong>；</li>
<li>输出电压计算公式为：</li>
</ul>
<p>$$<br>U_o &#x3D; U_{xx} + \left( \frac{U_{xx}}{R} + I_d \right) R_w<br>$$</p>
<p>其中：</p>
<ul>
<li>$U_{xx}$：稳压器自身的输出参考电压（如 5V）；</li>
<li>$I_d$：调整电流；</li>
<li>$R_w$ 增大时，$U_o$ 上升。</li>
</ul>
<hr>
<p><strong>图 4.21(b)：负极性连续可调电源（CW7800）</strong></p>
<p><img src="/blog/image/Snipaste_2025-07-05_20-45-57.png"></p>
<ul>
<li>输入端加入额外负电源</li>
<li>通过 2DW7 稳压管（6.2V）和电阻 $R_3$，提供负电压基准约 $-6\text{V}$；</li>
<li>稳压器地端参考点下移，<strong>实现输出电压从 0V ~15V连续可调</strong>；</li>
<li>若 $R_w &#x3D; 0$，则：</li>
</ul>
<p>$$<br>U_o &#x3D; U_{xx} - 6 &#x3D; -1\text{V}<br>$$</p>
<blockquote>
<ul>
<li>图 4.21(a) 的最低输出电压为 $5\text{V}$；</li>
<li>图 4.21(b) 可通过下移 GND 实现从 $0\text{V}$ 起调；</li>
</ul>
</blockquote>
<h2 id="三极管基础知识"><a href="#三极管基础知识" class="headerlink" title="三极管基础知识"></a>三极管基础知识</h2><p><img src="/blog/image/Snipaste_2025-05-24_16-04-32.png"></p>
<blockquote>
<p>电路符号中其<strong>发射极箭头方向</strong>就是该类型管子<strong>发射极正向电流的方向</strong></p>
</blockquote>
<p><strong>三极管工作在放大状态的条件</strong></p>
<p>三极管放大状态时的外部条件如图所示  </p>
<p><img src="/blog/image/Snipaste_2025-05-24_16-13-40.png"></p>
<p><strong>电流关系</strong></p>
<p>无论是 NPN 型还是PNP 型三极管都满足发射极电流等于基极电流与集电极电流之和<br>$$<br>I_E&#x3D;I_B+I_C<br>$$<br><strong>三极管各电极的电流方向</strong>  </p>
<p><img src="/blog/image/Snipaste_2025-05-24_16-20-37.png"></p>
<blockquote>
<p>如果将三极管看成节点, 三极管各电极间的电流关系应满足节点电流定律: <strong>流入三极管的电流之和等于流出三极管的电流之和</strong>  </p>
</blockquote>
<p>基极电流变化引起集电极电流变化, 但集电极与基极电流之比保持不变<br>$$<br>\beta&#x3D;\frac{I_C}{I_B}<br>$$</p>
<h2 id="扩展输出电流电路"><a href="#扩展输出电流电路" class="headerlink" title="扩展输出电流电路"></a>扩展输出电流电路</h2><p>当所需输出电流超过 $1.5,\text{A}$ 时，可采用外接功率管的办法来扩展电流。CW7800 系列稳压块的外接扩流功率管<strong>只能采用 PNP 型管</strong>。</p>
<p><img src="/blog/image/IMG_0128.jpg"></p>
<p>电阻 $R$ 的阻值由外接功率管的 $U_{BE}$ 值和集成稳压块的输入 电流 $I_{REG}$ 来决定，其表达式为：</p>
<p>$$<br>R &#x3D; \frac{U_{BE}}{I_{REG} - \frac{1}{\beta} I_T}<br>$$</p>
<p>其中：</p>
<ul>
<li>$I_{REG}$ 为流入集成稳压块的电流；</li>
<li>$I_T$ 为流过外接功率管 VT 的<strong>集电极电流</strong>；</li>
<li>$U_{BE}$ 为功率管的基极-发射极电压：<ul>
<li>对于锗管取 $0.3,\text{V}$；</li>
<li>对于硅管取 $0.7,\text{V}$；</li>
</ul>
</li>
<li>$\beta$ 为三极管的电流放大倍数</li>
<li>基极电流为 $I_b &#x3D; \dfrac{I_T}{\beta}$；</li>
<li>$R$ 处的压降为 $U_{BE}$，用来判断何时功率管导通。</li>
</ul>
<p><strong>在使用三端固定式集成稳压块时应注意以下问题</strong>  </p>
<ul>
<li><strong>使用固定式三端集成稳压器时，管脚不能接错，公共端不得悬空。</strong></li>
<li>当稳压器输出端使用大电容，且输出电压高于 ６Ｖ 时，应在<strong>输入、输出端跨接保护二极管</strong>，以防输入端短路时，输出电容通过稳压器进行放电使稳压器损坏。</li>
<li>目前三端式大功率稳压器一般采用塑封和金属封装。 <strong>加散热器时耗散功率可达７.５～1５Ｗ 。</strong></li>
<li>一般固定式集成稳压器的最大输入电压在 ３５～４０Ｖ 。 在使用时，<strong>整流电路输出电压的峰值不得超过此值。</strong></li>
</ul>
<h2 id="可调式集成稳压电源设计"><a href="#可调式集成稳压电源设计" class="headerlink" title="可调式集成稳压电源设计"></a>可调式集成稳压电源设计</h2><ul>
<li>３１７ 系列稳压器输出连续可调的正电压，３３７ 系列稳压器输出连续可调的负电压，可调范围为 １.２～３７Ｖ ，最大输出电流$I_{o \max}&#x3D;1.5A$。</li>
<li>稳压器内部含有过流、过热保护电路，具有安全可靠、性能优良、不易损坏、使用方便等优点。</li>
<li>其电压调整率和电流调整率均优于用固定式集成稳压块构成的可调电压稳压电源</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-07-06_08-36-02.png"><br>$$<br>U_o&#x3D;1.25(1+\frac{R_{p1}}{R_1})<br>$$</p>
<ul>
<li>1.25 是集成稳压块输出端与调整端之间的固有参考电压$U_{REF}$ ,此电压加于给定电阻$R_ 1$ 两端，将产生一个恒定电流通过输出电压调节电位器$R_\mathrm{Pl}$。</li>
<li>电阻$R_1$常取值 120~ 240 ,$R_{P1}$一般使用精密电位器，</li>
<li>与$R_{P1}$并联的电容器$C_2$可<strong>进一步减小输出电压的纹波</strong>。</li>
<li><strong>二极管 VD 的作用是防止输出端与地短路时$C_{2}$ 上的电压损坏稳压块。</strong></li>
</ul>
<h2 id="稳压二极管"><a href="#稳压二极管" class="headerlink" title="稳压二极管"></a>稳压二极管</h2><p><img src="/blog/image/Snipaste_2025-05-25_09-51-04.png"></p>
<p><strong>导通电压</strong>是稳压二极管在正向偏置下的阈值电压，即当正极电压高于负极（$V_P&gt;V_N$）时，二极管开始导通所需的最小电压。</p>
<ul>
<li>例如，硅材料稳压管的导通电压约为 <strong>0.7V</strong>，锗材料约为 <strong>0.3V</strong></li>
</ul>
<p><strong>稳压值</strong>（$V_Z$）是稳压二极管在反向击穿时维持的稳定电压，由PN结的掺杂浓度和结构设计决定。当反向电压达到 $V_Z$时，稳压管进入击穿区，电流大幅增加但电压基本恒定</p>
<p><strong>导通电压与稳压值的对比与联系</strong></p>
<table>
<thead>
<tr>
<th><strong>参数</strong></th>
<th><strong>导通电压（ $V_F$ ）</strong></th>
<th><strong>稳压值（$V_Z$ ）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>工作状态</strong></td>
<td>正向偏置（$V_P &gt; V_N $）</td>
<td>反向偏置（$V_P &lt; V_N $）</td>
</tr>
<tr>
<td><strong>典型值</strong></td>
<td>硅管0.7V，锗管0.3V</td>
<td>2V~200V（如5.1V、12V、24V等）</td>
</tr>
<tr>
<td><strong>核心功能</strong></td>
<td>不用于稳压，仅作为普通二极管导通</td>
<td>稳定电压，用于电源、保护、限幅等</td>
</tr>
<tr>
<td><strong>设计目标</strong></td>
<td>正向导通时尽量降低压降</td>
<td>反向击穿时维持电压稳定</td>
</tr>
</tbody></table>
<p><img src="/blog/image/100873.jpg"></p>
<p><img src="/blog/image/1747964224927.jpg"></p>
<p><strong>例题</strong></p>
<p><img src="/blog/image/1748049757394_%E7%9C%8B%E5%9B%BE%E7%8E%8B.jpg"></p>
<div>


<p>$$<br>I_2&#x3D;I_1+I_d \<br>I_1&#x3D;\frac {5}{R_1} \<br>6.2&#x3D;5+I_2R_2 \<br>$$</p>
</div>

<p>得到$R_1$和$R_2$有个比例关系，这时取定一个值确定另一个即可</p>
<h2 id="电压比较器"><a href="#电压比较器" class="headerlink" title="电压比较器"></a>电压比较器</h2><p>电压比较器通常用来判断输入信号的相对大小，对信号幅度进行控制或根据输入信号的幅度决定输出信号的极性。 </p>
<ul>
<li>常用的电压比较器有三种：<strong>过零比较器</strong>、<strong>单限比较器</strong>和<strong>迟滞比较器</strong>（滞回比较器）。</li>
</ul>
<h3 id="过零比较器"><a href="#过零比较器" class="headerlink" title="过零比较器"></a>过零比较器</h3><p><span style="color:#FF0000">输入 接在反相端</span></p>
<p><img src="/blog/image/Snipaste_2025-05-26_09-34-00.png"></p>
<p>图4.24(a)所示电路是一个电压比较器，运放在该电路中处于<strong>开环状态</strong>工作。其基本组成包括：</p>
<ul>
<li><strong>$U_i$</strong>：输入电压信号；</li>
<li><strong>$U_R$</strong>：参考电压。</li>
</ul>
<p>根据理想运放的特性，输出电压$U_o$的状态取决于$U_i$与$U_R$的比较结果：</p>
<ul>
<li>当 $U_i &lt; U_R$ 时，输出电压为：<br>$$<br>U_o &#x3D; +U_{om}<br>$$</li>
<li>当 $U_i &gt; U_R$ 时，输出电压为：<br>$$<br>U_o &#x3D; -U_{om}<br>$$</li>
</ul>
<p>因此，可以通过输出电压$U_o$的<strong>极性</strong>判断输入电压$U_i$是否<strong>大于或小于参考电压$U_R$</strong>。</p>
<hr>
<p><strong>过零比较器</strong></p>
<p>若将图4.24(a)中的同相端接地，即 $U_R &#x3D; 0$，则比较器成为<strong>过零比较器</strong>。</p>
<ul>
<li>输入信号 $U_i$ 从负值增加至正值时，在<strong>过零点</strong>，输出电压$U_o$发生<strong>极性变化</strong>，从 $+U_{om}$ 跳变到 $-U_{om}$。</li>
<li>图4.24(b) 展示了输入 $U_i$ 与输出 $U_o$ 的关系曲线，即<strong>输入-输出特性曲线</strong>，呈现明显的跳变特性。</li>
</ul>
<hr>
<p><strong>输出特性分析</strong></p>
<ul>
<li><p>$U_i$作用在同相端，反相输入端接地。其输出特性为：<br>$$<br>U_o &#x3D;<br>\begin{cases}<br>-U_{om}, &amp; U_i &lt; 0 \<br>+U_{om}, &amp; U_i &gt; 0<br>\end{cases}<br>$$<br>这种特性称为<strong>上行特性</strong>。</p>
</li>
<li><p>若反过来，则特性变为：<br>$$<br>U_o &#x3D;<br>\begin{cases}<br>+U_{om}, &amp; U_i &lt; 0 \<br>-U_{om}, &amp; U_i &gt; 0<br>\end{cases}<br>$$<br>此为<strong>下行特性</strong>。(上面图示)</p>
</li>
</ul>
<hr>
<h3 id="单限电压比较器"><a href="#单限电压比较器" class="headerlink" title="单限电压比较器"></a>单限电压比较器</h3><p>参考电压 $U_R \neq 0$ 的比较器称为单限电压比较器  </p>
<p><img src="/blog/image/Snipaste_2025-05-26_09-47-25.png"></p>
<h3 id="迟滞比较器（下行）"><a href="#迟滞比较器（下行）" class="headerlink" title="迟滞比较器（下行）"></a>迟滞比较器（下行）</h3><p>若在过零比较器或单限比较器电路中引入<strong>正反馈</strong>，比较器的输入-输出特性曲线便呈现<strong>迟滞回线形状</strong>，这类比较器称为<strong>迟滞比较器</strong>或<strong>滞回比较器</strong></p>
<blockquote>
<p>图中的$U_R$应该为$U_i$</p>
</blockquote>
<p><img src="/blog/image/Snipaste_2025-05-26_10-00-54.png"></p>
<p>如图4.26(a)，通过电阻 $R_f$ 和 $R_F$ 构成正反馈通路，反馈信号作用于运放的<strong>同相端</strong>。反馈电压$U_f$由输出电压$U_o$分压得到：</p>
<p>$$<br>U_f &#x3D; \frac{R_f}{R_f + R_F} U_o \tag{4-27}<br>$$</p>
<p>此时有：</p>
<p>$$<br>V^+ &#x3D; U_f &#x3D; \frac{R_f}{R_f + R_F} U_o<br>$$</p>
<hr>
<p><strong>迟滞现象分析</strong></p>
<p>若当前输出电压为 $U_o &#x3D; +U_{om}$，要使其从正饱和值变为负饱和值（$-U_{om}$），则反相端电压必须<strong>高于</strong>正相端参考电压 $V^+$，即：</p>
<p>$$<br>U_i &gt; V^+ &#x3D; \frac{R_f}{R_f + R_F} U_{om}<br>$$</p>
<p>因此，称该电压为<strong>上阈值电压（Upper Threshold Voltage）</strong>，记作 $U_{TH1}$：</p>
<p>$$<br>U_{TH1} &#x3D; \frac{R_f}{R_f + R_F} U_{om} \tag{4-28}<br>$$</p>
<p>反之，若当前输出电压为 $U_o &#x3D; -U_{om}$，要使其由负变正，则反相端输入 $U_i$ 必须<strong>低于</strong>下列阈值：</p>
<p>$$<br>U_i &lt; V^+ &#x3D; \frac{R_f}{R_f + R_F} (-U_{om})<br>$$</p>
<p>即定义为<strong>下阈值电压（Lower Threshold Voltage）</strong>，记作 $U_{TH2}$：</p>
<p>$$<br>U_{TH2} &#x3D; \frac{R_f}{R_f + R_F} (-U_{om}) \tag{4-29}<br>$$</p>
<hr>
<p><strong>特性曲线说明（图4.26(b)）</strong></p>
<p>在图4.26(b)中，输出电压$U_o$与输入电压$U_i$的关系曲线呈<strong>迟滞回线</strong>特征，表现为：</p>
<ul>
<li>当 $U_i$ 从低变高并超过 $U_{TH1}$ 时，输出电压从 $+U_{om}$ 跳变到 $-U_{om}$；</li>
<li>当 $U_i$ 从高变低并低于 $U_{TH2}$ 时，输出电压从 $-U_{om}$ 跳变到 $+U_{om}$；</li>
</ul>
<h3 id="迟滞比较器（接入参考电压-E-R-）（下行）"><a href="#迟滞比较器（接入参考电压-E-R-）（下行）" class="headerlink" title="迟滞比较器（接入参考电压$E_R$）（下行）"></a>迟滞比较器（接入参考电压$E_R$）（下行）</h3><p>相比基本迟滞比较器，<strong>将反馈电阻$R_f$通过电源$E_R$接地</strong>。此改动使得输入-输出特性曲线在<strong>水平方向（$U_i$轴）上偏移</strong>，即阈值电压位置发生了改变。该电路依然属于迟滞比较器，但其阈值不再关于零对称。</p>
<p><img src="/blog/image/Snipaste_2025-05-26_10-16-55.png"></p>
<p><strong>电压偏移分析</strong></p>
<p>当电源 $E_R$ 单独作用于运放的同相输入端（$+$端）时，产生的偏置电压为：</p>
<p>$$<br>V^{\prime} &#x3D; \frac{R_F}{R_f + R_F} E_R<br>$$</p>
<p>当输出电压 $U_o$单独作用时</p>
<p>$$<br>V^{\prime\prime} &#x3D; \frac{R_f}{R_f + R_F} U_o<br>$$</p>
<p>因此，同相端最终的电位为：</p>
<p>$$<br>V_+ &#x3D; V^{\prime} + V^{\prime\prime} &#x3D; \frac{R_f}{R_f + R_F} U_o + \frac{R_F}{R_f + R_F} E_R \tag{4-30}<br>$$</p>
<hr>
<p><strong>上阈值电压推导</strong></p>
<p>当 $U_o &#x3D; +U_{om}$ 时，要使输出电压翻转为 $-U_{om}$，输入电压 $U_i$ 必须高于 $V_+$，因此有：</p>
<p>$$<br>U_i &gt; U_{TH1} &#x3D; \frac{R_f}{R_f + R_F} U_{om} + \frac{R_F}{R_f + R_F} E_R \tag{4-31}<br>$$</p>
<p><strong>下阈值电压推导</strong></p>
<p>当 $U_o &#x3D; -U_{om}$ 时，要使输出跳变为正值 $+U_{om}$，此时$U_i$应满足：</p>
<p>$$<br>U_i &lt;U_{TH2} &#x3D; \frac{R_F}{R_f + R_F} E_R + \frac{R_f}{R_f + R_F} (-U_{om})<br>$$</p>
<hr>
<p><strong>特性曲线分析</strong></p>
<ul>
<li>输出翻转点分别为 $U_{TH1}$ 和 $U_{TH2}$，其中 $U_{TH1} &gt; U_{TH2}$。</li>
</ul>
<h3 id="迟滞比较器（接入参考电压-E-R-）（上行）"><a href="#迟滞比较器（接入参考电压-E-R-）（上行）" class="headerlink" title="迟滞比较器（接入参考电压$E_R$）（上行）"></a>迟滞比较器（接入参考电压$E_R$）（上行）</h3><p><img src="/blog/image/Snipaste_2025-05-26_10-23-47.png"></p>
<p>输入信号 $U_i$ 施加于运放的<strong>同相端</strong>，而反相端接参考电压 $E_R$，构成具有<strong>上行特性</strong>的迟滞比较器。</p>
<p><strong>电压分析与偏置电位计算</strong></p>
<p>在该结构中</p>
<ul>
<li><p>反相端的电位为 $V_- &#x3D; E_R$</p>
</li>
<li><p>同相端电位 $V_+$ 可通过叠加法求得：</p>
</li>
</ul>
<p>$$<br>V_+ &#x3D; \frac{R_F}{R_f + R_F} U_i + \frac{R_f}{R_f + R_F} U_o<br>$$</p>
<blockquote>
<ul>
<li><p>当 $V_+ &gt; V_-$ 时，输出电压 $U_o &#x3D; +U_{om}$；</p>
</li>
<li><p>当 $V_+ &lt; V_-$ 时，输出电压 $U_o &#x3D; -U_{om}$。</p>
</li>
</ul>
</blockquote>
<ol>
<li>当 $U_o &#x3D; -U_{om}$ 时，要使其变为 $+U_{om}$，必须使 $V_+ &gt; V_-$，即：</li>
</ol>
<p>$$<br>\frac{R_F}{R_f + R_F} U_i + \frac{R_f}{R_f + R_F} (-U_{om}) &gt; E_R \tag{4-33}<br>$$</p>
<p>由此推出</p>
<p>$$<br>U_i &gt; \frac{R_f + R_F}{R_F} E_R + \frac{R_f}{R_F} U_{om} \tag{4-34}<br>$$</p>
<p>才能使输出从 $-U_{om}$ 跳变至 $+U_{om}$。这一定义为<strong>上阈值电压</strong> $U_{TH1}$。</p>
<p><strong>上阈值电压公式</strong><br>$$<br>U_{TH1} &#x3D; \frac{R_f + R_F}{R_F} E_R + \frac{R_f}{R_F} U_{om}<br>$$</p>
<ol start="2">
<li>当 $U_o &#x3D; +U_{om}$，要使其变为 $-U_{om}$，则必须使 $V_+ &lt; V _-$，即：</li>
</ol>
<p>$$<br>\frac{R_F}{R_f + R_F} U_i + \frac{R_f}{R_f + R_F} U_{om} &lt; E_R \tag{4-35}<br>$$</p>
<p>由此得出，输入信号需满足：</p>
<p>$$<br>U_i &lt; \frac{R_f + R_F}{R_F} E_R - \frac{R_f}{R_F} U_{om} \tag{4-36}<br>$$</p>
<p>该值定义为<strong>下阈值电压</strong> $U_{TH2}$。<br>$$<br>U_{TH2}&#x3D;\frac{R_f + R_F}{R_F} E_R - \frac{R_f}{R_F} U_{om} \tag{4-36}<br>$$</p>
<hr>
<p><strong>特性曲线分析（图4.28(b)）</strong></p>
<ul>
<li>当 $U_i$ 增大并超过 $U_{TH1}$ 时，输出由 $-U_{om}$ 跳变至 $+U_{om}$；</li>
<li>当 $U_i$ 减小并低于 $U_{TH2}$ 时，输出由 $+U_{om}$ 跳变至 $-U_{om}$；</li>
<li>迟滞区间由 $U_{TH1}$ 和 $U_{TH2}$ 确定，特性为<strong>上行型迟滞回线</strong>。</li>
</ul>
<hr>
<h3 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h3><p><img src="/blog/image/g45eg.jpg"></p>
<blockquote>
<ul>
<li><strong>这就是一个下行的迟滞比较器，抓住两个阈值电压即可解题</strong></li>
</ul>
</blockquote>
<p><strong>例题</strong></p>
<p><img src="/blog/image/1748049757362_%E7%9C%8B%E5%9B%BE%E7%8E%8B.jpg"></p>
<h2 id="电压跟随器"><a href="#电压跟随器" class="headerlink" title="电压跟随器"></a>电压跟随器</h2><blockquote>
<p><strong>电压跟随器（Voltage Follower）工作原理推导</strong></p>
<hr>
<p><strong>1. 电路结构</strong></p>
<p>电压跟随器是一种将<strong>运算放大器输出端</strong>直接连接到其<strong>反相输入端（$-$）<strong>的特殊形式，输入信号加在</strong>同相端（$+$）</strong>。</p>
<blockquote>
<p><strong>记忆</strong>：<span style="color:#FF0000">同相输入，反相输出</span></p>
</blockquote>
<p>其结构特点是：</p>
<ul>
<li>$U_+ &#x3D; U_i$（输入端）</li>
<li>$U_- &#x3D; U_o$（因为反相端与输出端直接相连）</li>
</ul>
<hr>
<p><strong>2. 运算放大器基本关系式</strong></p>
<p>理想运算放大器的基本输出关系为：</p>
<p>$$<br>U_o &#x3D; A(U_+ - U_-)<br>$$</p>
<p>其中：</p>
<ul>
<li>$U_o$：输出电压  </li>
<li>$A$：开环增益（$A \to \infty$）  </li>
<li>$U_+$：同向端电压  </li>
<li>$U_-$：反相端电压</li>
</ul>
<hr>
<p><strong>3. 引入负反馈分析</strong></p>
<p>由于：</p>
<ul>
<li>$U_+ &#x3D; U_i$  </li>
<li>$U_- &#x3D; U_o$</li>
</ul>
<p>将其代入上式：</p>
<p>$$<br>U_o &#x3D; A(U_i - U_o)<br>$$</p>
<p>整理得：</p>
<p>$$<br>U_o + A U_o &#x3D; A U_i<br>$$</p>
<p>$$<br>U_o (1 + A) &#x3D; A U_i<br>$$</p>
<p>$$<br>U_o &#x3D; \frac{A}{1 + A} U_i<br>$$</p>
<p>当 $A \to \infty$ 时：</p>
<p>$$<br>\frac{A}{1 + A} \to 1<br>$$</p>
<p>所以：</p>
<p>$$<br>U_o \approx U_i<br>$$</p>
<p>即输出电压等于输入电压。</p>
<hr>
<p><strong>4. 工作原理总结</strong></p>
<p>电压跟随器依靠运放的高增益特性与强负反馈作用，迫使其输出电压自动调整到与输入电压一致，从而达到：</p>
<p>$$<br>U_o \approx U_i<br>$$</p>
<p>这种“紧随输入”的特性，就是电压跟随器名称的由来。</p>
<hr>
<p><img src="/blog/image/Snipaste_2025-06-30_09-27-45.png"></p>
</blockquote>
<h2 id="V-F电路设计"><a href="#V-F电路设计" class="headerlink" title="V&#x2F;F电路设计"></a>V&#x2F;F电路设计</h2><h3 id="V-F转换电路"><a href="#V-F转换电路" class="headerlink" title="V&#x2F;F转换电路"></a>V&#x2F;F转换电路</h3><p>$\bigstar$<strong>定义</strong><span style="color:#FF0000">（什么是V&#x2F;F转换）</span></p>
<p>V&#x2F;F（电压&#x2F;频率）转换器能把<strong>输入信号电压转换成相应的频率信号</strong>，即它的<strong>输出信号频率与输入信号电压值成比例</strong>，故又称为电压控制（压控）振荡器（VCO）。</p>
<p><strong>应用</strong></p>
<p>在<u>调频（电压调频）</u>，<u>锁相</u>和<u>A&#x2F;D变换</u>等许多技术领域得到非常广泛的应用。</p>
<p><strong>指标</strong></p>
<ul>
<li>额定工作频率和动态范围</li>
<li>灵敏度或变换系数</li>
<li>非线性误差</li>
<li>灵敏度误差和温度系数等</li>
</ul>
<p><strong>最简信号频率输入通道结构</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-25_09-31-37.png"></p>
<ul>
<li>将被测量转换成与被测信号成比例的电压(或电流)脉冲频率(f)、周期(T)或周期数(N)。</li>
</ul>
<p>因此，前向通道只需将代表被测物理量的这些电压脉冲信号通过整形放大成TTL(Transister-Transister-Logic晶体管-晶体管逻辑电平)电平的频率、周期、周期数信号送入计算机应用系统中即可。为了防止噪声侵入，可经过光电耦合后送入。</p>
<p><strong>V&#x2F;F转换信号频率输入通道结构</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-25_09-36-31.png"></p>
<ul>
<li><p>这种输入通道结构与一般A&#x2F;D转换器前向通道结构相似，只不过是将A&#x2F;D转换器改换成V&#x2F;F转换器</p>
</li>
<li><p>传感器一般都是模拟量小信号电流或电压输出，经过信号调节器调节成能满足V&#x2F;F转换器输入要求的大电压信号。</p>
</li>
<li><p>V&#x2F;F转换器把这些模拟输入电压转换成相应的TTL频率信号，经光电耦合后送入计算机。同样可以送入I&#x2F;O口、计数器输入端或中断源输入端上。</p>
</li>
<li><p>在这类通道中，信号调节器及其前端电路皆为模拟电路。</p>
</li>
</ul>
<p><strong>R、L、C&#x2F;F转换信号频率输入通道结构</strong></p>
<p><img src="/blog/image/Snipaste_2025-06-25_09-34-14.png"></p>
<p>这种输入通道中的传感器都是R、L、C类传感器，如热敏电阻、光敏电阻、电感传感器，电容传感器等。</p>
<p>把外界被测物理量变换成R、L、C的变化，这些敏感元件可称为参量变换器。将这些R、L、C参量接入R、L、C振荡电路或脉冲宽度调制器，则振荡电路输出的信号频率f或脉冲宽度调制器输出的信号周期T与相应的R、L、C成正比。</p>
<p><span style="color:#FF0000">  <strong>$ \bigstar$ V&#x2F;F转换原理</strong></span></p>
<p><strong>原理</strong>：利用过零比较器的工作原理，转换器产生<strong>频率</strong>正比于输入电压的<strong>脉冲序列</strong>，然后在固定的时间内对脉冲进行计数。</p>
<p><strong>两种方法：</strong></p>
<ul>
<li>电荷平衡式V&#x2F;F转换器</li>
<li>积分复原型</li>
</ul>
<h3 id="电荷平衡式V-F转换电路"><a href="#电荷平衡式V-F转换电路" class="headerlink" title="电荷平衡式V&#x2F;F转换电路"></a>电荷平衡式V&#x2F;F转换电路</h3><blockquote>
<p>课本图做大概推导，PPT解释具体的电荷转移原理</p>
</blockquote>
<p><img src="/blog/image/Snipaste_2025-07-27_19-38-58.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-06_14-13-33.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-06_14-14-14.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-06_14-14-30.png"></p>
<h3 id="积分复原型V-F转换电路"><a href="#积分复原型V-F转换电路" class="headerlink" title="积分复原型V&#x2F;F转换电路"></a>积分复原型V&#x2F;F转换电路</h3><ul>
<li><p>电路包含积分器、电平检测器、积分复原开关</p>
</li>
<li><p><span style="color:#FF0000">积分复原开关</span>：当积分电容充电到<strong>下限值电平</strong>（图中$u_2$）时，电平检测器使积分复原开关导通，使电容迅速放电，积分器输出复原到<strong>上限阀值电压</strong>（图中$u_1$)，复原开关重新截止，积分器再次积分  </p>
</li>
<li><p>$u_i$越高$u_c$越快达到$u_p$电平，比较器翻转越快</p>
</li>
<li><blockquote>
<p><strong>该电路精度低，适用于精度不高的场合</strong></p>
</blockquote>
</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-07-06_14-15-07.png"></p>
<h2 id="接口设计"><a href="#接口设计" class="headerlink" title="接口设计"></a>接口设计</h2><h3 id="接口分类"><a href="#接口分类" class="headerlink" title="接口分类"></a>接口分类</h3><p><span style="color:#FF0000">接口：</span>接口是指计算机系统中一个部件与另一些部件的相互连接。</p>
<p><strong>接口分类</strong></p>
<ul>
<li><p>存储器接口</p>
</li>
<li><p>I&#x2F;O接口</p>
</li>
<li><p>总线接口（通用接口）</p>
</li>
</ul>
<h3 id="电平转换"><a href="#电平转换" class="headerlink" title="电平转换"></a>电平转换</h3><ol>
<li><p><span style="color:#FF0000">为什么要进行电平转换?</span><br>与计算机相连的其它功能单元各<u>自有各自的工作电平</u>， 需要一个<u>媒介</u>与这些功能单元电平之间进行相互转换。</p>
</li>
<li><p><strong>什么是TTL电平?</strong><br>TTL电平信号通常数据表示采用二进制规定，+5V等于逻辑”1”，0V等于逻辑”0”，这被称做TTL（晶体管-晶体管逻辑电平）信号系统，这是计算机处理控制的设备内部各部分之间通信的标准技术。</p>
</li>
<li><p><strong>TTL电平转换</strong></p>
<ul>
<li>TTL——继电器连接</li>
<li>TTL——MOS电平转换</li>
</ul>
</li>
</ol>
<h3 id="TTL——继电器连接"><a href="#TTL——继电器连接" class="headerlink" title="TTL——继电器连接"></a>TTL——继电器连接</h3><ul>
<li><p><strong>继电器</strong>：是一种电控控制器件。它具有控制系统（又称输入回路）和被控制系统（又称输出回路）之间的互动关系。通常应用于自动化的控制电路中，它实际上是用<strong>小电流去控制大电流运作的一种“自动开关”</strong>，故在电路中起着自动调节、安全保护、转换电路等作用。</p>
</li>
<li><p>TTL——继电器连接只适用于<strong>慢变信号</strong>，在TTL信号与继电器连接时往往要经过一个驱动级，用以提供继电器工作所必需的电流。</p>
<p><span style="color:#FF0000">下图为<strong>继电器驱动电路</strong></span></p>
</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-06-24_16-39-03.png"></p>
<p><span style="color:#FF0000">图 4.44 及图 4.45 为计算机电平与交流电网之间的电平转换电路。</span></p>
<ul>
<li><p>图 4.44 中，合上开关，与 220V 电网接通，继电器吸合，在计算机输入端得到 TTL 低电平。</p>
</li>
<li><p>电路中的滤波器用以<strong>抑制干扰</strong>。</p>
</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-06-25_09-55-29.png"></p>
<ul>
<li>图 4.45 用一个 TTL 电平信号控制晶闸管（可控硅）整流电路的工作。来自计算机的输入为 TTL 高电平时，继电器闭合，其触点将晶闸管的控制级与控制电路接通，使得与晶闸管相连的负载 $R_L$ 上流过整流电流。</li>
<li>若输入为 TTL 低电平则继电器触点断开，晶闸管控制级得不到相应的点火控制，晶闸管截止，负载上无电流。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-06-25_09-54-37.png"></p>
<h3 id="例题-2"><a href="#例题-2" class="headerlink" title="例题"></a>例题</h3><p><img src="/blog/image/Snipaste_2025-07-08_20-29-26.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-08_20-29-45.png"></p>
<h3 id="TTL-MOS电平转换"><a href="#TTL-MOS电平转换" class="headerlink" title="TTL-MOS电平转换"></a>TTL-MOS电平转换</h3><p>无论是 <u>TTL 电路驱动 CMOS</u>（Complementary Metal Oxide Semiconductor，互补金属氧化物半导体）电路还是 <u>COMS 电路驱动 TTL 电路</u>，<strong>驱动门</strong>必须为<strong>负载门</strong>提供合乎标准的高、低电平和足够的驱动电流</p>
<ul>
<li>MOS 器件中，除了采用 +5V 电源的 CMOS 器件能与 TTL 电路直接连接外，大部分 MOS 器件与 TTL 电路之间要经过电平转换连接。</li>
<li>一般的 MOS 电路采用大约 <strong>15V</strong> 的电源电压。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-06-25_10-33-54.png"></p>
<ol>
<li><p>OC型MOS-TTL电平转换</p>
<p>TTL电路的输出级采用<strong>集电极开路</strong>的电路（OC门）</p>
</li>
<li><p>一般型TTL-CMOS</p>
<p>TTL电路的末级不是 ＯＣ 门，用一<strong>晶体管</strong>来完成电平转换</p>
</li>
</ol>
<blockquote>
<p>用 TTL 门可直接驱动 CMOS 门，而用 CMOS 门却只能驱动低功率肖特基门。</p>
<p><strong>在用CMOS驱动标准TTL门时，要加一级晶体管作驱动级</strong>  </p>
</blockquote>
<p><strong>对于负逻辑（高电平 -12V，低电平 4V）的 MOS，也可用分立元件使它与 TTL 电路相连接。</strong></p>
<ul>
<li><p>晶体管T1实现电平移动，T2提供驱动</p>
<p><img src="/blog/image/Snipaste_2025-06-25_10-44-09.png"></p>
</li>
</ul>
<h3 id="光耦合器的技术特性与应用"><a href="#光耦合器的技术特性与应用" class="headerlink" title="光耦合器的技术特性与应用"></a>光耦合器的技术特性与应用</h3><ul>
<li>光耦合器（optical coupler，英文缩写为OC），也称光电隔离器，简称<strong>光耦</strong>。光耦合器以光为媒介传输电信号，对输入、输出电信号有良好的隔离作用， 所以在各种电路中得到广泛应用。</li>
<li>光耦合器一般由三部分组成：<strong>光的发射、光的接收及信号放大。</strong></li>
<li>**工作原理：**光耦合器的发光器件为二极管，光接收器为光敏二极管。当有电流通过发光二极管时，便形成一个光源，照射到光敏二极管表面上，使光敏二极管产生<u>集电极电流</u>。<strong>电流大小与光照的强弱（流过二极管电流的大小）成正比。</strong></li>
<li>为了提高驱动能力，芯片输出级加了一只晶体管</li>
</ul>
<h4 id="光耦合器的主要优点"><a href="#光耦合器的主要优点" class="headerlink" title="光耦合器的主要优点"></a>光耦合器的主要优点</h4><ul>
<li>信号单向传输，输入端与输出端完全实现了电气隔离；</li>
<li>输出信号对输入端无影响，抗干扰能力强；</li>
<li>工作稳定，无触点，使用寿命长，传输效率高。</li>
</ul>
<h4 id="光耦合器的主要应用"><a href="#光耦合器的主要应用" class="headerlink" title="光耦合器的主要应用"></a>光耦合器的主要应用</h4><ul>
<li>广泛应用于电气绝缘、电平转换、驱动电路、开关电路、信号隔离、通讯设备及微机接口中。</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-07-06_16-46-08.png"></p>
<h3 id="继电器、接触器的功率接口"><a href="#继电器、接触器的功率接口" class="headerlink" title="继电器、接触器的功率接口"></a>继电器、接触器的功率接口</h3><ul>
<li><p><strong>接触器</strong>：是指工业电中利用线圈流过电流产生磁场，使触头闭合，以达到控制负载的电器。</p>
<ul>
<li>其原理是当接触器的电磁线圈通电后，会产生很强的磁场，使铁心产生电磁吸力吸引衔铁，并带动触头动作，<span style="color:#FF0000">常闭触头断开</span>，<span style="color:#FF0000">常开触头闭合</span>；当线路断电时，电磁吸力消失，衔铁在弹簧的作用下释放，使触头复原，<span style="color:#FF0000">常闭触头闭合</span>，<span style="color:#FF0000">常开触头断开</span>。</li>
</ul>
</li>
<li><p>继电器、接触器的<strong>供电</strong>系统分为<strong>直流电磁系统</strong>和<strong>交流电磁系统</strong>，工作电压也较高，因此从单片机输出的信号需要经过<strong>驱动</strong>电路进行<strong>转换</strong>，使输出的驱动电压能够适应继电器或接触器线圈的要求。</p>
</li>
<li><p>继电器、接触器动作时，对电源有一定的干扰，为了提高单片机系统的可靠性，在单片机和继电器、接触器之间都用<strong>光电耦合器</strong>隔离。 —些超小型的继电器，由于线圈工作电流较小，对电源的影响不大，也可以不加隔离电路。</p>
</li>
</ul>
<h4 id="直流电磁式继电器功率接口"><a href="#直流电磁式继电器功率接口" class="headerlink" title="直流电磁式继电器功率接口"></a>直流电磁式继电器功率接口</h4><ul>
<li>直流电磁式继电器、接触器一般用<strong>功率接口集成电路</strong>或<strong>晶体管</strong>驱动  </li>
<li>常用的继电器大部分属于<strong>直流电磁式继电器</strong>，也称为<strong>直流继电器</strong>  </li>
<li>一片SN75468可以驱动 ７ 个继电器，驱动电流可达500mA，输出端最大工作电压为100V</li>
</ul>
<p><span style="color:#FF0000">直流继电器接口电路图</span>（图要会画，工作原理要清楚）</p>
<p><img src="/blog/image/Snipaste_2025-07-06_20-03-18.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-06_20-05-22.png"></p>
<p><span style="color:#FF0000">工作原理</span>：</p>
<ul>
<li><p>单片机 <strong>P1.0 输出低电平</strong> 时，光电耦合器 TIL117 导通，为晶体管 9013 提供基极电流，9013 饱和导通，继电器线圈通电吸合；</p>
</li>
<li><p><strong>P1.0 输出高电平</strong> 时，光耦截止，9013 关断，线圈断电释放。（采用这种控制逻辑可以使继电器在上电复位或单片机受控复位时不吸合  ）</p>
</li>
<li><p>二极管 D 在断电瞬间吸收反向感应电动势，保护晶体管 9013</p>
<blockquote>
<p>二极管 Ｄ 的作用是保护晶体管 Ｔ </p>
<p><strong>原理</strong>：</p>
<ul>
<li>当继电器 Ｊ 吸合时，二极管 Ｄ 截止，不影响电路工作</li>
<li>当<strong>继电器释放</strong>时，线圈因电感特性产生 <strong>上负下正的反向感应电动势</strong>，其正端接晶体管 T 的集电极，与电源$V_c$叠加后易超过 T 的集电结反向耐压。此时 <strong>二极管 D 正向导通</strong>，为感应电流提供 <strong>续流回路</strong>，使线圈储能通过 D 缓慢释放，避免感应电压急剧升高，从而保护晶体管 T 免受高压损坏。</li>
</ul>
</blockquote>
<blockquote>
<p>记住二极管的方向，忘了现场推：导通时，继电器电流从上到下，突然断电，感应电动势抑制电流变化，产生从上到下的电流，感应电动势上负下正，二极管电流从下到上导通。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p><strong>例题</strong></p>
<p><img src="/blog/image/IMG_20250606_102808.jpg"></p>
<p><img src="/blog/image/IMG_20250606_103337.jpg"></p>
<p><strong>TTL输入 → 信号调理 → 隔离 → 功率驱动 → 电磁阀</strong></p>
<p><strong>一、设计核心需求</strong></p>
<ol>
<li><p><strong>电气隔离</strong>：TTL 侧（5V）与电磁阀侧（24V、1A）不能直接电连接，需通过 “电→光→电” 转换隔离（光电耦合器是关键）。</p>
</li>
<li><p><strong>驱动能力</strong>：电磁阀工作电流 1A，TTL 电平（mA 级）无法直接驱动，需 <strong>功率放大电路</strong>（三极管）。</p>
</li>
<li><p><strong>感性负载保护</strong>：电磁阀是电感，断电时产生反向电动势，需 <strong>续流二极管</strong> 吸收能量，保护功率管</p>
</li>
</ol>
  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[&quot;TTL低电平&quot;] --&gt; B[&quot;U2反相 → 高电平&quot;]</span><br><span class="line">    B --&gt; C[&quot;U1发光二极管导通 → 发光&quot;]</span><br><span class="line">    C --&gt; D[&quot;U1光敏三极管导通&quot;]</span><br><span class="line">    D --&gt; E[&quot;T1基极获电流 → 饱和导通&quot;]</span><br><span class="line">    E --&gt; F[&quot;24V电源 → 电磁阀供电 → 工作&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[&quot;TTL高电平&quot;] --&gt; B[&quot;U2反相 → 低电平&quot;]</span><br><span class="line">    B --&gt; C[&quot;U1发光二极管熄灭&quot;]</span><br><span class="line">    C --&gt; D[&quot;U1光敏三极管截止&quot;]</span><br><span class="line">    D --&gt; E[&quot;T1基极无电流 → 截止&quot;]</span><br><span class="line">    E --&gt; F[&quot;电磁阀断电&quot;]</span><br><span class="line">    F --&gt; G[&quot;续流二极管吸收反向电动势 → 保护T1&quot;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>元件</th>
<th>名称</th>
<th>核心作用</th>
</tr>
</thead>
<tbody><tr>
<td>U2</td>
<td>反相驱动器</td>
<td>① 缓冲 TTL 输入信号，增强驱动能力；② 反相逻辑，匹配光电耦合器的触发逻辑。</td>
</tr>
<tr>
<td>U1</td>
<td>光电耦合器</td>
<td>实现“电气隔离”：左侧电信号→光信号→右侧电信号，切断两侧电路的直接电连接。</td>
</tr>
<tr>
<td>R1</td>
<td>限流电阻（发光侧）</td>
<td></td>
</tr>
<tr>
<td>R2</td>
<td>限流电阻（三极管基极）</td>
<td></td>
</tr>
<tr>
<td>T1</td>
<td>功率三极管</td>
<td>放大电流：将光电耦合器的微弱信号放大，驱动 1A 的电磁阀。</td>
</tr>
<tr>
<td>续流二极管</td>
<td>保护 T1</td>
<td>吸收电磁阀断电时的反向电动势，保护 T1 不被击穿。</td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<ol>
<li><strong>隔离层</strong>：光电耦合器 U1 是 “隔离核心”，通过光信号传递，彻底切断两侧电连接。</li>
<li><strong>驱动层</strong>：功率三极管 T1 负责 “大电流放大”，将微弱信号提升至 1A 驱动能力。</li>
<li><strong>保护层</strong>：续流二极管应对感性负载的反向电动势</li>
</ol>
</blockquote>
<h4 id="交流电磁式接触器的功率接口"><a href="#交流电磁式接触器的功率接口" class="headerlink" title="交流电磁式接触器的功率接口"></a>交流电磁式接触器的功率接口</h4><ul>
<li><p>交流电磁式接触器由于线圈的工作<u>电压</u>要求是<u>交流电</u>，所以通常使用<u><strong>双向晶闸管</strong></u>驱动或使用一个<u>直流继电器</u>作为中间继电器控制。</p>
</li>
<li><p>晶闸管是<strong>晶体</strong>闸流管的简称，又可称做<strong>可控硅</strong>整流器，晶闸管是PNPN四层<strong>半导体</strong>结构，它有三个极：<strong>阳极、阴极和门极</strong>。</p>
</li>
<li><p>晶闸管具有硅整流<strong>器件</strong>的特性，能在高电压、大<strong>电流</strong>条件下工作，且其工作过程可以控制，被广泛应用用于可控整流、交流调压、等电子电路中。</p>
</li>
</ul>
<p><img src="/blog/image/Snipaste_2025-07-06_21-17-06.png"></p>
<p><img src="/blog/image/Snipaste_2025-07-06_21-17-31.png"></p>
<p><strong>光电耦合器 Ｍ ＯＣ３０４１ 的作用：</strong></p>
<ul>
<li><p>触发双向晶闸管 ＫＳ </p>
</li>
<li><p>隔离单片机系统和接触器系统</p>
</li>
</ul>
<p><span style="color:#FF0000">工作原理</span>：</p>
<p>P1.0 输出<strong>低电平</strong>时，双向晶闸管KS 导通、接触器 C 吸合；</p>
<p>P1.0 输出<strong>高电平</strong>时，双向晶闸管KS 关断、接触器 C 释放 。</p>
<ul>
<li>这种控制逻辑可以使得单片机复位时，晶闸管 ＫＳ 的状态为关断，不会引起 ＫＳ 误导通</li>
</ul>
<blockquote>
<p><strong>注意</strong>：光电耦合器 Ｍ ＯＣ３０４１ 内部带过零控制电路，使 KS 工作在 <strong>过零触发方式</strong> 。</p>
</blockquote>
<blockquote>
<p><img src="/blog/image/IMG_20250606_103503.jpg"></p>
<p><img src="/blog/image/IMG_20250606_103538.jpg"></p>
<p>一、设计核心需求</p>
<ol>
<li><p><strong>电气隔离</strong>：5V TTL（直流小信号）与 220V 交流（高压强电）必须彻底隔离，防止高压串入控制电路。</p>
</li>
<li><p><strong>交流驱动</strong>：负载是 220V 交流电（正弦波，正负交替），需 <strong>双向导通的开关器件</strong>（应对交流正负半周）。</p>
</li>
<li><p><strong>信号匹配</strong>：TTL 电平需缓冲 &#x2F; 反相，匹配隔离器件的触发逻辑</p>
</li>
</ol>
<p>  二、元件功能解析</p>
<table>
<thead>
<tr>
<th>元件符号</th>
<th>名称</th>
<th>核心作用</th>
</tr>
</thead>
<tbody><tr>
<td>U2</td>
<td>反相驱动器</td>
<td>①缓冲TTL信号,增强驱动能力;②反相逻辑,匹配光控器件的触发电平。</td>
</tr>
<tr>
<td>U1</td>
<td>光控晶闸管（光电耦合器）</td>
<td>实现“电气隔离”:将TTL侧电信号 → 光信号 → 电信号,触发交流侧的双向晶闸管。</td>
</tr>
<tr>
<td>U3</td>
<td>双向晶闸管</td>
<td>作为交流开关:受U1触发后,双向导通220V交流电,控制加热炉通断。</td>
</tr>
<tr>
<td>R1&#x2F;R2&#x2F;R3</td>
<td>限流电阻</td>
<td></td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<p>三、设计逻辑的关键思考</p>
<ol>
<li><strong>为什么选双向晶闸管（U3）？</strong></li>
</ol>
<p>交流电压是 <strong>正弦波（正负交替）</strong>：</p>
<ul>
<li>普通三极管仅能 <strong>单向导通</strong>（应对直流），无法处理交流负半周；</li>
<li>双向晶闸管可在 <strong>正负半周均触发导通</strong>，完美匹配交流负载的双向特性。</li>
</ul>
<ol start="2">
<li><strong>为什么用 “光控” 实现隔离？</strong></li>
</ol>
<ul>
<li><p>U1（光控晶闸管）或 “光电耦合器 + 晶闸管” 的组合，通过 <strong>“电→光→电” 的信号转换</strong>，彻底切断：</p>
</li>
<li><p>直流控制侧（5V，低电压）与交流高压侧（220V，强电）的直接电连接，实现电气隔离。</p>
</li>
</ul>
<ol start="3">
<li><strong>反相驱动器（U2）的意义？</strong></li>
</ol>
<ul>
<li><strong>逻辑匹配</strong>：TTL 高电平可能与 U1 的触发逻辑冲突（如 U1 需低电平触发），反相器可调整电平逻辑。</li>
<li><strong>驱动增强</strong>：TTL 信号驱动能力弱，反相器可增强带载能力，避免信号失真。</li>
</ul>
</blockquote>
<h3 id="电光、电热型功率接口"><a href="#电光、电热型功率接口" class="headerlink" title="电光、电热型功率接口"></a>电光、电热型功率接口</h3><ul>
<li>电光型功率接口主要用于各类<strong>照明</strong>以及<strong>闪光</strong>指示器等的驱动，电光型功率接口采用<strong>连续</strong>方式控制；</li>
<li>电热型功率接口主要用于各种<strong>电炉和加热器</strong>等的驱动，电热型功率接口采用<strong>连续或断续</strong>方式控制。</li>
</ul>
<h4 id="电光、电子型器件"><a href="#电光、电子型器件" class="headerlink" title="电光、电子型器件"></a>电光、电子型器件</h4><ol>
<li><p><strong>电光型</strong></p>
<ul>
<li>目前应用最广泛的电光源是<strong>白炽灯</strong>。白炽灯的<strong>发光原理</strong>是热辐射原理，利用电流通过钨丝，使钨丝温度升高，达到“白炽”的状态，从而辐射出光能。白炽灯调光时，通常采用<strong>连续控制</strong>，用双向晶闸管作为控制元件，调节双向晶闸管的控制角来控制白炽灯的亮度。</li>
</ul>
</li>
<li><p><strong>电热型</strong></p>
<ul>
<li>电热器件是能把电能转化为热能的各类器件，常用的电热器件有：<strong>电阻丝电热器件</strong>、多孔玻璃态碳电热器件、电热膜；硅钼棒电热器件和PTC半导体电热器件。</li>
</ul>
</li>
</ol>
<h4 id="电光型功率接口"><a href="#电光型功率接口" class="headerlink" title="电光型功率接口"></a>电光型功率接口</h4><p><img src="/blog/image/Snipaste_2025-07-06_21-53-03.png"></p>
<p><strong>工作原理：</strong></p>
<p>MOC3021 由单片机 8031 的 P1.0 端经 7407 控制，</p>
<ul>
<li><p>P1.0 输出低电平时，双向晶闸管 KS 导通，白炽灯 L 发亮；</p>
</li>
<li><p>P1.0 输出高电平时，双向晶闸管 KS 关断，白炽灯 L 不亮。</p>
</li>
<li><blockquote>
<p>这种控制逻辑可以使得单片机复位时，晶闸管 KS 的状态为关断，不会引起 KS 误导通。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>电光型功率接口通常用<strong>晶闸管</strong>作为控制元件，配上<strong>过零检测</strong>电路后，可以调节输出的电压，控制电光器件的发光程度  </p>
</blockquote>
<h4 id="电热型功率接口"><a href="#电热型功率接口" class="headerlink" title="电热型功率接口"></a>电热型功率接口</h4><blockquote>
<p><strong>电热型功率接口通常用继电器或晶闸管控制</strong>  </p>
</blockquote>
<p><img src="/blog/image/Snipaste_2025-07-07_07-39-02.png"></p>
<ul>
<li>电热器件由双向晶闸管 KS 控制，KS 由光电耦合器 4N25 和晶体管 9013 触发。采用直流脉冲触发。触发电压由变压器 B 的其中一个绕组$L_{2}$提供。经整流滤波后，直流电压为 12V ,触发电流可达 200m A 。</li>
</ul>
<p><span style="color:#FF0000">工作原理：</span></p>
<ol>
<li><strong>触发原理</strong></li>
</ol>
<p>单片机 8031 的 P1.0 端输出的触发信号经 7407 后，送到光电耦合器 4N25。</p>
<ul>
<li><p>P1.0端输出高电平时，4N25 没有电流输人，晶体管 T 截止，双向晶闸管 KS 关断， 电热器不加热。</p>
</li>
<li><p>当 P1. 0端输出低电平时，7407 输出低电平，4N25 导通 ,输出端的电流经晶体管 9013 放大后 ,双向晶闸管导通 ,电热器加热。</p>
<blockquote>
<p>电阻$R_3$ 的作用是限制触发电流，当双向晶闸管 KS 的功率较小时 ,$R$3 可由 30$\Omega$改为 100$\Omega_\circ$</p>
</blockquote>
<ol start="2">
<li><strong>温度检测电路原理</strong></li>
</ol>
<p>温度检测电路由热电偶、运算放大器组成。</p>
<ul>
<li>热电偶产生的毫伏级电压经运算放大器变成 0~5V 的电压后，送到 A&#x2F;D 转换器输入端，经 A&#x2F;D 转换器变成反映温度的数字信号。</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong>过零检测电路原理</strong></li>
</ol>
<ul>
<li>过零检测电路由变压器 B 的其中一个绕组$L_{3}$和电容器$C_2$组成。$L_3$产生2.5V 的交流电压，通过$C_2$交连到 8031 的 INT1 和 INT0 端。<ul>
<li>INT1 是过零检测端，它可对过零的上升信号检测而产生中断：</li>
</ul>
</li>
<li>INT0 也是过零检测端，它可对过零的下降信号检测而产生中断。<ul>
<li>把 INTl 和 INT 0 产生的中断综合处理，即可得到电源电压过零的时刻。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>机电一体化分析与建模</tag>
      </tags>
  </entry>
  <entry>
    <title>机电一体化背诵版本</title>
    <url>/blog/2025/02/25/%E6%9C%BA%E7%94%B5%E4%B8%80%E4%BD%93%E5%8C%96%E8%83%8C%E8%AF%B5%E7%89%88%E6%9C%AC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><ol>
<li><p><strong>机电系统</strong>：是机械电子系统的简称，是由<strong>机械系统</strong>和<strong>电气系统</strong>组成的，其核心是<strong>控制系统。</strong></p>
</li>
<li><p>机电控制系统一般由7个部分组成：</p>
</li>
</ol>
<p><img src="/blog/../image/Snipaste_2025-06-28_08-40-57-17542059526173.png"></p>
<p><strong>放大器</strong>：是将比较得出的偏差信号进行放大，用来推动<strong>执行器</strong>去控制被控对象。</p>
<p><strong>被控对象</strong>：是控制系统要操纵的对象。</p>
<p><strong>$ \bigstar \bigstar \bigstar$机电控制系统的执行器</strong>：也称为执行元件或执行装置。</p>
<ol start="3">
<li>根据<strong>使用能量的不同</strong>，可以将<strong>执行装置</strong>大体分为<u>电气式</u>、<u>液压式</u>、<u>气动式</u>  <span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
</ol>
<p><strong>液压式执行装置</strong>：</p>
<p>a)    优点：液压驱动装置具有<u>重量轻、惯性小、快速性好</u>等优点；</p>
<p>b)   缺点：液压元件<u>易漏油</u>，会<u>污染环境</u>，也有可能<u>引起火灾</u>；液压系统<u>易受环境温度变化的影响</u></p>
<p><strong>气动执行装置：</strong></p>
<p>a)    优点：是<u>动作迅速、反应快、维护简单、成本低</u>，同时由于空气黏度很小，压力损失小，节能高效，适用于<u>远距离输送</u>；<u>工作环境适应性好</u></p>
<p>b)   缺点：由于空气可压缩性较大。负载变化时系统的动作稳定性较差，也不易获得较大输出力或力矩，同时需要对气源中杂质和水分进行处理，排气时噪声较大。</p>
<ol start="4">
<li><p><strong>机电控制系统的基本要求</strong>：<u>稳定性、快速性、准确性</u><span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></p>
<ul>
<li><p><u>稳定性</u>是保证控制系统正常工作的先决条件。</p>
</li>
<li><p>稳定系统：被控量偏离期望值的偏差 <strong>随时间增长逐渐减小或趋于零</strong>，过渡过程的振荡 <strong>逐渐减弱</strong>，最终能达到平衡状态（<span style="color:#FF0000">偏差减小，震荡减弱</span>）</p>
</li>
<li><p>不稳定系统：被控量偏离期望值的偏差 <strong>随时间增长而发散</strong>，过渡过程的振荡 <strong>逐步增强</strong>，导致被控量失控（）</p>
</li>
<li><p><strong>稳态误差</strong>：被控量的<u>稳态值</u>与<u>期望值</u>之间会有误差存在，称之为稳态误差。</p>
</li>
</ul>
</li>
<li><p><strong>机电控制系统控制方式的分类</strong>：一般可以分为<u>开环控制</u>、<u>闭环控制</u>和<u>复合控制</u>。</p>
</li>
<li><p><strong>复合控制方式</strong>：是把<u>偏差控制</u>与按<u>扰动控制</u>结合起来的控制方式</p>
</li>
<li><p><strong>开环控制系统与闭环控制系统不同的地方是</strong>：开环控制系统不需要被控对象的<u>反馈信号</u>，他的控制器直接根据<u>给定信号</u>去控制被控对象工作。</p>
</li>
</ol>
<h1 id="第二章-自动控制系统基本知识"><a href="#第二章-自动控制系统基本知识" class="headerlink" title="第二章 自动控制系统基本知识"></a>第二章 自动控制系统基本知识</h1><ol>
<li><p><strong>控制系统的组成</strong>：由<u>给定单元</u>、<u>控制单元</u>、<u>执行单元</u>、<u>被控对象</u>、<u>测量单元</u>等五大部分组成。</p>
<p><img src="/blog/../image/Snipaste_2025-06-28_09-32-30-17542059526172.png"></p>
</li>
<li><p><strong>控制系统的分类：</strong></p>
<ul>
<li>按<strong>系统输入信号</strong>的特点分类：<u>定值控制系统</u>、<u>随动控制系统</u>、<u>程序控制系统</u>。</li>
<li>按<strong>系统信号的传递</strong>特点分类：<u>开环控制系统</u>、<u>闭环控制系统</u>、<u>复合控制系统</u>。</li>
<li>按<strong>系统的变量</strong>特点分类：<u>连续控制系统</u>、<u>离散控制系统</u>。</li>
</ul>
</li>
<li><p><strong>建立系统数学模型的方法</strong>：</p>
</li>
</ol>
<p>（1）分析计算法（<strong>解析法</strong>）</p>
<p>（2）<strong>实验测定法</strong></p>
<ol start="4">
<li><p><strong>传递函数</strong>定义为：在零初始条件下，线性定常系统的输出量的拉普拉斯变换式与输入量的拉普拉斯变换式之比  </p>
</li>
<li><p><strong>恒值系统与随动系统</strong>：它们的特征方程和通解是相同的，所不同的是它们的边界条件和特解。研究恒值系统和随动系统不仅在方法上基本相同，而且运动方程也很相似。（特解代表系统强制运动，通解代表系统自然运动）</p>
</li>
<li><p><strong>几个典型环节的传递函数</strong></p>
<ul>
<li><p><strong>比例环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_09-57-05-17542059526175.png"></p>
</li>
<li><p><strong>惯性环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-00-48-17542059526161.png"></p>
</li>
<li><p><strong>积分环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-00-58-17542059526179.png"></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-17-17542059526174.png"></p>
</li>
<li><p><strong>振荡环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-10-175420595261711.png"></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-24-175420595261820.png"></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-29-17542059526176.png"></p>
</li>
<li><p><strong>实际微分环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-38-17542059526177.png"></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-43-17542059526178.png"></p>
</li>
<li><p><strong>延迟环节</strong></p>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-50-175420595261710.png"></p>
</li>
</ul>
</li>
</ol>
<p><img src="/blog/../image/Snipaste_2025-06-28_10-01-54-175420595261715.png"></p>
<h2 id="控制器的控制规律及响应特性（PID）"><a href="#控制器的控制规律及响应特性（PID）" class="headerlink" title="控制器的控制规律及响应特性（PID）"></a>控制器的控制规律及响应特性（PID）</h2><p><span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></p>
<p><strong>为了提高闭环控制系统的特性，控制器常采用什么控制规律？说明其控制规律中的各个参数各起什么作用。</strong><br>答：PID 控制 (比例、积分、微分控制规律)<br>P：克服干扰，减小偏差，<strong>提高快速性</strong>。<br>I：<strong>减小稳态误差</strong>。<br>D：提高系统的快速性，<strong>具有超前的控制作用，抑制超调，改善动态响应</strong>。</p>
<p><span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span>闭环控制系统中加入<strong>比例微分</strong>控制规律的主要作用是提高系统的稳定性</p>
<p><strong>1. 比例控制（P）</strong></p>
<p><u><strong>工作原理</strong></u></p>
<p>控制器输出与输入信号 <strong>成比例关系</strong>，数学表达式：</p>
<p>$$<br>y(t) &#x3D; Kx(t) \quad \text{或} \quad \Delta y &#x3D; K\Delta x<br>$$</p>
<p>（$K$ 为比例放大系数，$\Delta$ 表示信号变化量）</p>
<p><u><strong>特性</strong></u></p>
<ul>
<li><p><strong>余差特性</strong>：过渡过程结束后，被控量的稳定值与给定值存在 <strong>余差</strong>（偏差无法完全消除）。</p>
</li>
<li><p><strong>响应特性</strong>：比例系数 $K$ 越大，响应越快；$K$ 越小，响应越慢</p>
</li>
</ul>
<p><u><strong>性能</strong></u></p>
<ul>
<li><p><strong>优点</strong>：结构简单，响应快速</p>
</li>
<li><p><strong>缺点</strong>：无法消除稳态误差（余差），仅适用于对稳态精度要求不高的场景。</p>
</li>
</ul>
<blockquote>
<p>加快响应，<strong>但无法消除余差</strong></p>
</blockquote>
<hr>
<p>   <strong>2. 比例积分控制（PI）</strong></p>
<p><strong>工作原理</strong></p>
<p>   输出为 <strong>比例作用 + 积分作用</strong>，数学表达式：</p>
<p>$$<br>   y(t) &#x3D; K\left[ x(t) + \frac{1}{T_i} \int x(t)dt \right]<br>$$</p>
<p>   （$T_i$ 为积分时间，积分部分累积历史偏差，逐步消除余差）</p>
<p><strong>特性</strong></p>
<ul>
<li><p><strong>余差特性</strong>：积分作用可 <strong>理论上消除余差</strong>（稳态误差为零）。</p>
</li>
<li><p><strong>积分特性</strong>：$T_i$ 越小，积分速度越快、作用越强；但 $T_i$ 过小会导致系统振荡加剧，甚至失稳（积分作用与稳定性存在矛盾）。</p>
</li>
</ul>
<p><strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：消除稳态误差，提高控制精度；继承比例控制的快速性。</p>
</li>
<li><p><strong>缺点</strong>：积分作用会降低系统稳定性（需合理设置 $T_i$），过渡过程可能更振荡或变慢。</p>
<blockquote>
<p><strong>消除稳态误差，积分作用会降低系统稳定性</strong></p>
</blockquote>
<hr>
</li>
</ul>
<p>   <strong>3. 比例微分控制（PD）</strong></p>
<p>   <strong>工作原理</strong></p>
<p>   输出为 <strong>比例作用 + 微分作用</strong>，数学表达式：</p>
<p>$$<br>   y(t) &#x3D; K\left[ x(t) + T_d \frac{dx(t)}{dt} \right]<br>$$</p>
<p>   （$T_d$ 为微分时间，微分部分反映信号变化率，实现 “超前控制”）</p>
<p>   <strong>特性</strong></p>
<ul>
<li><p><strong>超前特性</strong>：微分作用可 <strong>预见偏差变化趋势</strong>（如偏差增大时提前抑制），改善动态响应。</p>
</li>
<li><p><strong>微分特性</strong>：$T_d$ 越大，微分作用越强，超调越小；但 $T_d$ 过大易引发被控量剧烈振荡；$T_d$ 过小则控制效果不明显。</p>
</li>
</ul>
<p>   <strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：抑制超调，改善动态响应（超前控制）</p>
</li>
<li><p><strong>缺点</strong>：对高频噪声敏感</p>
<blockquote>
<p>抑制超调，改善动态响应;微分作用过强会引发被控量剧烈振荡</p>
</blockquote>
<hr>
</li>
</ul>
<p>   <strong>4. 比例积分微分控制（PID）</strong></p>
<p>   <strong>工作原理</strong></p>
<p>   输出为 <strong>比例 + 积分 + 微分作用</strong>，数学表达式：</p>
<p>$$<br>y(t) &#x3D; K\left[ x(t) + \frac{1}{T_i} \int x(t)dt + T_d \frac{dx(t)}{dt} \right]<br>$$</p>
<p>   <strong>特性</strong></p>
<ul>
<li><p><strong>协同特性</strong>：综合三者优势，兼顾 <strong>快速性（P）、稳定性（D）、精度（I）</strong>。</p>
</li>
<li><p><strong>参数特性</strong>：参数整定复杂（需平衡 $K$、$T_i$、$T_d$），但适配范围广（尤其高精度控制）。</p>
</li>
</ul>
<p>   <strong>性能</strong></p>
<ul>
<li><p><strong>优点</strong>：兼具快速响应、消除余差、抑制振荡的能力，适用于<strong>高精度复杂控制</strong>场景</p>
</li>
<li><p><strong>缺点</strong>：参数调试难度大</p>
</li>
</ul>
<ol start="7">
<li><p><strong>控制系统的控制质量指标</strong>：<u>衰减率</u>、<u>余差</u>、<u>最大偏差</u>、<u>过渡过程时间</u></p>
</li>
<li><p>**稳定性：**当自控系统处于平衡状时，由于受到内部或外部的扰动，被调量偏离原有的平衡值，当扰动过后，经过足够的时间，系统仍能够回到原有的平衡工作状态，即被调量回到原有平衡值上，则系统是稳定的，否则，系统是不稳定的</p>
</li>
<li><p><strong>误差</strong>是描述自动控制系统精度的指标，反映了系统在<strong>跟随输入信号</strong>和<strong>抑制干扰信号</strong>整个过程的精度。 所以误差有动态误差和稳态误差两种。</p>
</li>
</ol>
<ul>
<li><p><strong>动态误差</strong>描述系统的误差随时间变化的过程</p>
</li>
<li><p><strong>稳态误差</strong>（也称静态误差或余差）反映动态过程在时间趋于无穷大时，系统到达稳态时的误差**(过渡过程结束后，被控量稳态值与期望值的偏差)**</p>
</li>
</ul>
<h1 id="第三章-机电系统中的传感器技术"><a href="#第三章-机电系统中的传感器技术" class="headerlink" title="第三章 机电系统中的传感器技术"></a>第三章 机电系统中的传感器技术</h1><ul>
<li>传感器的主要任务是将<strong>非电信号</strong>转换成<strong>电信号</strong></li>
</ul>
<ol>
<li><strong>传感器的组成</strong>：传感器一般由<u>敏感元件</u>、<u>转换元件</u>、<u>基本转换电路</u>三部分组成</li>
</ol>
<p><img src="/blog/../image/Snipaste_2025-06-28_14-53-18-175420595261712.png"></p>
<ol start="2">
<li><strong>传感器的分类</strong>：</li>
</ol>
<p>按<strong>输入量</strong>分类：<u>物理量传感器</u>、<u>化学量传感器</u>、<u>生物量传感器</u>三大类；</p>
<p>按<strong>输出信号形式</strong>分类：<u>模拟式</u>、<u>开关式</u>、<u>数字式</u>；</p>
<p>按<strong>转换原理</strong>分类：<u>结构型</u>、<u>物性型</u>、<u>复合型</u>；</p>
<ol start="3">
<li><p><strong>传感器的基本特性</strong>：静态特性、动态特性</p>
<p>传感器的特性都可以通过<strong>静态特性</strong>、<strong>动态特性</strong>进行描述<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></p>
<ul>
<li><strong>静态特性</strong>：灵敏度、线性度、迟滞性、重复性、分辨力以及零漂等  </li>
<li><strong>动态特性</strong>：传感器要检测的输入信号是随时间而变化的，传感器的特性应能<strong>跟踪</strong>输入信号的变化，才能获得准确的输出信号</li>
</ul>
</li>
<li><p><strong>电学式压力传感器</strong>：</p>
<ul>
<li><p><strong>电阻应变片式压力传感器</strong> ：靠电阻值来度量压变和压力的，所以必需考虑电阻丝的温度效应</p>
</li>
<li><p><strong>电容式压力传感器</strong>：采用变电容测量原理，将由被测压力引起的<u>弹性元件的位移变形</u>转变为<u>电容的变化</u>，测出电容量便可知道被测压力的大小。<br>$$<br>C &#x3D; \frac{\varepsilon A}{d}<br>$$</p>
</li>
<li><p><strong>压阻式压力传感器</strong>：  压阻式压力传感器是基于半导体材料（单晶硅）的<strong>压阻效应</strong>（<u>固体受力后电阻率发生变化的现象</u>  ）原理制成的传感器  </p>
<p>特点：灵敏度高，频率响应高；测量范围宽；精度高，工作可靠；易于微小型化  </p>
</li>
<li><p><strong>压电式压力传感器</strong>  ：压电传感器主要是利用<strong>压电效应</strong>制造而成的</p>
<p><strong>压电效应</strong> ：某些晶体介质，当沿着一定方向受到机械力作用发生变形时，就产生了<strong>极化效应</strong>，而在其某些表面上会产生电荷；当机械力撤掉之后，又会重新回到不带电的状态，此现象称为“压电效应  “<br>$$<br>p &#x3D; \frac{Q}{kS} \tag{3-4}<br>$$<br>$Q$ 为电荷量，$k$ 为压电常数，$S$ 为作用面积，$p$ 为压力。通过测量电荷量可知被测压力大小。</p>
</li>
<li><p><strong>差动变压器式压力传感器</strong>  :由弹性敏感元件和差动变压器构成的压力传感器。 它的弹性敏感元件作为受力机构，把<strong>被测压力转换成位移</strong>，再用差动变压器把位移转换为与被测压力成一定关系的电信号</p>
</li>
</ul>
</li>
<li><p><strong>位移传感器</strong>：<u>电感式位移传感器</u>、<u>电容式位移传感器</u>、电阻式位移传感器、<u>光栅位移传感器</u>、光电式位移传感器、超声波式位移传感器、霍尔式位移传感器等。  </p>
</li>
<li><p><strong>电感式位移传感器</strong>：</p>
<ul>
<li><p><strong>电涡流式位移传感器</strong>：电涡流式位移传感器是利用<strong>电涡流原理</strong>设计而成的，它可以实现静态和动态地、非接触、高线性度、高分辨率地<strong>测量金属表面与传感器探头之间的距离及其变化</strong>  </p>
</li>
<li><p><strong>差动变压器式位移传感器</strong></p>
<p>差动变压器式位移传感器是利用<strong>线圈的互感作用</strong>将<strong>位移转换成感应电势的变化</strong>。</p>
<ul>
<li><p>传感器主要由线圈、铁心和活动衔铁三个部分组成，如图3.10（a）（b）所示。</p>
</li>
<li><p>线圈包括一个初级线圈和两个反接的次级线圈，当线圈输入交流激励电压时，次级线圈将产生感应电动势$e_1$和$e_2$。由于两个次级线圈极性反接，因此传感器的输出电压为两者之差，即$e_y&#x3D;e_1-e_2$</p>
</li>
<li><p>活动衔铁能改变线圈之间的耦合程度。输出ey的大小随活动衔铁的位置而改变。当活动衔铁的位置居中时，即e1&#x3D;e2，ey&#x3D;0；当活动衔铁向上移时，即e1&gt;e2，ey&gt;0;当活动衔铁向下移时，即e1&lt;e2，ey&lt;0。活动衔铁的位置往复变化，其输出电压也随之变化，输出特性如图3.10（c）所示。</p>
</li>
</ul>
<p><img src="/blog/../image/Snipaste_2025-06-23_15-51-57-175420595261713.png"></p>
</li>
</ul>
</li>
<li><p><strong>光栅式位移传感器</strong></p>
<ul>
<li>光栅的特点是<strong>测量精度高</strong>（可达±１μｍ）、<strong>响应速度快</strong>和<strong>量程范围大</strong>等。 用于精密机械的位移测量  </li>
<li>光栅传感器工作的基础是<strong>莫尔条纹</strong>  </li>
<li>光栅传感器可以根据<u>莫尔条纹移动量和移动方</u>向判定<u>光栅的位移量和位移的方向</u></li>
</ul>
</li>
<li><p><strong>速度传感器</strong>：测速发电机、电涡轮式转速传感器  、霍尔转速传感器   、光电式转速传感器  </p>
<ul>
<li>光电法测转速分透射式和反射式两种</li>
</ul>
</li>
<li><p><strong>温度传感器</strong>：热电偶、热敏电阻、热电阻</p>
</li>
<li><p><strong>热电偶冷端补偿</strong>（温度补偿）的3种方法：<u>延长导线法、机械调零法、补偿电桥法</u></p>
<blockquote>
<p><strong>说明热电偶的工作原理。当热端与冷端之间距离较远时，采用什么冷端补偿方式较好？</strong></p>
<p>热电偶的工作原理是<strong>基于物体的热电效应</strong></p>
<p>（即不同导体或半导体材料连接形成回路时，在两个接点处温度不同会产生热电动势，从而测量温度。）</p>
<p><strong>当热端与冷端之间的距离较远时：</strong></p>
<ul>
<li>需要使用<strong>补偿导线</strong>来延长热电偶的冷端，使之远离测量点</li>
<li>注意<strong>导线的型号、极性、以及接点的温度</strong>。</li>
</ul>
</blockquote>
</li>
<li><p><strong>热敏电阻</strong>：一般把<u>金属氧化物陶瓷半导体</u>材料经成形、烧结等工艺制成的测温元件叫做热敏电阻</p>
<ul>
<li><p>热敏电阻是<strong>中低温区</strong>最常用的一种温度检测器  </p>
</li>
<li><p><strong>分类</strong>：</p>
<p><strong>根据温度系数正负</strong>：PTC热敏电阻（电阻温度系数为正）、NTC热敏电阻（电阻温度系数为负）。</p>
<p><strong>NTC</strong>热敏电阻<strong>根据不同的用途</strong>：负指数型NTC（电阻值与温度之间呈负指数关系，用于测量宽度较宽的温度测量）、突变型NTC（当温度上升到某一设定值时，其电阻值突然下降，多作电路保护）</p>
<p><strong>PTC</strong>热敏电阻：突变型PTC（温度范围较窄，一般用于恒温加热控制或温度开关）、线性型PTC（可用于温度补偿或温度测量）。</p>
</li>
</ul>
</li>
<li><p><strong>热电阻</strong>:把金<u>属导体</u>如铜、镍、铂制成的测温电阻称为热电阻。  </p>
<ul>
<li>热电阻是利用物质在温度变化时本身电阻也随着发生变化的特性来测量温度的</li>
</ul>
</li>
<li><p><strong>热电阻传感器的测量电路</strong><br>热电阻传感器的测量电路一般使用电桥电路，由于工业用热电阻安装在生产现场，离控制室较远，因此热电阻的引线对测量结果有较大影响。为此，热电阻内部引线方式有<strong>二线制、三线制和四线制三种</strong>。</p>
</li>
</ol>
<p>​      <img src="/blog/../image/IMG_20250328_095737_%E7%9C%8B%E5%9B%BE%E7%8E%8B-175420595261819.jpg"></p>
<blockquote>
<p><strong>两线制</strong></p>
<p><span style="color:#FF0000">电路结构</span></p>
<ul>
<li><p>采用 <strong>电桥电路</strong> 测量热电阻 $  R_t  $：电源 $  E_s  $ 供电，桥臂含固定电阻 $  R_1 \quad R_2  $、可调电阻 $  R_3  $，中间串联微安表 $  \mu A  $ 检测平衡。</p>
</li>
<li><p>热电阻 $  R_t  $ 通过 <strong>两根引线</strong> 接入电桥，引线自身存在电阻 $  r  $（图中虚线框内两侧的 $  r  $），即 <strong>引线电阻会串联在热电阻回路中</strong>。</p>
</li>
</ul>
<p><span style="color:#FF0000">优缺点</span></p>
<ul>
<li>这种引线方式简单、费用低，但是引线电阻以及引线电阻的变化会带来附加误差。</li>
<li>两线制适于引线不长，精度要求较低的场合。</li>
</ul>
</blockquote>
<p><img src="/blog/../image/Snipaste_2025-06-29_10-12-28-175420595261714.png"></p>
<blockquote>
<p><strong>三线制</strong></p>
<p>热电阻的一端与一根导线相接，另一端同时接两根导线。</p>
<p><span style="color:#FF0000">工作原理</span></p>
<p>惠斯通电桥</p>
<p><img src="/blog/../image/Snipaste_2025-06-29_11-00-42-175420595261716.png"></p>
<p>图中热电阻 $  R_t  $ 的三根导线，粗细相同，长度相等，阻值都是 $  r  $。其中一根串联在电桥的电源上，对电桥的平衡与否毫无影响。另外两根分别串联在电桥的相邻两臂里，使相邻两臂的阻值都增加同样大的阻值 $  r  $。</p>
<p><strong>当电桥平衡时，可写出下列关系，即</strong><br>$$<br>(R_t + r)R_2 &#x3D; (R_3 + r)R_1<br>$$</p>
<p>由此可以得出</p>
<p>$$<br>R_t &#x3D; \frac{(R_3 + r)R_1 - rR_2}{R_2} &#x3D; \frac{R_3R_1}{R_2} + \frac{R_1r}{R_2} - r<br>$$</p>
<p>设计电桥时如满足 $  R_1 &#x3D; R_2  $，则上式等号右边含有 $  r  $ 的两项完全消去，就和 $  r&#x3D;0  $ 的电桥平衡公式完全一样了。这种情况下，导线电阻 $  r  $ 对热电阻的测量毫无影响。但必须注意，只有在左右对称的电桥（即 $  R_1 &#x3D; R_2  $ 的电桥），且只有在平衡状态下才是如此。</p>
<p><img src="/blog/../image/IMG_20250328_095926-175420595261717.jpg"></p>
<p><strong>为什么使用三线制？有什么作用？</strong></p>
<p>由于热电阻的电阻值较小，因此在热电阻与测量仪表之间引线过长会引起测量误差。所以此时引线电阻及其随长度和温度的变化就不能忽略不计。<span style="color:#FF0000">为了消除和减小引线电阻对测量精度的影响</span>，通常采用三线制连接法  </p>
<ul>
<li>减少引线电阻误差，提高测量精度</li>
<li>适用于长距离测温</li>
</ul>
</blockquote>
<blockquote>
<p><strong>四线制</strong></p>
<p><span style="color:#FF0000">工作原理</span></p>
<ol>
<li><strong>电流激励回路</strong></li>
</ol>
<ul>
<li>恒流源（如 1mA）通过两根导线向热电阻提供稳定电流 I。</li>
<li>引线电阻（$r_1 \quad r_4$）的压降被恒流源的高输出阻抗克服，不影响电流大小。</li>
</ul>
<ol start="2">
<li><strong>电压测量回路</strong></li>
</ol>
<ul>
<li><p>高阻抗电压表（输入阻抗 &gt;10 MΩ）通过另两根导线直接测量热电阻两端电压 U。</p>
</li>
<li><p>因测量回路电流趋近于零（I≈0），引线电阻（$r_2 \quad r_3$）的压降 IR≈0</p>
<p>故<br>$$<br>R_t&#x3D;\frac{U}{I}<br>$$<br><img src="/blog/../image/IMG_20250328_095932-175420595261718.jpg"></p>
<p><strong>为什么使用四线制？有什么作用？</strong></p>
<p><span style="color:#FF0000">为了消除和减小引线电阻对测量精度的影响</span></p>
<ul>
<li>消除引线电阻误差，提高测量精度</li>
<li>适用于长距离与高精度测量</li>
</ul>
</li>
</ul>
</blockquote>
<h1 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h1><ul>
<li>12位D&#x2F;A转换器与微机接口要用<strong>3</strong>个锁存器保证微机同时接收<strong>高8位</strong>和<strong>低4位</strong></li>
</ul>
<h3 id="集成稳压电源的性能指标"><a href="#集成稳压电源的性能指标" class="headerlink" title="集成稳压电源的性能指标"></a>集成稳压电源的性能指标</h3><ul>
<li><p>最大输出电流</p>
</li>
<li><p>输出电压</p>
</li>
<li><p>纹波电压</p>
</li>
<li><p>稳压系数</p>
</li>
<li><p>输出电阻</p>
</li>
</ul>
<p>两种稳压电源的典型应用电路</p>
<p><img src="/blog/../image/1748049757448-175420607325541.jpg"></p>
<ul>
<li><p>其中输入端电容$ C_i$用以<strong>旁路高频干扰脉冲及改善纹波</strong>。</p>
</li>
<li><p>输出端所接电容$C_0$起<strong>改善瞬态响应特性、减小高频输出阻抗</strong>的作用。</p>
</li>
<li><p>一般在输出端无需接入大电解电容器。</p>
</li>
</ul>
<blockquote>
<p><strong>78XX:1入，2出，3地</strong></p>
<p><strong>79XX:1地，2出，3入</strong></p>
<p>（两者都按照电平从高到低排列的）</p>
</blockquote>
<p>$\bigstar$<strong>定义</strong><span style="color:#FF0000">（什么是V&#x2F;F转换）</span></p>
<p>V&#x2F;F（电压&#x2F;频率）转换器能把<strong>输入信号电压转换成相应的频率信号</strong>，即它的<strong>输出信号频率与输入信号电压值成比例</strong>，故又称为电压控制（压控）振荡器（VCO）。</p>
<p><span style="color:#FF0000">  <strong>$ \bigstar$ V&#x2F;F转换原理</strong></span></p>
<p><strong>原理</strong>：利用过零比较器的工作原理，转换器产生<strong>频率</strong>正比于输入电压的<strong>脉冲序列</strong>，然后在固定的时间内对脉冲进行计数。</p>
<p><strong>两种方法：</strong></p>
<ul>
<li>电荷平衡式V&#x2F;F转换器</li>
<li>积分复原型</li>
</ul>
<h3 id="积分复原型V-F转换电路"><a href="#积分复原型V-F转换电路" class="headerlink" title="积分复原型V&#x2F;F转换电路"></a>积分复原型V&#x2F;F转换电路</h3><ul>
<li>电路包含积分器、电平检测器、积分复原开关</li>
</ul>
<p><span style="color:#FF0000">接口</span>**：**接口是指计算机系统中一个部件与另一些部件的相互连接。</p>
<p><strong>接口分类</strong></p>
<ul>
<li><p>存储器接口</p>
</li>
<li><p>I&#x2F;O接口</p>
</li>
<li><p>总线接口（通用接口）</p>
</li>
</ul>
<p><span style="color:#FF0000">为什么要进行电平转换?</span><br>与计算机相连的其它功能单元各<u>自有各自的工作电平</u>， 需要一个<u>媒介</u>与这些功能单元电平之间进行相互转换。</p>
<p><span style="color:#FF0000">TTL电平和MOS电平为什么要进行转换</span>？</p>
<p>无论是 <u>TTL 电路驱动 CMOS</u>（Complementary Metal Oxide Semiconductor，互补金属氧化物半导体）电路还是 <u>COMS 电路驱动 TTL 电路</u>，<strong>驱动门</strong>必须为<strong>负载门</strong>提供合乎标准的高、低电平和足够的驱动电流</p>
<ul>
<li><p>用 TTL 门可直接驱动 CMOS 门，而用 CMOS 门却只能驱动低功率肖特基门。</p>
<p><strong>在用CMOS驱动标准TTL门时，要加一级晶体管作驱动级</strong></p>
</li>
</ul>
<p>TTL——继电器连接只适用于<strong>慢变信号</strong>，在TTL信号与继电器连接时往往要经过一个驱动级，用以提供继电器工作所必需的电流。</p>
<p>**工作原理：**光耦合器的发光器件为二极管，光接收器为光敏二极管。当有电流通过发光二极管时，便形成一个光源，照射到光敏二极管表面上，使光敏二极管产生<u>集电极电流</u>。<strong>电流大小与光照的强弱（流过二极管电流的大小）成正比。</strong></p>
<h1 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h1><ol>
<li><strong>微机测控系统的硬件</strong></li>
</ol>
<p>按各部分在系统中的作用,该系统可分为</p>
<ul>
<li><strong>主机</strong></li>
<li><strong>输入输出通道</strong>：过程输入输出通道，又称过程通道。是微机与外部物理世界建立信息传递与转换的<u>链接渠道</u></li>
<li>常规外部设备</li>
<li><strong>接口电路：在过程通道与外部设备间，接口电路起着媒介作用，使主机与过程通道及外部</strong><br><strong>设备之间的<u>信息交换</u>得以顺利实现</strong></li>
<li>运行操作台</li>
<li>系统总线等</li>
</ul>
<ol start="2">
<li><p><strong>测控系统软件组成</strong></p>
<p>软件通常分为两大类，一类是<u>系统软件</u>，另一类为<u>应用软件</u></p>
</li>
<li><p><strong>模拟量输入通道的一般组成</strong></p>
<p>一般由<u>信号调理电路</u>、<u>多路转换器</u>、<u>放大器</u>和<u>模／数转换器</u>组成</p>
<p>模拟量输出通道（D&#x2F;A通道或AO通道）构成： 一般是由<u>接口电路</u>（核心部分）、<span style="color:#FF00FF"><u>数&#x2F;模转换器</u>（简称D&#x2F;A或DAC）</span>和<u>电压&#x2F;电流变换器</u>等；</p>
<p><strong>为什么使用采样-保持器？</strong></p>
<p>当某一通道进行A&#x2F;D转换时，由于A&#x2F;D转换需要一定的时间，如果输入信号变化较快，就会引起较大的转换误差。为了保证A&#x2F;D转换的精度，需要应用采样保持器</p>
<h3 id="采样-保持器原理"><a href="#采样-保持器原理" class="headerlink" title="采样-保持器原理"></a>采样-保持器原理</h3><p><strong>采样保持器在两次采样的间隔时间内，一直保持采样值不变直到下一个采样时刻。</strong></p>
<ul>
<li>多路转换器又称多路开关，利用它可将各个输入信号<strong>依次</strong>或<strong>随机</strong>地接到公用放大器或模／数转换器上</li>
</ul>
<p><span style="color:#FF0000"><strong>多路开关注意事项</strong></span>(简答题)</p>
<ul>
<li><p>在自动数据采集中，应选用“<strong>先断后通</strong>”的多路开关，否则，就会发生<strong>两个通道短接</strong>的现象，严重时会损坏信号源或多路开关自身。  </p>
</li>
<li><p>然而，在程控增益放大器中，若用多路开关来改变集成运算放大器的反馈电阻，以改变放大器的增益，就不宜选用“先断后通”的多路开关。否则，放大器就会出现<strong>开环状态</strong>。放大器的开环增益极高，易破坏电路的正常工作，甚至损坏元器件，一般应予避免</p>
</li>
</ul>
</li>
</ol>
<p>集成A&#x2F;D转换芯片都具有如下功能引脚：<strong>数据输出</strong>、<strong>启动转换</strong>（输入）、<strong>转换结束</strong>（输出）。</p>
<h4 id="连接A-D芯片时，注意事项"><a href="#连接A-D芯片时，注意事项" class="headerlink" title="连接A&#x2F;D芯片时，注意事项"></a>连接A&#x2F;D芯片时，注意事项</h4><p><span style="color:#FF0000">①  A&#x2F;D芯片能否与微处理机总线直接兼容：</span></p>
<p>所谓直接兼容是指A&#x2F;D芯片的<u>数据输出线</u>可以直接挂在<u>CPU的数据总线</u>上。这不仅要求A&#x2F;D芯片的数据输出具有TTL电平，更重要的是要求A&#x2F;D芯片的数据输出寄存器具有可控的<strong>三态</strong>输出功能。（三态包含 <strong>高电平（逻辑 1）、低电平（逻辑 0）、高阻态（浮空态，记为 Z）</strong>）</p>
<p><span style="color:#FF0000">②  启动A&#x2F;D转换的方式：</span></p>
<p>A&#x2F;D转换电路需要外加启动转换信号才能开始工作，这一信号往往由CPU给出。一般有<u>脉冲启动信号及电平控制信号</u>两种形式。通常用CPU的$\overline{WR}$或$\overline{RD}$信号、地址译码器的输出信号等直接控制A&#x2F;D转换器的启动转换端。</p>
<p><span style="color:#FF0000">③  转换结束信号的应用方式：</span></p>
<p>A&#x2F;D转换结束时，A&#x2F;D芯片输出一个转换结束标志电平，通知CPU读取转换结果数据（即控制EOC端）</p>
<p>对于 Ａ Ｄ５７４ 的输入端一般可接成<strong>单极性输入</strong>和<strong>双极性输入</strong>两种工作方式  </p>
<p><span style="color:#FF0000">请简要回答采用计数测频法测量频率时产生±1误差的原因。   </span></p>
<p>解：（2分）由于<span style="color:rgb(28, 57, 123)"><strong>用于计数的时标脉冲</strong></span>与<span style="color:rgb(28, 57, 123)"><strong>控制主门的被测周期</strong></span><strong>不同步</strong>而引起的。在测频率时，由于<span style="color:rgb(28, 57, 123)"><strong>闸门开启时间</strong></span>和<span style="color:rgb(28, 57, 123)"><strong>被计数脉冲周期</strong></span><strong>不成整数倍</strong>。（3分）</p>
<blockquote>
<p>实际应用中，转换后的模拟信号需要保持一段时间，便于测量或控制，而 CPU 在执行向外设给输出数据的指令时，数据在数据总线上的存在时间只维持一个时钟周期。因此，对于不带<strong>输入数据寄存器</strong>的 DAC 芯片，其<strong>数据输入端</strong>须经<strong>锁存器</strong>与 CPU 数据总线相连</p>
</blockquote>
<blockquote>
<p><strong>内置反馈电阻</strong><br>$$<br>V_o&#x3D;-\frac{V_{REF}}{2^n}D_n<br>$$<br><strong>外接反馈电阻</strong><br>$$<br>V_o&#x3D;-\frac{R_F}{R}\frac{V_{REF}}{2^n}D_n<br>$$</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3></blockquote>
<p>- </p>
<p>- </p>
<ul>
<li><p>微机总线兼容型 Ｄ／Ａ 转换器芯片内部带有<strong>输入数据寄存器</strong>  </p>
</li>
<li><p>拥有一个数据寄存器的叫<strong>单缓冲型</strong>，带有两个数据寄存器的叫<strong>双缓冲型</strong>  </p>
</li>
<li><p><span style="color:#FF0000"><strong>双缓冲型优点(简答)</strong> </span>：当一个数字量送入 DAC 进行转换输出同时，能输入下一个数字量，从而提高转换速度。</p>
</li>
</ul>
<p><strong>改变占空比的两种调制方法</strong></p>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>脉冲宽度调制（PWM）</strong></th>
<th><strong>脉冲频率调制（PFM）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>实现方式</strong></td>
<td>固定 <strong>开关周期 T</strong>，改变 <strong>导通脉冲宽度$t_{on}$</strong></td>
<td>固定 <strong>导通脉冲宽度</strong>，改变 <strong>开关周期 T</strong>（即改变频率 $f&#x3D;1&#x2F;T$)</td>
</tr>
<tr>
<td><strong>关键特性</strong></td>
<td>频率固定，仅脉宽变化。</td>
<td>脉宽固定，仅频率变化。</td>
</tr>
<tr>
<td><strong>缺陷</strong></td>
<td></td>
<td>若遇到 <strong>特定频率的机械谐振</strong>，会引发 <strong>系统振荡、音频啸叫声</strong></td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td></td>
<td>因谐振问题，<strong>伺服系统中不适用</strong></td>
</tr>
</tbody></table>
<ol>
<li>机电控制系统的执行器也称为 <strong>执行元件</strong> 或执行装置 ，该执行器，常用有 <strong>电气式</strong> 、 <strong>液压式</strong> 、 <strong>气动式</strong> 等。</li>
<li>控制器的常用控制规律有 <strong>P</strong> 、 <strong>PI</strong> 、 <strong>PD</strong> 、 <strong>PID</strong> </li>
<li>获取系统数学模型主要有 <strong>解析</strong> 、 <strong>实验</strong> 等方法。</li>
<li>闭环控制是将输出量 <strong>反馈</strong> 到输入端，用 <strong>差值</strong> 经过运算进行控制。</li>
<li>闭环控制系统的开环增益越 <strong>小</strong> ，系统越容易稳定。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>闭环控制系统中加入 <strong>微分</strong> 控制规律的主要目的是提高系统的稳定性。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>传感器的主要任务是将 <strong>被测（非电）</strong> 信号转换成 <strong>电</strong> 信号。</li>
<li>常用运算放大器构成 <strong>反相</strong> 放大器、 <strong>同相</strong> 放大器、 <strong>差动</strong> 放大器。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>同相放大器输入信号极性与输出信号极性 <strong>相同</strong> 。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>PWM 是 <strong>脉冲宽度调制</strong> 的英文缩写。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>用在液压系统中供电为直流 24 伏中的伺服阀的最大电流约 <strong>40</strong> 毫安。</li>
<li>读取 A&#x2F;D 转换结果最快方法是 <strong>中断</strong> 、最慢方法是 <strong>定时采样</strong> 、中等是 <strong>程序查询</strong> 。</li>
<li><strong>实现A&#x2F;D转换</strong>所需的软件设计方式不同，目前常用的控制方式有：<strong>程序查询方式、定时采样方式、中断方式</strong></li>
<li>机电控制系统控制方式有 <strong>开环</strong> 、 <strong>闭环</strong> 、 <strong>复合</strong> 控制。</li>
<li>开环控制是直接用 <strong>给定量</strong> 进行控制，与输出 <strong>无</strong> 关系。</li>
<li>闭环控制系统的开环增益值越 <strong>大</strong> ，系统越不容易稳定。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>闭环控制系统中加入 <strong>积分</strong> 的主要目的是消除系统的稳态误差。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>常用传感器输出的信号有 <strong>模拟式</strong> 信号、 <strong>开关式</strong> 信号、 <strong>数字式</strong> 信号。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
<li>反相放大器输入信号极性与输出信号极性 <strong>相反</strong> 。</li>
<li>如果输入到比较器的信号存在小波动，应选用 <strong>迟滞</strong> 比较器。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></li>
</ol>
<p>1、 运动微分方程的特解代表系统的 <strong>强迫</strong> 运动，而通解代表系统的 <strong>自由运动</strong> 。<br>2、 微分作用的特点是具有 <strong>超前控制</strong> 性质。<br>3、 传感器的作用不仅是信息的采集和 <strong>传输</strong> ，还是机电结合的 <strong>接口</strong> 。<br>4、 闭环控制系统的开环增益值越 <strong>高</strong> ，系统越不容易稳定。闭环控制系统中加入 <strong>积分环节</strong> 的主要目的是消除系统的稳态误差。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span><br>5、 常用传感器输出的信号有 <strong>模拟式</strong> 信号、 <strong>开关式</strong> 信号、 <strong>数字式</strong> 信号。<br>6、 反相放大器输入信号极性与输出信号极性 <strong>相反</strong> 。<br>7、 如果输入到比较器的信号存在小波动，应选用 <strong>迟滞</strong> 比较器。<br>8、 读取 A&#x2F;D 转换结果的 3 种方法是： <strong>程序查询式</strong> 、 <strong>定时采样方式</strong> 、 <strong>中断方式</strong> 。<br>9、 <strong>脉冲宽度调制</strong>的英文缩写是 <strong>PWM</strong> 。<br>10、 用在液压系统中供电为直流 24 伏中的比例阀的最大电流约 <strong>800</strong> 毫安。<br>11、 为减小比例阀零位死区、滞环，需要控制电路中分别叠加 <strong>初始电流</strong> 、 <strong>颤振</strong> 信号。<span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span></p>
<ul>
<li><p>电压比较器中引入正反馈的比较器为<strong>迟滞比较器</strong></p>
</li>
<li><p>当开关周期恒定，脉冲宽度调制方法是通过改变<strong>导通脉冲宽度</strong>来改变<strong>占空比</strong>，从而控制电动机转速</p>
</li>
</ul>
<h1 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h1><ul>
<li>比例节流阀必须与溢流阀联合使用，才能实现对流量的准确控制</li>
</ul>
<p>电液比例流量控制的作用是什么？在顺序控制系统中采用比例控制技术比传统液压控制技术有何优点？<br>答：<strong>调节执行机构的运行速度</strong>，简化液压系统、利于实现自动控制</p>
<p><u>电液比例流量控制系统</u>用<u>电液比例流量阀</u>来控制<u>系统的速度</u>，也称电液比例速度控制系统，是一种阀控比例系统。</p>
<p> <strong>电液比例速度调节</strong>有三种方式：  </p>
<ul>
<li><p>比例节流调速</p>
</li>
<li><p>比例容积调速</p>
</li>
<li><p>比例容积节流调速</p>
</li>
</ul>
<p><u><strong>比例节流阀</strong>必须与 <strong>溢流阀</strong> 联合使用，才能实现对流量的准确控制。</u>0</p>
<h4 id="初始电流设定电路"><a href="#初始电流设定电路" class="headerlink" title="初始电流设定电路"></a>初始电流设定电路</h4><p>主要用于产生比例电磁铁的预激磁电流，<strong>调整比例阀的零位死区大小，或避开死区</strong>。 使比例阀在设定值输入时，从起始位置迅速启动  </p>
<h4 id="颤振信号发生器"><a href="#颤振信号发生器" class="headerlink" title="颤振信号发生器"></a>颤振信号发生器</h4><p><span style="color:#FF0000">为降低比例电磁铁的摩擦滞环，往往采用在控制信号上叠加颤振信号的方法 </span></p>
]]></content>
      <categories>
        <category>想法</category>
      </categories>
      <tags>
        <tag>井中月</tag>
      </tags>
  </entry>
  <entry>
    <title>数值分析公式记忆汇总</title>
    <url>/blog/2025/06/12/%E6%95%B0%E5%80%BC%E5%88%86%E6%9E%90%E5%85%AC%E5%BC%8F%E8%AE%B0%E5%BF%86%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="拉格朗日插值"><a href="#拉格朗日插值" class="headerlink" title="拉格朗日插值"></a>拉格朗日插值</h1><p><strong>两点一次插值（线性插值）</strong></p>
<p><strong>条件</strong>：2个节点 $(x_0, y_0)$ 和 $(x_1, y_1)$  </p>
<p><strong>多项式</strong>：<br>$$<br>L_1(x) &#x3D; \frac{x - x_1}{x_0 - x_1} y_0 + \frac{x - x_0}{x_1 - x_0} y_1<br>$$</p>
<p><strong>等价形式</strong>：<br>$$<br>L_1(x) &#x3D; y_0 + \frac{y_1 - y_0}{x_1 - x_0}(x - x_0)<br>$$</p>
<hr>
<p><strong>三点二次插值（抛物插值）</strong></p>
<p><strong>条件</strong>：3个节点 $(x_0, y_0)$，$(x_1, y_1)$，$(x_2, y_2)$<br><strong>多项式</strong>：<br>$$<br>L_2(x) &#x3D; \frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)} y_0 + \frac{(x - x_0)(x - x_2)}{(x_1 - x_0)(x_1 - x_2)} y_1 + \frac{(x - x_0)(x - x_1)}{(x_2 - x_0)(x_2 - x_1)} y_2<br>$$</p>
<hr>
<p><strong>多个插值节点</strong><br>$$<br>L_n(x)&#x3D; \sum_{i&#x3D;0}^n l_i(x) y_i&#x3D; \sum_{i&#x3D;0}^n \left[ \prod_{\substack{j&#x3D;0 \ j \neq i}}^n \frac{x - x_j}{x_i - x_j} \right] y_i<br>$$</p>
<hr>
<h2 id="插值余项与误差估计"><a href="#插值余项与误差估计" class="headerlink" title="插值余项与误差估计"></a>插值余项与误差估计</h2><p>对任意 $x \in [a,b]$，插值余项满足：<br>$$<br>R_n(x) &#x3D; f(x) - L_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} \prod_{j&#x3D;0}^n (x - x_j) \quad<br>$$<br>其中 $\xi \in (a, b)$，且 $\xi$ 的值依赖于 $x$</p>
<p><strong>n&#x3D;1时，线性插值余项</strong><br>$$<br>R_1(x) &#x3D; \frac{1}{2} f’’(\xi) \omega_2(x) &#x3D; \frac{1}{2} f’’(\xi) (x - x_0)(x - x_1), \quad \xi \in [x_0, x_1]<br>$$</p>
<p><strong>n&#x3D;2时，抛物插值余项</strong><br>$$<br>R_2(x) &#x3D; \frac{1}{6} f’’’(\xi) (x - x_0)(x - x_1)(x - x_2), \quad \xi \in [x_0, x_2]<br>$$</p>
<h1 id="二点三次埃尔米特插值多项式"><a href="#二点三次埃尔米特插值多项式" class="headerlink" title="二点三次埃尔米特插值多项式"></a>二点三次埃尔米特插值多项式</h1><p>**问题描述：**给定区间 $[x_0, x_1]$ 两端点的函数值与导数值：</p>
<table>
<thead>
<tr>
<th>$x$</th>
<th>$x_0$</th>
<th>$x_1$</th>
</tr>
</thead>
<tbody><tr>
<td>$f(x)$</td>
<td>$y_0$</td>
<td>$y_1$</td>
</tr>
<tr>
<td>$f’(x)$</td>
<td>$m_0$</td>
<td>$m_1$</td>
</tr>
</tbody></table>
<ol>
<li><strong>最终表达式</strong><br>$$<br>H_3(x) &#x3D; y_0\left(1 - 2\dfrac{x - x_0}{x_0 -x_1}\right)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2<br>$$</li>
</ol>
<p>$$<br>+y_1\left(1 - 2\dfrac{x - x_1}{x_1 - x_0}\right)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<p>$$<br>+m_0(x - x_0)\left(\dfrac{x - x_1}{x_0 - x_1}\right)^2 + m_1(x - x_1)\left(\dfrac{x - x_0}{x_1 - x_0}\right)^2<br>$$</p>
<h1 id="牛顿插值"><a href="#牛顿插值" class="headerlink" title="牛顿插值"></a>牛顿插值</h1><p>$$<br>N_n(x)&#x3D; f(x_0) + f[x_0, x_1](x - x_0) + \cdots + f[x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})<br>$$</p>
<p><strong>余项公式</strong><br>$$<br>R_n(x)&#x3D;f[x, x_0, \ldots, x_n](x - x_0)\cdots(x - x_{n-1})(x - x_n)&#x3D;f[x, x_0, \ldots, x_n]\omega_{n+1}(x)<br>$$<br><strong>差商表</strong></p>
<table>
<thead>
<tr>
<th align="center">$ x_i $</th>
<th align="center">$ f(x_i) $</th>
<th align="center">一阶差商</th>
<th align="center">二阶差商</th>
<th align="center">三阶差商</th>
</tr>
</thead>
<tbody><tr>
<td align="center">$ x_0 $</td>
<td align="center">$ f(x_0) $</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_1 $</td>
<td align="center">$ f(x_1) $</td>
<td align="center">$ f[x_0, x_1] $</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_2 $</td>
<td align="center">$ f(x_2) $</td>
<td align="center">$ f[x_1, x_2] $</td>
<td align="center">$ f[x_0, x_1, x_2] $</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">$ x_3 $</td>
<td align="center">$ f(x_3) $</td>
<td align="center">$ f[x_2, x_3] $</td>
<td align="center">$ f[x_1, x_2, x_3] $</td>
<td align="center">$ f[x_0, x_1, x_2, x_3] $</td>
</tr>
</tbody></table>
<h1 id="差分形式的牛顿插值"><a href="#差分形式的牛顿插值" class="headerlink" title="差分形式的牛顿插值"></a>差分形式的牛顿插值</h1><p><span style="color:rgb(255, 53, 116)">牛顿前插公式：</span><br>设 $ x &#x3D; x_0 + th $（$ 0 \leq t \leq 1 $），则<br>$$<br>N_n(x) &#x3D; N_n(x_0 + th) &#x3D; \sum_{k&#x3D;0}^{n} \binom{t}{k} \Delta^k f(x_0)<br>$$</p>
<p>$$<br>&#x3D; f_0 + t\Delta f_0 + \frac{t(t - 1)}{2!}\Delta^2 f_0 + \dots + \frac{t(t - 1)\dots(t - n + 1)}{n!}\Delta^n f_0<br>$$</p>
<p>余项：<br>$$<br>R_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} t(t-1)\cdots(t-n) h^{n+1}, \quad \xi \in (x_0, x_n)<br>$$</p>
<p><span style="color:rgb(255, 53, 116)">牛顿后插公式：</span><br>将节点顺序倒置：<br>$$<br>N_n(x) &#x3D; f(x_n) + f[x_n, x_{n-1}](x - x_n) + \cdots + f[x_n, \ldots, x_0](x - x_n)\cdots(x - x_1)<br>$$<br>设 $ x &#x3D; x_n + th $（$ -1 \leq t \leq 0 $），则<br>$$<br>N_n(x) &#x3D; N_n(x_n + th) &#x3D; \sum_{k&#x3D;0}^{n} (-1)^k \binom{-t}{k} \nabla^k f(x_n)<br>$$</p>
<p>$$<br>&#x3D; f_n + t\nabla f_n + \frac{t(t + 1)}{2!}\nabla^2 f_n + \dots + \frac{t(t + 1)\dots(t + n - 1)}{n!}\nabla^n f_n<br>$$</p>
<p>余项：<br>$$<br>R_n(x) &#x3D; \frac{f^{(n+1)}(\xi)}{(n+1)!} t(t+1)\cdots(t+n) h^{n+1}, \quad \xi \in (x_0, x_n)<br>$$</p>
<p>注：一般当 $ x $ 靠近 $ x_0 $ 时用前插，靠近 $ x_n $ 时用后插，故两种公式亦称为表初公式和表末公式。</p>
<p><strong>差分表</strong></p>
<p><img src="/blog/../image/Snipaste_2025-03-12_16-09-19-17497100633471.png"></p>
<h1 id="三次样条插值"><a href="#三次样条插值" class="headerlink" title="三次样条插值"></a>三次样条插值</h1><h2 id="第一边界条件"><a href="#第一边界条件" class="headerlink" title="第一边界条件"></a>第一边界条件</h2><p><strong>第一种边界条件</strong>(已知两端的<strong>一阶</strong>导数值)<br>$$<br>s^{\prime}\left(x_0\right)&#x3D;y_0^{\prime}\<br>s^{\prime}\left(x_n\right)&#x3D;y_n^{\prime}<br>$$</p>
<span>

<h1 id="题目中所给节点数，就是系数矩阵的阶数-begin-bmatrix-2-lambda-0-mu-1-2-lambda-1-ddots-ddots-ddots-mu-n-1-2-lambda-n-1-mu-n-2-end-bmatrix-begin-bmatrix-M-0-M-1-vdots-M-n-1-M-n-end-bmatrix"><a href="#题目中所给节点数，就是系数矩阵的阶数-begin-bmatrix-2-lambda-0-mu-1-2-lambda-1-ddots-ddots-ddots-mu-n-1-2-lambda-n-1-mu-n-2-end-bmatrix-begin-bmatrix-M-0-M-1-vdots-M-n-1-M-n-end-bmatrix" class="headerlink" title="题目中所给节点数，就是系数矩阵的阶数$$\begin{bmatrix}2 &amp; \lambda_0 &amp; &amp; &amp; \\mu_1 &amp; 2 &amp; \lambda_1 &amp; &amp; \ &amp; \ddots &amp; \ddots &amp; \ddots &amp; \ &amp; &amp; \mu_{n-1} &amp; 2 &amp; \lambda_{n-1} \ &amp; &amp; &amp; \mu_{n} &amp; 2\end{bmatrix}\begin{bmatrix}M_0 \M_1 \\vdots \M_{n-1} \M_n\end{bmatrix}"></a><span style="color:#FF0000">题目中所给节点数，就是系数矩阵的阶数</span><br>$$<br>\begin{bmatrix}<br>2 &amp; \lambda_0 &amp; &amp; &amp; \<br>\mu_1 &amp; 2 &amp; \lambda_1 &amp; &amp; \<br> &amp; \ddots &amp; \ddots &amp; \ddots &amp; \<br> &amp; &amp; \mu_{n-1} &amp; 2 &amp; \lambda_{n-1} \<br> &amp; &amp; &amp; \mu_{n} &amp; 2<br>\end{bmatrix}<br>\begin{bmatrix}<br>M_0 \<br>M_1 \<br>\vdots \<br>M_{n-1} \<br>M_n<br>\end{bmatrix}</h1><p>\begin{bmatrix}<br>d_0 \<br>d_1 \<br>\vdots \<br>d_{n-1} \<br>d_n<br>\end{bmatrix}<br>$$<br></span></p>
<blockquote>
<p>$$<br>\lambda_0 &#x3D; 1\<br>\mu_n &#x3D; 1\<br>\quad h_j&#x3D;x_{j+1}-x_j<br>$$</p>
<p>$$<br>\lambda_{j}&#x3D; \frac{h_j}{h_{j-1}+h_j}\<br>\mu_j &#x3D; \frac{h_{j-1}}{h_{j-1}+h_j}<br>$$</p>
<p><span style="color:#FF0000">可以这样记，系数矩阵中$\lambda$在对角线上，$\mu$在下,故$\lambda_{j}$取大的$h_j$，$\mu_{j}$取小的$h_{j-1}$，二者和为1</span><br>$$<br>d_0 &#x3D; \frac{6}{h_0} \left( f[x_0, x_1] - f’_0 \right)<br>$$</p>
<p>$$<br>d_j &#x3D; 6 \frac{f[x_j, x_{j+1}] - f[x_{j-1}, x_j]}{h_{j-1} + h_j} &#x3D; 6 f[x_{j-1}, x_j, x_{j+1}], \quad j &#x3D; 1, 2, \dots, n-1<br>$$</p>
<p>$$<br>d_n &#x3D; \frac{6}{h_{n-1}} \left( f’_n - f[x _{n-1}, x_n] \right)<br>$$</p>
<p>$$<br>s(x) &#x3D; \frac{\left(x_{j+1}-x\right)^{3}}{6 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{3}}{6 h_{j}} M_{j+1} + \left(y_{j}-\frac{M_{j} h_{j}^{2}}{6}\right)\frac{x_{j+1}-x}{h_{j}} + \left(y_{j+1}-\frac{M_{j+1} h_{j}^{2}}{6}\right)\frac{x-x_{j}}{h_{j}}<br>$$</p>
</blockquote>
<h2 id="第二边界条件"><a href="#第二边界条件" class="headerlink" title="第二边界条件"></a>第二边界条件</h2><h1 id="begin-bmatrix-2-lambda-1-mu-2-2-lambda-2-ddots-ddots-ddots-mu-n-1-2-end-bmatrix-begin-bmatrix-M-1-M-2-vdots-M-n-1-end-bmatrix"><a href="#begin-bmatrix-2-lambda-1-mu-2-2-lambda-2-ddots-ddots-ddots-mu-n-1-2-end-bmatrix-begin-bmatrix-M-1-M-2-vdots-M-n-1-end-bmatrix" class="headerlink" title="$$\begin{bmatrix}2 &amp; \lambda_1 &amp; &amp; \\mu_2 &amp; 2 &amp; \lambda_2 &amp; \ &amp; \ddots &amp; \ddots &amp; \ddots \ &amp; &amp; \mu_{n-1} &amp; 2\end{bmatrix}\begin{bmatrix}M_1 \M_2 \\vdots \M_{n-1}\end{bmatrix}"></a>$$<br>\begin{bmatrix}<br>2 &amp; \lambda_1 &amp; &amp; \<br>\mu_2 &amp; 2 &amp; \lambda_2 &amp; \<br> &amp; \ddots &amp; \ddots &amp; \ddots \<br> &amp; &amp; \mu_{n-1} &amp; 2<br>\end{bmatrix}<br>\begin{bmatrix}<br>M_1 \<br>M_2 \<br>\vdots \<br>M_{n-1}<br>\end{bmatrix}</h1><p>\begin{bmatrix}<br>d_1 - \mu_1 f’’<em>0 \<br>d_2 \<br>\vdots \<br>d</em>{n-1} - \lambda_{n-1} f’’_n<br>\end{bmatrix}<br>$$</p>
<p>$$<br>\begin{cases}<br>M_0 &#x3D; f’’_0 \<br>M_n &#x3D; f’’_n<br>\end{cases}<br>$$</p>
<p>$$<br>s(x) &#x3D; \frac{\left(x_{j+1}-x\right)^{3}}{6 h_{j}} M_{j} + \frac{\left(x-x_{j}\right)^{3}}{6 h_{j}} M_{j+1} + \left(y_{j}-\frac{M_{j} h_{j}^{2}}{6}\right)\frac{x_{j+1}-x}{h_{j}} + \left(y_{j+1}-\frac{M_{j+1} h_{j}^{2}}{6}\right)\frac{x-x_{j}}{h_{j}}<br>$$</p>
<h1 id="向量范数"><a href="#向量范数" class="headerlink" title="向量范数"></a>向量范数</h1><p><span style="color:#FF0000">所有的范数无论是比值，或是求和、积分或者其他运算，都是以绝对值进行的</span></p>
<p>设 $x &#x3D; (x_1, \dots, x_n)^T \in \mathbb{R}^n$，定义以下三种常用范数：  </p>
<ol>
<li><p><strong>∞-范数（最大范数）</strong>：<br>$$<br>||x|| _ \infty &#x3D; \max_{1 \leq i \leq n} |x_i|<br>$$</p>
</li>
<li><p><strong>1-范数</strong>：<br>$$<br>||x|| _ 1 &#x3D; \sum_{i&#x3D;1}^n |x_i|<br>$$</p>
</li>
<li><p><strong>2-范数</strong>：<br>$$<br>||x|| _ 2 &#x3D; \left( \sum_{i&#x3D;1}^n x_i^2 \right)^{1&#x2F;2}<br>$$</p>
</li>
</ol>
<hr>
<h1 id="函数范数"><a href="#函数范数" class="headerlink" title="函数范数"></a>函数范数</h1><p>设 $f(x) \in C[a, b]$，定义以下三种常用范数：  </p>
<ol>
<li><p><strong>∞-范数</strong>：<br>$$<br>||f||_ \infty &#x3D; \max_{a \leq x \leq b} |f(x)|<br>$$</p>
</li>
<li><p><strong>1-范数</strong>：<br>$$<br>||f||_1 &#x3D; \int_a^b |f(x)| , dx<br>$$</p>
</li>
<li><p><strong>2-范数</strong>：<br>$$<br>||f||_2 &#x3D; \left( \int_a^b f^2(x) , dx \right)^{1&#x2F;2}<br>$$</p>
</li>
</ol>
<h1 id="矩阵范数"><a href="#矩阵范数" class="headerlink" title="矩阵范数"></a>矩阵范数</h1><blockquote>
<p><strong>常用矩阵范数</strong>(<strong>下面的$x$都指的是向量</strong>)</p>
<ol>
<li><strong>Frobenius范数</strong></li>
</ol>
<p>$$<br>||A||_F &#x3D; \sqrt {\sum _{i&#x3D;1}^n  \sum _{j&#x3D;1}^n |a _{ij}|^2}<br>$$</p>
<p>对于方阵 $A \in \mathbb{R}^{n \times n}$ 和向量 $x \in \mathbb{R}^n$ 有：</p>
<p>$$<br>||Ax||_2 \leq ||A||_F \cdot ||x||_2<br>$$</p>
<ol start="2">
<li><strong>算子范数（Operator Norm）</strong></li>
</ol>
<p>矩阵范数与向量范数的<strong>相容性</strong>（<em>consistent</em>）</p>
<p>$$<br>||A|| _p &#x3D; \max _{x \neq 0} \frac{||Ax|| _p}{||x|| _p} &#x3D; \max _{||x|| _p&#x3D;1} ||Ax|| _p<br>$$</p>
<p>进一步：</p>
<p>$$<br>||Ax||_p \leq ||A||_p ||x||_p<br>$$</p>
<blockquote>
<p><strong>行和范数（∞-范数）</strong><br>$$<br>||A|| _\infty &#x3D; \max _{1 \leq i \leq n} \sum _{j&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>列和范数（1-范数）</strong></p>
<p>$$<br>||A||_1 &#x3D; \max _{1 \leq j \leq n} \sum _{i&#x3D;1}^n |a _{ij}|<br>$$</p>
</blockquote>
<blockquote>
<p><strong>谱范数（2-范数）</strong></p>
</blockquote>
<blockquote>
<p>$$<br>||A||_2 &#x3D; \sqrt{\lambda _{\max}(A^T A)}<br>$$</p>
<p>矩阵$A^T A$的最大特征根</p>
</blockquote>
<p><strong>矩阵谱半径定义</strong></p>
<p>设矩阵 $A \in \mathbb{C}^{n \times n}$ 的特征根为 $\lambda_1, \lambda_2, \ldots, \lambda_n$，则矩阵 $A$ 的<strong>谱半径</strong>（<em>spectral radius</em>）定义为：</p>
<p>$$<br>\rho(A) &#x3D; \max_{1 \leq i \leq n} |\lambda_i|<br>$$</p>
</blockquote>
<p><strong>一些定理</strong></p>
<ol>
<li>对于任意算子范数  $||\cdot||$  ，有：</li>
</ol>
<p>$$<br>\rho(A) \leq ||A||<br>$$</p>
<ol start="2">
<li><p>若$A$对称，则有</p>
<p>$$<br>||A||_2 &#x3D; \rho(A)<br>$$</p>
</li>
</ol>
<h1 id="向量内积"><a href="#向量内积" class="headerlink" title="向量内积"></a>向量内积</h1><p>在 $\mathbb{R}^n$ 中，向量 $x &#x3D; (x_1, x_2, \dots, x_n)^T$ 和 $y &#x3D; (y_1, y_2, \dots, y_n)^T$ 的内积定义为：<br>$$<br>(x, y) &#x3D; x_1 y_1 + x_2 y_2 + \dots + x_n y_n \tag{1.5}<br>$$</p>
<h1 id="函数内积"><a href="#函数内积" class="headerlink" title="函数内积"></a>函数内积</h1><p>设 $f(x), g(x) \in C[a, b]$，$\rho(x)$ 是 $[a, b]$ 上的权函数，积分<br>$$<br>(f, g) &#x3D; \int_a^b \rho(x) f(x) g(x) , dx<br>$$<br>称为函数 $f(x)$ 与 $g(x)$ 在 $[a, b]$ 上的<strong>内积</strong>。</p>
<hr>
<p>设函数 $ f(x) \in C[a, b] $，定义量<br>$$<br>|| f ||_2 &#x3D; \sqrt{ \int_a^b \rho(x) f^2(x) , dx } &#x3D; \sqrt{ (f, f) }<br>$$</p>
<p>$$<br>|| f ||_2^2&#x3D;(f, f)<br>$$</p>
<p>称为函数 $ f(x) $ 的<strong>欧氏范数</strong>。</p>
<h1 id="最佳平方逼近"><a href="#最佳平方逼近" class="headerlink" title="最佳平方逼近"></a>最佳平方逼近</h1><p><strong>正规方程组</strong><br>$$<br>\sum_{j&#x3D;0}^{n} (\varphi_j, \varphi_k) a_j &#x3D; (f, \varphi_k), \quad (k &#x3D; 0, 1, \ldots, n)<br>$$<br><strong>误差</strong><br>$$<br>|\delta(x)|^2_2 &#x3D; |f(x)|^2_2 - \sum_{k&#x3D;0}^n a_k^* (\varphi_k(x), f(x)).<br>$$</p>
<h3 id="勒让德多项式作为基函数"><a href="#勒让德多项式作为基函数" class="headerlink" title="勒让德多项式作为基函数"></a>勒让德多项式作为基函数</h3><p>当 $ f(x) \in C[-1, 1] $ 时，可以用勒让德多项式 $ {P_k(x)} $ 作为基函数，即<span> $ {g_k(x)} &#x3D; {P_k(x)} $</span>。此时，最佳平方逼近多项式为：</p>
<span>
$$
s_n^*(x) = a_0^* P_0(x) + a_1^* P_1(x) + \dots + a_n^* P_n(x)
$$

</span>

<p>其中，系数 $ a_k^* $ 的计算公式为：<br>$$<br>a_k^* &#x3D; \frac{(P_k, f)}{(P_k, P_k)} &#x3D; \frac{2k+1}{2} \int_{-1}^1 f(x) P_k(x) , dx \quad(k&#x3D;0,1,\cdots,n)<br>$$</p>
<p>则 $ s_n^<em>(x) $ 是使 $ || f(x) - \sum _{k&#x3D;0}^n a_k^</em>  P_k(x) ||_2^2 $ 最小的最佳平方逼近多项式。</p>
<p><strong>此时的平方误差为</strong>：</p>
<span>
$$
\|\delta_n\|_2^2 = \int_{-1}^{1} [f(x)]^2 \, dx - \sum_{k=0}^{n} \frac{2}{2k+1} a_k^{*2}
$$

</span>

<p><u>如果所给的区间不是 $[-1, 1]$，而是一般的有限区间 $[a, b]$，可以通过变量置换将其转化为区间 $[-1, 1]$ 上的情形来处理</u>。</p>
<p>变量置换公式</p>
<p>通过以下变量置换公式，将区间 $[a, b]$ 转化为 $[-1, 1]$：</p>
<p>$$<br>x &#x3D; \frac{a + b}{2} + \frac{b - a}{2} t<br>$$</p>
<h1 id="勒让德（Legendre）多项式"><a href="#勒让德（Legendre）多项式" class="headerlink" title="勒让德（Legendre）多项式"></a>勒让德（Legendre）多项式</h1><ul>
<li>$ P_0(x) &#x3D; 1 $</li>
<li>$ P_1(x) &#x3D; x $</li>
<li>$ P_2(x) &#x3D; \frac{1}{2}(3x^2 - 1)$</li>
<li>$P3(x)&#x3D;\frac{1}{2}(5x^3 - 3x)$</li>
</ul>
<p>在区间 $[-1, 1]$ 上满足正交性：<br>$$<br>\int_{-1}^1 P_n(x) P_m(x) , dx &#x3D;<br>\begin{cases}<br>0, &amp; m \neq n \<br>\frac{2}{2n+1}, &amp; m &#x3D; n<br>\end{cases}<br>$$</p>
<h1 id="切比雪夫Chebyshev多项式"><a href="#切比雪夫Chebyshev多项式" class="headerlink" title="切比雪夫Chebyshev多项式"></a>切比雪夫Chebyshev多项式</h1><p>当区间为 $[-1, 1]$，权函数 $\rho(x) &#x3D; \dfrac{1}{\sqrt{1 - x^2}}$ 时，由序列 ${1, x, \cdots, x^n, \cdots}$ 正交化得到的正交多项式就是 Chebyshev 多项式，它可表为：</p>
<p>$$<br>T_n(x) &#x3D; \cos(n \arccos x) \quad |x| \leq 1<br>$$<br>若令 $x &#x3D; \cos\theta$，则 $T_n(x) &#x3D; \cos n\theta$，$0 \leq \theta \leq \pi$。</p>
<h2 id="Chebyshev-多项式重要性质"><a href="#Chebyshev-多项式重要性质" class="headerlink" title="Chebyshev 多项式重要性质"></a>Chebyshev 多项式重要性质</h2><p><strong>性质 1</strong>  </p>
<p>Chebyshev 多项式 ${T_n(x)}$ 在区间 $[-1, 1]$ 上带权 $\rho(x) &#x3D; \dfrac{1}{\sqrt{1 - x^2}}$ 正交，<br>$$<br>T_k(x) &#x3D; \cos(k \cdot \arccos x)<br>$$</p>
<p>且：</p>
<span>
$$
\int_{-1}^{1} \dfrac{T_n(x)T_m(x)}{\sqrt{1 - x^2}} \, dx = 
\begin{cases} 
0, & n \neq m \\
\dfrac{\pi}{2}, & n = m \neq 0 \\
\pi, & n = m = 0 
\end{cases}
$$

</span>

<p><strong>性质 2 递推关系</strong>  </p>
<span>
$$
\begin{cases}
T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x) & (n = 1, 2, \cdots), \\
T_0(x) = 1, \\
T_1(x) = x.
\end{cases}
$$

</span>

<p>由递推关系可得：</p>
<span>
$$
T_0(x)= 1 \quad \\
T_1(x)= x \quad  \\
T_2(x)= 2x^2 - 1 \quad \\
T_3(x)= 4x^3 - 3x \quad \\
T_4(x) = 8x^4 - 8x^2 + 1 \quad \\
T_5(x) = 16x^5 - 20x^3 + 5x
$$

</span>



<blockquote>
<p>$T_{n+1}$的根为：<br>$$<br>x_k &#x3D; \cos\left(\frac{(2k+1)\pi}{2(n+1)})\right),\quad k&#x3D;0,1,\ldots,n<br>$$</p>
</blockquote>
<h1 id="最小二乘拟合"><a href="#最小二乘拟合" class="headerlink" title="最小二乘拟合"></a>最小二乘拟合</h1><p>若用 ${\varphi_0, \varphi_1, \ldots, \varphi_m}$ 构成一个 $N \times (m+1)$ 的矩阵 $A$，即：</p>
<span>
$$
A = 
\begin{bmatrix}
\varphi_0(x_1) & \varphi_1(x_1) & \cdots & \varphi_m(x_1) \\
\varphi_0(x_2) & \varphi_1(x_2) & \cdots & \varphi_m(x_2) \\
\vdots & \vdots & \ddots & \vdots \\
\varphi_0(x_N) & \varphi_1(x_N) & \cdots & \varphi_m(x_N)
\end{bmatrix}
$$

</span>

<p>引入向量：</p>
<p>$$<br>\alpha &#x3D; (a_0, a_1, \ldots, a_m)^T, \quad Y &#x3D; (y_1, y_2, \ldots, y_N)^T<br>$$</p>
<p><strong>法方程组</strong>可以写成以下矩阵形式：(权w&#x3D;1)<br>$$<br>A^T A \alpha &#x3D; A^T Y<br>$$</p>
<p>由于 $\varphi_0, \varphi_1, \ldots, \varphi_m$ 线性无关，法方程组存在唯一解：</p>
<p>$$<br>\alpha &#x3D; (a_0^* , a_1^* , \ldots, a_m^* )^T<br>$$</p>
<p>从而得到函数：</p>
<p>$$<br>\varphi^* (x) &#x3D; a_0^*  \varphi_0 + a_1^*  \varphi_1 + \cdots + a_m^*  \varphi_m<br>$$</p>
<p>最小平方误差为：</p>
<p>$$<br>\delta^2 &#x3D; || y - \varphi^*  ||^2_2 &#x3D; (y - \varphi^* , y - \varphi^* ) &#x3D; || y ||^2_2 - \sum_{j&#x3D;0}^m a_j^*  (\varphi_j, y)<br>$$</p>
<h3 id="代数多项式拟合"><a href="#代数多项式拟合" class="headerlink" title="代数多项式拟合"></a>代数多项式拟合</h3><p>若取基函数 $\varphi_0 &#x3D; 1, \varphi_1 &#x3D; x, \ldots, \varphi_m &#x3D; x^m$，则相应的法方程组为：</p>
<span>
$$
\begin{bmatrix}
\sum_{i=1}^{N} \omega_i & \sum_{i=1}^{N} \omega_i x_i & \cdots & \sum_{i=1}^{N} \omega_i x_i^m \\
\sum_{i=1}^{N} \omega_i x_i & \sum_{i=1}^{N} \omega_i x_i^2 & \cdots & \sum_{i=1}^{N} \omega_i x_i^{m+1} \\
\vdots & \vdots & \ddots & \vdots \\
\sum_{i=1}^{N} \omega_i x_i^m & \sum_{i=1}^{N} \omega_i x_i^{m+1} & \cdots & \sum_{i=1}^{N} \omega_i x_i^{2m}
\end{bmatrix}
\begin{bmatrix}
a_0 \\
a_1 \\
\vdots \\
a_m
\end{bmatrix}
=
\begin{bmatrix}
\sum_{i=1}^{N} \omega_i y_i \\
\sum_{i=1}^{N} \omega_i x_i y_i \\
\vdots \\
\sum_{i=1}^{N} \omega_i x_i^m y_i
\end{bmatrix}
$$

</span>

<p>即<br>$$<br>A^T\omega A\alpha&#x3D;A^T\omega Y<br>$$<br><span><br>$$<br>A &#x3D;<br>\begin{bmatrix}<br>1 &amp; x_1 &amp; \cdots &amp; x_1^m \<br>1 &amp; x_2 &amp; \cdots &amp; x_2^m  \<br>1 &amp; x_3 &amp; \cdots &amp; x_3^m  \<br>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \<br>1 &amp; x_N &amp; \cdots &amp; x_N^m<br>\end{bmatrix}<br>$$</p>
</span>   
$$
\omega =\begin{bmatrix}
\omega_1& &  &  \\
 & \omega _2 &  &   \\
 &  & \omega_3 &   \\
 &  &  & \ddots \\
 &  &  &  & \omega _n
\end{bmatrix}
$$


<p>求出法方程组的解 $a_0, a_1, \ldots, a_m$，即可得到拟合多项式：<br>$$<br>\varphi(x) &#x3D; a_0 + a_1 x + \cdots + a_m x^m<br>$$<br><span style="color:#FF0000">PS:当$n\geq3$时候，求解法方程时将出现系数矩阵为病态的问题</span></p>
<h1 id="最佳一次一致逼近多项式"><a href="#最佳一次一致逼近多项式" class="headerlink" title="最佳一次一致逼近多项式"></a>最佳一次一致逼近多项式</h1><p>求 $ p_1(x) &#x3D; a_0 + a_1 x $ 的方法</p>
<p><span style="color:#FF0000">首先判断$f’’(x)$不变号</span></p>
</span>

<p>$$<br>a_1 &#x3D; \frac{f(b) - f(a)}{b - a}<br>$$</p>
<p>$$<br>a_0 &#x3D; \frac{1}{2} \left[ f(a) + f(x_2) \right] - \frac{a+x_2}{2} a_1\<br>f’(x_2) &#x3D; a_1<br>$$</p>
<p>由此得 $ f $ 在 $[a, b]$ 上的最佳一次逼近多项式</p>
<p>$$<br>p_1(x) &#x3D; a_0 + a_1 x.<br>$$<br><strong>偏差</strong><br>$$<br>\Delta(f, P_1) &#x3D; \max_{a \leq x \leq b} |f(x) - P_1| \<br>&#x3D;\max_{a \leq x \leq b} |f(a) - P_1(a)| \<br>&#x3D;\max_{a \leq x \leq b} |f(b) - P_1(b)| \<br>&#x3D;\max_{a \leq x \leq b} |f(x_2) - P_1(x_2)|<br>$$</p>
<h1 id="梯形公式"><a href="#梯形公式" class="headerlink" title="梯形公式"></a>梯形公式</h1><p>$$<br>\int _{a}^{b} f(x) dx \approx \frac{(b - a)}{2} \left[ f(a) + f(b) \right]<br>$$</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D;-\frac{1}{12} (b-a)^3 f’’(\xi)<br>$$</p>
<p>$$<br>\xi \in [a,b]<br>$$</p>
<h1 id="复化梯形公式"><a href="#复化梯形公式" class="headerlink" title="复化梯形公式"></a>复化梯形公式</h1><p> <strong>区间划分</strong></p>
<p>$$<br>h &#x3D; \frac{b - a}{n}, \quad x_k &#x3D; a + kh \quad (k &#x3D; 0, \ldots, n)<br>$$<br><strong>整体复化公式</strong><br>$$<br>\begin{aligned}<br>\int_a^b f(x) dx &amp;\approx \sum_{k&#x3D;1}^n \frac{h}{2} [f(x_{k-1}) + f(x_k)] \<br>&amp;&#x3D; \frac{h}{2} \left[ f(a) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right] \<br>&amp;&#x3D;T_n<br>\end{aligned}<br>$$</p>
<p><strong>4.误差分析</strong><br>$$<br>\begin{aligned}<br>R[f]<br>&amp;&#x3D; -\frac{(b - a)}{12} h^2 f’’(\xi), \quad \xi \in (a, b)<br>\end{aligned}<br>$$</p>
<h1 id="矩形公式"><a href="#矩形公式" class="headerlink" title="矩形公式"></a>矩形公式</h1><p>$$<br>\int _{a}^{b} f(x) dx \approx (b - a) f\left( \frac{a + b}{2} \right)<br>$$</p>
<h1 id="辛普森公式"><a href="#辛普森公式" class="headerlink" title="辛普森公式"></a>辛普森公式</h1><p>$$<br>\int _{a}^{b} f(x) dx \approx \frac{(b - a)}{6} \left[ f(a) + 4f\left( \frac{a + b}{2} \right) + f(b) \right]<br>$$</p>
<p><strong>余项公式</strong>:<br>$$<br>R[f] &#x3D;-\frac{1}{2880} (b-a)^5 f^{(4)}(\xi)<br>$$</p>
<p>$$<br>\xi \in [a,b]<br>$$</p>
<h1 id="复化Simpson公式"><a href="#复化Simpson公式" class="headerlink" title="复化Simpson公式"></a>复化Simpson公式</h1><p><strong>1. 区间划分</strong></p>
<p>$$<br> h &#x3D; \frac{b - a}{n}<br>$$</p>
<p>$$<br> x_k &#x3D; a + kh \quad (k &#x3D; 0, \ldots, n)<br>$$</p>
<p><strong>2. 整体复化公式</strong><br>$$<br>\begin{aligned}<br>\int_a^b f(x) dx &amp;\approx \frac{h}{6} \left[ f(a) + 4\sum_{k&#x3D;0}^{n-1} f\left(x_{k+\frac{1}{2}}\right) + 2\sum_{k&#x3D;1}^{n-1} f(x_k) + f(b) \right] \<br>&amp;&#x3D; S_n<br>\end{aligned}<br>$$</p>
<p><strong>3.误差分析</strong><br>$$<br>R[f] &#x3D; -\frac{b - a}{2880} h^4 f^{(4)}(\xi), \quad \xi \in (a,b)<br>$$</p>
<h1 id="代数精度"><a href="#代数精度" class="headerlink" title="代数精度"></a>代数精度</h1><p>欲使求积公式有 $m$ 次代数精度，需满足它对 $f(x) &#x3D; 1, x, x^2, \ldots, x^m$ 都能准确成立：<br>$$<br>\sum_{k&#x3D;0}^n A_k x_k^\alpha &#x3D; \int_a^b x^\alpha dx \quad (\alpha &#x3D; 0,1,2,\ldots,m)<br>$$<br>具体表现为：</p>
<span>
$$
\begin{aligned}
\sum_{k=0}^n A_k &= b - a \\
\sum_{k=0}^n A_k x_k &= \frac{1}{2}(b^2 - a^2) \\
\sum_{k=0}^n A_k x_k^2 &= \frac{1}{3}(b^3 - a^3) \\
&\vdots \\
\sum_{k=0}^n A_k x_k^m &= \frac{1}{m+1}(b^{m+1} - a^{m+1})
\end{aligned}
$$

</span>

<h1 id="插值型的求积公式"><a href="#插值型的求积公式" class="headerlink" title="插值型的求积公式"></a>插值型的求积公式</h1><p><strong>最终得到插值型求积公式：</strong><br>$$<br>I _{ n } &#x3D; \sum _{ k&#x3D;0 }^{ n } A _{ k } f ( x _{ k } )<br>$$</p>
<p>求积系数：</p>
<span>
$$
A _{ k } = \int _{ a }^{ b } l _{ k } ( x ) dx=\int _{ a }^{ b }\prod_{\substack{j=0 \\ j \neq k}}^{n} \frac{x - x_j}{x_k - x_j} dx \quad (k = 0,1,\ldots,n) \\
$$
</span>

<p><strong>余项公式</strong></p>
<p>插值型求积公式的余项为：<br>$$<br>R[f] &#x3D; I - I_n &#x3D; \int_a^b \frac{f^{(n+1)}(\xi)}{(n+1)!} \omega_{n+1}(x) dx<br>$$<br>式中 $\xi$ 与变量 $x$ 有关，<br>$$<br>\omega_{n+1}(x) &#x3D; (x - x_0)(x - x_1) \cdots (x - x_n)<br>$$</p>
<h1 id="高斯求积公式"><a href="#高斯求积公式" class="headerlink" title="高斯求积公式"></a>高斯求积公式</h1><p>构造具有2n+1次代数精度的求积公式</p>
<p>$$<br>\int_a^b \rho(x) f(x) dx \approx \sum_{k&#x3D;0}^{n} A_k f(x_k)<br>$$</p>
<ul>
<li><p>节点：$x_0, \ldots, x_n$（共n+1个）</p>
</li>
<li><p>系数：$A_0, \ldots, A_n$（共n+1个）</p>
<p>二者都作为待定系数</p>
</li>
</ul>
<p><strong>精度条件方程</strong>：<br>$$<br>\int \rho(x) \cdot 1 dx &#x3D; \sum_{k&#x3D;0}^{n} A_k \<br>\int \rho(x) x dx &#x3D; \sum_{k&#x3D;0}^{n} A_k x_k \<br>\vdots \<br>\int \rho(x) x^{2n+1} dx &#x3D; \sum_{k&#x3D;0}^{n} A_k x_k^{2n+1}<br>$$</p>
<p><strong>代数精度</strong>：</p>
<blockquote>
<p>当取$f(x)&#x3D;1,x,x^2,\ldots,x^{2n+1}$代入可求解，得到的公式具有<strong>2n+1次代数精度</strong></p>
</blockquote>
<ul>
<li>节点称为<strong>Gauss点</strong></li>
<li>公式称为<strong>Gauss型求积公式</strong></li>
</ul>
<h3 id="高斯求积公式的余项"><a href="#高斯求积公式的余项" class="headerlink" title="高斯求积公式的余项"></a>高斯求积公式的余项</h3><p>$$<br>R_n[f] &#x3D; \int_a^b \rho(x) f(x) , dx - \sum_{k&#x3D;0}^{n} A_k f(x_k) \<br> &#x3D; \frac{f^{(2n+2)}(\eta)}{(2n+2)!} \int_a^b \omega_{n+1}^2(x) \rho(x) , dx, \quad \eta \in [a, b]<br>$$</p>
<h2 id="高斯-勒让德求积公式"><a href="#高斯-勒让德求积公式" class="headerlink" title="高斯-勒让德求积公式"></a>高斯-勒让德求积公式</h2><p>(1) 一个节点时  <strong>$n&#x3D;0$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx 2f(0).<br>$$</p>
<p>(2) 两个节点时 <strong>$n&#x3D;1$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx<br>f\left(-\frac{1}{\sqrt{3}}\right)+<br>f\left(\frac{1}{\sqrt{3}}\right).<br>$$</p>
<p>(3) 三个节点时 <strong>$n&#x3D;2$</strong><br>$$<br>\int_{-1}^{1} f(x)dx \approx<br>\frac{5}{9}f\left(-\sqrt{\frac{3}{5}}\right)+<br>\frac{8}{9}f(0)+<br>\frac{5}{9}f\left(\sqrt{\frac{3}{5}}\right).<br>$$</p>
<h1 id="高斯-切比雪夫求积公式"><a href="#高斯-切比雪夫求积公式" class="headerlink" title="高斯-切比雪夫求积公式"></a>高斯-切比雪夫求积公式</h1><p>可以得到$n+1$点的Gauss型求积公式：<br>$$<br>\int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \frac{\pi}{n+1} \sum_{k&#x3D;0}^{n} f\left(\cos\frac{2k+1}{2(n+1)}\pi\right) \<br> k&#x3D;0,1,\ldots,n<br>$$</p>
<ul>
<li><p>$n&#x3D;1$<br>$$<br>\int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \frac{\pi}{2} f\left(-\frac{\sqrt{2}}{2}\right) + \frac{\pi}{2} f\left(\frac{\sqrt{2}}{2}\right)<br>$$</p>
</li>
<li><p>$n&#x3D;2$<br>$$<br>\int_{-1}^{1} \frac{f(x)}{\sqrt{1-x^2}} dx \approx \frac{\pi}{3} f\left(\cos(\frac{5}{6}\pi)\right) + \frac{\pi}{3} f\left(\cos(\frac{1}{2}\pi)\right)</p>
<ul>
<li>\frac{\pi}{3} f\left(\cos(\frac{1}{6}\pi)\right)<br>$$</li>
</ul>
</li>
</ul>
<h1 id="道立特分解法（Doolittle-Factorization）"><a href="#道立特分解法（Doolittle-Factorization）" class="headerlink" title="道立特分解法（Doolittle Factorization）"></a>道立特分解法（Doolittle Factorization）</h1><p>通过比较法直接导出L和U的计算公式。</p>
<p><img src="/blog/../image/Snipaste_2025-04-07_20-28-30-17498878480523.png"></p>
<p><strong>方法备注：</strong></p>
<ol>
<li><span style="color:#FF0000">L的对角线元素为1，U的第一行元素$u_{1j}&#x3D;a_{1j}$</span></li>
<li>然后求L的第一列元素，随后求U的第二列，然后L，随后U，交替往复。<strong>（瞪眼法）</strong></li>
</ol>
<h1 id="追赶法"><a href="#追赶法" class="headerlink" title="追赶法"></a>追赶法</h1><span>
$$
A=\begin{bmatrix}b_1&c_1\\a_2&b_2&c_2\\&\ddots&\ddots&\ddots\\&&a_{n-1}&b_{n-1}&c_{n-1}\\&&&a_n&b_n\end{bmatrix}=\begin{bmatrix}\alpha_1\\r_2&\alpha_2\\&\ddots&\ddots\\&&r_n&\alpha_n\end{bmatrix}\begin{bmatrix}1&\beta_1\\&1&\ddots\\&&\ddots&\beta_{n-1}\\&&&1\end{bmatrix}
$$
</span>

<p>并且满足</p>
<ol>
<li><p>$a_i \ne 0\ (i &#x3D; 2, 3, \dots, n),\ c_i \ne 0\ (i &#x3D; 1, 2, \dots, n - 1);$</p>
</li>
<li><p>$|b_1| &gt; |c_1|,\ |b_i| \ge |a_i| + |c_i|\ (i &#x3D; 2, 3, \dots, n - 1),\ |b_n| &gt; |a_n|.$</p>
</li>
</ol>
<p>$$<br>\boxed{<br>\text{条件1保证方程组不能降阶，条件2保证三角分解可做到底。}<br>}<br>$$</p>
<p>$$<br>r_i&#x3D;a_i<br>$$</p>
<p>$$<br>\beta_1&#x3D;\frac{c_1}{b_1}<br>$$</p>
<p>$$<br>\beta_i&#x3D;\frac{c_i}{b_i-a_i \beta_{i-1}}<br>$$</p>
<p>$$<br>\alpha_1&#x3D;b_{1}\quad \<br>\alpha_{i}&#x3D;b_{i}-a_{i}\beta_{i-1}<br>$$</p>
<h1 id="Jacobi-雅可比-迭代法"><a href="#Jacobi-雅可比-迭代法" class="headerlink" title="Jacobi(雅可比)迭代法"></a>Jacobi(雅可比)迭代法</h1><p><strong>Jacobi迭代公式（分量形式）</strong></p>
<p>第i分量迭代式</p>
<p>$$<br>x_i^{(k+1)} &#x3D; \frac{1}{a_{ii}} \left( b_i - \sum_{\substack{j&#x3D;1 \ j \neq i}}^{n} a_{ij}x_j^{(k)} \right)<br>$$</p>
<ol>
<li>第一分量：$x_1 &#x3D; \frac{1}{a_{11}}(-a_{12}x_2 - \cdots - a_{1n}x_n + b_1)$</li>
<li>第二分量：$x_2 &#x3D; \frac{1}{a_{22}}(-a_{21}x_1 - \cdots - a_{2n}x_n + b_2)$</li>
<li>第n分量：$x_n &#x3D; \frac{1}{a_{nn}}(-a_{n1}x_1 - \cdots - a_{nn-1}x_{n-1} + b_n)$</li>
</ol>
<p><strong>Jacobi迭代的矩阵形式</strong></p>
<p><strong>矩阵分解形式</strong></p>
<p><img src="/blog/../image/Snipaste_2025-04-06_16-16-19-17498920634395.png"></p>
<p>$$<br>A\vec{x} &#x3D; \vec{b} \Leftrightarrow (D + L + U)\vec{x} &#x3D; \vec{b}<br>$$</p>
<p>$$<br>\begin{gathered}<br>\boldsymbol{L}&#x3D;\begin{bmatrix}0\a_{21}&amp;0\\vdots&amp;\ddots\\vdots&amp;&amp;\ddots\a_{n-1}&amp;\cdots&amp;\cdots&amp;a_{n,n-1}&amp;0\end{bmatrix}<br>U&#x3D;\begin{bmatrix}<br>0&amp;a_{12}&amp;\cdots&amp;a_{1n}\&amp;\ddots&amp;\ddots&amp;\vdots\&amp;&amp;\ddots&amp;a_{n-1,n}\<br>&amp;&amp;&amp;0<br>\end{bmatrix}<br>\quad<br>\boldsymbol{D}&#x3D;\begin{bmatrix}a_{11}\&amp;a_{22}\&amp;&amp;\ddots\&amp;&amp;&amp;\ddots\&amp;&amp;&amp;&amp;a_{nn}\end{bmatrix}\quad\end{gathered}<br>$$<br><span style="color:#FF0000">Jacobi迭代阵</span><br>$$<br>B_J&#x3D;-D^{-1}(L + U)<br>$$</p>
<h1 id="Gauss-Seidel迭代法"><a href="#Gauss-Seidel迭代法" class="headerlink" title="Gauss-Seidel迭代法"></a>Gauss-Seidel迭代法</h1><p><strong>迭代公式</strong></p>
<ol>
<li>第1分量： $x_1^{(k+1)} &#x3D; \frac{1}{a_{11}} \left( -a_{12}x_2^{(k)} - a_{13}x_3^{(k)} - \cdots - a_{1n}x_n^{(k)} + b_1 \right)$</li>
<li>第2分量： $x_2^{(k+1)} &#x3D; \frac{1}{a_{22}} \left( -a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} - \cdots - a_{2n}x_n^{(k)} + b_2 \right)$</li>
<li>第3分量： $x_3^{(k+1)} &#x3D; \frac{1}{a_{33}} \left( -a_{31}x_1^{(k+1)} - a_{32}x_2^{(k+1)} - \cdots - a_{3n}x_n^{(k)} + b_3 \right)$</li>
<li>第n分量：  $x_n^{(k+1)} &#x3D; \frac{1}{a_{nn}} \left( -a_{n1}x_1^{(k+1)} - \cdots - a_{n,n-1}x_{n-1}^{(k+1)} + b_n \right)$</li>
</ol>
<p><span style="color:#FF0000">Gauss-Seidel迭代阵</span><br>$$<br>B &#x3D; -(D + L)^{-1}U<br>$$</p>
<hr>
<p><strong>定理</strong></p>
<p>设有方程组</p>
<p>$$<br>x &#x3D; Bx + f<br>$$</p>
<p>对于任意初始向量 $x^{(0)}$ 及任意 $f$，解此方程组的迭代法</p>
<p>$$<br>x^{(k+1)} &#x3D; Bx^{(k)} + f<br>$$</p>
<p>收敛的充要条件是</p>
<p>$$<br>\rho(B) &lt; 1<br>$$</p>
<p>当$\rho(B) &lt; 1$时，迭代过程收敛，且$\rho(B) $越小，迭代收敛越快。</p>
<p><strong>定义</strong></p>
<p>称 $R(B) &#x3D; -\ln \rho(B)$ 为迭代法的<span style="color:#FF0000">收敛速度</span></p>
<p><strong>定理（充分条件）</strong></p>
<p>若存在一个矩阵范数使得 $|B| &#x3D; q &lt; 1$，则迭代收敛，且有下列误差估计：</p>
<p>$$<br>|\vec{x}^* - \vec{x}^{(k)}| \leq \frac{q}{1-q} |\vec{x}^{(k)} - \vec{x}^{(k-1)}|<br>$$</p>
<p>$$<br>|\vec{x}^* - \vec{x}^{(k)}| \leq \frac{q^k}{1-q} |\vec{x}^{(1)} - \vec{x}^{(0)}|<br>$$</p>
<p><strong>注</strong>：因 $\rho(B) \leq |B| &lt; 1$，故收敛性得证。</p>
<hr>
<p><strong>定理（充分条件）：</strong></p>
<p>若A为严格对角占优阵，则解$A \vec x&#x3D; \vec b$的Jacobi和Gauss-Seidel迭代均收敛。</p>
<h1 id="松弛法"><a href="#松弛法" class="headerlink" title="松弛法"></a>松弛法</h1><p>$$<br>x_i^{(k+1)} &#x3D; &#x3D;x_i^{(k)} + \frac{\omega }{a_{ii}}\left [b_i - \sum_{j&lt;i} a_{ij}x_j^{(k+1)} - \sum_{j \geq i} a_{ij}x_j^{(k)} \right ]<br>$$</p>
<p><strong>定理</strong>：设$A$可逆，且$a_{ii} \neq 0$，则松弛法从任意$\vec{x}^{(0)}$出发对某个$\omega$收敛的充要条件为： $\rho(H_\omega) &lt; 1$ 其中<br>$$<br>H_\omega &#x3D; (D + \omega L)^{-1} \left[ (1 - \omega) D - \omega U \right]<br>$$</p>
<p>为迭代矩阵</p>
<p><strong>定理</strong>（必要条件）</p>
<p>设$A$可逆，且$a_{ii} \neq 0$，则松弛法从任意$\vec{x}^{(0)}$出发对某个$\omega$收敛$\Rightarrow 0&lt; \omega&lt;2 $</p>
<hr>
<p><strong>定理（Ostrowski-Reich充分条件）</strong></p>
<p><strong>设</strong> $A$ 为对称正定矩阵，且松弛因子满足 $0 &lt; \omega &lt; 2$，<br><strong>则</strong> 松弛法从任意初始向量 $\vec{x}^{(0)}$ 出发均收敛。</p>
<h1 id="不动点迭代法"><a href="#不动点迭代法" class="headerlink" title="不动点迭代法"></a>不动点迭代法</h1><h3 id="等价变换"><a href="#等价变换" class="headerlink" title="等价变换"></a>等价变换</h3><p>$$<br>f(x) &#x3D; 0 \quad \longleftrightarrow \quad x &#x3D; \varphi(x)<br>$$</p>
<p>$$<br>f(x) &#x3D; 0 \text{ 的根} \quad \longleftrightarrow \quad \varphi(x) \text{ 的不动点}<br>$$</p>
<p>从一个初值 $x_0$ 出发，计算 $x_1 &#x3D; \varphi(x_0)$, $x_2 &#x3D; \varphi(x_1)$, …,<br>若 $ {x_k }_{k&#x3D;0}^{\infty}$ 收敛，即存在 $x^* $ 使得<br>$$<br>\lim _{k \to \infty} x_k &#x3D; x^*<br>$$</p>
<p>且 $\varphi$ 连续，则由<br>$$<br>\lim_{k \to \infty} x_{k+1} &#x3D; \lim_{k \to \infty} \varphi(x_k)<br>$$<br>可知 $x^*  &#x3D; \varphi(x^* )$，即 $x^*$ 是 $\varphi$ 的不动点，也就是 $f &#x3D; 0$ 的根。</p>
<blockquote>
<p>迭代法是一种逐次逼近法，其基本思想是将隐式方程归结为一组显式的计算公式，即说，迭代过程实际上是一个逐步显示化的过程。</p>
</blockquote>
<h2 id="迭代法收敛定理"><a href="#迭代法收敛定理" class="headerlink" title="迭代法收敛定理"></a>迭代法收敛定理</h2><blockquote>
<p><strong>定理1</strong> 如果迭代函数 $\varphi(x) \in C[a,b]$，并且  </p>
<ol>
<li>$\forall x \in [a,b]$，都有 $\varphi(x) \in [a,b]$，  </li>
<li>$\exists 0 \leq \text{常数 } L &lt; 1$，使得 $\forall x,y \in [a,b]$，都有</li>
</ol>
<p>$$<br> |\varphi(x) - \varphi(y)| \leq L |x - y|;<br>$$</p>
<p>那么 $\varphi(x)$ 在 $[a,b]$ 上存在唯一的不动点 $x^*$。</p>
<p><strong>定理2</strong> 考虑方程 $x &#x3D; \varphi(x)$, $\varphi(x) \in C^1[a, b]$，若：</p>
<p>(I) 当 $x \in [a, b]$ 时，$\varphi(x) \in [a, b]$；</p>
<p>(II) 存在$0 \leq L &lt; 1$，使得 $|\varphi’(x)| \leq L &lt; 1$ 对 $\forall x \in [a, b]$ 成立。</p>
<p>则任取 $x_0 \in [a, b]$，由 $x_{k+1} &#x3D; \varphi(x_k)$ 得到的序列 ${x_k}_{k&#x3D;0}^{\infty}$ 收敛于 $\varphi(x)$ 在 $[a, b]$ 上的<strong>唯一</strong>不动点，并且有误差估计式：</p>
<p>$$<br>|x^* - x_k| \leq \frac{1}{1 - L} |x_{k+1} - x_k|<br>$$</p>
<p>$$<br>|x^* - x_k| \leq \frac{L^k}{1 - L} |x_1 - x_0| \quad (k &#x3D; 1, 2, \dots)<br>$$</p>
<p>并且存在极限：</p>
<p>$$<br>\lim_{k \to \infty} \frac{x^* - x_{k+1}}{x^* - x_k} &#x3D; \varphi’(x^*)<br>$$</p>
</blockquote>
<h2 id="迭代法的收敛阶"><a href="#迭代法的收敛阶" class="headerlink" title="迭代法的收敛阶"></a>迭代法的收敛阶</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>设迭代 $x_{k+1} &#x3D; \varphi(x_k)$ 收敛到 $\varphi(x)$ 的不动点 $x^*$。</p>
<p>设 $e_k &#x3D; x_k - x^*$，若</p>
<p>$$<br>\lim_{k \to \infty}  \frac{e_{k+1}}{e_k^p} &#x3D; C<br>$$</p>
<p>则称该迭代为 <strong>$p$ 阶收敛</strong>，其中 $C$ 称为渐近误差常数（$C \neq0$）。</p>
<blockquote>
<ul>
<li>$p &#x3D; 1$ 时称作<strong>线性收敛</strong></li>
<li>$p &gt; 1$ 时称作<strong>超线性收敛</strong></li>
<li>p &#x3D; 2 时称作<strong>平方收敛</strong></li>
</ul>
</blockquote>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><p>设 $x^* $ 为方程 $x &#x3D; \varphi(x)$ 的不动点，若 $\varphi \in C^p(R(x^*))$ 且 $p \geq 2$；</p>
<p>$$<br>\varphi’(x^* ) &#x3D; \dots &#x3D; \varphi^{(p-1)}(x^* ) &#x3D; 0, \quad \varphi^{(p)}(x^* ) \neq 0,<br>$$</p>
<p>则 $x_{k+1} &#x3D; \varphi(x_k)$ 在 $R(x^*)$ 内 $p$ 阶收敛。</p>
<h3 id="定理-1"><a href="#定理-1" class="headerlink" title="定理"></a>定理</h3><p>设 $x^* $ 为方程 $x &#x3D; \varphi(x)$ 的不动点，若 $\varphi \in C^p(R(x^*))$ 且 $p \geq 2$；</p>
<p>$$<br>\varphi’(x^* ) &#x3D; \dots &#x3D; \varphi^{(p-1)}(x^* ) &#x3D; 0, \quad \varphi^{(p)}(x^* ) \neq 0,<br>$$</p>
<p>则 $x_{k+1} &#x3D; \varphi(x_k)$ 在 $R(x^*)$ 内 $p$ 阶收敛。</p>
<p><strong>证明</strong>：<br>$$<br>x_{k+1} &#x3D; \varphi(x_k) &#x3D; \varphi(x^* ) + \varphi’(x^* ) (x_k - x^* ) + \dots + \frac{\varphi^{(p)}(\xi_k)}{p!} (x_k - x^* )^p<br>$$</p>
<p>其中 $\xi_k \to x^<em>$ as $k \to \infty$，极限值为 $C$。<br>$$<br>\lim <em>{k\rightarrow\infty}\frac{e</em>{k+1}}{e_k^p}&#x3D; \lim <em>{k\rightarrow\infty}\frac{x</em>{k+1}-x^{</em>}}{\left(x_{k}-x^{<em>}\right)^{p}}&#x3D;\frac{\varphi^{(p)}\left(x^{</em>}\right)}{p !}<br>$$</p>
<h1 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h1><h3 id="牛顿迭代法"><a href="#牛顿迭代法" class="headerlink" title="牛顿迭代法"></a>牛顿迭代法</h3><p>牛顿迭代法是一种特殊的不动点迭代法，其计算公式为：</p>
<p>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \cdots<br>$$</p>
<p>其迭代函数为：</p>
<p>$$<br>\varphi(x) &#x3D; x - \frac{f(x)}{f’(x)}<br>$$<br><strong>牛顿迭代法的收敛速度</strong></p>
<p>当 $f(x^* ) &#x3D; 0, f’(x^* ) \neq 0$ 时，容易证明，$\varphi’(x^* ) &#x3D; 0, \varphi’’(x^* ) &#x3D;  \frac{f’’(x^* )}{f’(x^* )}$，由定理 7.4 知，牛顿迭代法是平方收敛的，且</p>
<p>$$<br>\lim_{k \to \infty} \frac{e_{k+1}}{e_k^2} &#x3D; \frac{f’’(x^* )}{2f’(x^* )}<br>$$</p>
<p>其中，$e_k &#x3D; x_k - x^*$ 为误差。</p>
<h3 id="简化牛顿法"><a href="#简化牛顿法" class="headerlink" title="简化牛顿法"></a>简化牛顿法</h3><p>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k)}{f’(x_0)}<br>$$</p>
<h3 id="牛顿下山法："><a href="#牛顿下山法：" class="headerlink" title="牛顿下山法："></a>牛顿下山法：</h3><p>$$<br>x_{k+1} &#x3D; x_k - \lambda \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \dots<br>$$</p>
<p>其中下山因子 $\lambda &#x3D; 1$，逐次减半直至满足 $|f(x_{k+1})| &lt; |f(x_k)|$。</p>
<h3 id="牛顿法的重根情形"><a href="#牛顿法的重根情形" class="headerlink" title="牛顿法的重根情形"></a>牛顿法的重根情形</h3><p><strong>方法1</strong>（知道重数）<br>$$<br>x_{k+1} &#x3D; x_k - m \frac{f(x_k)}{f’(x_k)}, \quad k &#x3D; 0, 1, 2, \dots<br>$$<br><strong>方法2</strong><br>$$<br>x_{k+1} &#x3D; x_k - \frac{f(x_k) f’(x_k)}{[f’(x_k)]^2 - f(x_k) f’’(x_k)}, \quad (k &#x3D; 0, 1, 2, \dots)<br>$$</p>
<h2 id="弦截法"><a href="#弦截法" class="headerlink" title="弦截法"></a>弦截法</h2><p>$$<br>x_{k+1} &#x3D; x_k -  \frac{f(x_k)}{f(x_k)-f(x_{k-1})} (x_k-x_{k-1}), \quad k &#x3D;  1, 2, \dots<br>$$</p>
<blockquote>
<p><strong>欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + h f(x_n, y_n)<br>$$<br><strong>隐式欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + h f(x_{n+1}, y_{n+1}) \quad (n &#x3D; 0, \dots, N-1)<br>$$</p>
<p><strong>改进欧拉法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{2} \left[ f(x_n, y_n) + f(x_{n+1}, y_n + h f(x_n, y_n)) \right]<br>$$</p>
<p><strong>四阶经典R-K方法</strong><br>$$<br>y_{n+1} &#x3D; y_n + \frac{h}{6} (K_1 + 2K_2 + 2K_3 + K_4)<br>$$</p>
<p>$$<br>K_1 &#x3D; f(x_n, y_n)<br>$$</p>
<p>$$<br>K_2 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_1)<br>$$</p>
<p>$$<br>K_3 &#x3D; f(x_n + \frac{h}{2}, y_n + \frac{h}{2} K_2)<br>$$</p>
<p>$$<br>K_4 &#x3D; f(x_n + h, y_n + h K_3)<br>$$</p>
<p><strong>稳定区间</strong></p>
<ol>
<li>欧拉法</li>
</ol>
 <div>


<p>$$<br> E(h\lambda)&#x3D;1+h\lambda \<br> -2 &lt; \lambda h &lt; 0<br>$$</p>
 </div>

<ol start="2">
<li>改进欧拉法</li>
</ol>
 <div>


<p>$$<br> E(h\lambda)&#x3D;1 + h\lambda + \frac{(h\lambda)^2}{2} \<br> -2 &lt; h\lambda &lt; 0<br>$$</p>
 </div>

<ol start="3">
<li>4阶经典龙格库塔方法</li>
</ol>
<p>$$<br> E(h\lambda) &#x3D; 1 + h\lambda + \frac{(h\lambda)^2}{2!} + \frac{(h\lambda)^3}{3!} + \frac{(h\lambda)^4}{4!}.<br>$$</p>
<p>$$<br> -2.78 &lt; h\lambda &lt; 0<br>$$</p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数值分析</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习相关知识</title>
    <url>/blog/2025/02/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Batch-Normalization（批量归一化）-和-Layer-Normalization（层归一化）"><a href="#Batch-Normalization（批量归一化）-和-Layer-Normalization（层归一化）" class="headerlink" title="Batch Normalization（批量归一化） 和 Layer Normalization（层归一化）"></a>Batch Normalization（批量归一化） 和 Layer Normalization（层归一化）</h1><hr>
<h2 id="1-核心概念对比"><a href="#1-核心概念对比" class="headerlink" title="1. 核心概念对比"></a>1. <strong>核心概念对比</strong></h2><h3 id="Batch-Normalization-BN"><a href="#Batch-Normalization-BN" class="headerlink" title="Batch Normalization (BN)"></a><strong>Batch Normalization (BN)</strong></h3><ul>
<li><p><strong>归一化方向</strong>：对 <strong>同一特征维度</strong> 跨所有样本和空间位置归一化。</p>
</li>
<li><p><strong>核心公式</strong>：</p>
<p>假设输入张量形状为 <code>(N, C, H, W)</code>（Batch Size, Channels, Height, Width），则对每个通道 <code>c</code> 计算均值和方差：<br>$$<br>\mu_c &#x3D; \frac{1}{N \cdot H \cdot W} \sum_{n&#x3D;1}^N \sum_{h&#x3D;1}^H \sum_{w&#x3D;1}^W x_{n,c,h,w}, \quad \sigma_c^2 &#x3D; \frac{1}{N \cdot H \cdot W} \sum_{n&#x3D;1}^N \sum_{h&#x3D;1}^H \sum_{w&#x3D;1}^W (x_{n,c,h,w} - \mu_c)^2<br>$$</p>
</li>
<li><p><strong>适用场景</strong>：图像处理（CNN）、固定长度的结构化数据。</p>
</li>
</ul>
<h3 id="Layer-Normalization-LN"><a href="#Layer-Normalization-LN" class="headerlink" title="Layer Normalization (LN)"></a><strong>Layer Normalization (LN)</strong></h3><ul>
<li><p><strong>归一化方向</strong>：对 <strong>同一样本</strong> 的所有特征维度归一化。</p>
</li>
<li><p><strong>核心公式</strong>：</p>
<p>假设输入张量形状为 <code>(N, C, H, W)</code>，对每个样本 <code>n</code> 计算均值和方差：<br>$$<br>\mu_n &#x3D; \frac{1}{C \cdot H \cdot W} \sum_{c&#x3D;1}^C \sum_{h&#x3D;1}^H \sum_{w&#x3D;1}^W x_{n,c,h,w}, \quad \sigma_n^2 &#x3D; \frac{1}{C \cdot H \cdot W} \sum_{c&#x3D;1}^C \sum_{h&#x3D;1}^H \sum_{w&#x3D;1}^W (x_{n,c,h,w} - \mu_n)^2<br>$$</p>
</li>
<li><p><strong>适用场景</strong>：序列数据（RNN、Transformer）、动态长度输入。</p>
</li>
</ul>
<hr>
<h2 id="2-公式符号解释"><a href="#2-公式符号解释" class="headerlink" title="2. 公式符号解释"></a>2. <strong>公式符号解释</strong></h2><h3 id="输入张量形状"><a href="#输入张量形状" class="headerlink" title="输入张量形状"></a><strong>输入张量形状</strong></h3><p>假设输入为 <code>(N, C, H, W)</code>：</p>
<ul>
<li><code>N</code>: 批次大小（Batch Size）</li>
<li><code>C</code>: 通道数（特征维度）</li>
<li><code>H</code>: 高度（空间维度）</li>
<li><code>W</code>: 宽度（空间维度）</li>
</ul>
<h3 id="BN-公式符号"><a href="#BN-公式符号" class="headerlink" title="BN 公式符号"></a><strong>BN 公式符号</strong></h3><ul>
<li><code>μₐ</code>: 第 <code>c</code> 个通道的均值（跨所有样本和空间位置）。</li>
<li><code>σₐ²</code>: 第 <code>c</code> 个通道的方差。</li>
<li><code>xₙ,ₐ,ₕ,ᵥ</code>: 第 <code>n</code> 个样本、第 <code>c</code> 个通道、位置 <code>(h, w)</code> 的像素值。</li>
</ul>
<h3 id="LN-公式符号"><a href="#LN-公式符号" class="headerlink" title="LN 公式符号"></a><strong>LN 公式符号</strong></h3><ul>
<li><code>μₙ</code>: 第 <code>n</code> 个样本的均值（跨所有特征和空间位置）。</li>
<li><code>σₙ²</code>: 第 <code>n</code> 个样本的方差。</li>
<li><code>xₙ,ₐ,ₕ,ᵥ</code>: 同上。</li>
</ul>
<hr>
<h2 id="3-具体示例对比"><a href="#3-具体示例对比" class="headerlink" title="3. 具体示例对比"></a>3. <strong>具体示例对比</strong></h2><h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a><strong>输入数据</strong></h3><ul>
<li><code>N=2</code>（2张图像），<code>C=3</code>（RGB三通道），<code>H=2</code>, <code>W=2</code>（2x2像素）。</li>
<li><strong>样本1</strong>：<ul>
<li>通道0（红）：<code>[[1, 3], [5, 7]]</code></li>
<li>通道1（绿）：<code>[[2, 4], [6, 8]]</code></li>
<li>通道2（蓝）：<code>[[3, 5], [7, 9]]</code></li>
</ul>
</li>
<li><strong>样本2</strong>：<ul>
<li>通道0（红）：<code>[[2, 4], [6, 8]]</code></li>
<li>通道1（绿）：<code>[[3, 5], [7, 9]]</code></li>
<li>通道2（蓝）：<code>[[4, 6], [8, 10]]</code></li>
</ul>
</li>
</ul>
<hr>
<h3 id="BN-计算示例（以通道0为例）"><a href="#BN-计算示例（以通道0为例）" class="headerlink" title="BN 计算示例（以通道0为例）"></a><strong>BN 计算示例（以通道0为例）</strong></h3><ol>
<li><strong>计算均值 <code>μ₀</code></strong>：<br>$$<br>\mu_0 &#x3D; \frac{(1+3+5+7) + (2+4+6+8)}{8} &#x3D; \frac{16 + 20}{8} &#x3D; 4.5<br>$$</li>
<li><strong>计算方差 <code>σ₀²</code></strong>：<br>$$<br>\sigma_0^2 &#x3D; \frac{(1-4.5)^2 + (3-4.5)^2 + \cdots + (8-4.5)^2}{8} &#x3D; \frac{21 + 21}{8} &#x3D; 5.25<br>$$</li>
<li><strong>归一化后</strong>：每个像素值变为 <code>(x - 4.5) / √(5.25 + ε)</code>。</li>
</ol>
<hr>
<h3 id="LN-计算示例（以样本1为例）"><a href="#LN-计算示例（以样本1为例）" class="headerlink" title="LN 计算示例（以样本1为例）"></a><strong>LN 计算示例（以样本1为例）</strong></h3><ol>
<li><strong>计算均值 <code>μ₁</code></strong>：<br>$$<br>\mu_1 &#x3D; \frac{1+3+5+7 + 2+4+6+8 + 3+5+7+9}{12} &#x3D; \frac{60}{12} &#x3D; 5<br>$$</li>
<li><strong>计算方差 <code>σ₁²</code></strong>：<br>$$<br>\sigma_1^2 &#x3D; \frac{(1-5)^2 + (3-5)^2 + \cdots + (9-5)^2}{12} &#x3D; \frac{84}{12} &#x3D; 7<br>$$</li>
<li><strong>归一化后</strong>：每个像素值变为 <code>(x - 5) / √(7 + ε)</code>。</li>
</ol>
<hr>
<h2 id="4-对比总结表格"><a href="#4-对比总结表格" class="headerlink" title="4. 对比总结表格"></a>4. <strong>对比总结表格</strong></h2><table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th>Batch Normalization (BN)</th>
<th>Layer Normalization (LN)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>归一化维度</strong></td>
<td>同一特征维度跨样本和空间位置</td>
<td>同一样本的所有特征维度</td>
</tr>
<tr>
<td><strong>参数数量</strong></td>
<td><code>2C</code>（每通道独立参数）</td>
<td><code>2</code>（全局共享参数）</td>
</tr>
<tr>
<td><strong>依赖条件</strong></td>
<td>需大 Batch Size（如32+）</td>
<td>不依赖 Batch Size</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>图像（CNN）、静态数据</td>
<td>文本（Transformer）、动态序列数据</td>
</tr>
<tr>
<td><strong>训练&#x2F;测试差异</strong></td>
<td>测试时用全局移动平均统计量</td>
<td>测试时直接计算当前样本统计量</td>
</tr>
</tbody></table>
<hr>
<h2 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5. 注意事项"></a>5. <strong>注意事项</strong></h2><ol>
<li><p><strong>BN 的局限性</strong>：</p>
<ul>
<li>小 Batch Size 时性能下降（方差估计不准确）。</li>
<li>对序列数据（如变长文本）不友好。</li>
</ul>
</li>
<li><p><strong>LN 的优势</strong>：</p>
<ul>
<li>适用于单样本推理（如实时生成文本）。</li>
<li>对特征维度间的动态变化更鲁棒。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="6-代码示例（PyTorch）"><a href="#6-代码示例（PyTorch）" class="headerlink" title="6. 代码示例（PyTorch）"></a>6. <strong>代码示例（PyTorch）</strong></h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Batch Normalization（图像任务）</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">bn = nn.BatchNorm2d(num_features=<span class="number">3</span>)  <span class="comment"># 输入通道数 C=3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Layer Normalization（NLP任务）</span></span><br><span class="line">ln = nn.LayerNorm(normalized_shape=<span class="number">256</span>)  <span class="comment"># 输入特征维度=256</span></span><br></pre></td></tr></table></figure>



<h1 id="上采样（Upsampling）与下采样（Downsampling）详解"><a href="#上采样（Upsampling）与下采样（Downsampling）详解" class="headerlink" title="上采样（Upsampling）与下采样（Downsampling）详解"></a>上采样（Upsampling）与下采样（Downsampling）详解</h1><hr>
<h2 id="核心区别"><a href="#核心区别" class="headerlink" title="核心区别"></a><strong>核心区别</strong></h2><ul>
<li><strong>上采样</strong>：放大特征图尺寸，<strong>恢复细节信息</strong>（如目标边缘、小物体位置）。  </li>
<li><strong>下采样</strong>：缩小特征图尺寸，<strong>提取抽象语义</strong>（如目标类别、整体形状）。  </li>
<li><strong>协作关系</strong>：两者结合实现多尺度检测（如同时识别近处大车和远处小车）。</li>
</ul>
<hr>
<h2 id="1-下采样（Downsampling）"><a href="#1-下采样（Downsampling）" class="headerlink" title="1. 下采样（Downsampling）"></a><strong>1. 下采样（Downsampling）</strong></h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a><strong>作用</strong></h3><ul>
<li>压缩特征图，减少计算量。</li>
<li>捕获高层语义信息（例如“这是一辆车”）。</li>
</ul>
<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a><strong>实现方式</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>跨步卷积</strong></td>
<td>增大卷积步长（如<code>stride=2</code>），跳过部分像素，直接缩小特征图尺寸。</td>
</tr>
<tr>
<td><strong>池化（Pooling）</strong></td>
<td>取局部区域的最大值（Max Pooling）或平均值（Average Pooling）。</td>
</tr>
</tbody></table>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a><strong>特点</strong></h3><ul>
<li><strong>输出尺寸</strong>：缩小（例如输入<code>256x256</code> → 输出<code>128x128</code>）。</li>
<li><strong>信息保留</strong>：丢弃细节，保留整体特征。</li>
<li><strong>类比</strong>：眯眼看照片，忽略纹理细节，只关注轮廓。</li>
</ul>
<hr>
<h2 id="2-上采样（Upsampling）"><a href="#2-上采样（Upsampling）" class="headerlink" title="2. 上采样（Upsampling）"></a><strong>2. 上采样（Upsampling）</strong></h2><h3 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a><strong>作用</strong></h3><ul>
<li>扩大特征图尺寸，辅助精确定位（如车轮、车灯位置）。</li>
<li>与浅层特征融合，增强小目标检测能力。</li>
</ul>
<h3 id="实现方式-1"><a href="#实现方式-1" class="headerlink" title="实现方式"></a><strong>实现方式</strong></h3><table>
<thead>
<tr>
<th>方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>插值（Interpolation）</strong></td>
<td>通过双线性插值、最近邻插值等算法填充像素（类似图像放大）。</td>
</tr>
<tr>
<td><strong>转置卷积（Transposed Convolution）</strong></td>
<td>反向卷积操作，通过可学习参数生成更大特征图。</td>
</tr>
</tbody></table>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a><strong>特点</strong></h3><ul>
<li><strong>输出尺寸</strong>：放大（例如输入<code>128x128</code> → 输出<code>256x256</code>）。</li>
<li><strong>信息保留</strong>：补充细节，但可能引入噪声。</li>
<li><strong>类比</strong>：放大模糊图片，猜测缺失的像素。</li>
</ul>
<hr>
<h2 id="对比总结"><a href="#对比总结" class="headerlink" title="对比总结"></a><strong>对比总结</strong></h2><table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th>下采样</th>
<th>上采样</th>
</tr>
</thead>
<tbody><tr>
<td><strong>目的</strong></td>
<td>提取抽象特征，减少计算量</td>
<td>恢复细节，精确定位</td>
</tr>
<tr>
<td><strong>典型操作</strong></td>
<td>池化、跨步卷积</td>
<td>插值、转置卷积</td>
</tr>
<tr>
<td><strong>信息流</strong></td>
<td>从细节到语义</td>
<td>从语义到细节</td>
</tr>
<tr>
<td><strong>应用阶段</strong></td>
<td>Backbone（特征提取层）</td>
<td>Neck（特征融合层）</td>
</tr>
</tbody></table>
<h2 id="实际例子"><a href="#实际例子" class="headerlink" title="实际例子"></a><strong>实际例子</strong></h2><ul>
<li><strong>场景</strong>：检测一张包含“近处行人”和“远处车辆”的图像。</li>
<li><strong>下采样</strong>：深层特征图（20x20）捕获“远处车辆”的抽象轮廓。</li>
<li><strong>上采样</strong>：将该特征图放大到40x40，与浅层特征（包含“近处行人”细节）融合，实现多尺度检测。</li>
</ul>
<h1 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h1><h1 id="空洞卷积（Dilated-Convolution）详解"><a href="#空洞卷积（Dilated-Convolution）详解" class="headerlink" title="空洞卷积（Dilated Convolution）详解"></a>空洞卷积（Dilated Convolution）详解</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p><strong>空洞卷积</strong>（Dilated Convolution），又称<strong>膨胀卷积</strong>或<strong>扩张卷积</strong>，是一种通过<strong>插入“空洞”</strong>（间隔）来扩大感受野的卷积操作。它能在<strong>不增加参数量</strong>的前提下捕捉更大范围的上下文信息，常用于图像分割、语音合成等任务。</p>
<h2 id="2-为什么需要空洞卷积？"><a href="#2-为什么需要空洞卷积？" class="headerlink" title="2. 为什么需要空洞卷积？"></a>2. 为什么需要空洞卷积？</h2><p><strong>问题背景</strong>：</p>
<ul>
<li>传统卷积神经网络（CNN）通过堆叠卷积层和池化层（下采样）逐步扩大感受野，但池化会<strong>降低图像分辨率</strong>（丢失细节），导致小目标（如红外弱小目标）难以识别。</li>
<li>如果直接去掉池化层（降低下采样率），后续层的<strong>感受野会变小</strong>，模型无法捕捉全局特征，导致性能下降。</li>
</ul>
<p><strong>空洞卷积的解决方案</strong>：</p>
<ul>
<li><p><strong>保持分辨率</strong>：不进行下采样（保留细节）。</p>
</li>
<li><p><strong>扩大感受野</strong>：通过空洞卷积核覆盖更大区域，避免池化带来的信息损失。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th align="center">卷积核</th>
<th align="center">感受野（3层后）</th>
<th>分辨率</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>普通卷积</strong>（3×3）</td>
<td align="center">连续像素</td>
<td align="center">7×7</td>
<td>逐渐降低（需池化）</td>
<td>常规目标检测</td>
</tr>
<tr>
<td><strong>空洞卷积</strong>（3×3，rate&#x3D;2）</td>
<td align="center">间隔1像素</td>
<td align="center">15×15</td>
<td><strong>保持原始分辨率</strong></td>
<td>小目标检测、图像分割</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="3-优点"><a href="#3-优点" class="headerlink" title="3. 优点"></a>3. 优点</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><table>
<thead>
<tr>
<th>优势</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>更大的感受野</strong></td>
<td>捕捉长距离依赖，适合分割&#x2F;检测任务</td>
</tr>
<tr>
<td><strong>保持分辨率</strong></td>
<td>无需下采样即可扩大感受野，减少信息损失</td>
</tr>
<tr>
<td><strong>参数量不变</strong></td>
<td>相比堆叠卷积层或增大核尺寸更高效</td>
</tr>
</tbody></table>
<h2 id="4-缺点"><a href="#4-缺点" class="headerlink" title="4. 缺点"></a>4. 缺点</h2><table>
<thead>
<tr>
<th>缺点</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>网格效应（Gridding）</strong></td>
<td>高扩张率可能导致局部信息丢失</td>
</tr>
<tr>
<td><strong>优化难度</strong></td>
<td>需平衡扩张率与任务需求</td>
</tr>
</tbody></table>
<h1 id="MIRST与SIRST"><a href="#MIRST与SIRST" class="headerlink" title="MIRST与SIRST"></a>MIRST与SIRST</h1><p><strong>SIRST</strong></p>
<ul>
<li><strong>全称 (Full Name):</strong> <strong>S</strong>ingle-frame <strong>I</strong>nfrared <strong>S</strong>mall <strong>T</strong>arget (单帧红外小目标)</li>
<li><strong>含义 (Meaning):</strong> SIRST问题指的是在<strong>单张红外图像</strong>（即一张静态照片或视频中的某一帧）中检测出小型和暗弱目标的问题。</li>
<li><strong>特点 (Characteristics):</strong><ul>
<li><strong>局限于空间信息：</strong> 算法主要依赖于目标与背景在<strong>空间域</strong>（如亮度、对比度、形状、纹理等）上的差异来识别目标。</li>
<li><strong>不利用时间信息：</strong> 由于只处理单帧，无法利用目标在不同时间帧之间的运动轨迹、背景变化等<strong>时间域</strong>信息。</li>
<li><strong>挑战：</strong> 如果目标的热对比度非常低，或者背景杂波复杂且与目标特征相似，单帧检测会非常困难，因为缺乏时间维度的辅助信息来区分目标和噪声&#x2F;杂波。</li>
</ul>
</li>
<li><strong>相关算法：</strong> 许多传统的基于图像处理的方法（如基于滤波、形态学、局部对比度等）以及一些早期的深度学习方法，都首先在SIRST问题上进行研究和验证。</li>
</ul>
<hr>
<p><strong>MIRST</strong></p>
<ul>
<li><strong>全称 (Full Name):</strong> <strong>M</strong>ulti-frame <strong>I</strong>nfrared <strong>S</strong>mall <strong>T</strong>arget (多帧红外小目标)</li>
<li><strong>含义 (Meaning):</strong> MIRST问题指的是在<strong>连续的多帧红外图像序列</strong>（即视频流）中检测出小型和暗弱目标的问题。</li>
<li><strong>特点 (Characteristics):</strong><ul>
<li><strong>结合空间和时间信息：</strong> 除了单帧图像中的空间特征外，MIRST算法还能利用目标在不同帧之间的<strong>运动信息</strong>（如速度、方向、轨迹一致性）来辅助检测。</li>
<li><strong>区分运动目标与静止杂波：</strong> 这是MIRST最大的优势。真正的目标通常是运动的，而背景杂波、噪声或热点是相对静止或随机变化的。通过分析时间上的连续性，可以有效抑制静止杂波和瞬时噪声。</li>
<li><strong>挑战：</strong> 需要处理时间同步、运动估计、数据量大、计算复杂度高等问题。</li>
</ul>
</li>
<li><strong>相关算法：</strong> 通常涉及背景抑制、目标轨迹跟踪、运动补偿、时空滤波等技术，近年来的深度学习方法也开始更多地利用视频序列信息来提升检测性能。</li>
</ul>
<h1 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h1><p>TP（True Positives)：真正例，预测为正例而且实际上也是正例；</p>
<p>FP（False Positives)：假正例，预测为正例然而实际上却是负例；</p>
<p>FN（false Negatives)：假负例，预测为负例然而实际上却是正例；</p>
<p>TN（True Negatives)：真负例，预测为负例而且实际上也是负例。</p>
<p><img src="/blog/image/TP.PNG"></p>
<h2 id="检测率"><a href="#检测率" class="headerlink" title="检测率"></a>检测率</h2><p><strong>Probability of Detection, $P_d$</strong></p>
<ul>
<li><p><strong>定义：</strong> 算法正确检测到的真实目标数，占所有真实目标数的比例。衡量 “不漏检” 能力，军事场景中 Pd 至关重要（如导弹告警，漏检会导致防御失效）。</p>
</li>
<li><p><strong>计算公式：</strong><br>$$<br>P_d &#x3D; \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Negatives (FN)}} &#x3D; \frac{\text{TP}}{\text{Actual Positives}}<br>$$</p>
<ul>
<li><strong>True Positives (TP，真阳性):</strong> 算法正确地将目标识别为目标（即检测到了真实存在的目标）。</li>
<li><strong>False Negatives (FN，假阴性):</strong> 算法未能检测到真实存在的目标（即漏报了目标）。</li>
<li><strong>Actual Positives (实际正例):</strong> 数据集中所有真实存在的目标数量 ($TP + FN$)。</li>
</ul>
</li>
<li><p><strong>含义与解读：</strong></p>
<ul>
<li>$P_d$ 越高越好，表示算法的“捕获能力”越强，漏掉真实目标的可能性越小。</li>
<li>在军事侦察、搜救等应用中，$P_d$ 是一个非常关键的指标，因为它直接关系到任务的成功率和安全性。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="虚警率"><a href="#虚警率" class="headerlink" title="虚警率"></a>虚警率</h2><p> Probability of False Alarm, $P_{fa}$ 或 $F_a$</p>
<ul>
<li><p><strong>定义：</strong> 指的是检测算法错误地将背景或非目标物体识别为目标的比例。换句话说，算法报告的所有检测结果中，有多少是错误的。</p>
</li>
<li><p><strong>计算公式：</strong><br>$$<br>P_{fa} &#x3D; \frac{\text{False Positives (FP)}}{\text{False Positives (FP)} + \text{True Negatives (TN)}} &#x3D; \frac{\text{FP}}{\text{Actual Negatives}}<br>$$</p>
<ul>
<li><strong>False Positives (FP，假阳性):</strong> 算法错误地将非目标识别为目标（即误报了）。</li>
<li><strong>True Negatives (TN，真阴性):</strong> 算法正确地将非目标识别为非目标。</li>
<li><strong>Actual Negatives (实际负例):</strong> 数据集中所有真实存在的非目标数量 ($FP + TN$)。</li>
</ul>
</li>
<li><p><strong>含义与解读：</strong></p>
<ul>
<li>$P_{fa}$ 越低越好，表示算法的“识别准确性”越高，误报的可能性越小。</li>
<li>过高的虚警率会导致大量无效警报，增加人工复核的负担，降低系统的实用性。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="精确率"><a href="#精确率" class="headerlink" title="精确率"></a>精确率</h2><p>Precision</p>
<ul>
<li><p><strong>定义：<strong>以</strong>预测结果</strong>为判断依据，<strong>预测为正例的样本中预测正确的比例</strong>。预测为正例的结果分两种，要么实际是正例TP，要么实际是负例FP</p>
</li>
<li><p><strong>计算公式：</strong><br>$$<br>\text{Precision} &#x3D; \frac{\text{TP}}{\text{TP} + \text{FP}}<br>$$</p>
</li>
<li><p><strong>含义与解读：</strong> 关注的是“查得准不准”。高精确率意味着算法报告的检测结果中，<u>错误警报的比例较低</u>。精确度还有一个名字，叫做**“查准率”<strong>，我们关心的主要部分是正例，所以查准率就是相对正例的预测结果而言，正例预测的准确度。直白的意思就是模型预测为正例的样本中，其中真正的正例占预测为正例样本的比例，用此标准来</strong>评估预测正例的准确度**。</p>
</li>
</ul>
<h2 id="召回率"><a href="#召回率" class="headerlink" title="召回率"></a>召回率</h2><p>Recall</p>
<ul>
<li><p><strong>定义：</strong> 召回率就是检测率 $P_d$，只是在机器学习领域更常使用“召回率”这个术语。</p>
</li>
<li><p><strong>计算公式：</strong> 同 $P_d$<br>$$<br>\text{Recall} &#x3D; \frac{\text{TP}}{\text{TP} + \text{FN}}<br>$$</p>
</li>
<li><p><strong>含义与解读：</strong> 关注的是“查得全不全”。高召回率意味着算法能够找到大部分真实目标，很少有漏报。</p>
</li>
</ul>
<h2 id="F1-分数"><a href="#F1-分数" class="headerlink" title="F1 分数"></a>F1 分数</h2><p> F1-score</p>
<ul>
<li><p><strong>定义：</strong> 精确率和召回率的调和平均值。当需要同时考虑精确率和召回率时，F1分数是一个很好的综合指标。</p>
</li>
<li><p><strong>计算公式：</strong><br>$$<br>\text{F1-score} &#x3D;  \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}<br>$$</p>
</li>
<li><p><strong>含义与解读：</strong> F1分数越高，表示算法在精确率和召回率之间取得了更好的平衡。</p>
</li>
</ul>
<h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>Receiver Operating Characteristic Curve</p>
<ul>
<li><strong>定义：</strong> 以 $P_{fa}$（或 False Positive Rate, FPR，即虚警率）为<strong>横轴</strong>，以 $P_d$（或 True Positive Rate, TPR，即召回率）为<strong>纵轴</strong>绘制的曲线。通过改变分类阈值（例如，检测置信度），可以得到一系列的 ($P_{fa}, P_d$) 点。</li>
<li><strong>含义与解读：</strong><ul>
<li>ROC 曲线能直观地展示算法在不同检测阈值下，$P_d$ 和 $P_{fa}$ 之间的权衡关系。</li>
<li>曲线越靠近左上角（即高 $P_d$ 和低 $P_{fa}$），表示算法性能越好。</li>
<li>一条完美的检测算法会通过 (0,1) 点。</li>
<li>对角线表示随机猜测的性能。</li>
</ul>
</li>
</ul>
<h2 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h2><p> (Area Under the ROC Curve)</p>
<ul>
<li><p><strong>定义：</strong> ROC 曲线下方的面积。</p>
</li>
<li><p><strong>含义与解读：</strong></p>
<ul>
<li>AUC 值介于 0 到 1 之间。</li>
<li>AUC 越高，表示算法的整体性能越好，因为它综合考虑了所有可能的阈值下的 $P_d$ 和 $P_{fa}$。</li>
<li>AUC 为 1 表示完美分类器；AUC 为 0.5 表示随机分类器。</li>
</ul>
<p><strong>8. 准确率 Accuracy</strong></p>
<blockquote>
<p><strong>准确度</strong>：正例和负例中预测正确数量占总数量的比例。</p>
</blockquote>
<p>用公式表示：<br>$$<br>ACC&#x3D;\frac{TP+TN}{TP+FP+FN+TN}<br>$$</p>
</li>
</ul>
<hr>
<p><strong>在红外小目标检测中的特殊考虑：</strong></p>
<p>在红外小目标检测中，通常会<strong>非常关注$P_d$和$P_{fa}$</strong>。因为小目标往往数量稀少、特征不明显，背景复杂，检测难度大。</p>
<ul>
<li><strong>高$P_d$</strong> 意味着能有效发现目标，避免漏报；</li>
<li><strong>低$P_{fa}$</strong> 意味着系统不会被大量虚假警报淹没。</li>
</ul>
<p>有时，研究者会绘制 <strong>$P_d$ vs $P_{fa}$ 曲线</strong>，以直观地比较不同算法在不同操作点（即不同的阈值设置）下的性能表现。这种曲线在目标检测领域通常被称为 <strong>Detection Error Tradeoff (DET) curve</strong> 或直接就是 ROC 曲线。</p>
<p>希望这些解释能帮助您更好地理解文章中可能出现的评估指标！</p>
<p>准确度(accuracy)、精确率（precision)、召回率（recall）、F1值</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/blog/2025/09/04/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%95%B4%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>用的都是开源数据集吗</strong></p>
<h1 id="小目标检测方法综述："><a href="#小目标检测方法综述：" class="headerlink" title="小目标检测方法综述："></a>小目标检测方法综述：</h1><ol>
<li><p>样本导向方法：解决样本不足</p>
</li>
<li><p>尺度感知方法：</p>
</li>
</ol>
<ul>
<li>尺度专属检测器：为不同尺度目标设计专门的检测分支</li>
<li>分层特征融合：融合不同层特征，给小目标补全信息</li>
</ul>
<ol start="3">
<li><p>特征模仿方法：GAN</p>
</li>
<li><p>注意力方法（Attention-Based Methods）：解决 “特征噪声”</p>
</li>
<li><p>特征模仿方法（Feature-Imitation Methods）：解决 “小目标特征质量差”</p>
</li>
</ol>
<ul>
<li><strong>相似度学习：强制小目标特征和大目标特征相似</strong></li>
<li><strong>超分辨率重建：把小目标 “放大”，再提取特征</strong></li>
</ul>
<ol start="5">
<li>上下文建模方法（Context-Modeling Methods）：解决 “小目标信息不足”</li>
<li>聚焦检测方法：先粗后精，两步走”。第一步，先用一个轻量级的网络快速地扫描整张图，找到可能包含小目标的“嫌疑区域”（Region Proposal）。第二步，再对这些被筛选出来的“小块”区域进行精细化的、高成本的检测。</li>
</ol>
<h1 id="通用小目标检测算法"><a href="#通用小目标检测算法" class="headerlink" title="通用小目标检测算法"></a>通用小目标检测算法</h1><h2 id="思路-1：提升输入特征分辨率（最直接有效的方法）"><a href="#思路-1：提升输入特征分辨率（最直接有效的方法）" class="headerlink" title="思路 1：提升输入特征分辨率（最直接有效的方法）"></a>思路 1：提升输入特征分辨率（最直接有效的方法）</h2><p>核心逻辑：小目标检测难，本质是 “特征太模糊”，那我们就想办法让特征图变清晰（高分辨率），或者让小目标的特征 “放大”。但要注意：高分辨率会增加计算量，所以算法都在 “精度” 和 “速度” 之间找平衡。</p>
<p>我们来看几种典型算法：</p>
<ol>
<li><p><strong>FPN（特征金字塔网络）</strong>：2017 年的经典模型，至今还在被广泛使用。</p>
<ul>
<li>问题背景：之前的模型（比如 SSD）用 “不同层特征图检测不同尺度目标”，但低层特征图（分辨率高）语义弱（分不清是猫还是狗），高层特征图（语义强）分辨率低（找不到小目标）；</li>
<li>核心操作：“自上而下融合”—— 把高层语义强的特征图通过 “上采样”（放大），和低层分辨率高的特征图融合，这样融合后的特征图 “又有细节又有语义”；</li>
<li>效果：小目标检测精度显著提升，还能保持 6 FPS（每秒处理 6 张图）的速度；</li>
<li>后续改进：PANet、BiFPN、ASFF 这些，都是在 FPN 的基础上优化 “融合方式”，让特征融合更高效。</li>
</ul>
</li>
<li><p><strong>RetinaNet：解决 “前景背景不平衡” 的单阶段模型</strong></p>
<ul>
<li><p>问题背景：之前单阶段模型（比如 YOLO）比两阶段（比如 Faster R-CNN）快，但精度低，因为 “前景少、背景多”—— 一张图里可能只有 1 个小目标（前景），但有几百个背景区域，模型学偏了；</p>
</li>
<li><p>核心创新：提出</p>
<p>Focal Loss（聚焦损失）</p>
<p>，公式如下：</p>
<p>$FL(p)&#x3D;\begin{cases}      -\alpha (1-p)^{\gamma }log(p) &amp; if\ y&#x3D;1 \      -(1-\alpha )p^{\gamma }log(1-p) &amp; otherwise      \end{cases}$</p>
<p>简单解释：</p>
<ul>
<li>(y&#x3D;1)代表 “正样本”（有目标），(y&#x3D;0)是 “负样本”（无目标）；</li>
<li>p是模型预测为正样本的概率：如果p很大（简单背景样本），((1-p)^\gamma)就很小，损失被 “压低”；如果p很小（难样本，比如模糊的小目标），损失被 “放大”；</li>
<li>这样模型就会 “聚焦” 于难样本，而不是在简单背景上浪费精力；</li>
</ul>
</li>
<li><p>效果：第一次让单阶段模型的精度超过两阶段，小目标检测也更准。</p>
</li>
</ul>
</li>
<li><p><strong>超分辨率（Super-Resolution）方法：直接 “放大” 小目标</strong></p>
<ul>
<li>思路：既然小目标像素少，那我们就用算法把它 “放大”，比如用生成对抗网络（GAN）生成高分辨率的小目标特征；</li>
<li>例子：EESRGAN（边缘增强超分 GAN）：<ul>
<li>在普通超分网络（ESRGAN）里加了 “边缘增强子网络（EEN）”，专门优化小目标的边缘细节（比如小车牌的边框、小人脸的轮廓）；</li>
<li>让 “判别器”（判断图像是真实还是生成的）和 “检测器” 一起监督 “生成器”—— 生成器不仅要生成 “看起来真实” 的超分图像，还要让检测器能检测到目标，这样生成的特征更有用；</li>
</ul>
</li>
<li>注意：超分能提升精度，但会增加计算量，比如有的模型速度从 28 FPS 降到 3 FPS，实时场景（比如自动驾驶）用不了。</li>
</ul>
</li>
<li><p><strong>其他优化：减少计算量的小技巧</strong></p>
<ul>
<li>QueryDet：用 “查询机制”—— 先预测小目标可能的位置，只在这些位置上做检测，不用遍历整个高分辨率特征图，推理速度提升不少；</li>
<li>HRDNet：多分辨率输入 —— 高分辨率图像进 “浅层网络”（保位置细节），低分辨率图像进 “深层网络”（提语义），最后融合，既保精度又控计算。</li>
</ul>
</li>
</ol>
<h4 id="思路-2：尺度感知训练（让模型-“认识”-不同大小的目标）"><a href="#思路-2：尺度感知训练（让模型-“认识”-不同大小的目标）" class="headerlink" title="思路 2：尺度感知训练（让模型 “认识” 不同大小的目标）"></a>思路 2：尺度感知训练（让模型 “认识” 不同大小的目标）</h4><p>核心逻辑：小目标和大目标的尺度差异太大（COCO 里最大目标是最小目标的 20 倍），CNN 的 “尺度不变性” 不好（比如学了检测大猫，就检测不了小猫）。所以我们要让模型 “主动适应” 不同尺度，尤其是小尺度。</p>
<p>典型算法：</p>
<ol>
<li><strong>SNIP 和 SNIPER：优化图像金字塔训练</strong><ul>
<li>图像金字塔：把一张图缩放成多个尺度（比如 800×800、1000×1000、1200×1200），分别训练，让模型见多识广；</li>
<li>问题：全尺度训练内存不够；</li>
<li>SNIP：只对 “目标尺寸在预定范围” 的样本计算损失（比如小目标只在小尺度金字塔上训练），其他尺度的损失不反向传播，减少计算；</li>
<li>SNIPER：更极端，从每个金字塔层选 512×512 的 “芯片”（小块图像）训练，batch size 能更大，效率更高。</li>
</ul>
</li>
<li><strong>TridentNet（三叉戟网络）：多分支适配不同尺度</strong><ul>
<li>结构：3 个并行分支，每个分支用不同的 “膨胀率”（dilation rate）—— 膨胀率越大，感受野（卷积核能看到的原图区域）越大；</li>
<li>逻辑：小目标用小感受野分支，大目标用大感受野分支，每个分支只训练对应尺度的目标（公式(l_i \leq \sqrt{wh} \leq u_i)，(\sqrt{wh})是目标尺寸，(l_i、u_i)是分支的尺度范围）；</li>
<li>好处：避免小目标被大感受野 “淹没”（比如感受野是 200×200，小目标是 20×20，就像用大网捞小鱼，捞不到）。</li>
</ul>
</li>
</ol>
<h4 id="思路-3：融入上下文信息（“借周围环境判断”）"><a href="#思路-3：融入上下文信息（“借周围环境判断”）" class="headerlink" title="思路 3：融入上下文信息（“借周围环境判断”）"></a>思路 3：融入上下文信息（“借周围环境判断”）</h4><p>核心逻辑：小目标自身特征弱，但它的 “周围环境” 能提供线索 —— 比如 “马路上的小矩形” 大概率是车牌，“天空中的小亮点” 可能是飞机。所以我们要让模型利用 “上下文信息” 辅助检测。</p>
<p>上下文分两类：<strong>图像级上下文</strong>（全图环境）和<strong>实例级上下文</strong>（目标间的关系），典型算法：</p>
<ol>
<li><strong>ION（内外网）：利用 ROI 内外信息</strong><ul>
<li>ROI（感兴趣区域）内：用 “skip pooling” 提取多尺度特征（比如小目标的局部细节）；</li>
<li>ROI 外：用 “空间 RNN” 提取周围环境特征（比如小目标旁边的树、路），融合后提升检测精度。</li>
</ul>
</li>
<li><strong>SMN（空间记忆网络）：记住已检测目标，帮找漏检的</strong><ul>
<li>逻辑：小目标常被遮挡或扎堆（比如人群里的小脸），第一次检测可能漏检；</li>
<li>操作：检测到一个目标后，“记住” 它的位置和特征，下次检测时，用这个已检测目标作为 “先验”，推断周围可能有同类小目标（比如检测到一个行人，周围可能还有其他行人），减少漏检。</li>
</ul>
</li>
<li><strong>FA-SSD：结合上下文和注意力</strong><ul>
<li>F-SSD：把高层语义特征（上下文，比如 “这是街道场景”）和低层特征（小目标细节）拼接；</li>
<li>A-SSD：用注意力机制 “屏蔽” 背景无用特征（比如街道上的杂草），只关注可能有小目标的区域；</li>
<li>效果：比普通 SSD 的小目标检测精度提升 10% 左右。</li>
</ul>
</li>
</ol>
<h4 id="思路-4：数据增强（“造更多小目标样本”）"><a href="#思路-4：数据增强（“造更多小目标样本”）" class="headerlink" title="思路 4：数据增强（“造更多小目标样本”）"></a>思路 4：数据增强（“造更多小目标样本”）</h4><p>核心逻辑：小目标数据集少，标注贵，那我们就 “人造” 样本 —— 通过各种方法增加小目标的多样性，让模型见得多、学得好。</p>
<p>传统数据增强（比如旋转、裁剪）对中大型目标有效，但对小目标没用（旋转 20×20 的小目标，可能就糊了），所以研究者设计了针对小目标的增强方法：</p>
<ol>
<li><strong>过采样和自适应粘贴（Kisantal 等人 &amp; RRNet）</strong><ul>
<li>Kisantal 等人：发现 COCO 里 “含小目标的图像” 只占少数，所以 “过采样” 这些图像（比如重复用 10 次），还把小目标 “复制粘贴” 到其他图像里；</li>
<li>问题：复制粘贴会导致 “背景不匹配”（比如把小车牌贴到草地上，不合理）；</li>
<li>RRNet：用语义分割网络先 “标出图像里的合理区域”（比如车牌只能在汽车上），再把小目标粘贴到这些区域，解决背景不匹配问题。</li>
</ul>
</li>
<li><strong>切片增强（Ünel 等人）</strong><ul>
<li>操作：把一张大图像分成多个重叠的 “切片”（比如把 1000×1000 的图切成 5 个 512×512 的切片，重叠部分 200 像素）；</li>
<li>好处：小目标在切片里的 “相对像素面积” 变大了（比如 20×20 的小目标在 1000×1000 图里占 0.04%，在 512×512 切片里占 0.15%），模型更容易学到特征。</li>
</ul>
</li>
<li><strong>动态尺度训练（DST）</strong><ul>
<li>思路：用 “小目标的损失比例” 当反馈 —— 如果模型在小目标上的损失太小（说明没学好），下次训练就把图像 “放大拼接”（比如把两张 800×800 的图拼成 1600×800），增加小目标的占比，强迫模型学小目标。</li>
</ul>
</li>
</ol>
<h4 id="补充：其他有用的小技巧"><a href="#补充：其他有用的小技巧" class="headerlink" title="补充：其他有用的小技巧"></a>补充：其他有用的小技巧</h4><p>除了上述 4 种思路，还有一些针对性优化：</p>
<ul>
<li><strong>用新指标代替 IoU</strong>：IoU（交并比）对小目标的位置偏差特别敏感 —— 比如小目标框偏了 1 个像素，IoU 可能从 0.8 降到 0.2，导致模型误判。所以有人提出 NWD（归一化高斯 Wasserstein 距离），把框当成高斯分布，用分布相似度代替 IoU，对小目标更友好；</li>
<li><strong>无锚点模型（CenterNet++）</strong>：传统模型用 “锚点”（预设的框）匹配目标，小目标难匹配（锚点比小目标大太多）。CenterNet++ 用 “中心点 + 两个角点” 表示目标，不用锚点，更适合小目标；</li>
<li><strong>SAHI（切片推理）</strong>：推理时把图像切成切片，分别检测，再合并结果，不用改模型，直接提升小目标检测精度（比如在遥感图上，小目标 AP 提升 8%）。</li>
</ul>
<h1 id="方向"><a href="#方向" class="headerlink" title="方向"></a>方向</h1><p><span style="color:#FF0000">方向 1：设计专为小目标优化的特征提取器（Effective Feature Extractor for Small Objects）</span></p>
<ul>
<li><strong>低下采样率架构</strong>：通过 “空洞卷积（Dilated Convolution）”“转置卷积（Transposed Convolution）” 等技术，在不增加计算量的前提下降低下采样率，保留小目标细节；</li>
<li><strong>多尺度特征对齐</strong>：让提取器在不同深度自动对齐小目标的 “细节特征” 与 “语义特征”，避免传统架构中 “低层细节足但语义弱、高层语义强但细节丢” 的矛盾；</li>
<li><strong>轻量化设计</strong>：小目标检测常需部署于边缘设备（如自动驾驶车载终端、无人机），需在 “特征提取能力” 与 “计算效率” 间平衡，避免模型过大导致实时性不足。</li>
</ul>
<p><span style="color:#FF0000">方向 2：改进特征金字塔的高质量分层特征表示（High-Quality Hierarchical Representation）</span></p>
<ul>
<li><strong>适应尺度分配</strong>：让网络根据目标的实际尺寸自动选择 “最优金字塔层”，而非人工设定，确保每一层特征都能被小目标充分利用；</li>
<li><strong>跨层特征蒸馏</strong>：将高层的语义信息 “蒸馏” 到低层，同时将低层的细节信息 “传递” 到高层，实现 “全层特征为小目标服务”，避免高层特征浪费；</li>
<li><strong>动态特征选择</strong>：检测时仅激活 “含小目标概率高的金字塔层”，而非全层检测，降低计算量（如小目标密集区域激活 P2 层，大目标区域激活 P5 层）。</li>
</ul>
<p><span style="color:#FF0000">方向 3：优化小目标的标签分配策略（Optimized Label Assignment Strategy）</span></p>
<ul>
<li><strong>多因素融合匹配</strong>：不再依赖单一的 IoU 或距离，而是结合 “目标尺寸、中心距离、上下文信息、类别样本量” 多维度判断正样本（如极小小目标降低 IoU 阈值，同时参考其与相邻目标的上下文关联）；</li>
<li><strong>动态阈值调整</strong>：根据类别样本量动态调整正样本阈值（如少样本类别降低阈值，多样本类别提高阈值），缓解类别不均衡导致的正样本分配偏差；</li>
<li><strong>正样本质量筛选</strong>：在增加正样本数量的同时，通过 “特征质量评分” 筛选低质量正样本（如背景区域），避免噪声干扰训练。</li>
</ul>
<p><span style="color:#FF0000">方向 4：设计更适合 SOD 的评估指标（Proper Evaluation Metric for SOD）</span></p>
<ul>
<li><strong>动态 IoU 阈值</strong>：根据目标尺寸调整 IoU 阈值（如 eS 级小目标用 IoU≥0.3，gS 级用 IoU≥0.5），避免对小目标的过度严苛；</li>
<li><strong>召回率加权 AP</strong>：在重视定位精度的同时，对 “召回率” 赋予更高权重（如搜救场景），或根据场景需求动态调整权重，让指标更贴合实际应用；</li>
<li><strong>极小小目标专项指标</strong>：单独设计 “极小小目标召回率（RecallₑS）”“极小小目标定位误差（LocErrₑS）” 等指标，精准评估算法对最难场景的适配性。</li>
</ul>
<h4 id="2-未来研究方向（值得做的选题）"><a href="#2-未来研究方向（值得做的选题）" class="headerlink" title="2. 未来研究方向（值得做的选题）"></a>2. 未来研究方向（值得做的选题）</h4><ol>
<li><strong>弱监督 &#x2F; 无监督 SOD</strong>：全监督需要大量 bounding box 标注，成本太高。弱监督只用 “图像级标签”（比如标 “这张图有小行人”，不用标位置），无监督 &#x2F; 自监督（比如对比学习）不用任何标注，是未来的热点；</li>
<li><strong>设计 SOD 专用指标</strong>：目前的指标都是从普通目标检测沿用的，需要一个能 “公平衡量小目标检测性能” 的指标（比如结合位置偏差和尺度差异）；</li>
<li><strong>多任务联合优化</strong>：把 SOD 和超分、语义分割、目标跟踪结合 —— 比如超分提供高分辨率特征，语义分割提供上下文，联合训练可能比单独训练效果好；</li>
<li><strong>开放世界 &#x2F; 少样本 SOD</strong>：现实中会遇到 “没见过的小目标”（比如模型学了检测小车牌，突然遇到小井盖），开放世界 SOD 要让模型能 “识别未知小目标” 并 “增量学习”；少样本 SOD 则是用 10-50 个标注样本就能训练出好模型，解决标注成本问题。</li>
</ol>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<p><span style="color:#FF0000"></span></p>
<h1 id="红外目标检测"><a href="#红外目标检测" class="headerlink" title="红外目标检测"></a>红外目标检测</h1><h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><table>
<thead>
<tr>
<th>传统方法类别</th>
<th>核心思路</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>滤波与背景抑制</td>
<td>用滤波器（如中值滤波）或背景模型（如红外块模型）过滤背景，保留目标</td>
<td>计算简单、速度快</td>
<td>只能处理<strong>均匀背景</strong>（比如纯天空），复杂背景（多云、城市）里漏检 &#x2F; 虚警高</td>
</tr>
<tr>
<td>视觉对比度方法</td>
<td>模拟人眼：目标和周围像素的对比度高，据此构建显著性图，分割目标</td>
<td>实现简单</td>
<td>容易被背景中的 “强边缘”（如建筑物边缘、云边界）干扰，误把边缘当目标</td>
</tr>
<tr>
<td>低秩模型方法</td>
<td>把红外图像拆成 “低秩背景” 和 “稀疏目标”（背景有规律性，目标是零散的）</td>
<td>能分离背景和目标</td>
<td>计算慢（张量分解耗时），暗目标场景下虚警率高</td>
</tr>
</tbody></table>
<h2 id="深度学习方法"><a href="#深度学习方法" class="headerlink" title="深度学习方法"></a>深度学习方法</h2><h3 id="单帧检测（SIRST）：解决-“小目标特征丢失”-问题"><a href="#单帧检测（SIRST）：解决-“小目标特征丢失”-问题" class="headerlink" title="单帧检测（SIRST）：解决 “小目标特征丢失” 问题"></a>单帧检测（SIRST）：解决 “小目标特征丢失” 问题</h3><h4 id="全监督学习：分-“检测型”-和-“分割型”"><a href="#全监督学习：分-“检测型”-和-“分割型”" class="headerlink" title="全监督学习：分 “检测型” 和 “分割型”"></a>全监督学习：分 “检测型” 和 “分割型”</h4><ul>
<li><strong>检测型</strong>：输出目标的 bounding box（边界框），类似 YOLO；</li>
</ul>
<p>代表方法：<strong>YOLO-FR（Mou et al., 2023）</strong>—— 基于 YOLOv5 改进，核心是 “特征重组采样”，避免目标丢失：</p>
<ul>
<li><p>下采样改进：用 “时空下采样块（STD Block）”—— 下采样时把空间信息 “转移” 到通道维度，不丢小目标特征；</p>
</li>
<li><p>上采样改进：用 “CARAFE 算子”—— 基于区域内容的上采样（不是简单插值），能还原目标细节；</p>
</li>
<li><p>新增小目标检测头：减小感受野（感受野是网络能 “看到” 的图像范围，小目标需要小感受野）。<br>实验效果：在红外飞机数据集上，精度 97%，召回 95.4%，mAP50（IoU&#x3D;0.5 时的平均精度）97.4%—— 比原始 YOLOv5 提升明显。</p>
</li>
<li><p><strong>分割型</strong>：输出像素级的 “目标掩码”（区分每个像素是目标还是背景），精度更高，是当前主流。</p>
</li>
</ul>
<p>① 注意力机制：让网络 “聚焦” 目标区域</p>
<p>② 生成对抗网络（GAN）：让生成器 “学会” 区分目标与背景</p>
<p>③ 视觉 Transformer（ViT）：捕捉长距离依赖，处理复杂背景</p>
<p>④ 模型驱动 + 数据驱动融合：结合传统模型的 “先验知识” 和深度学习的 “自动学习”</p>
<p>⑤ 轻量化网络：适配嵌入式设备（如机载传感器）</p>
<h4 id="弱监督学习：减少-“标注成本”"><a href="#弱监督学习：减少-“标注成本”" class="headerlink" title="弱监督学习：减少 “标注成本”"></a>弱监督学习：减少 “标注成本”</h4><h3 id="多帧检测（MIRST）：深度学习-时空信息，降虚警"><a href="#多帧检测（MIRST）：深度学习-时空信息，降虚警" class="headerlink" title="多帧检测（MIRST）：深度学习 + 时空信息，降虚警"></a>多帧检测（MIRST）：深度学习 + 时空信息，降虚警</h3><h3 id="总结与未来方向：这个领域还能怎么发展？"><a href="#总结与未来方向：这个领域还能怎么发展？" class="headerlink" title="总结与未来方向：这个领域还能怎么发展？"></a>总结与未来方向：这个领域还能怎么发展？</h3><p>这篇综述的贡献很明确：梳理了 12 个数据集、近三年的核心网络、完整的指标体系，给研究者提供了 “全景图”。但领域还有很多待解决的问题，文献提出了 5 个未来方向，我们逐个理解：</p>
<ol>
<li><strong>需要更大规模、更多样的数据集</strong><ul>
<li>现状：真实数据集少，极端场景（如极低辐射目标、强干扰背景）的数据更少；多是单帧图像，视频序列数据少（视频能提供运动信息，利于跟踪）。</li>
<li>未来：建立 “工程级视频数据集”，细分背景类别（如 “海雾”“城市雾霾”），补充极端场景数据。</li>
</ul>
</li>
<li><strong>改进数据集标注质量</strong><ul>
<li>现状：手动标注小目标容易错（比如漏标 1 个像素的目标），且没考虑 “大气干扰、光学系统误差”（这些会影响真实检测效果）。</li>
<li>未来：开发自动标注工具，标注时加入物理误差（如大气衰减），同时设计算法修正错标数据。</li>
</ul>
</li>
<li><strong>传统方法与深度学习的深度融合</strong><ul>
<li>现状：目前只是 “简单结合”（如把局部对比度当模块嵌入网络），没有真正融合两者的优势（传统方法的可解释性、深度学习的泛化能力）。</li>
<li>未来：比如用传统方法的 “低秩背景建模” 指导深度学习的特征提取，让网络既会自动学习，又能 “理解” 为什么这么学。</li>
</ul>
</li>
<li><strong>多模态融合检测</strong><ul>
<li>现状：单波段红外图像缺少颜色、纹理、距离信息，复杂场景下容易误判。</li>
<li>未来：结合多光谱（如红外 + 可见光）、多探测器（如红外 + 雷达）、距离信息（如激光雷达），让网络获得更全面的目标信息 —— 比如 “红外看到小亮点，雷达确认是移动目标，可见光看到是无人机，三者结合就不会误判成云”。</li>
</ul>
</li>
<li><strong>平衡实时性与精度</strong><ul>
<li>现状：高精度网络都复杂（如 DNA-Net），轻量网络精度又不够（如早期轻量网）。</li>
<li>未来：用 “结构重参数化”“量化压缩”“硬件定制加速”（如 ST-Net 设计专用加速器）等方法，让轻量网络也能达到高精度。</li>
</ul>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>研究方向总结规划</title>
    <url>/blog/2025/09/17/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E6%80%BB%E7%BB%93%E8%A7%84%E5%88%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>用transformer做小目标检测</p>
<p>红外与可见光融合做小目标检测</p>
]]></content>
  </entry>
  <entry>
    <title>机电一体化分析与建模（5-6章）</title>
    <url>/blog/2025/06/29/%E6%9C%BA%E7%94%B5%E4%B8%80%E4%BD%93%E5%8C%96%E5%88%86%E6%9E%90%E4%B8%8E%E5%BB%BA%E6%A8%A1%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="第五章-微机测控系统设计"><a href="#第五章-微机测控系统设计" class="headerlink" title="第五章 微机测控系统设计"></a>第五章 微机测控系统设计</h1><ol>
<li><strong>微机测控系统的硬件</strong></li>
</ol>
<p>按各部分在系统中的作用,该系统可分为</p>
<ul>
<li><strong>主机</strong></li>
<li><strong>输入输出通道</strong>：过程输入输出通道，又称过程通道。是微机与外部物理世界建立信息传递与转换的<u>链接渠道</u></li>
<li>常规外部设备</li>
<li><strong>接口电路：在过程通道与外部设备间，接口电路起着媒介作用，使主机与过程通道及外部</strong><br><strong>设备之间的<u>信息交换</u>得以顺利实现</strong></li>
<li>运行操作台</li>
<li>系统总线等</li>
</ul>
<ol start="2">
<li><p><strong>测控系统软件组成</strong></p>
<p>软件通常分为两大类，一类是<u>系统软件</u>，另一类为<u>应用软件</u></p>
</li>
<li><p><strong>模拟量输入通道的一般组成</strong></p>
<p>一般由<u>信号调理电路</u>、<u>多路转换器</u>、<u>放大器</u>和<u>模／数转换器</u>组成</p>
</li>
</ol>
<p><img src="/blog/./image/Snipaste_2025-06-29_14-52-43.png"></p>
<p>显然，该通道中的<span style="color:#FF0000">核心</span>是模&#x2F;数转换器，也就是<strong>A&#x2F;D转换器</strong><br>通常把模拟量输入通道称为<strong>A&#x2F;D通道</strong></p>
<blockquote>
<p><strong>采样-保持器作用 &#x2F; 为什么使用采样-保持器 &#x2F; 采样-保持器原理？</strong></p>
<p>当被测信号变化较快时,要求通道也能及时反应,而模<u>&#x2F;数转换需要一定的时间才能完成</u>｡</p>
<p>如在转换过程中模拟输入发生显著变化,使得转换得到的数字量不能真正代表发出命令的那一瞬间所要转换的数据电平｡为了克服这一缺点,在模&#x2F;数转换器前面往往采用一个采样-保持器｡</p>
<p>（<strong>PPT版</strong>：当某一通道进行A&#x2F;D转换时，由于A&#x2F;D转换需要一定的时间，如果输入信号变化较快，就会引起较大的转换误差。为了保证A&#x2F;D转换的精度，需要应用采样保持器。）</p>
<p><strong>采样-保持器对变化的模拟信号进行快速“采样”,并在转换过程中“保持”该信号｡</strong></p>
</blockquote>
<blockquote>
<p><strong>放大器作用？</strong></p>
<p>为使模&#x2F;数转换达到应有的<strong>精度</strong>,需将各路传感器来的信号放大到模&#x2F;数转换器所要求的输入电平值(如满度为10V或5V)</p>
<ul>
<li><p>当所用的传感器很多时,可多路共用一个放大器｡</p>
</li>
<li><p>如果各路信号要求的放大倍数不同,则可设计一个可编程的放大器,由计算机控制它的闭环增益｡</p>
</li>
</ul>
</blockquote>
<blockquote>
<p>采样保持器和放大器背诵时都关于<strong>精度</strong></p>
</blockquote>
<h2 id="多路转换器"><a href="#多路转换器" class="headerlink" title="多路转换器"></a>多路转换器</h2><p><span style="color:#FF0000">多路转换器又称多路开关，利用它可将各个输入信号<strong>依次</strong>或<strong>随机</strong>地接到公用放大器或模／数转换器上  </span></p>
<ul>
<li>应用</li>
</ul>
<p>目前，计算机控制系统使用的多路开关种类很多，(<strong>多为集成多路电子开关</strong>)并具有不同的功能和用途。</p>
<p>如集成电路芯片CD4051(双向、单端、8路)、CD4052(单向、双端、4路)、AD7506(单向、单端、16路)等。</p>
<blockquote>
<p><strong>双向</strong>:就是芯片既可以实现多到一的切换，也可以完成一到多的切换；</p>
<p><strong>单向</strong>:只能完成多到一的切换。<br><strong>双端</strong>:是指芯片内的一对开关同时动作，从而完成<strong>差动输入信号</strong>的切换，以满足抑制共模干扰的需要。</p>
</blockquote>
<h3 id="CD4051结构原理"><a href="#CD4051结构原理" class="headerlink" title="CD4051结构原理"></a>CD4051结构原理</h3><p><img src="/blog/./image/Snipaste_2025-06-29_15-51-48.png"></p>
<ul>
<li><p>CD4051就是一种单端8通道多路开关，它带有<strong>三个输入端A、B、C</strong>，和一个<strong>禁止输入端INH。</strong></p>
</li>
<li><p>从A、B、C输入的信号来选择8个通道中的一个。</p>
</li>
<li><p>当INH&#x3D;1时，通道断开，禁止模拟量输入；当INH&#x3D;0时，通道接通，允许模拟量输入，通过改变输入端C、B、A的值，就可以选通S0~S7中的一路通道。</p>
</li>
</ul>
<p><strong>CD4051工作过程</strong></p>
<ul>
<li>INH输入为0时，译码器正常工作，此时若<br>C&#x3D;0, B&#x3D;0, A&#x3D;0, 译码器Y0端输出1，通道S0接通。<br>C&#x3D;0, B&#x3D;0, A&#x3D;1, 译码器Y1端输出1，通道S1接通。<br>C&#x3D;0, B&#x3D;1, A&#x3D;0, 译码器Y2端输出1，通道S2接通。<br>C&#x3D;0, B&#x3D;1, A&#x3D;1, 译码器Y3端输出1，通道S3接通。<br>C&#x3D;1, B&#x3D;0, A&#x3D;0, 译码器Y4端输出1，通道S4接通。<br>C&#x3D;1, B&#x3D;0, A&#x3D;1, 译码器Y5端输出1，通道S5接通。<br>C&#x3D;1, B&#x3D;1, A&#x3D;0, 译码器Y6端输出1，通道S6接通。<br>C&#x3D;1, B&#x3D;1, A&#x3D;1, 译码器Y7端输出1，通道S7接通。</li>
</ul>
<blockquote>
<p><span style="color:#FF0000"><strong>多路开关注意事项</strong></span>(简答题)</p>
<ul>
<li><p>在自动数据采集中，应选用“<strong>先断后通</strong>”的多路开关，否则，就会发生<strong>两个通道短接</strong>的现象，严重时会损坏信号源或多路开关自身。  </p>
</li>
<li><p>然而，在程控增益放大器中，若用多路开关来改变集成运算放大器的反馈电阻，以改变放大器的增益，就不宜选用“先断后通”的多路开关。否则，放大器就会出现<strong>开环状态</strong>。放大器的开环增益极高，易破坏电路的正常工作，甚至损坏元器件，一般应予避免</p>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>应用场景</strong></th>
<th>对多路开关的需求</th>
<th>原因</th>
</tr>
</thead>
<tbody><tr>
<td>普通信号通道切换</td>
<td>需 “先断后通”（避免通道短路）</td>
<td>通道短接，损坏信号源</td>
</tr>
<tr>
<td>程控增益放大器</td>
<td>需 “先通后断”（避免反馈断裂）</td>
<td>反馈断裂会导致运放开环，损坏电路</td>
</tr>
</tbody></table>
</blockquote>
<blockquote>
<p><strong>差动输入的CD4051</strong></p>
<p><img src="/blog/./image/Snipaste_2025-06-29_16-21-40.png"></p>
<p><span style="color:#FF0000">备注</span>：</p>
<ul>
<li><p>$D_0D_1D_2D_3$与$Q_3Q_0Q_1Q_2$是一一对应的。</p>
</li>
<li><p>$$<br> D_0\leftrightarrow Q_3,D_1\leftrightarrow Q_0,D_2\leftrightarrow Q_1,D_3\leftrightarrow Q_2<br> $$</p>
</li>
</ul>
<p> 例如CPU总线输出1100，$Q_3Q_0Q_1Q_2$为1100</p>
<ul>
<li><p>$Q_3$为1时：0号和1号的INH&#x3D;1，<strong>通道断开</strong>，$Q_3$经非门后，2号和3号的INH&#x3D;0，<strong>通道接通</strong></p>
</li>
<li><p>$Q_0 \quad Q_1 \quad Q_2$分别连接$A \quad B \quad C$</p>
</li>
</ul>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p><img src="/blog/../image/IMG_20250628_182022.jpg"></p>
<p><img src="/blog/./image/IMG_20250628_182102.jpg"></p>
</blockquote>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><p>（1）试设计虚线框内16通道差动输入CD4051电路图，设2号和3号CD4051芯片的X1通道为差动输入第9通道</p>
<p>（2）试分析CPU数据总线D0～D3数字位应输入信号值?</p>
<p><img src="/blog/./image/IMG_0197.jpg"></p>
<h2 id="采样保持器"><a href="#采样保持器" class="headerlink" title="采样保持器"></a>采样保持器</h2><p><span style="color:#FF0000">当某一通道进行A&#x2F;D转换时，由于A&#x2F;D转换需要一定的时间，如果输入信号变化较快，就会引起较大的转换误差。为了保证A&#x2F;D转换的精度，需要应用采样保持器。</span></p>
<h3 id="采样器常用术语"><a href="#采样器常用术语" class="headerlink" title="采样器常用术语"></a>采样器常用术语</h3><p>① 采样器（采样开关）：执行采样动作的装置。<br>② 采样时间（采样宽度 $\tau$）：采样开关每次闭合的时间。<br>③ 采样周期 $T$：采样开关每次通断的时间间隔。</p>
<h3 id="采样-保持器原理"><a href="#采样-保持器原理" class="headerlink" title="采样-保持器原理"></a>采样-保持器原理</h3><p><strong>采样保持器在两次采样的间隔时间内，一直保持采样值不变直到下一个采样时刻。</strong></p>
<p><strong>构成：</strong></p>
<p>采样保持器由输入输出放大器<strong>A1</strong>、<strong>A2</strong>和采样开关<strong>S</strong>、保持电容**$C_H$**等组成。</p>
<p><span style="color:#FF0000">图要会画：①电压跟随器：同相端输入，反相端接输出②符号：</span></p>
<p><img src="/blog/./image/Snipaste_2025-06-30_08-35-22.png"></p>
<p><strong>原理：</strong></p>
<ol>
<li><p>采样期间，开关S闭合，输入电压$V_{IN}$通过A1对$C_H$快速充电，输出电压$V_{OUT}$跟随$V_{IN}$变化；</p>
</li>
<li><p>保持期间，开关S断开，由于A2的输入阻抗很高，理想情况下电容CH将保持电压$V_{CH}$不变，因而输出电压$V_{OUT}$&#x3D;$V_{CH}$也保持恒定。</p>
</li>
</ol>
<h3 id="两项指标"><a href="#两项指标" class="headerlink" title="两项指标"></a>两项指标</h3><ul>
<li><strong>捕获时间</strong>定义: <u>跟随输入信号</u>到达所规定的的<u>百分比误差</u>之内需要的<strong>最小时间</strong>。</li>
</ul>
<p>捕获时间主要是<u>电容器充电时间常数</u>、<u>放大器摆率</u>及<u>建立时间</u>的函数。</p>
<ul>
<li><p><strong>电压下降率</strong>定义: 为<strong>保持阶段</strong>存储电容的<strong>放电速度</strong>。</p>
<p>它是<u>电容的容量</u>、<u>漏电阻</u>、<u>缓冲放大器的输入电阻</u>及<u>开关的断开电阻</u>的函数。</p>
</li>
</ul>
<hr>
<ul>
<li><strong>注摆率</strong>: <u>运算放大器输出电压的转换速率,</u> 它反映的是一个运算放大器在速度方面的指标, 表示<u>运放对信号变化速度的适应能力</u>, 单位有通常有V&#x2F;s, V&#x2F;ms和V&#x2F;µs三种。</li>
</ul>
<h3 id="转换精度"><a href="#转换精度" class="headerlink" title="转换精度"></a>转换精度</h3><p>A&#x2F;D转换器的转换精度可以用绝对误差和相对误差来表示。</p>
<ul>
<li><p><strong>绝对误差</strong>: 是指对应于一个给定数字量A&#x2F;D转换器的误差，其误差的大小由<strong>实际模拟量输入值和理论值之差</strong>来度量。绝对误差包括增益误差，零点误差和非线性误差等。</p>
</li>
<li><p><strong>相对误差</strong>: 指<strong>绝对误差与满刻度值之比</strong>，一般用百分数来表示，对A&#x2F;D转换器常用最低有效值的位数LSB (Least Significant Bit)) 来表示，$1 \mathrm{LSB} &#x3D; 1&#x2F;2^n$。</p>
</li>
</ul>
<h3 id="模数转换器接口"><a href="#模数转换器接口" class="headerlink" title="模数转换器接口"></a>模数转换器接口</h3><p>集成A&#x2F;D转换芯片都具有如下功能引脚：<strong>数据输出</strong>、<strong>启动转换</strong>（输入）、<strong>转换结束</strong>（输出）。</p>
<h4 id="连接A-D芯片时，注意事项"><a href="#连接A-D芯片时，注意事项" class="headerlink" title="连接A&#x2F;D芯片时，注意事项"></a>连接A&#x2F;D芯片时，注意事项</h4><p><span style="color:#FF0000">①  A&#x2F;D芯片能否与微处理机总线直接兼容：</span></p>
<p>所谓直接兼容是指A&#x2F;D芯片的<u>数据输出线</u>可以直接挂在<u>CPU的数据总线</u>上。这不仅要求A&#x2F;D芯片的数据输出具有TTL电平，更重要的是要求A&#x2F;D芯片的数据输出寄存器具有可控的<strong>三态</strong>输出功能。（三态包含 <strong>高电平（逻辑 1）、低电平（逻辑 0）、高阻态（浮空态，记为 Z）</strong>）</p>
<p><span style="color:#FF0000">②  启动A&#x2F;D转换的方式：</span></p>
<p>A&#x2F;D转换电路需要外加启动转换信号才能开始工作，这一信号往往由CPU给出。一般有<u>脉冲启动信号及电平控制信号</u>两种形式。通常用CPU的$\overline{WR}$或$\overline{RD}$信号、地址译码器的输出信号等直接控制A&#x2F;D转换器的启动转换端。</p>
<p><span style="color:#FF0000">③  转换结束信号的应用方式：</span></p>
<p>A&#x2F;D转换结束时，A&#x2F;D芯片输出一个转换结束标志电平，通知CPU读取转换结果数据（即控制EOC端）。</p>
<h2 id="8位A-D转换器与微机接口设计"><a href="#8位A-D转换器与微机接口设计" class="headerlink" title="8位A&#x2F;D转换器与微机接口设计"></a>8位A&#x2F;D转换器与微机接口设计</h2><h3 id="text-ADC0809-管脚"><a href="#text-ADC0809-管脚" class="headerlink" title="$$\text{ADC0809 管脚}$$"></a>$$\text{ADC0809 管脚}$$</h3><ul>
<li><p><strong>EOC</strong>:转换结束信号。当 A&#x2F; D 转换完毕之后发出一个正脉冲，表示 A&#x2F; D 转换结束，此信号可用作 A&#x2F; D 转换是否结束的检测信号或中断申请信号(加一个反相器)。(<strong>转换结束后输出高电平</strong>)</p>
</li>
<li><p>OUTPUT ENABLE(<strong>OE</strong>):输出允许信号，当此信号被选中时，允许从A&#x2F;D 转换器锁存器中读取数字量，此信号即为 ADC0809 片选信号，<strong>高电平有效</strong>。</p>
</li>
</ul>
<h3 id="text-ADC0809-转换器与微机接口硬件电路设计"><a href="#text-ADC0809-转换器与微机接口硬件电路设计" class="headerlink" title="$$\text{ADC0809 转换器与微机接口硬件电路设计}$$"></a>$$\text{ADC0809 转换器与微机接口硬件电路设计}$$</h3><p><img src="/blog/./image/Snipaste_2025-06-30_10-40-44.png"></p>
<blockquote>
<p>可以把 <strong>ADC0809 与单片机的交互过程</strong> 拆解为 <strong>“启动转换→转换过程→读取结果”</strong> 三个阶段</p>
<p>**一、阶段 1：启动转换（写操作，对应 **<code>P2.3 + WR</code><strong>低电平</strong>)</p>
<ul>
<li><p><code>P2.3</code>：单片机的<strong>片选信号</strong>（选中 ADC0809 芯片）。</p>
</li>
<li><p><code>WR</code>：单片机的<strong>写信号</strong>（表示当前是 “写操作”，向 ADC 发命令）。</p>
</li>
<li><p><code>ALE</code>（地址锁存允许）：把单片机地址总线中的 <code>C、B、A</code> 信号**（低 3 位，用于选择 ADC 的 8 个通道，如 <code>C=0,B=0,A=0</code> 选 <code>IN0</code> 通道）**锁存到 ADC 内部，避免地址变化影响通道选择。</p>
</li>
<li><p><code>START</code>（启动转换）：触发 ADC 开始工作。</p>
</li>
</ul>
<p> <span style="color:#FF0000">硬件动作</span>：</p>
<p> 当 <code>P2.3</code> 和 <code>WR</code> <strong>同时为低电平时</strong>：ADC0809 检测到这两个信号，使 <code>ALE</code> 和 <code>START</code> 有效。<code>ALE</code> 先锁存 <code>C、B、A</code>，选定要采集的模拟通道（比如温度传感器接 <code>IN3</code>，则 <code>C=0,B=1,A=1</code>）。<code>START</code> 随后产生<strong>下降沿</strong>（从高变低），正式启动 <strong>逐次逼近转换</strong>（ADC 的核心工作模式）。</p>
<p><strong>二、阶段 2：转换过程（逐次逼近，</strong><code>EOC</code><strong>低电平</strong>）</p>
<blockquote>
<p>ADC 内部有一个 <strong>逐次逼近寄存器（SAR）</strong>，像 “猜数字游戏” 一样<strong>从最高位到最低位逐位尝试</strong></p>
</blockquote>
<ul>
<li><p><code>START</code> 下降沿后，<code>EOC</code>（转换结束信号）立即<strong>变低电平</strong>（表示 “正在转换，忙！”）。</p>
</li>
<li><p>转换期间，<strong>模拟输入必须保持稳定</strong>（通常由采样保持器实现），否则比较结果会出错；比较器持续工作，不断调整 SAR 的值。</p>
</li>
</ul>
<p>**三、阶段 3：读取结果（读操作，对应 **<code>P2.3 + RD</code><strong>低电平</strong>）</p>
<ol>
<li><strong>转换结束的信号通知</strong>：</li>
</ol>
<ul>
<li><p>当 8 位都比较完成后，<code>EOC</code> <strong>变高电平</strong>（表示 “转换结束，数据 ready！”）。</p>
</li>
<li><p><code>EOC</code> 经反向器（非门）连接到单片机的 <code>P3.3</code>（外部中断引脚）(这里<code>p3.3</code>复用<code>INT1</code>引脚)，高电平的 <code>EOC</code> 会被反转为<strong>低电平</strong>，触发单片机中断（告诉 CPU：“数据好了，快来读！”）。</p>
</li>
</ul>
<ol start="2">
<li><strong>读取数据的硬件动作</strong>：&#xA;</li>
</ol>
<p>单片机响应中断后，使 <code>P2.3</code>（片选仍有效）和 <code>RD</code>（读信号，低电平）<strong>同时为低</strong>：</p>
<ul>
<li><p>这会触发 ADC0809 的 <code>OE</code><strong>（输出允许）</strong> 有效。</p>
</li>
<li><p>ADC 内部的锁存器将转换好的数字量（如 <code>0110 0100</code>）送到<strong>数据总线</strong>，单片机通过读操作将数据读入内存。</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;graph TD</span><br><span class="line">   A[&quot;单片机发出：P2.3+WR低电平&quot;] --&gt; B[&quot;启动脉冲START和地址锁存允许ALE有效：ADC锁存C/B/A&quot;]</span><br><span class="line">   B --&gt; C[&quot;在START下降沿的作用下开始逐次逼近+EOC变低电平&quot;]</span><br><span class="line">   C --&gt; D[&quot;转换完成，EOC变高，向单片机申请中断→P3.3=0&quot;]</span><br><span class="line">   D --&gt; E[&quot;单片机发出输出允许信号：P2.3+RD低电平&quot;] --&gt; F[&quot;OE高电平有效，允许从A/D转换器锁存器读取数字量&quot;]</span><br></pre></td></tr></table></figure>

</blockquote>
<ul>
<li><strong>实现A&#x2F;D转换</strong>所需的软件设计方式不同，目前常用的控制方式有：</li>
</ul>
<p><strong>程序查询方式、定时采样方式、中断方式</strong></p>
<ul>
<li>根据 A&#x2F;D 与单片机连接方式及控制系统要求不同，读取 A&#x2F;D 转换结果的三种方式是： <strong>程序查询方式、定时采样方式、中断方式</strong></li>
</ul>
<h2 id="12位A-D转换器微机接口技术"><a href="#12位A-D转换器微机接口技术" class="headerlink" title="12位A&#x2F;D转换器微机接口技术"></a>12位A&#x2F;D转换器微机接口技术</h2><h3 id="内部寄存器控制输入管脚（-A-0-和-12-overline-8-）"><a href="#内部寄存器控制输入管脚（-A-0-和-12-overline-8-）" class="headerlink" title="内部寄存器控制输入管脚（$A_0$和$12&#x2F; \overline{8}$）"></a>内部寄存器控制输入管脚（$A_0$和$12&#x2F; \overline{8}$）</h3><ul>
<li><p>$A_0($字节选择)和 12&#x2F;$\bar{8}($数字形式)输人端一起用来控制<strong>输出数据</strong>和<strong>转换脉冲</strong>。</p>
</li>
<li><p>当 12&#x2F;$\bar{8}$接高电平时，允许 12 位输出。当 12&#x2F;$\bar{8}$接低电平时，作为 8 位接口。在<br>这种状态下，当$A_0$被选中时一次只允许高 8 位和低 4 位输入。当$A_0$是低电平状态<br>时允许高 8 位输入，当$A_0$为高电平时允许低 4 位输人(高 8 位被禁止)。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong><code>12/8</code> 电平</strong></th>
<th><strong><code>A₀</code> 电平</strong></th>
<th><strong>输出有效位</strong></th>
<th><strong>数据意义</strong></th>
<th><strong>核心逻辑</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>高电平</strong></td>
<td>任意（0&#x2F;1）</td>
<td><em>D</em>11∼<em>D</em>0（12 位）</td>
<td>完整 12 位转换结果</td>
<td>12 位总线直接读取，<code>A₀</code> 此模式下无效</td>
</tr>
<tr>
<td><strong>低电平</strong></td>
<td><strong>低电平（0）</strong></td>
<td><em>D</em>11∼<em>D</em>4（8 位）</td>
<td>12 位结果的<strong>高 8 位</strong></td>
<td>8 位总线 “第一次读”，获取高位数据</td>
</tr>
<tr>
<td><strong>低电平</strong></td>
<td><strong>高电平（1）</strong></td>
<td><em>D</em>3∼<em>D</em>0（4 位，总线低 4 位补 0 成 8 位）</td>
<td>12 位结果的<strong>低 4 位</strong>（扩展为 8 位）</td>
<td>8 位总线 “第二次读”，获取低位数据（需与高 8 位拼接）</td>
</tr>
</tbody></table>
<ol>
<li><strong><code>12/8</code> 高→12 位并行出</strong>（适配 12 位总线，一步到位）；</li>
<li><strong><code>12/8</code> 低 +<code>A₀</code> 低→读高 8 位</strong>（先抓高位，占总线前 8 位）；</li>
<li><strong><code>12/8</code> 低 +<code>A₀</code> 高→读低 4 位</strong>（后补低位，总线低 4 位有效，高 4 位补 0）。</li>
</ol>
<blockquote>
<p>要理解AD574 中 <strong><code>12/8</code> 和 <code>A₀</code> 引脚的功能</strong>，需结合 <strong>“12 位数据与 8 位总线的兼容性矛盾”</strong> 分析，拆解如下：  </p>
<h3 id="一、12-8-引脚：决定数据输出模式（12-位并行-vs-8-位分时）"><a href="#一、12-8-引脚：决定数据输出模式（12-位并行-vs-8-位分时）" class="headerlink" title="一、12/8 引脚：决定数据输出模式（12 位并行 vs 8 位分时）"></a><strong>一、<code>12/8</code> 引脚：决定数据输出模式（12 位并行 vs 8 位分时）</strong></h3><p>AD574 是 <strong>12 位 ADC</strong>（可输出 0~4095 的数字量，对应 12 位二进制），但多数单片机是 <strong>8 位数据总线</strong>（一次只能传输 8 位）。<code>12/8</code> 引脚用于解决这个矛盾：  </p>
<table>
<thead>
<tr>
<th>12&#x2F;8</th>
<th>功能</th>
<th>数据输出方式</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>高电平</strong></td>
<td>12 位并行输出模式</td>
<td>12 位数据（<code>D₁₁~D₀</code>）同时输出</td>
<td>具备 12 位总线的系统（如 DSP）</td>
</tr>
<tr>
<td><strong>低电平</strong></td>
<td>8 位分时输出模式</td>
<td>12 位数据拆分为 <strong>高 8 位</strong>（<code>D₁₁~D₄</code>）和 <strong>低 4 位</strong>（<code>D₃~D₀</code>），分两次传输</td>
<td>8 位单片机系统（如 8051）</td>
</tr>
</tbody></table>
<h3 id="二、A₀-引脚：8-位模式下的“高低位切换开关”"><a href="#二、A₀-引脚：8-位模式下的“高低位切换开关”" class="headerlink" title="二、A₀ 引脚：8 位模式下的“高低位切换开关”"></a><strong>二、<code>A₀</code> 引脚：8 位模式下的“高低位切换开关”</strong></h3><p>当 <code>12/8</code> 接 <strong>低电平</strong>（8 位模式）时，<code>A₀</code> 用于控制 <strong>哪部分数据输出</strong>（高 8 位或低 4 位）：  </p>
<h4 id="1-A₀-低电平：输出高-8-位（D₁₁-D₄）"><a href="#1-A₀-低电平：输出高-8-位（D₁₁-D₄）" class="headerlink" title="1. A₀ = 低电平：输出高 8 位（D₁₁~D₄）"></a>1. <strong><code>A₀ = 低电平</code>：输出高 8 位（<code>D₁₁~D₄</code>）</strong></h4><ul>
<li>此时，AD574 将 12 位数据的 <strong>高 8 位</strong>（第 4<del>11 位，共 8 位）放到数据总线，**低 4 位（&#96;D₃</del>D₀&#96;）呈高阻态**（相当于“断开”，避免干扰总线）。</li>
</ul>
<h4 id="2-A₀-高电平：输出低-4-位（D₃-D₀）"><a href="#2-A₀-高电平：输出低-4-位（D₃-D₀）" class="headerlink" title="2. A₀ = 高电平：输出低 4 位（D₃~D₀）"></a>2. <strong><code>A₀ = 高电平</code>：输出低 4 位（<code>D₃~D₀</code>）</strong></h4><ul>
<li>此时，AD574 将 12 位数据的 <strong>低 4 位</strong>（第 0<del>3 位）放到数据总线，**高 8 位（&#96;D₁₁</del>D₄&#96;）呈高阻态**。</li>
</ul>
<h3 id="三、实例演示：12-位数据如何拆分传输？"><a href="#三、实例演示：12-位数据如何拆分传输？" class="headerlink" title="三、实例演示：12 位数据如何拆分传输？"></a><strong>三、实例演示：12 位数据如何拆分传输？</strong></h3><p>假设 AD574 转换结果为 <strong>12 位二进制 <code>1001 0001 1010</code></strong>（十进制 2330，十六进制 <code>0x91A</code>）：  </p>
<ul>
<li><strong>高 8 位</strong>：<code>1001 0001</code>（<code>D₁₁~D₄</code>，对应 <code>0x91</code>）；  </li>
<li><strong>低 4 位</strong>：<code>1010</code>（<code>D₃~D₀</code>，对应 <code>0x0A</code>）。</li>
</ul>
<h4 id="8-位单片机的读取流程："><a href="#8-位单片机的读取流程：" class="headerlink" title="8 位单片机的读取流程："></a>8 位单片机的读取流程：</h4><ol>
<li><strong>第一步：读高 8 位</strong></li>
</ol>
<ul>
<li>置 <code>A₀ = 低电平</code>，AD574 输出 <code>1001 0001</code>（<code>0x91</code>），单片机读取该值并暂存。</li>
</ul>
<ol start="2">
<li><strong>第二步：读低 4 位</strong></li>
</ol>
<ul>
<li>置 <code>A₀ = 高电平</code>，AD574 输出 <code>0000 1010</code>（低 4 位补 0 凑 8 位，即 <code>0x0A</code>），单片机读取该值。</li>
</ul>
<ol start="3">
<li><strong>第三步：拼接数据</strong></li>
</ol>
<ul>
<li>将高 8 位（<code>0x91</code>）左移 4 位，加上低 4 位（<code>0x0A</code>），得到完整 12 位数据 <code>0x91A</code>（<code>1001 0001 1010</code>）。</li>
</ul>
<p><code>A₀</code> 的“高&#x2F;低”控制，本质是 <strong>避免两次读取时的总线冲突</strong>（若高低位同时输出，会导致数据混乱甚至短路）。  </p>
<p><strong>总结</strong>：<code>12/8</code> 决定“是否拆分 12 位数据”，<code>A₀</code> 决定“拆分后读高 8 位还是低 4 位”，两者配合让 AD574 灵活适配不同位数的 CPU 总线，是模拟→数字转换中 <strong>“硬件兼容性设计”的经典案例</strong>。</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p><strong>下列关于 AD574 中 12&#x2F;8 和 A₀ 引脚功能的描述，正确的有（   ）</strong><br>选项：<br>A. 当 12&#x2F;8 接高电平时，AD574 可直接输出 12 位并行数据，A₀ 引脚此模式下功能无效<br>B. 当 12&#x2F;8 接低电平、A₀ 接低电平时，数据总线输出 12 位结果的低 4 位（补 0 为 8 位）<br>C. 8 位接口模式下，A₀ 为高电平时，12 位结果的 高 8 位会被禁止输出（呈高阻态）<br>D. 若需适配 8 位单片机总线，应将 12&#x2F;8 接低电平，通过 A₀ 分两次读取高 8 位和低 4 位<br>答案解析：<br>✅ A：12&#x2F;8 高→12 位并行输出，A₀ 仅在 8 位模式生效，此模式下无意义。<br>❌ B：12&#x2F;8 低 +A₀ 低→输出 高 8 位（D₁₁<del>D₄），而非低 4 位（干扰项颠倒高低位）。<br>✅ C：A₀ 高→高 8 位（D₁₁</del>D₄）高阻（禁止），仅低 4 位（D₃~D₀，补 0 为 8 位）输出。<br>✅ D：8 位模式通过 12&#x2F;8 低 +A₀ 切换，分两次读取并拼接，适配 8 位总线。</p>
<hr>
<p><strong>简述 AD574 中 12&#x2F;8 和 A₀ 引脚的作用，并说明 8 位接口模式 下的工作逻辑。</strong><br>12&#x2F;8 引脚：<br>高电平：启用 12 位并行输出模式，12 位数据（D₁₁<del>D₀）同时上总线，适配 12 位宽系统。<br>低电平：启用 8 位分时模式，12 位数据拆分为 高 8 位（D₁₁</del>D₄） 和 低 4 位（D₃<del>D₀），分两次传输。<br>A₀ 引脚（仅 12&#x2F;8 低电平时有效）：<br>低电平：选通 高 8 位（D₁₁</del>D₄）输出，低 4 位呈高阻态。<br>高电平：选通 低 4 位（D₃~D₀，补 0 为 8 位）输出，高 8 位呈高阻态。<br>8 位模式流程：通过控制 A₀ 电平，分 “读高 8 位→读低 4 位” 两步获取数据，最终软件拼接为 12 位结果。</p>
</blockquote>
<p>对于 Ａ Ｄ５７４ 的输入端一般可接成<strong>单极性输入</strong>和<strong>双极性输入</strong>两种工作方式  </p>
<h2 id="微机频率测量技术"><a href="#微机频率测量技术" class="headerlink" title="微机频率测量技术"></a>微机频率测量技术</h2><ul>
<li><p><strong>频率量</strong>是相对来说比较<u>容易</u>实现<u>精密测量</u>的一种电量  </p>
</li>
<li><p>频率信号与计算机的接口也比电压信号更容易实现</p>
</li>
</ul>
<h3 id="计数测频法（闸门时间法）"><a href="#计数测频法（闸门时间法）" class="headerlink" title="计数测频法（闸门时间法）"></a>计数测频法（闸门时间法）</h3><p>计数测频法的<strong>基本思想</strong>就是在某一选定的时间间隔内对被测信号进行<u>计数</u>，然后将<u>计数值</u>除以<u>时间间隔（时基）</u>就得到所测频率</p>
<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><p>被测信号经过一个可控闸门输给计数器，<span style="color:#FF0000">该闸门实际上就是一个<u>与门</u>或<u>与非门</u></span>，与门的另一输入端由微型计算机的一根输出线($P_1)$控制，<span style="color:#FF0000">当此线为“**高”**时，<u>闸门打开</u>，被测信号经闸门进入计数器使计数器计数；如此线为“<strong>低</strong>”则<u>闸门关闭</u> ,计数停止</span>。利用微机内部的定时器 ,可控制闸门按要求的时间间隔打开或关闭.从而实现频率测量。</p>
<p><img src="/blog/./image/Snipaste_2025-06-30_15-49-27.png"></p>
<p>设所选的闸门开启时时间间隔为 $t$,在此间隔内计得的计数值为$N$ ,则测得的</p>
<p>频率为</p>
<p>$$<br>f&#x3D;N&#x2F;t<br>$$</p>
<p>选取$t&#x3D;$ 1s ,则$f&#x3D;N($Hz),如$t&#x3D;0.1$s,则$f&#x3D;10N($Hz)。</p>
<h4 id="测频方法的误差分析"><a href="#测频方法的误差分析" class="headerlink" title="测频方法的误差分析"></a>测频方法的误差分析</h4><p>测频方法的误差主要有两类:</p>
<ol>
<li><strong>量化误差 (±1误差)</strong>: 将模拟量转化为数字量所产生的误差叫量化误差**。是由于用于计数的时标脉冲与控制主门的被测周期不同步而引起的**。</li>
<li><strong>标准频率误差 (时基误差)</strong>: 电子计数器在测量时, 都是以晶振产生的各种时基和时标信号作为基准的, 晶体振荡器不稳定将引起误差。</li>
</ol>
<blockquote>
<p><span style="color:#FF0000">请简要回答采用计数测频法测量频率时产生±1误差的原因。   </span></p>
<p>解：（2分）由于<span style="color:rgb(28, 57, 123)"><strong>用于计数的时标脉冲</strong></span>与<span style="color:rgb(28, 57, 123)"><strong>控制主门的被测周期</strong></span><strong>不同步</strong>而引起的。在测频率时，由于<span style="color:rgb(28, 57, 123)"><strong>闸门开启时间</strong></span>和<span style="color:rgb(28, 57, 123)"><strong>被计数脉冲周期</strong></span><strong>不成整数倍</strong>。（3分）</p>
</blockquote>
<blockquote>
<p><strong>±1误差原理</strong></p>
<p>$\pm 1$误差在测频时，闸门的开启时刻与计数脉冲的时间关系是不相关的，所以它们在时间轴上的相对位置是随机的。这样，在相同的闸门开启时间内，计数器所计得的数却不一定相同，当闸门开启时间$T$接近甚至等于被测信号周期$T_x$的整数$N$倍时，此项误差为最大。</p>
<ul>
<li><p>$T_S$为计数器的闸门开启时间</p>
</li>
<li><p>$T_x$为被测信号周期</p>
</li>
<li><p>$\Delta t_1$为闸门开启时刻至第一个计数脉冲前的时间（<strong>假设计数脉冲前沿使计数器翻转计数</strong>） $0 \leq \Delta t_1 \leq T_x$</p>
</li>
<li><p>$\Delta t_2$为闸门关闭时刻至下一个计数脉冲前沿的时间   $0 \leq \Delta t_2 \leq T_x$</p>
</li>
<li><p>设计数值为$N$，计数值误差为$\Delta N$</p>
</li>
</ul>
<p><img src="/blog/./image/Snipaste_2025-06-30_16-58-28.png"></p>
<p>为作图方便，图中$N$取6</p>
<p>由图可见</p>
<p>$$<br>T_S &#x3D; NT_{x} + \Delta t_{1} - \Delta t_{2} &#x3D; \left[ N + \frac{ \left( \Delta t_{1} - \Delta t_{2} \right) }{ T_{x} } \right] T_{x}<br>$$</p>
<p>显然，计数器的计数值$N$为正整数，它通常不能准确地反映频率关系式，即$ N \neq f_{x} T_s $，这就造成了计数误差：</p>
<p>$$<br>\Delta N &#x3D; f_{x} T_S-N   &#x3D; f_x\left[ N + \frac{ \left( \Delta t_{1} - \Delta t_{2} \right) }{ T_{x} } \right] T_{x}-N<br>$$</p>
<p>得</p>
<p>$$<br>\Delta N &#x3D; \frac{ \left( \Delta t_{1} - \Delta t_{2} \right) }{ T_{x} }<br>$$</p>
<ol>
<li>当$\Delta t_{1} &#x3D; \Delta t_{2}$时，$\Delta N &#x3D; 0$  </li>
<li>当$\Delta t_{1} &#x3D; 0$，$\Delta t_{2} &#x3D; T_{x}$时，$\Delta N &#x3D; -1$  </li>
<li>当$\Delta t_{1} &#x3D; T_{x}$，$\Delta t_{2} &#x3D; 0$时，$\Delta N &#x3D; 1$</li>
</ol>
<p><strong>即最大计数误差为$\pm 1$个数</strong></p>
<p><span style="color:#FF0000">低频时，误差主要由±1误差引起</span></p>
<ul>
<li><p>由“±１”误差造成的计数误差是随被测频率变化的相对误差，该误差的影响随着被测频率的下降而急骤增大  </p>
</li>
<li><p>相对误差（误差占测量值的比例）定义为：</p>
</li>
<li><p>$$<br>\text{相对误差} E &#x3D; \frac{|\text{绝对误差}|}{\text{测量值}} &#x3D; \frac{|\Delta N|}{N}&#x3D;\frac{1}{N} &#x3D; \frac{1}{f_x \cdot T_s}<br>$$</p>
</li>
<li><p>当 $T_s$固定时，<strong>相对误差与被测频率 $f_x$ 成反比</strong>$(f_x \downarrow \Rightarrow \text{相对误差} \uparrow) $</p>
</li>
</ul>
<p>以 $T_s &#x3D; 1,\text{秒}$ 为例，对比不同频率下的相对误差：</p>
<table>
<thead>
<tr>
<th>被测频率 f（Hz）</th>
<th>闸门内脉冲数 $N &#x3D; f \cdot T_s$</th>
<th>相对误差$ \dfrac{1}{N}$</th>
</tr>
</thead>
<tbody><tr>
<td>1M</td>
<td>1M</td>
<td>$10^{-6}$</td>
</tr>
<tr>
<td>100</td>
<td>100</td>
<td>1%</td>
</tr>
<tr>
<td>10</td>
<td>10</td>
<td>10%</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>100%</td>
</tr>
</tbody></table>
</blockquote>
<ul>
<li>对于闸门时间为 １ｓ 的情况，当频率超过 １Ｍ Ｈｚ 时，测量误差主要由时基误差来决定。 这一误差要比“±１”在低频时引起的误差小得多。</li>
</ul>
<p><img src="/blog/./image/IMG_20250628_184645.jpg"></p>
<h3 id="周期测量法"><a href="#周期测量法" class="headerlink" title="周期测量法"></a>周期测量法</h3><p><img src="/blog/./image/Snipaste_2025-07-01_10-54-08.png"></p>
<blockquote>
<p>周期测量中，改用固定频率很高的参考脉冲**$f_{r}$作计数器的脉冲源**，而让**被测信号$f_{m}$**经放大整形后再经过一个门控双稳去控制闸门。</p>
</blockquote>
<p>其电路原理图如图5.18所示，在门控双稳输入B的两个下降沿之间（<span style="color:#FF0000">保证一个周期</span>），触发器输出高电平使闸门打开，计数器对$f_{r}$进行计数。闸门开启的时间就是被测信号的周期。</p>
<p>门控双稳输出的下降沿表示一次计数完毕，此信号引入微型计算机通知它取走计数器的数值。</p>
<blockquote>
<p>**注意：**由于计数器不清零，与被测周期对应的数值应为两次相邻读数之差。如出现第三次读数小于前一次时，表明计数器已出现过满量程进位，<strong>应将第二次读数加上计数器的满量程值再相减</strong>。通过所获得的周期值，微型计算机很容易计算其倒数，即对应的频率值。</p>
</blockquote>
<ul>
<li>计数器的计数结果为$N$</li>
</ul>
<p>$$<br>T_m&#x3D;NT_r \<br>f_m&#x3D;\frac {f_r}{N}<br>$$</p>
<p>周期测量法中，“±1”所引起的相对误差为</p>
<p>$$<br> E&#x3D;\frac {1}{T_{m}\cdot f_{r}}&#x3D;\frac {f_{m}}{f_{r}}<br>$$<br><span style="color:#FF0000">参考脉冲的频率越高则相对误差越小，并且相对误差与被测频率成正比，对低频测量，周期法有较高的精度，随着被测频率的增高，其相对误差逐渐增大  </span></p>
<p><img src="/blog/./image/IMG_20250628_185302.jpg"></p>
<h3 id="多倍周期测量法"><a href="#多倍周期测量法" class="headerlink" title="多倍周期测量法"></a>多倍周期测量法</h3><p><span style="color:#FF0000">为了克服1KHZ附近误差大的缺点，可应用多倍周期测量法  </span></p>
<p>多倍周期法的基本做法是利用微型计算机自动控制计数闸门开启 𝑚个被测信号周期的时间使得计数器在一次测量中得到的读数值接近满量程。</p>
<p>当被测频率较高时,自动选取较大的 𝑚值,频率转低时,则选用较小的 𝑚值,保证每次得到的读数值都在满量程值附近,从而使得对各种被测频率误差都很小。</p>
<p><img src="/blog/./image/Snipaste_2025-07-01_14-44-29.png"></p>
<ul>
<li><p>计数器$CT_1$累计闸门开启时间内的<strong>参考脉冲数</strong>；</p>
</li>
<li><p>$CT_2$为<strong>周期数计数器</strong>，它对被测信号进行计数  </p>
</li>
<li><p>$CT_1$计数器的计数结果为$N$</p>
</li>
<li><p>$m$为被测信号周期数</p>
</li>
<li><p><strong>$f_{r}$为计数器的脉冲源</strong></p>
</li>
<li><p><strong>$f_{m}$为被测信号</strong></p>
</li>
</ul>
<p>$$<br>mT_m&#x3D;NT_r \<br>f_m&#x3D;\frac {mf_r}{N}<br>$$</p>
<blockquote>
<p><span style="color:#FF0000">测量方法本质</span></p>
<ul>
<li><strong>计数法</strong>:是一种积分方法,在闸门时间内由计数器对被测信号进行脉冲累计。  低频误差的原因是指,在确定的闸门时间内,累计得到的脉冲数远小于计数器的满量程,致使“±1”引起的误差增大。</li>
<li><strong>周期法</strong>:也是一种积分方法,只不过计数器累计的不是被测信号而是参考脉冲。  高频时,由于受被测信号周期控制的闸门开启时间过短,使得计数值也远小于计数器的满量程,造成相对误差增大。  </li>
<li><strong>多倍周期法</strong>:是利用计算机自动控制计数闸门开启m个被测信号周期的时间,使得计数器在一次测量中得到的读数值接近满量程。当被测频率较高时,自动选取较大的m值,频率转低时,则选用较小的m值,保证每次得到的读数值都在满量程值附近,从而使得对各种被测频率</li>
</ul>
</blockquote>
<h2 id="模拟量输出技术"><a href="#模拟量输出技术" class="headerlink" title="模拟量输出技术"></a>模拟量输出技术</h2><h3 id="模拟量输出通道的结构组成"><a href="#模拟量输出通道的结构组成" class="headerlink" title="模拟量输出通道的结构组成"></a>模拟量输出通道的结构组成</h3><ul>
<li><p>模拟量输出通道的任务 —— 把计算机处理后的<span style="color:#FF0000">数字量信号</span>转换成<span style="color:#FF0000">模拟量（电压或电流信号）</span>，去驱动相应的执行器，从而达到控制的目的；</p>
</li>
<li><p>模拟量输出通道（D&#x2F;A通道或AO通道）构成： 一般是由<u>接口电路</u>（核心部分）、<span style="color:#FF00FF"><u>数&#x2F;模转换器</u>（简称D&#x2F;A或DAC）</span>和<u>电压&#x2F;电流变换器</u>等；</p>
</li>
</ul>
<hr>
<blockquote>
<p>⚠️ <strong>注意：</strong> 并非所有的DAC的数据输入都能直接挂在微处理机数据总线上。</p>
</blockquote>
<blockquote>
<p>🔍 <strong>原因：</strong> 实际应用中，转换后的模拟信号需要保持一段时间，便于测量或控制，而 CPU 在执行向外设给输出数据的指令时，数据在数据总线上的存在时间只维持一个时钟周期。因此，对于不带<strong>输入数据寄存器</strong>的 DAC 芯片，其<strong>数据输入端</strong>须经<strong>锁存器</strong>与 CPU 数据总线相连</p>
</blockquote>
<h3 id="不带输入数据寄存器的D-A转换器接口"><a href="#不带输入数据寄存器的D-A转换器接口" class="headerlink" title="不带输入数据寄存器的D&#x2F;A转换器接口"></a>不带输入数据寄存器的D&#x2F;A转换器接口</h3><p><img src="/blog/./image/Snipaste_2025-07-01_15-45-39.png"></p>
<ul>
<li>LS273为<strong>数据锁存器</strong></li>
<li>若图片中的D&#x2F;A转换器输出类型为电流输出，后接运放可实现<strong>电流-电压的转换</strong></li>
</ul>
<h3 id="微机总线兼容型D-A转换器接口"><a href="#微机总线兼容型D-A转换器接口" class="headerlink" title="微机总线兼容型D&#x2F;A转换器接口"></a>微机总线兼容型D&#x2F;A转换器接口</h3><ul>
<li><p>微机总线兼容型 Ｄ／Ａ 转换器芯片内部带有<strong>输入数据寄存器</strong>  </p>
</li>
<li><p>拥有一个数据寄存器的叫<strong>单缓冲型</strong>，带有两个数据寄存器的叫<strong>双缓冲型</strong>  </p>
</li>
<li><p><span style="color:#FF0000"><strong>双缓冲型优点(简答)</strong> </span>：当一个数字量送入 DAC 进行转换输出同时，能输入下一个数字量，从而提高转换速度。</p>
</li>
</ul>
<h3 id="原码、反码、补码、移码"><a href="#原码、反码、补码、移码" class="headerlink" title="原码、反码、补码、移码"></a>原码、反码、补码、移码</h3><h4 id="原码"><a href="#原码" class="headerlink" title="原码"></a>原码</h4><ul>
<li>符号位（最高位）+ 数值位</li>
<li><strong>规则</strong>：<code>0</code>表正，<code>1</code>表负，数值位为绝对值的二进制。</li>
</ul>
<h4 id="反码"><a href="#反码" class="headerlink" title="反码"></a>反码</h4><ul>
<li><strong>规则</strong>：正数反码同原码；负数反码是符号位不变，数值位逐位取反。</li>
</ul>
<h4 id="补码"><a href="#补码" class="headerlink" title="补码"></a>补码</h4><ul>
<li><strong>规则</strong>：正数补码同原码；负数补码是<strong>反码 + 1</strong>（符号位自动调整）。</li>
</ul>
<h4 id="偏移二进制码（移码）"><a href="#偏移二进制码（移码）" class="headerlink" title="偏移二进制码（移码）"></a>偏移二进制码（移码）</h4><p>$n$**(不包含符号位的真值位)**位二进制数$\pm D_i$的偏移二进制代码为<br>$$<br>D_m &#x3D; D_i + 2^n<br>$$</p>
<blockquote>
<p>$  D_i&#x3D;+110  $(十进制为+6)：$  D_m&#x3D; +110+1000&#x3D;1110(&#x3D;6+8&#x3D;14)  $ <span style="color:#FF0000">这里的移码没有符号位</span></p>
<p>$  D_i&#x3D;-110  $(十进制为-6)：$  D_m&#x3D;-110+1000&#x3D;0010(&#x3D;-6+8&#x3D;2)  $ (-110原码为1110，反码为1001，补码为1010；1010+1000&#x3D;10010取4位)</p>
</blockquote>
<p><span style="color:rgb(116, 219, 38)"><strong>将补码的符号位取反</strong></span>（<strong>推荐</strong>）</p>
<table>
<thead>
<tr>
<th>真值 $D_i$</th>
<th>原码(字节长度4位)&#xA;</th>
<th>反码&#xA;</th>
<th>补码&#xA;</th>
</tr>
</thead>
<tbody><tr>
<td>$+6$</td>
<td><code>0110</code></td>
<td><code>0110</code></td>
<td><code>0110</code></td>
</tr>
<tr>
<td>$-6$</td>
<td><code>1110</code></td>
<td><code>1001</code></td>
<td><code>1010</code></td>
</tr>
<tr>
<td>$+0$</td>
<td><code>0000</code></td>
<td><code>0000</code></td>
<td><code>0000</code></td>
</tr>
<tr>
<td>$-0$</td>
<td><code>1000</code></td>
<td><code>1111</code></td>
<td><code>0000</code></td>
</tr>
<tr>
<td>$-8$</td>
<td>无&#xA;</td>
<td>无&#xA;</td>
<td><code>1000</code></td>
</tr>
</tbody></table>
<blockquote>
<p><strong>例题</strong></p>
<p>分别求+78和-78的原码、反码、补码、移码</p>
<table>
<thead>
<tr>
<th></th>
<th align="center">+78</th>
<th align="center">-78</th>
</tr>
</thead>
<tbody><tr>
<td>原码（<strong>短除法</strong>）</td>
<td align="center">01001110</td>
<td align="center">11001110</td>
</tr>
<tr>
<td>反码</td>
<td align="center">01001110</td>
<td align="center">10110001</td>
</tr>
<tr>
<td>补码</td>
<td align="center">01001110</td>
<td align="center">10110010</td>
</tr>
<tr>
<td>移码（<strong>补码符号位取反</strong>）</td>
<td align="center">11001110</td>
<td align="center">00110010</td>
</tr>
</tbody></table>
</blockquote>
<h3 id="权电阻型D-A转换器"><a href="#权电阻型D-A转换器" class="headerlink" title="权电阻型D&#x2F;A转换器"></a>权电阻型D&#x2F;A转换器</h3><table>
<thead>
<tr>
<th align="center">$n$ 位二进制数</th>
<th>$D_{n-1}$</th>
<th>$D_{n-2}$</th>
<th>$\cdots$</th>
<th>$D_1$</th>
<th>$D_0$</th>
</tr>
</thead>
<tbody><tr>
<td align="center"></td>
<td>最高位（MSB）</td>
<td>⟵⟶</td>
<td>⟵⟶</td>
<td>⟵⟶</td>
<td>最低位（LSB）</td>
</tr>
<tr>
<td align="center"><strong>权</strong></td>
<td>$2^{n-1}$</td>
<td>$2^{n-2}$</td>
<td>$\cdots$</td>
<td>$2^1$</td>
<td>$2^0$</td>
</tr>
</tbody></table>
<p>转换为十进制数<br>$$<br>D_n &#x3D; D_{n-1} \cdot 2^{n-1} + D_{n-2} \cdot 2^{n-2} + \cdots + D_1 \cdot 2^1 + D_0 \cdot 2^0<br>$$<br><img src="/blog/./image/Snipaste_2025-07-01_20-47-17.png"><br>$$<br>i_0&#x3D;\frac {U_{REF}}{R}D_0 \Rightarrow i_i&#x3D;\frac {U_{REF}}{\frac{R}{2^i}}D_i<br>$$</p>
<p>$$<br>I_{REF}&#x3D;<br> \frac{ U_{REF}}{R} \sum_{i&#x3D;0}^{n-1} D_i  2^i<br>$$</p>
<p>$$<br>u_0&#x3D;-I_{REF} R_f&#x3D; -\frac{R_f U_{REF}}{R} \sum_{i&#x3D;0}^{n-1} D_i  2^i \<br>$$</p>
<p>$$<br>\text{$D_i$ 取0或1}<br>$$</p>
<blockquote>
<p><strong>输出电压除了与输入的二进制数有关，还与运算放大器的反馈电阻$R_f$以及基准电压$U_{REF}$有关</strong></p>
</blockquote>
<h3 id="倒T型电阻网络D-A转换器"><a href="#倒T型电阻网络D-A转换器" class="headerlink" title="倒T型电阻网络D&#x2F;A转换器"></a>倒T型电阻网络D&#x2F;A转换器</h3><p><img src="/blog/./image/20250702085853.png"></p>
<p><strong>内置反馈电阻</strong><br>$$<br>V_o&#x3D;-\frac{V_{REF}}{2^n}D_n<br>$$<br><strong>外接反馈电阻</strong><br>$$<br>V_o&#x3D;-\frac{R_F}{R}\frac{V_{REF}}{2^n}D_n<br>$$</p>
<h3 id="单极性输出的DAC转换器"><a href="#单极性输出的DAC转换器" class="headerlink" title="单极性输出的DAC转换器"></a>单极性输出的DAC转换器</h3><p><img src="/blog/./image/IMG_20250628_191911.jpg"></p>
<ul>
<li><p>DAC0832自带反馈电阻，且$n&#x3D;8$</p>
</li>
<li><p>$$<br>V_{\mathrm{OUT}}&#x3D;-B\times\frac{V_{\mathrm{REF}}}{2^8} \<br>B&#x3D;D_{7}\times2^{7}+D_{6}\times2^{6}+\cdots+D_{1}\times2^{1}+D_{0}\times2^{0}<br>$$</p>
</li>
</ul>
<blockquote>
<p><strong>几个注意事项</strong></p>
<ul>
<li>DAC是否自带反馈电阻</li>
<li>DAC是几位芯片</li>
<li>$V_{OUT}$电压是负数（由上面的电路决定的）</li>
<li>上面的二进制数为无符号数</li>
</ul>
</blockquote>
<h3 id="双极性输出的D-A转换器"><a href="#双极性输出的D-A转换器" class="headerlink" title="双极性输出的D&#x2F;A转换器"></a>双极性输出的D&#x2F;A转换器</h3><p><img src="/blog/./image/20250702093204.png"></p>
<hr>
<p><span style="color:#FF0000">总结：</span></p>
<p>构成双极性输出D&#x2F;A转换器的一般方法：</p>
<ul>
<li>只要在求和放大器的输入端接入一个偏移电流，使输入最高位为1而其他各位输入为0时的输出$v_{out2}&#x3D;0$，</li>
<li>同时将输入的符号位反相后接到一般的D&#x2F;A转换器的输入，就得到了双极性输出的D&#x2F;A转换器。</li>
</ul>
<p><img src="/blog/./image/IMG_20250628_190618.jpg"></p>
<blockquote>
<p>右下角的条件其实就是为了保证输入数字量10000000时，$V_{out2}&#x3D;0$,这个不重要</p>
</blockquote>
<p>$$<br>v_{out1} &#x3D; -\frac{V_{\mathrm{REF}}}{2^n} D_n<br>$$</p>
<p>$$<br>v_{out2} &#x3D; -2R(I_1 + I_2) \<br>&#x3D; -2R\left(\frac{V_{\mathrm{REF}}}{2R}+ \frac{v_{out1}}{R}  \right) \<br>&#x3D; \frac{V_{\mathrm{REF}}}{2^{n-1}} D_n - V_{\mathrm{REF}} \<br>&#x3D; \frac {D_n -2^{n-1}}{2^{n-1}} V_{\mathrm{REF}}<br>$$</p>
<blockquote>
<p>如果是DAC0832这种<strong>8</strong>位的芯片<br>$$<br>v_{out2} &#x3D;\frac {D_n -128}{128} V_{\mathrm{REF}}<br>$$</p>
</blockquote>
<blockquote>
<p><strong>例题</strong></p>
<p><img src="/blog/./image/IMG_20250628_192000.jpg"><br>$$<br>D_n &#x3D; \left(1 + \frac{V_{out2}}{V_{\mathrm{ref}}} \right) \cdot 2^{n-1}<br>&#x3D; 128D &#x3D; 80H &#x3D; 10000000B<br>$$</p>
</blockquote>
<table>
<thead>
<tr>
<th><strong>数制</strong></th>
<th>后缀</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>十进制</td>
<td>D</td>
<td></td>
</tr>
<tr>
<td>二进制</td>
<td>B</td>
<td></td>
</tr>
<tr>
<td>八进制</td>
<td>O</td>
<td></td>
</tr>
<tr>
<td>十六进制</td>
<td>H</td>
<td>位值：A&#x3D;10，B&#x3D;11，C&#x3D;12，D&#x3D;13，E&#x3D;14，F&#x3D;15</td>
</tr>
</tbody></table>
<blockquote>
<table>
<thead>
<tr>
<th><strong>转换方向</strong></th>
<th>方法核心</th>
<th>关键逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>十六进制 → 十进制</td>
<td>位权展开（$\sum \text{位值} \times 16^n$）</td>
<td>基数 16 的幂次计算</td>
</tr>
</tbody></table>
</blockquote>
<p><strong>示例 1：1AH 转十进制</strong></p>
<ul>
<li>位分解：第 1 位（左）是 <code>1</code>，第 0 位（右）是 <code>A</code>（10）。</li>
<li>位权计算：$1 \times 16^1 + 10 \times 16^0 &#x3D; 16 + 10 &#x3D; 26$</li>
</ul>
<p><strong>示例 2：FFH 转十进制</strong></p>
<ul>
<li>位分解：第 1 位是 <code>F</code>（15），第 0 位是 <code>F</code>（15）。</li>
<li>位权计算：$15 \times 16^1 + 15 \times 16^0 &#x3D; 240 + 15 &#x3D; 255$</li>
</ul>
<h2 id="步进电机基本控制技术"><a href="#步进电机基本控制技术" class="headerlink" title="步进电机基本控制技术"></a>步进电机基本控制技术</h2><h3 id="步进电机结构与工作原理"><a href="#步进电机结构与工作原理" class="headerlink" title="步进电机结构与工作原理"></a>步进电机结构与工作原理</h3><p>步进电机是一种将<span style="color:#FF0000">电脉冲信号</span>转换成机械位移的机电执行元件。每当一个脉冲信号施加于电机的控制绕组时，其转轴就转过一个固定的角度（<span style="color:#FF0000">步距角</span>）。顺序连续地发给脉冲，则电机轴<span style="color:#FF0000">一步接一步地运转</span>。</p>
<p><img src="/blog/./image/Snipaste_2025-07-02_10-28-28.png"></p>
<ul>
<li><p>在实际应用中，<strong>脉冲分配回路</strong>有各种构成的办法。最常用的是环形分配器电路，现在渐渐已采用微型计算机取代旧式的环形分配器，功率放大电路的结构对步进电机的性能有着十分重要的作用。</p>
</li>
<li><p>功率放大电路有<strong>单电压</strong>、<strong>双电压</strong>、<strong>斩波型</strong>、<strong>调频调压型</strong>和<strong>细分型</strong>等型式的电路。</p>
</li>
</ul>
<h3 id="驱动电源的组成"><a href="#驱动电源的组成" class="headerlink" title="驱动电源的组成"></a>驱动电源的组成</h3><p><img src="/blog/./image/Snipaste_2025-07-02_10-49-45.png"></p>
<p>步进电机的运行要求足够功率的电脉冲信号按一定的顺序分配到各相绕组。所以，与其它旋转电机不同的是步进电机的工作需要专门的驱动。</p>
<ul>
<li>步进电机的驱动包含<span style="color:#0000FF">脉冲分配（环行分配）</span>和<span style="color:#0000FF">功率放大</span>两部分。</li>
</ul>
<h3 id="步进电机功率放大电路"><a href="#步进电机功率放大电路" class="headerlink" title="步进电机功率放大电路"></a>步进电机功率放大电路</h3><p>步进电动机的功率驱动电路实际上是一种脉冲放大电路，使脉冲具有一定的功率驱动能力。</p>
<h4 id="单电压驱动电路（基本型改进电路）"><a href="#单电压驱动电路（基本型改进电路）" class="headerlink" title="单电压驱动电路（基本型改进电路）"></a>单电压驱动电路（基本型改进电路）</h4><p><img src="/blog/./image/Snipaste_2025-07-02_10-57-34.png"></p>
<p>$$<br>T_d &#x3D; \frac{L}{R_L + R_C + R_d}<br>$$</p>
<p>其中：</p>
<ul>
<li>$T_d$回路放电时间</li>
<li>$L$ —— 是电动机绕组</li>
</ul>
<hr>
<p><span style="color:#0000FF">两点改进：</span></p>
<ol>
<li><p>电阻 $R_C$ 两端<span style="color:#FF0000">并联电容 $C$</span>，是由于电容两端的电压不能突变，在绕组由<strong>截止到导通</strong>瞬间，电源电压全部降落到绕组上，使电流上升更快，所以，电容 $C$ 又称为<span style="color:#FF0000">加速电容</span>。</p>
</li>
<li><p>在续流二极管 $D$ 回路中<span style="color:#FF0000">串联了一个电阻 $R_D$</span>，对回路的放电时间 $T_d$ 有较大改善功能。续流二极管 $D$ 在晶体管 $T$ 截止时起<span style="color:#0000FF">续流和保护作用</span>，以防止晶体管截止瞬间绕组产生的反电动势对管子造成损坏。串联电阻也使电流下降更快，从而使绕组中电流脉冲的后沿变陡。</p>
</li>
</ol>
<h4 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h4><p><strong>综合题</strong></p>
<p>已知电动自行车系统构成结构简图如图所示，当该自行车以单片机作为控制器，并能实时进行速度控制时，<br>（1）试绘制自行车匀速运动的工作原理框图？<br>（2）若该轮毂电机采用单电压控制方式，试设计出单电压改进型功率放大电路，  并说明该改进型电路的优点？：</p>
<p><img src="/blog/./image/845883_003335729142_2.jpg"></p>
<p><img src="/blog/./image/Snipaste_2025-07-09_14-14-46.png"></p>
<hr>
<p>1、下图为遥控无人车结构简图。采用单片机作为主控制器，</p>
<p>（1）试画出车轮驱动系统的速度闭环的工作原理框图？</p>
<p>（2）设遥控无人车的 6-车轮驱动系统采用单电压基本型改进功率放大电路，<br>试画出该电路图并说明该电路改进后的特点？</p>
<p><img src="/blog/./image/Snipaste_2025-07-09_14-37-09.png"></p>
<p><img src="/blog/./image/Snipaste_2025-07-09_14-36-03.png"></p>
<h4 id="高低压切换型驱动电路（双电压驱动电路）"><a href="#高低压切换型驱动电路（双电压驱动电路）" class="headerlink" title="高低压切换型驱动电路（双电压驱动电路）"></a>高低压切换型驱动电路（<span style="color:#FF0000">双电压驱动电路</span>）</h4><p><span style="color:#0000FF">驱动电路的基本思想</span>：</p>
<p>无论电机的工作频率如何，在导通相的前沿用高电压供电，提高电流的前沿上升率；而在前沿过后用低压来维持绕组的电流。</p>
<hr>
<p><img src="/blog/./image/Snipaste_2025-07-02_14-26-20.png"></p>
<p><strong>元件说明：</strong></p>
<ul>
<li>$VT_1$：高压电源的开关管  </li>
<li>$VT_2$：低压侧功率驱动管  </li>
<li>$V_1$：续流二极管  </li>
<li>$V_2$：钳位二极管  </li>
<li>$L$：步进电机绕组电感  </li>
<li>$R$：串联电阻</li>
<li><strong>$U_{b1}$：步进控制信号</strong></li>
<li><strong>$U_{b2}$：高压电源开关控制信号</strong></li>
</ul>
<hr>
<p><strong>要求：</strong></p>
<p><span style="color:#FF0000">一、</span> $U_{b1}$ 和 $U_{b2}$ 上升沿的上 升时刻一致；</p>
<p><span style="color:#FF0000">二、</span> 有 $U_{b2}的脉宽 &lt; U_{b1}的脉宽$</p>
<hr>
<blockquote>
<p> 高低压驱动线路的<strong>优点</strong>是：启动力矩大、突跳频率和工作频率高。<br><strong>缺点</strong>是：低频振荡加剧，大功率管的数量多用一倍，增加了驱动电路复杂度。</p>
</blockquote>
<blockquote>
<p><span style="color:#FF0000">调频调压驱动电源的基本原理是：</span></p>
<ul>
<li>当步进电机在低频运行时，供电电压降低，当运行在高频段时，供电电压也升高，即供电电压随着步进电机转速的增加而升高。 </li>
<li>这样既解决了低频振荡问题，也保证了高频运行时的输出转矩。</li>
<li>实现调频调压控制的硬件电路可由软件配合适当硬件电路实现</li>
<li>$U_{CP} $是步进控制脉冲信号，$U_{CT} $是开关调压信号。</li>
</ul>
</blockquote>
<p><img src="/blog/./image/Snipaste_2025-07-02_14-38-46.png"></p>
<h2 id="直流电动机脉宽（PWM）调速系统"><a href="#直流电动机脉宽（PWM）调速系统" class="headerlink" title="直流电动机脉宽（PWM）调速系统"></a>直流电动机脉宽（PWM）调速系统</h2><h3 id="直流电动机的脉宽调制工作原理"><a href="#直流电动机的脉宽调制工作原理" class="headerlink" title="直流电动机的脉宽调制工作原理"></a>直流电动机的脉宽调制工作原理</h3><p><span style="color:#FF0000">PWM</span>（<span style="color:#FF0000">Pulse Width Modulation</span>）——利用<u>大功率晶体管的开关特性</u>来调制固定电压的<span style="color:#0000FF">直流电源</span>，按一个固定的<span style="color:#0000FF">频率</span>来<span style="color:#0000FF">接通</span>和<span style="color:#0000FF">断开</span>，并根据需要改变一个周期内<span style="color:#0000FF">接通</span>与<span style="color:#0000FF">断开</span>时间的<span style="color:#0000FF">长短</span>，通过改变直流电动机电枢上电压的<span style="color:#0000FF">占空比</span>来改变平均电压的大小，从而控制电动机的转速。</p>
<hr>
<p><img src="/blog/./image/Snipaste_2025-07-03_08-36-27.png"></p>
<p>周期为 $T$，导通时间为 $t_{\text{on}}$，关断时间为 $t_{\text{off}}$，满足：</p>
<p>$$<br>T &#x3D; t_{\text{on}} + t_{\text{off}}<br>$$</p>
<p>平均电压（有效控制量）为：</p>
<p>$$<br>U_{as} &#x3D; U_s \cdot \frac{t_{\text{on}}}{T}<br>$$</p>
<hr>
<blockquote>
<p>以晶体管的开关特性满足电机的周期通断</p>
</blockquote>
<p><strong>改变占空比的两种调制方法</strong></p>
<table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>脉冲宽度调制（PWM）</strong></th>
<th><strong>脉冲频率调制（PFM）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>实现方式</strong></td>
<td>固定 <strong>开关周期 T</strong>，改变 <strong>导通脉冲宽度$t_{on}$</strong></td>
<td>固定 <strong>导通脉冲宽度</strong>，改变 <strong>开关周期 T</strong>（即改变频率 $f&#x3D;1&#x2F;T$)</td>
</tr>
<tr>
<td><strong>关键特性</strong></td>
<td>频率固定，仅脉宽变化。</td>
<td>脉宽固定，仅频率变化。</td>
</tr>
<tr>
<td><strong>缺陷</strong></td>
<td></td>
<td>若遇到 <strong>特定频率的机械谐振</strong>，会引发 <strong>系统振荡、音频啸叫声</strong></td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td></td>
<td>因谐振问题，<strong>伺服系统中不适用</strong></td>
</tr>
</tbody></table>
<h3 id="直流电动机的调速方式"><a href="#直流电动机的调速方式" class="headerlink" title="直流电动机的调速方式"></a>直流电动机的调速方式</h3><p>直流速度控制系统常采用晶体管脉冲调制方式（<span style="color:#FF0000">PWM</span>）。</p>
<p><span style="color:#FF0000">PWM</span>方式是在大功率开关晶体管的基极上，加上脉冲宽度可调的方波电压，控制开关管的导通时间 $t$，改变占空比，达到控制目的。</p>
<p>图5.35 是直流<span style="color:#FF0000">PWM</span>系统原理框图。这是一个双闭环系统，有电流环和速度环。</p>
<ul>
<li>核心部分是<strong>脉冲功率放大器和脉宽调制器。</strong></li>
</ul>
<p><img src="/blog/./image/Snipaste_2025-07-03_08-57-06.png"></p>
<h4 id="脉冲功率放大器（PWM-系统主回路）"><a href="#脉冲功率放大器（PWM-系统主回路）" class="headerlink" title="脉冲功率放大器（ＰＷＭ 系统主回路）"></a>脉冲功率放大器（ＰＷＭ 系统主回路）</h4><p><img src="/blog/./image/Snipaste_2025-07-03_09-21-51.png"></p>
<ul>
<li>$VT_1 \sim VT_4$ 为大功率晶体管；</li>
<li>$VD_1 \sim VD_4$ 为续流二极管，用于保护 $VT_1 \sim VT_4$；</li>
<li>$SM$ 为直流伺服电动机。</li>
</ul>
<p><span style="color:#FF0000">工作原理</span></p>
<p><img src="/blog/./image/Snipaste_2025-08-11_08-40-20.png"></p>
<p>4 个功率管分为<strong>两组基极电压</strong></p>
<ul>
<li><p>$U_{b1} &#x3D; U_{b4}$（同相）</p>
</li>
<li><p>$U_{b2} &#x3D; U_{b3} &#x3D; -U_{b1}$(反相，与前一组互补）</p>
</li>
</ul>
<p><span style="color:#FF0000">当$0 \leq t \leq t_1$</span></p>
<ul>
<li><strong>基极电压</strong>：</li>
</ul>
<p>$U_{b1}、U_{b4}$为正（驱动 VT₁、VT₄导通）；$U_{b2}、U_{b3}$为负（ VT₂、VT₃截止）。</p>
<ul>
<li><strong>电流路径</strong>:（虚线 1）</li>
<li><strong>电机电压</strong>：两端加正向电压 <strong>$U_{AB} &#x3D; U_s$</strong>，电枢电流 $i_a$沿正向（A→B）增大</li>
</ul>
<hr>
<p><span style="color:#FF0000">$t_1 \leq t \leq T$</span></p>
<ul>
<li><p><strong>基极电压</strong>：$U_{b1}$、$U_{b4}$ 为负（$VT_1$、$VT_4$ 截止）；$U_{b2}$、$U_{b3}$ 为正（ $VT_2$、$VT_3$ 不能立即导通）。</p>
</li>
<li><p><strong>管子状态矛盾</strong>：$VT_1$、$VT_4$ 已截止，但 $VT_2$、$VT_3$ <span style="color:#FF0000">不能立即导通</span> —— 因为 <span style="color:#FF0000">电机电枢电感的反电动势</span> 阻碍电流突变：</p>
<ul>
<li>电感试图维持原电流方向（$A \rightarrow B$），产生 <span style="color:#FF0000">反向电动势</span>，迫使电流经 <span style="color:#FF0000">续流二极管 $VD_2$, $VD_3$</span> 形成回路。</li>
</ul>
</li>
<li><p><strong>续流路径（虚线 2）</strong>：</p>
<p>续流时，$VD_2$、$VD_3$ 的正向压降使 $VT_2$、$VT_3$ 承受 <span style="color:#FF0000">反向电压</span>，因此暂时无法导通。</p>
</li>
</ul>
<blockquote>
<p><strong>负半周的两种发展（决定电机转向）</strong></p>
</blockquote>
<p><strong>① 续流未断（负半周时间短）</strong></p>
<ul>
<li><p><strong>条件</strong>：$t_1 \sim T$ 时间短（负半周窄），或续流电流 $i_a$ 大→续流未降至零，<span style="color:#FF0000">下一个正半周已到来</span>（$U_{b1}$、$U_{b4}$ 又变正）。</p>
</li>
<li><p><strong>结果</strong>：$VT_1$、$VT_4$ 再次导通，电流沿回路 1 重新上升，$i_a$ 在 <span style="color:#FF0000">正值附近波动</span>。（对应图 5.37 (b) 的 $i_a$ 波形）</p>
</li>
</ul>
<p><strong>② 续流中断，电流反转（负半周时间长）</strong></p>
<ul>
<li><p><strong>条件</strong>：$t_1 \sim T$ 时间长（负半周宽），或续流电流 $i_a$ 小→续流降至零，此时 $U_{b2}$、$U_{b3}$ 的正电压驱动 $VT_2$、$VT_3$ 导通。</p>
</li>
<li><p><strong>反转电流路径（虚线 3）</strong>：<br>$$<br>+U_s \rightarrow VT_3 \rightarrow B \rightarrow SM \ (\text{电机}) \rightarrow A \rightarrow VT_2 \rightarrow \text{地}<br>$$</p>
</li>
</ul>
<p>电流方向 <span style="color:#FF0000">反向（$B \rightarrow A$）</span>（对应图 5.37 (c) 的 $i_a$ 波形）。</p>
<blockquote>
<p><span style="color:#FF0000"><strong>转向与转速的控制逻辑</strong></span></p>
<p>通过 <span style="color:#FF0000">正半周宽度 $t_1$</span> 和 <span style="color:#FF0000">负半周宽度 $T - t_1$</span> 的对比，决定电机的 <span style="color:#FF0000">转向和转速</span>：</p>
<ol>
<li><strong>正转</strong>：$t_1 &gt; T - t_1 \Rightarrow$ 电压平均值 $U_{AB} &gt; 0$，<strong>电机正转</strong>，正转转速随 $t_1$ 增大而升高（正脉冲越宽，平均电压越高）。</li>
<li><strong>反转</strong>：$t_1 &lt; T - t_1 \Rightarrow$ 电压平均值 $U_{AB} &lt; 0$，<strong>电机反转</strong>，反转转速随 $T - t_1$ 增大而升高（负脉冲越宽，反向平均电压越高）。</li>
<li><strong>停转</strong>：$t_1 &#x3D; T - t_1 \Rightarrow$ 正负脉冲对称，平均电压 $U_{AB} &#x3D; 0$，电机停止。</li>
</ol>
<blockquote>
<p>在一个开关周期内，$AB$ 端的<strong>平均电压</strong>为：</p>
<p>当 $0 \leq t &lt; t_1$ 时，$U_{AB} &#x3D; U_s$；</p>
<p>当 $t_1 \leq t &lt;T $ 时，$U_{AB} &#x3D; -U_s$；<br>$$<br>U_{AB} &#x3D; \frac{t_1}{T} U_s - \frac{T - t_1}{T} U_s<br>$$</p>
<p>$$<br>&#x3D; \left( \frac{2t_1}{T} - 1 \right) U_s<br>$$</p>
<p>$$<br>&#x3D; \rho U_s<br>$$</p>
<p>$$<br>U_{AB} &#x3D; \left( \frac{2t_1}{T} - 1 \right) U_s<br>$$</p>
<p><strong>占空比</strong><br>$$<br>\rho &#x3D; \frac{2t_1}{T} - 1 \quad (-1 \leq \rho \leq 1)<br>$$</p>
</blockquote>
</blockquote>
<h3 id="脉宽调制器（PWM系统控制回路）"><a href="#脉宽调制器（PWM系统控制回路）" class="headerlink" title="脉宽调制器（PWM系统控制回路）"></a>脉宽调制器（PWM系统控制回路）</h3><ul>
<li><p>能将电压信号（代表速度）转换为脉冲宽度的调节变换装置称为<strong>脉宽调制器</strong>。</p>
</li>
<li><p>脉宽调制器的调制信号有两种：<strong>锯齿波和三角波</strong></p>
</li>
</ul>
<p><img src="/blog/./image/Snipaste_2025-07-30_14-17-02.png"></p>
<p><strong>工作原理</strong>：微机输出的脉宽控制信号经驱动器放大，驱动 ＰＷＭ 主电路中的晶体管开关，控制电动机运行，其开关频率及脉冲宽度可采用软件控制，同时对速度和位置反馈信号进行采样，并利用软件对其进行调节。  </p>
<p>脉宽调制器的<strong>优点</strong>如下：</p>
<p>1）响应快。<br>2）电源利用率高。<br>3）动态特性好，响应频带宽。<br>4）稳速精度高。<br>5）损耗小。</p>
<p><strong>缺点</strong>：功率晶体管承受高峰值电流的能力较差。</p>
<p>脉宽调制的<strong>任务</strong>是将连续控制信号变成方波控制信号，加在主回路上功率晶体管的基极，作为输入信号，来控制直流电动机的转速和转矩。</p>
<p><img src="/blog/./image/Snipaste_2025-07-03_14-15-41.png"></p>
<p> <strong>针对此图的补充</strong>：<span style="color:#FF0000">PWM</span> 晶体管功率放大器的工作原理是：三角波发生器产生对称三角波载波 $U_T$，与转速控制电压 $U_I$ 经过加法器叠加后，输入比较器与 0 电位比较，生成占空比随 $U_I$ 变化的 PWM 方波 $U_S$；</p>
<p>该方波经功率放大器放大为驱动信号 $U_P$，借助 PWM 脉宽的平均电压特性调控伺服电动机转速，通过三角波对称性和控制滤波，实现“电压指令 → 脉宽调制 → 功率驱动 → 转速控制”的精准闭环。</p>
<p>核心是利用载波与指令的融合，将模拟电压转换为脉宽信号，最终驱动电机运行。</p>
<h2 id="放大电路中的反馈"><a href="#放大电路中的反馈" class="headerlink" title="放大电路中的反馈"></a>放大电路中的反馈</h2><p><img src="/blog/./image/20250705085329.png"></p>
<h1 id="第六章-电液伺服控制系统"><a href="#第六章-电液伺服控制系统" class="headerlink" title="第六章 电液伺服控制系统"></a>第六章 电液伺服控制系统</h1><h2 id="电液比例流量控制"><a href="#电液比例流量控制" class="headerlink" title="电液比例流量控制"></a>电液比例流量控制</h2><p><u>电液比例流量控制系统</u>用<u>电液比例流量阀</u>来控制<u>系统的速度</u>，也称电液比例速度控制系统，是一种阀控比例系统。</p>
<p> <strong>电液比例速度调节</strong>有三种方式：  </p>
<ul>
<li><p>比例节流调速</p>
</li>
<li><p>比例容积调速</p>
</li>
<li><p>比例容积节流调速</p>
</li>
</ul>
<p><u><strong>比例节流阀</strong>必须与 <strong>溢流阀</strong> 联合使用，才能实现对流量的准确控制。</u></p>
<h3 id="闭环同步调速系统"><a href="#闭环同步调速系统" class="headerlink" title="闭环同步调速系统"></a>闭环同步调速系统</h3><p><img src="/blog/./image/Snipaste_2025-07-03_16-13-32.png"></p>
<p><span style="color:#FF0000">采用两个电液比例调速阀实现闭环同步控制速度系统</span></p>
<h4 id="系统结构框图描述："><a href="#系统结构框图描述：" class="headerlink" title="系统结构框图描述："></a>系统结构框图描述：</h4><ul>
<li>主动液压缸：$1$</li>
<li>随动液压缸：$2$</li>
<li>位移传感器$L_1$、$L_2$输出：$U_1$、$U_2$</li>
<li>电压比较差值：$\Delta U &#x3D; U_2 - U_1$</li>
<li>放大器：$A_1$, $A_2$</li>
<li>比例调速阀：$BQ(1)$, $BQ(2)$</li>
<li>电流信号：$I_1$, $I_2$</li>
<li>基准速度电压：$U_0$</li>
</ul>
<hr>
<p><strong>工作过程</strong>：</p>
<ol>
<li><p>当 $1$ 和 $2$ 双缸同步，则：</p>
<p>$$<br>U_1 &#x3D; U_2, \quad \Delta U &#x3D; U_2 - U_1 &#x3D; 0<br>$$</p>
<p>两缸速度相等。</p>
</li>
<li><p>当 $1$ 和 $2$ 不同步时，则：</p>
<p>$$<br>\Delta U &#x3D; U_2 - U_1 \neq 0<br>$$</p>
<p>若 $U_2 &gt; U_1$，即 2 缸运行较快：</p>
<ul>
<li>此时 $U_0 - \Delta U$ 输入到 $A_2$ 放大器中。</li>
<li>原速度信号 $U_0$ 不变，但 $A_2$ 输出的 $I_2$ 要相应减小。</li>
<li>使得 $BQ_2$ 输出流量比例减小，导致 2 缸速度降低。</li>
<li>当速度再次与缸1相等时，$\Delta U &#x3D; 0$，$I_2$ 恢复。</li>
</ul>
</li>
</ol>
<p>由于 $U_0$ 不变、$I_1$ 不变，因此缸1速度始终不变。</p>
<blockquote>
<p><strong>例题</strong></p>
<p>下图是油缸闭环同步调速系统示意图，图中 $U_1$、$U_2$ 分别是油缸 1 和油缸 2 的速度输出信号，幅度为 $0,V \sim 5,V$。当两缸不同步时，则：$\Delta U &#x3D; U_1 - U_2 \ne 0$作为控制器输出，幅度为 $-5,V \sim 5,V$。</p>
<p>$U_1$、$U_2$ 作为控制器输入，用运算放大器、电阻等元件设计该比例控制器的电路图。可不必标具体参数值。</p>
<p><img src="/blog/./image/Snipaste_2025-07-03_16-13-32.png"></p>
<p><strong>要求完成：</strong></p>
<p>“输入 $U_1$ 与 输入 $U_2$” 构成减法关系。</p>
<p><strong>说明</strong>：答案不唯一，电路图只要完成上述功能即可。</p>
<p><img src="/blog/./image/Snipaste_2025-07-03_17-02-39.png"></p>
<p><img src="/blog/./image/Snipaste_2025-07-09_09-41-34.png"></p>
</blockquote>
<h2 id="比例控制放大器主要电路的构成、原理及功能"><a href="#比例控制放大器主要电路的构成、原理及功能" class="headerlink" title="比例控制放大器主要电路的构成、原理及功能"></a>比例控制放大器主要电路的构成、原理及功能</h2><h3 id="电源电路"><a href="#电源电路" class="headerlink" title="电源电路"></a>电源电路</h3><p><span style="color:#0000FF">① 主要作用</span></p>
<p>从标准电源中获得和分离出比例控制放大器正常工作所需的各种直流稳定电源，并且在电网电压、负载电流及环境温度允许范围内变化时，保证输出直流电压的稳定性。</p>
<p><span style="color:#FF0000">✔</span> 同时，还兼具电源电压极性反接、过流、短路自保护自恢复等非熔断式保护功能，以保证比例控制放大器的工作可靠性。</p>
<hr>
<p><span style="color:#0000FF">② 构成</span></p>
<p>包括<strong>滤波、稳压和过载保护</strong>等部分。</p>
<h3 id="输入接口单元"><a href="#输入接口单元" class="headerlink" title="输入接口单元"></a>输入接口单元</h3><p>用来满足各种外设需要，增强适应性。（包括<u>模拟量接口</u>、<u>数字量接口</u>、<u>遥控接口</u>等）。</p>
<h3 id="信号处理电路"><a href="#信号处理电路" class="headerlink" title="信号处理电路"></a>信号处理电路</h3><p>为适应各种不同控制对象和工况的要求， 比例控制放大器中还有各种信号处理电路，对输入信号进行相应的处理。</p>
<p>最常见的有<u>斜坡信号发生器</u>，<u>阶跃函数发生器</u>，<u>双路平衡电路</u>，<u>初始电流设定电路</u>等。</p>
<h4 id="斜坡信号发生器"><a href="#斜坡信号发生器" class="headerlink" title="斜坡信号发生器"></a><span style="color:#FF0000">斜坡信号发生器</span></h4><ul>
<li><p>以一个设定值<strong>阶跃</strong>作输入信号，斜坡发生器产生一个线慢上升或下降的输出信号。</p>
</li>
<li><p>输出信号的<strong>变化速率</strong>可通过电位器调节。</p>
</li>
</ul>
<p><span style="color:#FF0000">斜坡发生器的作用原理：</span><br>在输入阶跃信号情况下，由于电容C<u>充电的阻滞现象</u>，可使输出电压<u>缓慢连续</u>地变化。<br>调节电阻R能够改变输出电压的斜率，也就是决定电容C的充电速度。</p>
<p><img src="/blog/./image/Snipaste_2025-07-04_09-39-32.png"></p>
<h4 id="阶跃函数发生器"><a href="#阶跃函数发生器" class="headerlink" title="阶跃函数发生器"></a>阶跃函数发生器</h4><p>阶跃函数发生器，在设定值电压<strong>大于</strong>一个较小的电压值 $u_i$ 时产生一个恒定的输出信号，其大小可由 $P_1, P_2$ 调节。当设定值电压<strong>小于</strong> $u_i$ 时，输出信号为零。</p>
<p><img src="/blog/./image/Snipaste_2025-07-04_10-05-37.png"></p>
<h4 id="双路平衡电路"><a href="#双路平衡电路" class="headerlink" title="双路平衡电路"></a><span style="color:#FF0000">双路平衡电路</span></h4><p>在双路比例控制放大器中，为使两个比例电磁铁分别正常动作，且在两个比例电磁铁参数有所不同的情况下仍能得到对称的控制特性，常采用双路平衡电路，</p>
<p>如图 6.18 所示。调节电位器 $P$，使 $B$ 路比例电磁铁控制通道的增益与 $A$ 路比例电磁铁控制通道的增益相同，同时使 $B$ 路控制信号反相，保证比例电磁铁 $A$ 和 $B$ 实现<strong>差动</strong>工作。</p>
<p><img src="/blog/./image/Snipaste_2025-07-04_10-27-41.png"></p>
<h4 id="初始电流设定电路"><a href="#初始电流设定电路" class="headerlink" title="初始电流设定电路"></a>初始电流设定电路</h4><p>主要用于产生比例电磁铁的预激磁电流，调整比例阀的零位死区大小，或避开死区。 使比例阀在设定值输入时，从起始位置迅速启动  </p>
<h4 id="颤振信号发生器"><a href="#颤振信号发生器" class="headerlink" title="颤振信号发生器"></a>颤振信号发生器</h4><p><span style="color:#FF0000">为降低比例电磁铁的摩擦滞环，往往采用在控制信号上叠加颤振信号的方法  </span></p>
<p><img src="/blog/./image/Snipaste_2025-07-04_14-27-46.png"></p>
<ul>
<li><span style="color:#FF0000">调节$R$可改变颤振信号频率，调节$R_1$可改变颤振信号的幅值  </span></li>
<li>图中 $A_1$ 组成同相施密特触发器，$A_2$ 组成反相积分器。</li>
<li>通过 $R_2$ 构成正反馈，形成自激振荡，由 $A_1$ 输出方波，$A_2$ 输出三角波，</li>
<li>方波发生器由三角波触发，积分器 $A_2$ 对方波输出电压积分。</li>
</ul>
<p>为求出三角波的最大值，设方波电压为 $-V_z$，负的电压输入积分器，使它的输出电压为 $u_o$，<br>形成正的斜坡电压。利用叠加原理得：<br>$$<br>\frac{u_o-V_+}{ R_2} &#x3D; \frac{V_+-(-V_z)}{R_1}  \tag{6-1}<br>$$</p>
<p>$$<br>V_+ &#x3D; \frac{R_1}{R_1 + R_2} u_o - \frac{R_2}{R_1 + R_2} V_z \tag{6-1}<br>$$</p>
<p>因 $V_+ &#x3D; 0$ 时，由于比较器负端接地，$A_1$ 改变状态，所以$u_0$最大值出现在 $V_+ &#x3D; 0$ 时，</p>
<blockquote>
<p><span style="color:#FF0000">三角波电压 $u_0$的最大值为何出现在 $V_+ &#x3D; 0$的位置?</span></p>
<ul>
<li><strong>运放 A₁</strong>：输出 <strong>方波</strong>（幅度 $  \pm V_z  $），反相端接地（$  V_- &#x3D; 0  $），同相端 $  V_+  $ 接收两路反馈：</li>
</ul>
<p>支路 1：三角波 $  u_0  $（运放 A₂输出）经电阻 $  R_2  $ 连接到 $  V_+  $；</p>
<p>支路 2：方波（A₁自身输出）经电阻 $  R_1  $ 连接到 $  V_+  $。</p>
<ul>
<li><strong>运放 A₂（积分器）</strong>：对方波积分，输出 **三角波 **（线性上升 &#x2F; 下降），再反馈到 A₁的同相端，形成闭环振荡。</li>
</ul>
<hr>
<p>A1输出状态由 **同相端 与反相端 **的电位关系 决定：</p>
<ul>
<li><p>当 $  \boldsymbol{V_+ &gt; 0}  $：A₁输出 **正饱和电平 **</p>
</li>
<li><p>当 $  \boldsymbol{V_+ &lt; 0}  $：A₁输出 **负饱和电平 **</p>
</li>
<li><p>当 $  \boldsymbol{V_+ &#x3D; 0}  $：是状态切换的 <strong>临界点</strong>（从 “$  V_+ &lt; 0  $” 跳变到 “$  V_+ &gt; 0  $”，或反之）。</p>
</li>
<li><p>本质上是一种电压比较器</p>
</li>
</ul>
<hr>
<ul>
<li>A₁输出 **（负方波），A₂的积分器对 $-V_z$ 积分，使三角波 $  u_0  $ **线性上升（积分输入为负，输出反向增大，即从负向向正向上升）。</li>
</ul>
<p>$$<br>u_0&#x3D;-\frac{1}{RC} \int u_{o1} dt&#x3D;\frac{1}{RC} \int V_z dt<br>$$</p>
<ul>
<li><p>随着 $  u_0  $ 上升，支路 1 的反馈使 $  V_+  $ 逐渐升高。$V_+ &#x3D; \frac{R_1}{R_1 + R_2} u_o - \frac{R_2}{R_1 + R_2} V_z \tag{6-1}$</p>
</li>
<li><p>当 $  u_0  $ 上升到某一值时，$  V_+  $ 恰好等于 <strong>0</strong>：</p>
</li>
<li><p>此前，$  V_+ &lt; 0  $，A₁保持输出 $-V_z$，$  u_0  $ 持续上升；</p>
</li>
<li><p>当 $  V_+ &#x3D; 0  $ 瞬间，**继续上升的$u_0$ 会使 触发 A₁ **状态翻转（输出从 $-V_z$ 跳变为 $+V_z$）。</p>
</li>
<li><p>A₁输出跳变为 $+V_z$ 后，积分器的输入极性反转（从 “积分 $-V_z$” 变为 “积分 $+V_z$”），导致三角波 $  u_0  $ <strong>从上升转为下降</strong>。因此：</p>
<ul>
<li>$V_+&#x3D;0$是上升阶段的终点**，此时 $  u_0  $ 达到 **正向最大值</li>
</ul>
</li>
</ul>
</blockquote>
<p>由式 (6-1) 得：<br>$$<br>u_{o\max} &#x3D; \frac{R_2}{R_1} V_z \tag{6-2}<br>$$</p>
<p>同理，三角波的<strong>最低电压</strong>为：</p>
<p>(方波电压为 $V_z$,  $V_+ &#x3D; \frac{R_1}{R_1 + R_2} u_o + \frac{R_2}{R_1 + R_2} V_z \tag{6-1}$  $V_+&#x3D;0$时有$u_{o\min}$ )<br>$$<br>u_{o\min} &#x3D; -\frac{R_2}{R_1} V_z<br>$$</p>
<p><strong>最大振幅</strong>为：<br>$$<br>u_{o\max} - u_{o\min} &#x3D; 2 \frac{R_2}{R_1} V_z \tag{6-3}<br>$$<br><strong>可见，改变 $R_2$ 与 $R_1$ 的比值，可改变它的振幅</strong>。下面计算三角波的周期和频率。</p>
<p>当 $t &#x3D; 0$ 时，设积分器的输入电压为 $-V_z$，则 $A_2$ 的输出电压为：</p>
<p>$$<br>u_o(t) &#x3D; -\frac{1}{RC} \int_0^t (-V_z) , dt + u_o(t)\big|_{t&#x3D;0}<br>$$</p>
<p>积分后得：</p>
<p>$$<br>u_o(t) &#x3D; \frac{V_z}{RC} t - V_z \frac{R_2}{R_1} \tag{6-4}<br>$$</p>
<p>当 $t &#x3D; \frac{T}{2}$ 时，方波发生器翻转，此时应有 $V_+ &#x3D; 0$，<br>$u_o\left[\frac{T}{2}\right] &#x3D; u_{o\max} &#x3D; \frac{R_2}{R_1} V_z$，将 $t &#x3D; \frac{T}{2}$ 代入式 (6-4)，得：</p>
<p>$$<br>T &#x3D; \frac{4 R_2 RC}{R_1} \tag{6-5}<br>$$<br>振荡频率为：</p>
<p>$$<br>f &#x3D; \frac{1}{T} &#x3D; \frac{R_1}{4RC R_2} \tag{6-6}<br>$$</p>
<p>可见频率与幅值无关，改变 $R, C$ 或 $R_1&#x2F;R_2$ 均可改变频率。<br>然而，改变 $R_1 &#x2F; R_2$ 虽不影响方波的输出幅值，但会影响三角波的幅值。<br>方波的幅值由下式确定：<br>$$<br>u_{o1} &#x3D; 2(E_w + V_D) \tag{6-7}<br>$$</p>
<h4 id="测量放大电路"><a href="#测量放大电路" class="headerlink" title="测量放大电路"></a>测量放大电路</h4><p>在位移电反馈比例控制放大器中，为了通过装在比例阀上的位移传感器构成电反馈闭环，往往附加有与传感器匹配的<strong>测量放大电路</strong>  </p>
<h4 id="功率放大级"><a href="#功率放大级" class="headerlink" title="功率放大级"></a>功率放大级</h4><ul>
<li><p>功率放大级主要由<u>信号放大</u>和<u>功率驱动电路</u>组成  </p>
</li>
<li><p>根据功率放大级工作原理的不同，比例控制放大器有<u>模拟式</u>和<u>开关式</u>之分  </p>
</li>
<li><p>模拟式功率放大级：这种功率放大级技术比较成熟，结构简单，稳态控制性能较好，但功耗较大  </p>
</li>
<li><p>开关式功率放大级有<u>脉宽调制、脉频调制、脉幅调制、脉码调制</u>等多种方式  ，以<strong>脉宽调制（ＰＷＭ ）式最为常用</strong>  </p>
</li>
<li><p><strong>脉宽调制功率放大级</strong>  ：由脉宽调制器、功率驱动电路、电流负反馈单元、电流调节器等组成</p>
</li>
</ul>
<p><span style="color:#FF0000"><strong>脉宽调制式功率放大级</strong></span></p>
<p><img src="/blog/./image/Snipaste_2025-07-04_15-03-01.png"></p>
<table>
<thead>
<tr>
<th>运放</th>
<th>角色</th>
<th>核心贡献</th>
</tr>
</thead>
<tbody><tr>
<td>A₁</td>
<td>电流调节器</td>
<td>放大误差信号</td>
</tr>
<tr>
<td>A₂</td>
<td>比较器</td>
<td>电压→脉冲信号</td>
</tr>
<tr>
<td>A₃</td>
<td>施密特触发器</td>
<td>生成方波</td>
</tr>
<tr>
<td>A₄</td>
<td>反相积分器</td>
<td>方波→三角波</td>
</tr>
<tr>
<td>A₃+A₄</td>
<td>三角波调制信号发生器</td>
<td>生成三角波</td>
</tr>
<tr>
<td>A₂+A₃+A₄</td>
<td>脉宽调制器</td>
<td><strong>将连续变化信号转换成脉宽调制信号</strong></td>
</tr>
<tr>
<td>A₅</td>
<td>差动电压放大器</td>
<td>对电流采样信号进行综合、滤波和放大，构成电流负反馈</td>
</tr>
</tbody></table>
<ul>
<li><p>当输入电压 $u_i \leq 0$ 时，$A_1$ 正向饱和，$A_2$ 负向饱和，<strong>功率驱动电路各功放管截止</strong>，输出电流 $i &#x3D; 0$。</p>
</li>
<li><p>当 $u_i &gt; 0$ 时，$u_i$ 与反馈信号 $u_f$ 相比较，其差值经过电流调节器 $A_1$ 运算放大后输给脉宽调制器，<strong>脉宽调制器</strong><u>将电流调节器输出的连续信号转换成脉冲宽度与其大小成比例的脉冲信号</u>，该脉冲信号经过功率驱动电路功率放大，在比例电磁铁线圈两端产生与之同相的脉冲电压 $u_s$，当开关频率远高于三角电磁线圈的截止频率时，由于比例电磁铁线圈的惯性，在线圈上就可得到平均值与脉宽成比例的、带有交流纹波分量的直流电流  </p>
</li>
<li><p>与此同时，输出电流经过采样电阻 $R_f$ 检测，滤波及放大，反馈到输入端，构成输出电流平均值的闭环调节  。此闭环削弱了前向放大环节非线性，增益变化，负载阻抗变化以及电源电压波动对输出电流的影响。</p>
</li>
</ul>
<blockquote>
<p><span style="color:#FF0000">脉宽调制式功率放大级的工作原理为：</span></p>
<ol>
<li>当 $u_i \leq 0$ 时，$A_1$、$A_2$ 处于饱和状态，<strong>功率驱动电路各功放管截止</strong>，输出电流 $i &#x3D; 0$。</li>
<li>当 $u_i &gt; 0$ 时，$u_i$ 与反馈信号 $u_f$ 相比较，其差值经过电流调节器 $A_1$ 运算放大后输给由$A_2,A_3, A_4$ 构成的脉宽调制器，</li>
<li><strong>脉宽调制器</strong><u>将电流调节器输出的连续信号转换成脉冲宽度与其大小成比例的脉冲信号</u>，该脉冲信号经过功率驱动电路功率放大，在比例电磁铁线圈两端产生<strong>与之同相的脉冲电压 $u_s$</strong>，当开关频率远高于三角电磁线圈的截止频率时，由于比例电磁铁线圈的惯性，在线圈上就可得到<u>平均值与脉宽成比例的、带有交流纹波分量的直流电流</u></li>
<li>输出电流经过采样电阻 $R_f$ 检测，滤波及放大，反馈到输入端，构成输出电流平均值的闭环调节</li>
</ol>
</blockquote>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 1.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 4.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 5.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 6.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 7.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 8.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 9.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 10.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 11.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 12.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 13.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 14.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 15.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 16.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 17.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 18.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 19.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 20.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 21.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 22.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 23.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 24.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 25.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 26.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 27.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 28.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 29.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 30.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 31.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 32.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 33.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 34.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 35.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 36.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 37.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 38.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 39.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 40.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 41.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 42.jpg)</p>
<p>![](.&#x2F;image&#x2F;机电一体化真题2.pdf 43.jpg)</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>机电一体化分析与建模</tag>
      </tags>
  </entry>
  <entry>
    <title>笼中雀</title>
    <url>/blog/2025/02/25/%E7%AC%BC%E4%B8%AD%E9%9B%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>总有些时间，是想写点什么，但又感觉没什么好写的。</p>
<blockquote>
<p>以前总想着如果自己没能做到一些东西，通过逃避是可以躲过去的。但其实现在才发现人生上一个阶段没解决的问题，只会在下一个阶段更加放大，现在好像已经躲不掉了。 或许早该重新梳理一遍曾经的路了，沉下心来先解决 一些曾经没解决的问题！</p>
</blockquote>
<hr>
<p>一路走来，渐渐认识到，我一直是个很难做出决定的人。在每次决定前都会犹豫，所以就习惯拖着，最后发现已经无需做决定了，时间已经排除掉会犹豫的选项了。</p>
<hr>
<blockquote>
<p>2025&#x2F;4&#x2F;21 21:07 小雨 写于光机所研究生部</p>
</blockquote>
<p>前几天的小事有感而发。</p>
<p>对于不喜欢的人，我是一个字都不愿意多说的，所以在外人看来交流时很拘谨，说话的分寸感很强，界限拉满。</p>
<p>对于有些人的敌对感好似并不是因为某件事亦或者某个人突然产生的，而是经过了很长时间，以现在的视角回忆当年的事，慢慢察觉出自己当年的心境和行为并不是很成熟，说了违心的话，做了后悔的事，因此便试着将当年与之相关的人圈定在一起，在心底慢慢琢磨；而随着时间发展，等当年的某些人再次遇到时，这些年的思考以及酝酿的情绪便会因一些奇奇怪怪的事拉扯出来，当年的事便会因为这些年潜意思的思考形成对某些人的固有观感，差的人自然而然就无话可说。</p>
<hr>
<blockquote>
<p>2025&#x2F;5&#x2F;9 晴 写于光机所研究生部宿舍</p>
</blockquote>
<p>在经历了很多事后，发现人跟人之间是很不一样的。一个人在某个阶段的选择会根据当下所处的环境以及周围人的意见而有显著的差别，因为不同的人可接受的沉默成本是不一样。</p>
<blockquote>
<p>2025&#x2F;9&#x2F;19 多云 写于光机所图书馆</p>
</blockquote>
<p>在经历很多事后，慢慢认识到自己性格上的缺陷。当负面情绪涌来的时候，越来越讨厌现在的自己；往外推的好像正是自己渴望的。</p>
<hr>
<p>置身其中，好一个笼中雀。</p>
]]></content>
      <categories>
        <category>想法</category>
      </categories>
      <tags>
        <tag>笼中雀</tag>
      </tags>
  </entry>
  <entry>
    <title>自然辩证法</title>
    <url>/blog/2025/08/07/%E8%87%AA%E7%84%B6%E8%BE%A9%E8%AF%81%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><hr>
<h1 id="辩证唯物主义自然观的主要观点和特征？"><a href="#辩证唯物主义自然观的主要观点和特征？" class="headerlink" title="辩证唯物主义自然观的主要观点和特征？"></a><span style="color:#FF0000">辩证唯物主义自然观的主要观点和特征？</span></h1><blockquote>
<p><span style="color:rgb(28, 57, 123)"><strong>定义：</strong></span>关于自然界及其与人类关系的总观点</p>
<p><span style="color:rgb(28, 57, 123)"><strong>主要观点：</strong></span>自然界是客观的、变化发展的<strong>物质世界</strong>；物质在其永恒的循环中按照规律<strong>运动</strong>；<strong>物质运动</strong>在量和质的方面都是不灭的，时间和空间是<strong>物质</strong>的固有属性和存在方式；<strong>人</strong>是自然界的一部分，意识和思维是<strong>人脑</strong>的机能；<strong>实践</strong>是人类有目的地认识和改造自然界的能动活动，是<strong>人类存在</strong>的本质和方式；<strong>人</strong>是自然界的一部分，“人靠自然界生活”，“人与自然是生命共同体”；<strong>“人</strong>与自然是一种共生关系，对自然的伤害最终会伤及人类自身”。 认识自然界要遵循客观性原则。</p>
<p><span style="color:rgb(28, 57, 123)"><strong>特征：</strong></span></p>
<p>①<strong>实践性</strong>：主张自然界是人类社会<strong>实践</strong>的产物，<strong>实践</strong>对认识自然界起到决定作用</p>
<p>②<strong>历史性</strong>：主张<strong>自然界的历史</strong>是<strong>人类生成的历史</strong>和<strong>自然界对人的生成的历史</strong>，认识自然界也是以实践为基础的过程</p>
<p>③<strong>辩证性</strong>：以实践论为基础，实现唯物论和辩证法的统一、天然自然界和人工自然界的统一、人类史和自然史的统一、人与自然界关系上的能动性和受动性的统一</p>
<p>④<strong>批判性</strong>：辩证唯物主义自然观批判众多旧观念和错误思想，引入自觉辩证法用于自然观和历史观 。</p>
</blockquote>
<h1 id="如何把握系统自然观、人工自然观和生态自然观对认识人与自然辩证关系的意义和作用-？（如何理解系统自然观、人工自然观和生态自然观的辩证关系-）"><a href="#如何把握系统自然观、人工自然观和生态自然观对认识人与自然辩证关系的意义和作用-？（如何理解系统自然观、人工自然观和生态自然观的辩证关系-）" class="headerlink" title="如何把握系统自然观、人工自然观和生态自然观对认识人与自然辩证关系的意义和作用 ？（如何理解系统自然观、人工自然观和生态自然观的辩证关系?）"></a><span style="color:#FF0000">如何把握系统自然观、人工自然观和生态自然观对认识人与自然辩证关系的意义和作用 ？（如何理解系统自然观、人工自然观和生态自然观的辩证关系?）</span></h1><blockquote>
<p>（1）它们都围绕人与自然界关系这个主题展开研究，丰富和发展了马克思主义自然观的<strong>本体论、认识论、方法论和价值论</strong>；它们都坚持天然自然界、人工自然界和生态自然界的辩证统一，都为<strong>贯彻落实新发展理念</strong>和<strong>建设生态文明</strong>奠定理论基础。</p>
<p>（2）它们在<strong>认识和处理</strong>人与自然界的关系方面<span style="color:rgb(28, 57, 123)"><strong>各有侧重</strong></span>：系统自然观为正确认识和处理人与自然界的关系<strong>提供了新的思维方式</strong>；人工自然观<u>突出并反思</u>了<strong>人的主体性和创造性</strong>；生态自然观站在<strong>人类文明的立场</strong>，强调了<strong>人与自然界的协调发展和生态文明建设</strong>。</p>
<p>（3）它们在认识和处理人与自然界的关系方面<span style="color:rgb(28, 57, 123)"><strong>相互关联</strong></span>：系统自然观通过<strong>系统思维方式</strong>，为人工自然观和生态自然观<strong>提供了方法论基础</strong>；人工自然观通过突出<strong>人的主体性和实践性</strong>，为系统自然观和生态自然观<strong>提供了认识论前提</strong>；生态自然观通过强调人与自然界的<strong>统一性、协调性</strong>，为系统自然观和人工自然观<strong>指明了发展目标</strong>。</p>
<p>（4）生态自然观为生态文明建设提供理论基础。生态自然观<strong>提供引领</strong>系统自然观和人工自然观，积极推进“美丽中国”的宏伟蓝图的实现。</p>
</blockquote>
<h1 id="论述马克思和恩格斯的关于科学分类的思想"><a href="#论述马克思和恩格斯的关于科学分类的思想" class="headerlink" title="论述马克思和恩格斯的关于科学分类的思想"></a><span style="color:#FF0000">论述马克思和恩格斯的关于科学分类的思想</span></h1><blockquote>
<p><span style="color:rgb(28, 57, 123)"><strong>恩格斯：</strong></span></p>
<ul>
<li><p>恩格斯依据<strong>物质运动形式</strong>对<u>自然科学</u>进行了分类。</p>
</li>
<li><p>恩格斯将<u>自然科学的研究对象</u>规定为<u>运动着的物体</u>，并将科学具体分为数学、天文学、物理学、化学、生物学等</p>
</li>
</ul>
<p><span style="color:rgb(28, 57, 123)"><strong>马克思：</strong></span></p>
<ul>
<li><p><strong>马克思的“科学”<strong>不仅是西方意义上的实证的<u>自然科学</u>，可理解为同时包含了</strong>社会</strong>、<strong>历史</strong>科学的“大科学”。</p>
</li>
<li><p>对于“一门科学”中两大部分——<strong>自然科学</strong>和<strong>历史科学</strong>，马克思认为两者之前一直处于“<strong>疏远</strong>”的关系中，并认为<strong>自然科学</strong><u>脱离</u>人和社会的维度是不可能的，自然科学与历史科学最终将走向统<strong>一</strong>。</p>
</li>
</ul>
</blockquote>
<h1 id="结合马克思主义观点，论述科学技术与哲学的辩证关系"><a href="#结合马克思主义观点，论述科学技术与哲学的辩证关系" class="headerlink" title="结合马克思主义观点，论述科学技术与哲学的辩证关系?"></a><span style="color:#FF0000">结合马克思主义观点，论述科学技术与哲学的辩证关系?</span></h1><blockquote>
<p>马克思、恩格斯在对科学技术的研究中，一直强调科学技术和哲学的密切关系。</p>
<p><strong><span style="color:rgb(28, 57, 123)">科学技术对哲学具有推动作用</span></strong></p>
<p>恩格斯强调科学技术对哲学的推动作用，认为推动哲学前进的是<strong>自然科学的发展</strong>和<strong>社会大工业生产</strong></p>
<p><strong><span style="color:rgb(28, 57, 123)">科学的发展也受到哲学的制约和影响</span></strong></p>
<p>恩格斯针对一些科学家认为科学可以<u>脱离哲学</u>、可以<u>抛弃哲学</u>的幻想指出，<strong>科学与哲学在研究对象上具有本质上的共同点和内在的一致性</strong>。<strong>科学研究作为一种认识活动，必须通过理论思维才能揭示对象的本质和规律，这就自然地与哲学发生紧密的联系。</strong></p>
<p>自然辩证法作为马克思主义哲学与科学的交叉学科，一方面需要不断汲取科学的最新发展成果,实现理论创新。另一方面它所提供的哲学思维方法和思维规律对于我们深入科学研究也具有无可替代的作用。</p>
</blockquote>
<h1 id="科学的本质特征"><a href="#科学的本质特征" class="headerlink" title="科学的本质特征"></a><span style="color:#FF0000">科学的本质特征</span></h1><blockquote>
<p>（1）<strong>客观性和实证性</strong>。&#x3D;&#x3D;自然科学&#x3D;&#x3D;是对自然事物、自然过程和自然规律的真实的或客观的<u>反映</u>，<u>必须以</u>实验事实为基础，<u>必须有</u>实证性的材料和数据，<u>实证性</u>是科学特别是自然科学的一个基本的和显著的特征。</p>
<p>（2）<strong>探索性和创造性</strong>。科学是<u>认识客观世界</u>的动态过程。科学与按既定规程运作的物质生产过程<u>不同</u>，科学活动面对的是未知的或知之甚少的世界，它又难以完全按预定的目的和计划进行，而有其<u>不确定性和强烈的探索性</u>。科学的创造性体现在相互联系的两个方面：一是不断解释自然事物的新的属性和新的自然过程，提出新的观点和原理；二是运用新知识去创造物质文明的新成果。</p>
<p>（3）<strong>通用性和共享性</strong>。自然科学知识具有通用性和共享性，不存在与特定国家、特定民族或特定集团的特殊利益相关的自然科学，所有的人都可以利用自然科学知识。</p>
<p>（4）<strong>现代科学通过技术体现</strong>。人们一般认为，技术是科学的应用，但现代科学的发展过程中技术起到了<u>先导作用</u>，现代科学是通过或者借助于技术来完成的</p>
</blockquote>
<hr>
<h1 id="技术的特征"><a href="#技术的特征" class="headerlink" title="技术的特征"></a><span style="color:#FF0000">技术的特征</span></h1><blockquote>
<p>技术&#x3D;&#x3D;本质上&#x3D;&#x3D;体现<strong>人对自然的能动关系</strong>，属<strong>直接生产力</strong>，是自然性和社会性、物质性和精神性、中立性与价值性、主体性和客体性、跃迁性和累积性的统一。</p>
<p><code>自社物精，中价主客，跃积统一。</code></p>
<p>（1）<span style="color:rgb(28, 57, 123)"><strong>自然性和社会性</strong></span>。</p>
<ul>
<li><p>技术是<strong>客观自然界</strong>的一部分，符合自然物质的<u>运动规律</u>，具有<strong>自然性</strong>；</p>
</li>
<li><p>又需<strong>服务人类</strong>的目的，满足<strong>社会的需要</strong>，受社会经济、政治和文化的制约。</p>
</li>
</ul>
<p>（2）<span style="color:rgb(28, 57, 123)"><strong>物质性和精神性</strong></span></p>
<p>技术是实践中改造自然的 <strong>资料与手段</strong>（物质性），</p>
<p>也是  <strong>实践的知识体系</strong>（精神性）。</p>
<ul>
<li>马克思明确提出作为<strong>活动方式</strong>的<strong>技术手段</strong>，除了物质因素外还有精神因素，是二者在生产劳动过程中的统一</li>
</ul>
<p><strong><span style="color:rgb(28, 57, 123)">（3）中立性与价值性</span></strong></p>
<p>任何技术既具 <strong>方法论工具层面的中立性</strong>，又蕴含着一定的善恶、对错甚至好坏的<strong>价值取向</strong>。</p>
<p>其统一源于技术的<u>内在价值</u>与技术的<u>现实价值</u>的统一</p>
<p><strong><span style="color:rgb(28, 57, 123)">（4）主体性和客体性</span></strong></p>
<ul>
<li><p>&#x3D;&#x3D;技术&#x3D;&#x3D;是人对自然的能动&#x3D;&#x3D;过程&#x3D;&#x3D;，<strong>人们的知识、技能、经验</strong> 这些<u>主体要素</u>有重要的作用</p>
</li>
<li><p>&#x3D;&#x3D;技术&#x3D;&#x3D;还是 <strong>精神向物质转化</strong>，知识转化为<strong>物质手段和实体</strong>的&#x3D;&#x3D;过程&#x3D;&#x3D;。</p>
</li>
<li><p><strong>技术</strong>是主体的知识、技能、经验与客体要素的<strong>统一</strong></p>
</li>
</ul>
<p><strong><span style="color:rgb(28, 57, 123)">（5）跃迁性和累积性</span></strong></p>
<ul>
<li><strong>跃迁性</strong>：不同历史时期主导技术不同</li>
<li><strong>累积性</strong>：新技术并非否定旧技术，而是经过一个 <strong>扬弃</strong>的过程，形成技术的&#x3D;&#x3D;多层次性&#x3D;&#x3D;和多种技术的&#x3D;&#x3D;相互融合特征&#x3D;&#x3D;</li>
</ul>
</blockquote>
<h1 id="归纳与演绎"><a href="#归纳与演绎" class="headerlink" title="归纳与演绎 "></a><span style="color:#FF0000">归纳与演绎 </span></h1><blockquote>
<p><strong><span style="color:#FF0000">结合恩格斯的观点，分析归纳与演绎的辩证关系及其对科学研究的意义</span></strong></p>
<p>&#x3D;&#x3D;<strong>单独运用的局限</strong>&#x3D;&#x3D;</p>
<ul>
<li><p>归纳是 从<strong>特殊</strong>到<strong>一般</strong>的<u>推理方法</u>，单纯运用会遭遇“归纳难题”；     </p>
</li>
<li><p>演绎是 从<strong>一般</strong>到<strong>特殊</strong>的必然<u>推理方法</u>，单纯运用无法持续推进<u>科学实践</u>的<code>新发现、新发明</code>。</p>
</li>
</ul>
<p>&#x3D;&#x3D;<strong>辩证关联（恩格斯的观点）</strong>&#x3D;&#x3D; </p>
<ul>
<li><p>归纳与演绎如同综合和分析，<strong>相互关联、相辅相成</strong>;</p>
</li>
<li><p>只有把归纳与演绎相互结合起来，才能形成归纳与演绎的辩证思维，才能推动科学研究</p>
</li>
</ul>
<p>&#x3D;&#x3D;<strong>实践中的相互作用</strong>&#x3D;&#x3D;</p>
<p><strong>归纳是演绎的基础</strong>：演绎所需的<u>合理</u><strong>假定前提</strong>，源于对<u>大量实践中</u>无反例事实的归纳；     </p>
<p><strong>演绎指导归纳</strong>：演绎为归纳确定合理性与方向；  </p>
<p>归纳与演绎在实践中 <strong>相互渗透、相互转化</strong>，</p>
</blockquote>
<h1 id="科学观察、科学实验与科学理论的关系"><a href="#科学观察、科学实验与科学理论的关系" class="headerlink" title="科学观察、科学实验与科学理论的关系  "></a><span style="color:red">科学观察、科学实验与科学理论的关系  </span></h1><blockquote>
<p><span style="color:blue"> 观察</span></p>
<ul>
<li><p>传统观点认为观察是<strong>中性</strong>的，<u>理论依赖观察</u></p>
</li>
<li><p><u>现代科学哲学</u>认为<u>观察渗透着理论</u></p>
</li>
</ul>
<p><span style="color:blue"> 实验</span></p>
<p><u>科学实验哲学</u>提出，实验有自己独立的生命，以反对&#x3D;&#x3D;实验&#x3D;&#x3D;完全<strong>负载</strong>&#x3D;&#x3D;理论&#x3D;&#x3D;的极端观点。   </p>
<p> <span style="color:blue">马克思主义的科学方法论</span></p>
<ul>
<li>马克思主义的科学方法论&#x3D;&#x3D;提出了&#x3D;&#x3D;观察、特别是实验和理论有<strong>双向相互作用</strong>的&#x3D;&#x3D;观点&#x3D;&#x3D;；   </li>
<li>在科学发展中，&#x3D;&#x3D;实验相比理论&#x3D;&#x3D;，实验的<strong>实践性</strong>更强，因而具有更为<strong>基础</strong>的地位；实践比理论总是更<strong>积极活跃</strong>，实验的<strong>新发现</strong>不断<u>推动</u>理论的进步，<u>修正</u>理论，<u>指引</u>理论的发展；  </li>
<li>同样，理论一旦建立，就<strong>规范</strong>着实验，为实验的&#x3D;&#x3D;设计&#x3D;&#x3D;提供理论<strong>框架</strong>和<strong>指导</strong>，使得实验更具有<strong>理性的色彩</strong>。</li>
<li>观察、实验与理论的<strong>三螺旋生命之缠绕</strong>和相互作用，才是科学<strong>实践</strong>的真实过程。</li>
</ul>
<p><code>（双向相互作用，实验→理论，理论→实验，三螺旋）</code></p>
<p><span style="color:blue">如何对待</span></p>
<p>观察、实验与理论之间存在复杂的多样性关系，其相互关系因科学发展阶段和学科类型而异。只有采取演化的、过程的和多样性的观点，才能较为正确、全面地反映三者的真实关系</p>
</blockquote>
<h1 id="科学技术文化与人文文化的冲突与协调"><a href="#科学技术文化与人文文化的冲突与协调" class="headerlink" title="科学技术文化与人文文化的冲突与协调"></a><span style="color:#FF0000">科学技术文化与人文文化的冲突与协调</span></h1><blockquote>
<p><span style="color:blue">冲突</span></p>
<ul>
<li><strong>科学家视角</strong>：认为人文学者智力低下，输出无实际价值的 “闲言碎语”，忽视物质世界，缺乏远见、散漫无序；</li>
<li><strong>人文学者视角</strong>：认为科学家像 “思考与计算的机器”，缺乏对宇宙、自然、社会及人生的细微体验，漠视内心世界，浅薄乐观、刻板老套 。</li>
</ul>
<p><span style="color:blue">协调</span></p>
<ol>
<li><strong>承认文化差异</strong></li>
</ol>
<p>自然科学与人文学科在 <strong>认识对象、方法、特征、目的、评判认识的标准以及认识的功能</strong> 上本质不同，经过科学教育培养出来的人和经过人文教育培养出来的人，在科学文化和人文文化素养方面存在差异</p>
<ol start="2">
<li><strong>加强沟通与互补</strong></li>
</ol>
<ul>
<li>&#x3D;&#x3D;加强&#x3D;&#x3D;科学工作者与人文工作者之间的&#x3D;&#x3D;沟通和对话&#x3D;&#x3D;，使两种文化相互宽容、相互借鉴、相得益彰</li>
<li>科学工作者需关注 “人及人的存在”，涵养 <strong>人文精神</strong></li>
<li>人文学者需借鉴科学思维，关注事实功用，涵养 <strong>科学精神</strong></li>
</ul>
</blockquote>
<h1 id="科学技术专家知识和决策的局限性"><a href="#科学技术专家知识和决策的局限性" class="headerlink" title="科学技术专家知识和决策的局限性"></a><span style="color:#FF0000">科学技术专家知识和决策的局限性</span></h1><blockquote>
<p>在<code>科学技术</code><strong>风险评价</strong>与<strong>决策</strong>的主体上，有人认为，科学是例外的，<strong>享有特殊的地位，具有特殊的品质</strong>，有关<code>科学政策</code>应该置于一个特定的范围，由科学技术专家进行，这就是科学例外论。</p>
<p>&#x3D;&#x3D;科学例外论四个方面&#x3D;&#x3D;</p>
<p>一是<strong>知识论的例外论</strong>——<code>科学</code>获得了真理性的认识，<code>科学</code>是好的，<code>政治公共体系</code>应该<u>接受</u>科学家的建议，<u>支持</u>科学事业；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;科学→政治公共体系</span><br><span class="line">&gt;好的→接收、支持</span><br></pre></td></tr></table></figure>



<p>二是<strong>柏拉图式的例外论</strong>——<code>科学及其应用</code>是复杂的和深奥的，<code>公众</code>无法理解，所以也就不能<u>参与</u>，<code>科学政策</code>不受<code>民主决策</code>控制，应交由科学家进行；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;科学及其应用→公众</span><br><span class="line">&gt;复杂深奥→不能参与→不受控制</span><br></pre></td></tr></table></figure>



<p>三是社<strong>会学的例外论</strong>——<code>科学</code>具有一个能够<strong>自我管理</strong>的独特的<strong>规范秩序</strong>，<code>科学家</code>能够<strong>自我管理</strong>和<strong>理性批判</strong>，<strong>能够</strong>修正自身的不当和错误，<strong>能够</strong>正确决策，不需要其他决策主体如公众的参与；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;科学具有→科学家能够→其他决策主体</span><br><span class="line">&gt;规范秩序→管理批判，修正不当错误→不需要参与</span><br></pre></td></tr></table></figure>



<p>四是<strong>经济学的例外论</strong>——<code>科学</code>是为了在将来<strong>获得收益</strong>而就当前的资源进行的独特<u>投资</u>，是政府为了提高未来的<strong>经济劳动力</strong>所选择的最佳<u>投资对象</u>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;科学→政府</span><br><span class="line">&gt;投资→投资对象</span><br></pre></td></tr></table></figure>



<p>&#x3D;&#x3D;对科学例外论的批判&#x3D;&#x3D;</p>
<ol>
<li><strong>经济学例外论</strong>：科技风险具<strong>不确定性</strong>、<strong>增殖性</strong>、<strong>潜在性</strong>、<strong>不可逆性</strong>，一旦发生，对<strong>自然环境</strong>、<strong>人类健康</strong>、<strong>社会经济</strong>冲击巨大，无法通过未来收益抵消，故该论不成立。</li>
<li><strong>知识论例外论</strong>：面对核电站等复杂对象，科学认识<strong>复杂多变</strong>，科技专家<strong>存在</strong>无法直接感知、完全认识或量化的<strong>盲区</strong>，故该论错误。</li>
<li><strong>社会学例外论</strong>：科技风险决策中，专家可能因个人利益优先，沦为政治或经济利益的俘虏，无法保证客观公正，故该论错误。</li>
</ol>
</blockquote>
<h1 id="深刻剖析和准确阐释新一轮科技革命和产业变革的特点与社会影响"><a href="#深刻剖析和准确阐释新一轮科技革命和产业变革的特点与社会影响" class="headerlink" title="深刻剖析和准确阐释新一轮科技革命和产业变革的特点与社会影响"></a><span style="color:#FF0000">深刻剖析和准确阐释新一轮科技革命和产业变革的特点与社会影响</span></h1><blockquote>
<p><span style="color:blue"><code>全球科技创新</code>呈现出的新的<code>发展态势</code>和<code>特征</code></span></p>
<ul>
<li>第一，<code>新科技革命</code>和<code>产业变革</code>正在孕育兴起，一些重要<code>科学问题</code>和<code>关键核心技术</code>已经呈现出<strong>革命性突破的先兆</strong>，<code>重大颠覆性技术</code>不断涌现。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;新科技革命→→产业变革→→一些重要科学问题→→关键核心技术→→重大颠覆性技术</span><br></pre></td></tr></table></figure>



<ul>
<li><p>第二，<code>学科之间交叉融合</code>是<code>新科技革命</code>的另一个<strong>重要特征</strong>，也是新科技革命呈现<strong>革命性突破</strong>的<u>原因</u>。</p>
</li>
<li><p>第三，<code>科学经技术</code>向<code>产业</code>的成果转化的速度加快，<code>科技创新链条</code><u>更加灵巧</u>，<strong>技术更新</strong>和<strong>成果转化</strong><u>更加快捷</u></p>
</li>
<li><p>第四，<code>新科技革命</code>的兴起<strong>动因</strong>是人类社会的<strong>生产、生活需要。</strong></p>
</li>
<li><p>第五，<code>新科技革命</code>和<code>产业变革</code>深刻地改变着世界的政治、经济、文化和社会生活。</p>
</li>
</ul>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">态势特征→→原因→→转化→→动因→→影响</span><br></pre></td></tr></table></figure>

<p> <span style="color:blue">中国的应对策略</span></p>
<p> 为了更好顺应<code>新科技革命</code>和<code>产业变革</code>，首先要<strong>看清</strong>世界科技发展大势，牢牢<strong>把握</strong>科技进步大方向，抓紧<strong>制定</strong>新的科技发展战略，<strong>抢占</strong>科技和产业制高点。</p>
<p> 我们必须高度重视、密切跟踪、迎头赶上。</p>
</blockquote>
<h1 id="大力发展与民生相关的科学技术"><a href="#大力发展与民生相关的科学技术" class="headerlink" title="大力发展与民生相关的科学技术"></a><span style="color:#FF0000">大力发展与民生相关的科学技术</span></h1><blockquote>
<p><strong><span style="color:blue">核心立场与目标</span></strong></p>
<ul>
<li>习近平始终坚持<code>科学技术发展</code>以<code>人民为中心</code>的<strong>立场</strong>，强调要<strong>通过</strong>大力发展<u>与民生相关的科学技术</u>，<strong>着力解决</strong>人民群众所需所急所盼，<strong>让</strong>人民共享经济、政治、文化、社会、生态等各方面<u>发展成果</u>，有更多、更直接、更实在的获得感、幸福感、安全感，实现全体人民共同富裕。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;xx以xx的立场</span><br></pre></td></tr></table></figure>



<p><strong><span style="color:blue">符合党的宗旨与发展理念</span></strong></p>
<p>大力发展<code>与民生相关的科学技术</code>，<strong>符合</strong>中国共产党全心全意为人民服务的<strong>宗旨</strong>，<strong>符合</strong>以人民为中心的<strong>思想内涵</strong>。</p>
<p>党的十八大以来，以习近平同志为核心的党中央坚持<strong>以人民为中心</strong>的&#x3D;&#x3D;发展理念&#x3D;&#x3D;，始终坚持把实现好、维护好、发展好最广大人民的<strong>根本利益</strong>作为发展的<strong>根本目的</strong>，把人民对美好生活的向往作为<strong>奋斗目标</strong>，始终把<strong>坚持人民主体地位</strong>作为一切工作所遵循的<strong>首要原则</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;中心理念为人民，根本利益是目的；美好向往为目标，主体地位首原则</span><br></pre></td></tr></table></figure>

<p>为中国人民谋幸福，为中华民族谋复兴，是中国共产党人的初心和使命，也是改革开放的初心和使命。</p>
<p><strong><span style="color:blue">符合科技本身的发展需要</span></strong></p>
<p>大力发展与民生相关的科学技术，符合科技本身的发展需要。人民群众<strong>对切身利益的追求</strong>、<strong>对美好生活的向往</strong>，推动着<strong>历史</strong>的发展和进步，推动着<strong>科技</strong>的创新与突破</p>
<p>只有<code>科学技术发展</code>关注<code>民生</code>，才能实现科学技术本身的<strong>价值</strong>与人民的<strong>需要</strong>&#x3D;&#x3D;相统一&#x3D;&#x3D;，才能获得更多的政策资金支持，吸引更多的人才参与其中，在市场转化与成果推广中获得更多资源，为科学技术本身的发展提供更多动力。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;民生为基，价值统一；政策人才，市场助力；科技动力，源于民需</span><br></pre></td></tr></table></figure>

</blockquote>
]]></content>
      <categories>
        <category>自然辩证法</category>
      </categories>
      <tags>
        <tag>自然辩证法</tag>
      </tags>
  </entry>
  <entry>
    <title>论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks</title>
    <url>/blog/2025/08/31/%E8%AE%BA%E6%96%87-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ATowards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Towards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks"><a href="#Towards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks" class="headerlink" title="Towards Large-Scale Small Object Detection: Survey and Benchmarks"></a>Towards Large-Scale Small Object Detection: Survey and Benchmarks</h1><h2 id="一、文章基础信息"><a href="#一、文章基础信息" class="headerlink" title="一、文章基础信息"></a>一、文章基础信息</h2><ul>
<li><p><strong>期刊 &#x2F; 年份</strong>：IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE (TPAMI)，2023 年 11 月</p>
</li>
<li><p><strong>核心主题</strong>：小目标检测（Small Object Detection, SOD）的系统综述、两大专用大规模基准数据集（SODA）构建、主流算法评估</p>
</li>
<li><p><strong>作者单位</strong>：西北工业大学自动化学院</p>
</li>
<li><p><strong>开源资源</strong>：数据集与代码地址：<a href="https://shaunyuan22.github.io/SODA%EF%BC%9B%E8%A1%A5%E5%85%85%E6%9D%90%E6%96%99%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps://doi.org/10.1109/TPAMI.2023.3290594">https://shaunyuan22.github.io/SODA；补充材料地址：https://doi.org/10.1109/TPAMI.2023.3290594</a></p>
</li>
</ul>
<h2 id="二、摘要（核心浓缩）"><a href="#二、摘要（核心浓缩）" class="headerlink" title="二、摘要（核心浓缩）"></a>二、摘要（核心浓缩）</h2><h3 id="1-领域背景"><a href="#1-领域背景" class="headerlink" title="1. 领域背景"></a>1. 领域背景</h3><ul>
<li><p>深度卷积神经网络（DCNN）推动目标检测显著进步，但<strong>小目标检测（SOD）仍是计算机视觉公认难点</strong>—— 核心原因：小目标固有结构导致 “视觉外观差（细节模糊）” 和 “特征噪声多（易与背景混淆）”。</p>
</li>
<li><p>关键瓶颈：缺乏用于评估 SOD 方法的<strong>大规模专用基准数据集</strong>。</p>
</li>
</ul>
<h3 id="2-核心工作"><a href="#2-核心工作" class="headerlink" title="2. 核心工作"></a>2. 核心工作</h3><ol>
<li><p><strong>系统综述 SOD</strong>：全面梳理深度学习时代的 SOD 算法，建立分类体系。</p>
</li>
<li><p><strong>构建 SODA 数据集</strong>：推出两大场景专用大规模数据集：</p>
</li>
</ol>
<ul>
<li><ul>
<li><strong>SODA-D（驾驶场景）</strong>：24828 张高质量交通图像，278433 个实例（9 类别：人、骑手、自行车、摩托车、汽车、交通标志、红绿灯、交通摄像头、警示锥）。</li>
</ul>
</li>
<li><ul>
<li><strong>SODA-A（航拍场景）</strong>：2513 张高分辨率航拍图像，872069 个实例（9 类别：飞机、直升机、小车、大车、船、集装箱、储罐、游泳池、风车）。</li>
</ul>
</li>
<li><ul>
<li>特点：首个专为<strong>多类别 SOD</strong>设计的大规模基准，标注详尽（细分小目标等级、忽略区域）。</li>
</ul>
</li>
</ul>
<ol>
<li><strong>评估主流算法</strong>：在 SODA 上测试主流检测方法，提供性能基准。</li>
</ol>
<h3 id="3-研究意义"><a href="#3-研究意义" class="headerlink" title="3. 研究意义"></a>3. 研究意义</h3><p>填补 “多类别 SOD 大规模基准” 空白，推动 SOD 领域技术突破。</p>
<h2 id="三、引言（研究背景与动机）"><a href="#三、引言（研究背景与动机）" class="headerlink" title="三、引言（研究背景与动机）"></a>三、引言（研究背景与动机）</h2><h3 id="1-目标检测与-SOD-的定位"><a href="#1-目标检测与-SOD-的定位" class="headerlink" title="1. 目标检测与 SOD 的定位"></a>1. 目标检测与 SOD 的定位</h3><ul>
<li><p><strong>目标检测任务</strong>：对图像 &#x2F; 视频中的目标进行 “分类 + 定位”，是计算机视觉核心任务。</p>
</li>
<li><p><strong>SOD 定位</strong>：目标检测的子领域，聚焦 “小尺寸目标”（按 COCO 定义：面积≤1024 像素），应用场景包括：监控行人检测、无人机航拍分析、自动驾驶交通标志识别。</p>
</li>
<li><p><strong>发展差距</strong>：通用目标检测进步显著（如 Faster R-CNN、YOLO），但 SOD 性能滞后 —— 例：顶级检测器 DyHead 在 COCO 测试集上，小目标 mAP 仅 28.3%，中 &#x2F; 大目标分别为 50.3%&#x2F;57.5%。</p>
</li>
</ul>
<h3 id="2-SOD-的两大核心瓶颈"><a href="#2-SOD-的两大核心瓶颈" class="headerlink" title="2. SOD 的两大核心瓶颈"></a>2. SOD 的两大核心瓶颈</h3><table>
<thead>
<tr>
<th>瓶颈类型</th>
<th>具体表现</th>
</tr>
</thead>
<tbody><tr>
<td>技术瓶颈</td>
<td>小目标特征质量差：下采样导致信息丢失，卷积过程中特征被背景 &#x2F; 大目标污染</td>
</tr>
<tr>
<td>数据瓶颈</td>
<td>缺乏大规模 SOD 专用数据集：现有数据集或规模小、或单类别、或小目标分布不均</td>
</tr>
</tbody></table>
<h3 id="3-现有数据集的局限性"><a href="#3-现有数据集的局限性" class="headerlink" title="3. 现有数据集的局限性"></a>3. 现有数据集的局限性</h3><ul>
<li><p>专为 SOD 设计的数据集：规模小（如 SOD 仅 4925 张图、TinyPerson 仅 1610 张图）、单类别（如 TinyPerson 仅行人）。</p>
</li>
<li><p>含小目标的通用数据集：单类别（如 WiderFace 仅人脸）、小目标集中少数类别（如 DOTA 小目标以 “小车” 为主）。</p>
</li>
</ul>
<h3 id="4-研究动机"><a href="#4-研究动机" class="headerlink" title="4. 研究动机"></a>4. 研究动机</h3><p>受通用目标检测数据集（PASCAL VOC、COCO）推动领域发展的启发，提出核心问题：<strong>能否构建 “多类别、大规模、标注详尽” 的 SOD 专用数据集？</strong> 以支撑 SOD 模型训练与公平评估。</p>
<h3 id="5-文章核心贡献"><a href="#5-文章核心贡献" class="headerlink" title="5. 文章核心贡献"></a>5. 文章核心贡献</h3><ol>
<li><p>首次系统综述深度学习时代的 SOD 算法，分为 6 大类并分析优缺点。</p>
</li>
<li><p>构建 SODA-D&#x2F;SODA-A 两大大规模 SOD 基准数据集。</p>
</li>
<li><p>在 SODA 上评估主流算法，提供定量 &#x2F; 定性分析，指导后续研究。</p>
</li>
</ol>
<h3 id="6-文章结构"><a href="#6-文章结构" class="headerlink" title="6. 文章结构"></a>6. 文章结构</h3><ul>
<li>第 II 章：SOD 算法综述；第 III 章：SOD 相关数据集综述；第 IV 章：SODA 数据集构建；第 V 章：实验与结果分析；第 VI 章：结论与展望。</li>
</ul>
<h2 id="四、小目标检测综述（II-REVIEW-ON-SMALL-OBJECT-DETECTION）"><a href="#四、小目标检测综述（II-REVIEW-ON-SMALL-OBJECT-DETECTION）" class="headerlink" title="四、小目标检测综述（II. REVIEW ON SMALL OBJECT DETECTION）"></a>四、小目标检测综述（II. REVIEW ON SMALL OBJECT DETECTION）</h2><h3 id="1-SOD-的四大核心挑战"><a href="#1-SOD-的四大核心挑战" class="headerlink" title="1. SOD 的四大核心挑战"></a>1. SOD 的四大核心挑战</h3><h4 id="（1）信息丢失（Information-Loss）"><a href="#（1）信息丢失（Information-Loss）" class="headerlink" title="（1）信息丢失（Information Loss）"></a>（1）信息丢失（Information Loss）</h4><ul>
<li><p>原因：通用 CNN 特征提取器（ResNet、ResNeXt）通过下采样减少计算量，导致小目标（如 20×20 像素）特征被稀释 —— 例：32×32 目标经 5 次下采样后仅剩 1×1 特征点，关键信息丢失。</p>
</li>
<li><p>影响：检测头无法从抽象特征中识别小目标。</p>
</li>
</ul>
<h4 id="（2）噪声特征表示（Noisy-Feature-Representation）"><a href="#（2）噪声特征表示（Noisy-Feature-Representation）" class="headerlink" title="（2）噪声特征表示（Noisy Feature Representation）"></a>（2）噪声特征表示（Noisy Feature Representation）</h4><ul>
<li><p>原因：① 小目标视觉细节少，特征区分度低；② 卷积过程中，小目标特征易与背景（如路面、天空）或其他目标特征混淆。</p>
</li>
<li><p>影响：网络无法学习 “判别性特征”，易误判背景为小目标。</p>
</li>
</ul>
<h4 id="（3）边界框扰动容忍度低（Low-Tolerance-for-Bounding-Box-Perturbation）"><a href="#（3）边界框扰动容忍度低（Low-Tolerance-for-Bounding-Box-Perturbation）" class="headerlink" title="（3）边界框扰动容忍度低（Low Tolerance for Bounding Box Perturbation）"></a>（3）边界框扰动容忍度低（Low Tolerance for Bounding Box Perturbation）</h4><ul>
<li><p>现象：小目标定位偏差对 IoU（交并比）影响极大（文献 Fig. 1）：</p>
</li>
<li><ul>
<li>小目标（20×20）：偏差 6 像素→IoU 从 100%→32.5%；偏差 12 像素→IoU→8.7%。</li>
</ul>
</li>
<li><ul>
<li>中目标（40×40）：偏差 6 像素→IoU→56.6%；大目标（70×70）→IoU→71.8%。</li>
</ul>
</li>
<li><p>影响：定位轻微偏差即判定为检测失败，增加回归任务难度。</p>
</li>
</ul>
<h4 id="（4）训练样本不足（Inadequate-Samples-for-Training）"><a href="#（4）训练样本不足（Inadequate-Samples-for-Training）" class="headerlink" title="（4）训练样本不足（Inadequate Samples for Training）"></a>（4）训练样本不足（Inadequate Samples for Training）</h4><ul>
<li><p>原因：① 小目标在图像中占比小，与先验框（Anchor）重叠率低；② 传统标签分配（如 IoU&gt;0.5 为正样本）对小目标严苛，大量小目标被误判为负样本。</p>
</li>
<li><p>影响：网络缺乏足够正样本学习小目标特征，分类 &#x2F; 回归性能差。</p>
</li>
</ul>
<h3 id="2-六大类-SOD-算法（按技术思路分类）"><a href="#2-六大类-SOD-算法（按技术思路分类）" class="headerlink" title="2. 六大类 SOD 算法（按技术思路分类）"></a>2. 六大类 SOD 算法（按技术思路分类）</h3><h4 id="（1）样本导向方法（Sample-Oriented-Methods）——-解决-“样本不足”"><a href="#（1）样本导向方法（Sample-Oriented-Methods）——-解决-“样本不足”" class="headerlink" title="（1）样本导向方法（Sample-Oriented Methods）—— 解决 “样本不足”"></a>（1）样本导向方法（Sample-Oriented Methods）—— 解决 “样本不足”</h4><ul>
<li><p><strong>核心思想</strong>：增加小目标样本数量或优化样本选择规则。</p>
</li>
<li><p>子方向 1：数据增强策略</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>代表方法</th>
<th>核心逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>Kisantal (2019)</td>
<td>复制图像中已有的小目标，随机旋转 &#x2F; 缩放后粘贴到其他位置</td>
</tr>
<tr>
<td>RRNet (2019)</td>
<td>分割图引导粘贴位置（避免遮挡），对粘贴目标做尺度适配</td>
</tr>
<tr>
<td>DS-GAN (2023)</td>
<td>GAN 生成视觉真实的小目标样本，结合分割 &#x2F; 图像修复技术</td>
</tr>
</tbody></table>
<ul>
<li><ul>
<li>优缺点：优点→快速增加样本；缺点→生成样本迁移性差，GAN 易造伪纹理。</li>
</ul>
</li>
<li><p>子方向 2：优化标签分配</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>代表方法</th>
<th>核心逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>S³FD (2017)</td>
<td>尺度补偿匹配：降低小目标与 Anchor 的 IoU 阈值，设计小尺度 Anchor</td>
</tr>
<tr>
<td>DotD (2021)</td>
<td>用 “边界框中心距离” 替代 IoU，距离近即判定为正样本</td>
</tr>
<tr>
<td>RFLA (2022)</td>
<td>高斯感受野匹配：计算特征点感受野与小目标的相似度，相似度高为正样本</td>
</tr>
</tbody></table>
<ul>
<li><ul>
<li>优缺点：优点→适配小目标低重叠特性；缺点→易引入低质量正样本。</li>
</ul>
</li>
</ul>
<h4 id="（2）尺度感知方法（Scale-Aware-Methods）——-解决-“信息丢失与尺度差异”"><a href="#（2）尺度感知方法（Scale-Aware-Methods）——-解决-“信息丢失与尺度差异”" class="headerlink" title="（2）尺度感知方法（Scale-Aware Methods）—— 解决 “信息丢失与尺度差异”"></a>（2）尺度感知方法（Scale-Aware Methods）—— 解决 “信息丢失与尺度差异”</h4><ul>
<li><p><strong>核心思想</strong>：小目标需高分辨率特征，大目标需高层语义特征，通过 “分尺度处理” 或 “跨尺度融合” 优化。</p>
</li>
<li><p>子方向 1：尺度专用检测器</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>代表方法</th>
<th>核心逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>FPN (2017)</td>
<td>特征金字塔：低层（高分辨率）检测小目标，高层（低分辨率）检测大目标，跨层传特征</td>
</tr>
<tr>
<td>TridentNet (2019)</td>
<td>多分支架构：不同分支用不同空洞卷积率调整感受野，分别适配小 &#x2F; 中 &#x2F; 大目标</td>
</tr>
<tr>
<td>SNIP (2018)</td>
<td>尺度归一化训练：仅保留目标尺度在合理范围的样本，让分支专注学对应尺度</td>
</tr>
</tbody></table>
<ul>
<li><ul>
<li>优缺点：优点→分工明确；缺点→多分支增加计算量，尺度划分靠经验。</li>
</ul>
</li>
<li><p>子方向 2：分层特征融合</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>代表方法</th>
<th>核心逻辑</th>
</tr>
</thead>
<tbody><tr>
<td>PANet (2018)</td>
<td>双向特征融合：高层→低层传语义，低层→高层传细节</td>
</tr>
<tr>
<td>BiFPN (2020)</td>
<td>加权双向融合：去掉冗余路径，对小目标相关特征分配高权重</td>
</tr>
<tr>
<td>StairNet (2018)</td>
<td>反卷积上采样：放大低层特征后与高层融合，保留细节</td>
</tr>
</tbody></table>
<ul>
<li><ul>
<li>优缺点：优点→弥补小目标语义不足；缺点→融合易污染特征，策略设计复杂。</li>
</ul>
</li>
</ul>
<h4 id="（3）注意力方法（Attention-Based-Methods）——-解决-“噪声特征”"><a href="#（3）注意力方法（Attention-Based-Methods）——-解决-“噪声特征”" class="headerlink" title="（3）注意力方法（Attention-Based Methods）—— 解决 “噪声特征”"></a>（3）注意力方法（Attention-Based Methods）—— 解决 “噪声特征”</h4><ul>
<li><p><strong>核心思想</strong>：模仿人类视觉聚焦机制，通过注意力模块 “突出小目标区域，抑制背景噪声”。</p>
</li>
<li><p>代表方法：</p>
</li>
<li><ul>
<li>CBAM (2018)：通道注意力（突出小目标关键通道）+ 空间注意力（突出小目标区域）。</li>
</ul>
</li>
<li><ul>
<li>SCRDet (2019)：像素 + 通道双注意力，适配航拍小目标。</li>
</ul>
</li>
<li><ul>
<li>FBR-Net (2021)：层级注意力，平衡特征金字塔各层重要性。</li>
</ul>
</li>
<li><p>优缺点：优点→灵活性高，可嵌入任意架构；缺点→增加计算量，无监督注意力易关注无关区域。</p>
</li>
</ul>
<h4 id="（4）特征模仿方法（Feature-Imitation-Methods）——-解决-“特征质量差”"><a href="#（4）特征模仿方法（Feature-Imitation-Methods）——-解决-“特征质量差”" class="headerlink" title="（4）特征模仿方法（Feature-Imitation Methods）—— 解决 “特征质量差”"></a>（4）特征模仿方法（Feature-Imitation Methods）—— 解决 “特征质量差”</h4><ul>
<li><p><strong>核心思想</strong>：让小目标特征 “模仿” 大目标特征（大目标特征质量高），缩小小目标与大目标的特征差距。</p>
</li>
<li><p>子方向 1：相似度学习（如 Self-Mimic Learning (2020)：用损失约束小行人特征向大行人特征靠近）。</p>
</li>
<li><p>子方向 2：超分辨率重建（如 SOD-MTGAN (2018)：GAN 对小目标 RoI 做超分辨率，恢复细节）。</p>
</li>
<li><p>优缺点：优点→根源提升特征质量；缺点→超分辨率增加计算量，GAN 易造伪纹理。</p>
</li>
</ul>
<h4 id="（5）上下文建模方法（Context-Modeling-Methods）——-解决-“信息不足”"><a href="#（5）上下文建模方法（Context-Modeling-Methods）——-解决-“信息不足”" class="headerlink" title="（5）上下文建模方法（Context-Modeling Methods）—— 解决 “信息不足”"></a>（5）上下文建模方法（Context-Modeling Methods）—— 解决 “信息不足”</h4><ul>
<li><p><strong>核心思想</strong>：利用 “上下文信息”（小目标周围环境、其他目标关联）辅助检测，例：路边杆子→推测有交通摄像头。</p>
</li>
<li><p>代表方法：</p>
</li>
<li><ul>
<li>PyramidBox (2018)：用 “人脸上下文”（头发、周围人脸）检测小脸。</li>
</ul>
</li>
<li><ul>
<li>IONet (2016)：RNN 捕捉全局上下文（如航拍道路分布）辅助定位小车。</li>
</ul>
</li>
<li><ul>
<li>CAB Net (2022)：金字塔空洞卷积捕捉多尺度上下文。</li>
</ul>
</li>
<li><p>优缺点：优点→适配极小小目标；缺点→上下文区域选择靠经验，易引入干扰。</p>
</li>
</ul>
<h4 id="（6）聚焦检测方法（Focus-and-Detect-Methods）——-解决-“高分辨率效率低”"><a href="#（6）聚焦检测方法（Focus-and-Detect-Methods）——-解决-“高分辨率效率低”" class="headerlink" title="（6）聚焦检测方法（Focus-and-Detect Methods）—— 解决 “高分辨率效率低”"></a>（6）聚焦检测方法（Focus-and-Detect Methods）—— 解决 “高分辨率效率低”</h4><ul>
<li><p><strong>核心思想</strong>：高分辨率图像中小目标分散，先 “筛选有目标区域”，再高分辨率检测，减少计算量。</p>
</li>
<li><p>代表方法：</p>
</li>
<li><ul>
<li>ClusDet (2019)：小目标聚类成簇，仅对簇区域检测。</li>
</ul>
</li>
<li><ul>
<li>F&amp;D (2022)：聚焦网络预测候选区域，裁剪放大后检测。</li>
</ul>
</li>
<li><p>优缺点：优点→提升效率与精度；缺点→需额外训练聚焦模块，易漏检小目标区域。</p>
</li>
</ul>
<h2 id="五、SOD-相关数据集综述（III-REVIEW-OF-DATASETS-FOR-SMALL-OBJECT-DETECTION）"><a href="#五、SOD-相关数据集综述（III-REVIEW-OF-DATASETS-FOR-SMALL-OBJECT-DETECTION）" class="headerlink" title="五、SOD 相关数据集综述（III. REVIEW OF DATASETS FOR SMALL OBJECT DETECTION）"></a>五、SOD 相关数据集综述（III. REVIEW OF DATASETS FOR SMALL OBJECT DETECTION）</h2><h3 id="1-主流-SOD-相关数据集梳理"><a href="#1-主流-SOD-相关数据集梳理" class="headerlink" title="1. 主流 SOD 相关数据集梳理"></a>1. 主流 SOD 相关数据集梳理</h3><table>
<thead>
<tr>
<th>数据集</th>
<th>场景 &#x2F; 任务</th>
<th>规模（图像 &#x2F; 实例）</th>
<th>小目标特点</th>
<th>局限性</th>
</tr>
</thead>
<tbody><tr>
<td>COCO (2014)</td>
<td>通用自然场景</td>
<td>123K&#x2F;886K</td>
<td>30% 实例为小目标（≤1024 像素）</td>
<td>非 SOD 专用，部分类别小目标少</td>
</tr>
<tr>
<td>WiderFace (2016)</td>
<td>人脸检测</td>
<td>32.2K&#x2F;39.37K</td>
<td>50% 为小人脸（10-50 像素）</td>
<td>单类别，场景局限</td>
</tr>
<tr>
<td>TinyPerson (2020)</td>
<td>极小行人检测</td>
<td>1.6K&#x2F;7.25K</td>
<td>目标极小，含 ignore 标注</td>
<td>规模小，单场景（海边）+ 单类别</td>
</tr>
<tr>
<td>TT100K (2016)</td>
<td>交通标志检测</td>
<td>100K&#x2F;30K</td>
<td>80% 实例 &lt; 图像面积 0.1%</td>
<td>单类别，长尾分布</td>
</tr>
<tr>
<td>VisDrone (2021)</td>
<td>无人机交通场景</td>
<td>18.9K&#x2F;2.5M</td>
<td>高空视角目标小，含遮挡</td>
<td>水平框标注旋转目标，类别不均衡</td>
</tr>
<tr>
<td>DOTA (2022)</td>
<td>遥感航拍</td>
<td>11.2K&#x2F;1.79M</td>
<td>超 11 万极小小目标</td>
<td>小目标集中 “小车” 类，分辨率不均</td>
</tr>
</tbody></table>
<h3 id="2-现有数据集共性不足"><a href="#2-现有数据集共性不足" class="headerlink" title="2. 现有数据集共性不足"></a>2. 现有数据集共性不足</h3><ol>
<li><p><strong>规模不足</strong>：图像 &#x2F; 实例数量少，无法支撑 DCNN 训练。</p>
</li>
<li><p><strong>类别单一 &#x2F; 不均衡</strong>：单类别或小目标集中少数类别，无法适配多类别 SOD。</p>
</li>
<li><p><strong>标注问题</strong>：航拍场景用水平框（OBB 更精准），缺乏 ignore 标注（引入噪声）。</p>
</li>
<li><p><strong>场景局限</strong>：单一场景，泛化能力差。</p>
</li>
</ol>
<h3 id="3-SOD-评估指标（Average-Precision-AP）"><a href="#3-SOD-评估指标（Average-Precision-AP）" class="headerlink" title="3. SOD 评估指标（Average Precision, AP）"></a>3. SOD 评估指标（Average Precision, AP）</h3><h4 id="（1）基础概念"><a href="#（1）基础概念" class="headerlink" title="（1）基础概念"></a>（1）基础概念</h4><ul>
<li><p><strong>TP（真阳性）</strong>：预测框与 GT 框 IoU≥阈值，类别一致。</p>
</li>
<li><p><strong>FP（假阳性）</strong>：IoU 不达标或类别错误或重复检测。</p>
</li>
<li><p><strong>FN（假阴性）</strong>：GT 未被检测到。</p>
</li>
</ul>
<h4 id="（2）AP-计算范式"><a href="#（2）AP-计算范式" class="headerlink" title="（2）AP 计算范式"></a>（2）AP 计算范式</h4><table>
<thead>
<tr>
<th>范式</th>
<th>计算逻辑</th>
<th>优势 &#x2F; 局限</th>
</tr>
</thead>
<tbody><tr>
<td>VOC 范式（2007）</td>
<td>单一 IoU 阈值（0.5），计算 Precision-Recall 曲线下面积</td>
<td>局限→仅关注低定位精度，无法区分高定位算法</td>
</tr>
<tr>
<td>COCO 范式（2014）</td>
<td>10 个 IoU 阈值（0.5-0.95，步长 0.05），取 AP 平均值；分面积计算 AP（AP_S&#x2F;AP_M&#x2F;AP_L）</td>
<td>优势→鼓励高定位精度，适配 SOD “低容忍度” 需求，现为 SOD 评估黄金标准</td>
</tr>
</tbody></table>
<h4 id="（3）SOD-核心评估指标"><a href="#（3）SOD-核心评估指标" class="headerlink" title="（3）SOD 核心评估指标"></a>（3）SOD 核心评估指标</h4><ul>
<li><strong>AP</strong>：综合性能；<strong>AP₅₀&#x2F;AP₇₅</strong>：低 &#x2F; 高定位精度需求；<strong>APₑS&#x2F;APᵣS&#x2F;APgS</strong>：极小小 &#x2F; 相对小 &#x2F; 一般小目标性能。</li>
</ul>
<h2 id="六、SODA-基准数据集（IV-BENCHMARKS）"><a href="#六、SODA-基准数据集（IV-BENCHMARKS）" class="headerlink" title="六、SODA 基准数据集（IV. BENCHMARKS）"></a>六、SODA 基准数据集（IV. BENCHMARKS）</h2><h3 id="1-基础设计：小目标定义与数据来源"><a href="#1-基础设计：小目标定义与数据来源" class="headerlink" title="1. 基础设计：小目标定义与数据来源"></a>1. 基础设计：小目标定义与数据来源</h3><h4 id="（1）小目标分类标准（按像素面积）"><a href="#（1）小目标分类标准（按像素面积）" class="headerlink" title="（1）小目标分类标准（按像素面积）"></a>（1）小目标分类标准（按像素面积）</h4><table>
<thead>
<tr>
<th>目标类型</th>
<th>面积范围（像素）</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>极小小目标（eS）</td>
<td>(0, 144]</td>
<td>10×10 交通摄像头</td>
</tr>
<tr>
<td>相对小目标（rS）</td>
<td>(144, 400]</td>
<td>20×20 交通标志</td>
</tr>
<tr>
<td>一般小目标（gS）</td>
<td>(400, 1024]</td>
<td>30×30 摩托车</td>
</tr>
<tr>
<td>正常目标（N）</td>
<td>(1024, 2000]</td>
<td>40×40 行人</td>
</tr>
<tr>
<td>忽略目标（Ignore）</td>
<td>&gt;2000</td>
<td>大卡车（不参与评估）</td>
</tr>
</tbody></table>
<h4 id="（2）数据来源"><a href="#（2）数据来源" class="headerlink" title="（2）数据来源"></a>（2）数据来源</h4><table>
<thead>
<tr>
<th>数据集</th>
<th>数据来源</th>
<th>图像数量</th>
</tr>
</thead>
<tbody><tr>
<td>SODA-D</td>
<td>① MVD 数据集（25K 张街景图）；② 自拍摄（6 个城市车载 &#x2F; 手机拍摄）；③ 网络爬取</td>
<td>24828</td>
</tr>
<tr>
<td>SODA-A</td>
<td>Google Earth（全球数百城市，专家筛选含密集 &#x2F; 稀疏小目标的场景）</td>
<td>2513</td>
</tr>
</tbody></table>
<h3 id="2-标注规则与数据集分割"><a href="#2-标注规则与数据集分割" class="headerlink" title="2. 标注规则与数据集分割"></a>2. 标注规则与数据集分割</h3><h4 id="（1）标注细节"><a href="#（1）标注细节" class="headerlink" title="（1）标注细节"></a>（1）标注细节</h4><table>
<thead>
<tr>
<th>数据集</th>
<th>类别数量</th>
<th>标注方式</th>
<th>忽略区域标注规则</th>
</tr>
</thead>
<tbody><tr>
<td>SODA-D</td>
<td>9</td>
<td>水平框（HBB）</td>
<td>① 面积 &gt; 2000 像素；② 极小 &#x2F; 严重遮挡无法识别</td>
</tr>
<tr>
<td>SODA-A</td>
<td>9</td>
<td>有向框（OBB）</td>
<td>同 SODA-D（适配航拍旋转目标）</td>
</tr>
</tbody></table>
<h4 id="（2）数据集分割比例"><a href="#（2）数据集分割比例" class="headerlink" title="（2）数据集分割比例"></a>（2）数据集分割比例</h4><table>
<thead>
<tr>
<th>数据集</th>
<th>训练集比例</th>
<th>验证集比例</th>
<th>测试集比例</th>
<th>总实例数</th>
</tr>
</thead>
<tbody><tr>
<td>SODA-D</td>
<td>50%</td>
<td>20%</td>
<td>30%</td>
<td>278433</td>
</tr>
<tr>
<td>SODA-A</td>
<td>40%</td>
<td>25%</td>
<td>35%</td>
<td>872069</td>
</tr>
</tbody></table>
<h3 id="3-SODA-核心统计特征"><a href="#3-SODA-核心统计特征" class="headerlink" title="3. SODA 核心统计特征"></a>3. SODA 核心统计特征</h3><h4 id="（1）SODA-D（驾驶场景）"><a href="#（1）SODA-D（驾驶场景）" class="headerlink" title="（1）SODA-D（驾驶场景）"></a>（1）SODA-D（驾驶场景）</h4><ul>
<li><p><strong>小目标占比</strong>：71%（eS 25834 个、rS 71064 个、gS 102066 个）。</p>
</li>
<li><p><strong>独特优势</strong>：</p>
</li>
<li><ul>
<li>高分辨率：平均 3407×2470 像素（远高于 TT100K 的 2048×2048）。</li>
</ul>
</li>
<li><ul>
<li>场景多样性：覆盖晴天 &#x2F; 雨天 &#x2F; 夜晚、城市 &#x2F; 高速 &#x2F; 乡村。</li>
</ul>
</li>
<li><ul>
<li>忽略区域多：153976 个（提升评估准确性）。</li>
</ul>
</li>
</ul>
<h4 id="（2）SODA-A（航拍场景）"><a href="#（2）SODA-A（航拍场景）" class="headerlink" title="（2）SODA-A（航拍场景）"></a>（2）SODA-A（航拍场景）</h4><ul>
<li><p><strong>小目标占比</strong>：95%（eS 304900 个、rS 363738 个、gS 168874 个）。</p>
</li>
<li><p><strong>独特优势</strong>：</p>
</li>
<li><ul>
<li>超高分辨率：平均 4761×2777 像素（远高于 AI-TOD 的 800×800）。</li>
</ul>
</li>
<li><ul>
<li>密度差异大：单图实例数 1~11134 个（平均 347 个，是 DOTA 的 2 倍）。</li>
</ul>
</li>
<li><ul>
<li>朝向任意：倾斜角分布于(-\pi&#x2F;2)~(\pi&#x2F;2)（适配旋转目标）。</li>
</ul>
</li>
</ul>
<h3 id="4-SODA-与现有数据集的对比优势"><a href="#4-SODA-与现有数据集的对比优势" class="headerlink" title="4. SODA 与现有数据集的对比优势"></a>4. SODA 与现有数据集的对比优势</h3><h4 id="（1）SODA-D-vs-驾驶场景数据集（TT100K、EuroCity-Persons）"><a href="#（1）SODA-D-vs-驾驶场景数据集（TT100K、EuroCity-Persons）" class="headerlink" title="（1）SODA-D vs 驾驶场景数据集（TT100K、EuroCity Persons）"></a>（1）SODA-D vs 驾驶场景数据集（TT100K、EuroCity Persons）</h4><table>
<thead>
<tr>
<th>对比维度</th>
<th>SODA-D</th>
<th>TT100K</th>
</tr>
</thead>
<tbody><tr>
<td>eS 级小目标数量</td>
<td>25834 个</td>
<td>71 个</td>
</tr>
<tr>
<td>类别数</td>
<td>9 类（多类别 SOD）</td>
<td>1 类（仅交通标志）</td>
</tr>
<tr>
<td>平均分辨率</td>
<td>3407×2470</td>
<td>2048×2048</td>
</tr>
<tr>
<td>忽略区域标注</td>
<td>有</td>
<td>无</td>
</tr>
</tbody></table>
<h4 id="（2）SODA-A-vs-航拍场景数据集（AI-TOD、DOTA）"><a href="#（2）SODA-A-vs-航拍场景数据集（AI-TOD、DOTA）" class="headerlink" title="（2）SODA-A vs 航拍场景数据集（AI-TOD、DOTA）"></a>（2）SODA-A vs 航拍场景数据集（AI-TOD、DOTA）</h4><table>
<thead>
<tr>
<th>对比维度</th>
<th>SODA-A</th>
<th>AI-TOD</th>
</tr>
</thead>
<tbody><tr>
<td>小目标类别均衡性</td>
<td>9 类均匀（除直升机外均 &gt; 10000 个）</td>
<td>88% 为车辆</td>
</tr>
<tr>
<td>平均分辨率</td>
<td>4761×2777</td>
<td>800×800</td>
</tr>
<tr>
<td>标注方式</td>
<td>OBB（适配旋转）</td>
<td>HBB（定位偏差大）</td>
</tr>
<tr>
<td>单图实例数范围</td>
<td>1~11134 个</td>
<td>&lt;200 个</td>
</tr>
</tbody></table>
<h2 id="七、实验部分（V-EXPERIMENTS）"><a href="#七、实验部分（V-EXPERIMENTS）" class="headerlink" title="七、实验部分（V. EXPERIMENTS）"></a>七、实验部分（V. EXPERIMENTS）</h2><h3 id="1-实验设计基础"><a href="#1-实验设计基础" class="headerlink" title="1. 实验设计基础"></a>1. 实验设计基础</h3><h4 id="（1）评估协议"><a href="#（1）评估协议" class="headerlink" title="（1）评估协议"></a>（1）评估协议</h4><ul>
<li><p>核心指标：AP（0.5-0.95）、AP₅₀、AP₇₅、APₑS&#x2F;APᵣS&#x2F;APgS&#x2F;AP_N。</p>
</li>
<li><p>规则：仅统计非 Ignore 目标，NMS 去重（IoU&#x3D;0.5），置信度 &gt; 0.3 的预测框参与计算。</p>
</li>
</ul>
<h4 id="（2）实现细节"><a href="#（2）实现细节" class="headerlink" title="（2）实现细节"></a>（2）实现细节</h4><table>
<thead>
<tr>
<th>配置项</th>
<th>具体设置</th>
</tr>
</thead>
<tbody><tr>
<td>工具库</td>
<td>SODA-D→mmdetection；SODA-A→mmrotate</td>
</tr>
<tr>
<td>硬件</td>
<td>4×NVIDIA RTX 3090 GPU</td>
</tr>
<tr>
<td>图像处理</td>
<td>裁剪为 800×800 patch（步长 650），resize 至 1200×1200</td>
</tr>
<tr>
<td>训练参数</td>
<td>batch size：SODA-D&#x3D;8、SODA-A&#x3D;4；默认 12 epoch；仅水平翻转增强</td>
</tr>
<tr>
<td>基础 backbone</td>
<td>ResNet-50（后续测试 Swin-T、ConvNext-T 等）</td>
</tr>
</tbody></table>
<h3 id="2-SODA-D-实验结果（驾驶场景）"><a href="#2-SODA-D-实验结果（驾驶场景）" class="headerlink" title="2. SODA-D 实验结果（驾驶场景）"></a>2. SODA-D 实验结果（驾驶场景）</h3><h4 id="（1）主流算法整体性能排名（Top-5）"><a href="#（1）主流算法整体性能排名（Top-5）" class="headerlink" title="（1）主流算法整体性能排名（Top 5）"></a>（1）主流算法整体性能排名（Top 5）</h4><table>
<thead>
<tr>
<th>算法</th>
<th>AP</th>
<th>AP₅₀</th>
<th>AP₇₅</th>
<th>APₑS</th>
<th>核心优势</th>
</tr>
</thead>
<tbody><tr>
<td>Cascade R-CNN</td>
<td>31.2%</td>
<td>59.9%</td>
<td>27.8%</td>
<td>14.1%</td>
<td>级联回归优化定位，适配 SOD 低容忍度</td>
</tr>
<tr>
<td>RFLA（Faster R-CNN 改进）</td>
<td>29.7%</td>
<td>60.2%</td>
<td>25.2%</td>
<td>13.2%</td>
<td>高斯感受野标签分配，增加小目标正样本</td>
</tr>
<tr>
<td>Faster R-CNN</td>
<td>28.9%</td>
<td>59.7%</td>
<td>24.2%</td>
<td>13.9%</td>
<td>候选区域精准定位小目标</td>
</tr>
<tr>
<td>RetinaNet</td>
<td>28.2%</td>
<td>57.6%</td>
<td>23.7%</td>
<td>11.9%</td>
<td>一阶段效率高，但小目标正样本不足</td>
</tr>
<tr>
<td>RepPoints</td>
<td>28.0%</td>
<td>55.6%</td>
<td>24.7%</td>
<td>10.1%</td>
<td>点表示对小目标适配性差</td>
</tr>
</tbody></table>
<h4 id="（2）关键结论"><a href="#（2）关键结论" class="headerlink" title="（2）关键结论"></a>（2）关键结论</h4><ul>
<li><p><strong>范式优劣</strong>：two-stage 算法（Cascade R-CNN、Faster R-CNN）&gt; one-stage &gt; anchor-free（FCOS、CenterNet）&gt; query-based（Deformable DETR）。</p>
</li>
<li><p><strong>backbone 影响</strong>：Swin-T、ConvNext-T 优于传统 CNN（ResNet-50&#x2F;101）—— 例：Faster R-CNN 用 ConvNext-T 的 AP&#x3D;31.9%（ResNet-50 为 28.9%）。</p>
</li>
<li><p><strong>类别难度</strong>：rider（16%）、bicycle（12%）、traffic-camera（14%）AP 最低（样本少 + 尺寸小）。</p>
</li>
</ul>
<h3 id="3-SODA-A-实验结果（航拍场景）"><a href="#3-SODA-A-实验结果（航拍场景）" class="headerlink" title="3. SODA-A 实验结果（航拍场景）"></a>3. SODA-A 实验结果（航拍场景）</h3><h4 id="（1）主流旋转算法整体性能排名（Top-5）"><a href="#（1）主流旋转算法整体性能排名（Top-5）" class="headerlink" title="（1）主流旋转算法整体性能排名（Top 5）"></a>（1）主流旋转算法整体性能排名（Top 5）</h4><table>
<thead>
<tr>
<th>算法</th>
<th>AP</th>
<th>AP₅₀</th>
<th>AP₇₅</th>
<th>APₑS</th>
<th>核心优势</th>
</tr>
</thead>
<tbody><tr>
<td>RoI Transformer</td>
<td>36.0%</td>
<td>73.0%</td>
<td>30.1%</td>
<td>13.5%</td>
<td>旋转 RoI 生成器，精准匹配旋转小目标</td>
</tr>
<tr>
<td>Oriented R-CNN</td>
<td>34.4%</td>
<td>70.7%</td>
<td>28.6%</td>
<td>12.5%</td>
<td>旋转 RPN 生成高质量候选区域，参数增量小</td>
</tr>
<tr>
<td>Rotated Faster R-CNN</td>
<td>32.5%</td>
<td>70.1%</td>
<td>24.3%</td>
<td>11.9%</td>
<td>旋转 RoI 适配航拍目标，基线算法</td>
</tr>
<tr>
<td>DHRec</td>
<td>30.1%</td>
<td>68.8%</td>
<td>19.8%</td>
<td>10.6%</td>
<td>双水平矩形编码旋转目标，解决不连续性问题</td>
</tr>
<tr>
<td>DODet</td>
<td>31.6%</td>
<td>68.1%</td>
<td>23.4%</td>
<td>11.3%</td>
<td>用宽高比 &#x2F; 面积表示旋转目标，适配部分场景</td>
</tr>
</tbody></table>
<h4 id="（2）关键结论-1"><a href="#（2）关键结论-1" class="headerlink" title="（2）关键结论"></a>（2）关键结论</h4><ul>
<li><p><strong>旋转适配性</strong>：带 “旋转候选区域生成” 的算法（RoI Transformer、Oriented R-CNN）性能最优。</p>
</li>
<li><p><strong>backbone 特殊性</strong>：Swin-T 对 RPN-based 算法有益（如 Rotated Faster R-CNN AP 从 32.5%→33.6%），但对 RPN-free 算法有害（如 Rotated RetinaNet AP 从 26.8%→23.3%）。</p>
</li>
<li><p><strong>类别难度</strong>：helicopter（8-21%）、large-vehicle（2-26%）AP 最低（样本少 + 细长旋转目标）。</p>
</li>
</ul>
<h3 id="4-跨场景通用结论"><a href="#4-跨场景通用结论" class="headerlink" title="4. 跨场景通用结论"></a>4. 跨场景通用结论</h3><ol>
<li><p>two-stage 算法是当前 SOD 最优选择，核心优势是 “候选区域精准定位”。</p>
</li>
<li><p>极小小目标（eS）是最大难点，所有算法 APₑS 均 &lt; 15%。</p>
</li>
<li><p>新型 backbone（Swin-T、ConvNext-T）比传统深层 CNN 更适配 SOD。</p>
</li>
</ol>
<h2 id="八、结论与展望（VI-CONCLUSION-AND-OUTLOOK）"><a href="#八、结论与展望（VI-CONCLUSION-AND-OUTLOOK）" class="headerlink" title="八、结论与展望（VI. CONCLUSION AND OUTLOOK）"></a>八、结论与展望（VI. CONCLUSION AND OUTLOOK）</h2><h3 id="1-研究总结"><a href="#1-研究总结" class="headerlink" title="1. 研究总结"></a>1. 研究总结</h3><ul>
<li><p><strong>综述贡献</strong>：首次系统梳理深度学习时代 SOD 算法，建立 6 大类分类体系。</p>
</li>
<li><p><strong>数据集贡献</strong>：构建 SODA-D&#x2F;SODA-A 两大大规模 SOD 基准，填补多类别 SOD 数据集空白。</p>
</li>
<li><p><strong>实验贡献</strong>：在 SODA 上评估主流算法，提供定量 &#x2F; 定性分析，明确 SOD 核心难点。</p>
</li>
</ul>
<h3 id="2-未来研究方向"><a href="#2-未来研究方向" class="headerlink" title="2. 未来研究方向"></a>2. 未来研究方向</h3><h4 id="（1）小目标专用特征提取器"><a href="#（1）小目标专用特征提取器" class="headerlink" title="（1）小目标专用特征提取器"></a>（1）小目标专用特征提取器</h4><ul>
<li><p>现有问题：传统 CNN 下采样丢失信息，计算量与细节保留失衡。</p>
</li>
<li><p>突破点：低下采样率架构（空洞卷积）、多尺度特征对齐、轻量化设计。</p>
</li>
</ul>
<h4 id="（2）改进特征金字塔分层表示"><a href="#（2）改进特征金字塔分层表示" class="headerlink" title="（2）改进特征金字塔分层表示"></a>（2）改进特征金字塔分层表示</h4><ul>
<li><p>现有问题：FPN 尺度分配靠经验，低分辨率层检测效率低。</p>
</li>
<li><p>突破点：自适应尺度分配、跨层特征蒸馏、动态特征选择。</p>
</li>
</ul>
<h4 id="（3）优化小目标标签分配策略"><a href="#（3）优化小目标标签分配策略" class="headerlink" title="（3）优化小目标标签分配策略"></a>（3）优化小目标标签分配策略</h4><ul>
<li><p>现有问题：重叠率 &#x2F; 分布 - based 策略无法满足极小小目标需求。</p>
</li>
<li><p>突破点：多因素融合匹配（尺寸 + 距离 + 上下文）、动态阈值调整、正样本质量筛选。</p>
</li>
</ul>
<h4 id="（4）SOD-专用评估指标"><a href="#（4）SOD-专用评估指标" class="headerlink" title="（4）SOD 专用评估指标"></a>（4）SOD 专用评估指标</h4><ul>
<li><p>现有问题：COCO AP 对小目标严苛，忽视场景需求差异。</p>
</li>
<li><p>突破点：动态 IoU 阈值（按目标尺寸调整）、召回率加权 AP、极小小目标专项指标。</p>
</li>
</ul>
<h2 id="九、关键术语表"><a href="#九、关键术语表" class="headerlink" title="九、关键术语表"></a>九、关键术语表</h2><table>
<thead>
<tr>
<th>术语</th>
<th>英文全称</th>
<th>核心定义</th>
</tr>
</thead>
<tbody><tr>
<td>SOD</td>
<td>Small Object Detection</td>
<td>小目标检测，聚焦面积≤1024 像素的目标</td>
</tr>
<tr>
<td>AP</td>
<td>Average Precision</td>
<td>平均精度，衡量检测算法综合性能，COCO 范式下为 0.5-0.95 IoU 阈值的 AP 平均值</td>
</tr>
<tr>
<td>IoU</td>
<td>Intersection over Union</td>
<td>交并比，衡量预测框与 GT 框的重叠程度，1 为完美匹配，0 为无重叠</td>
</tr>
<tr>
<td>eS&#x2F;rS&#x2F;gS</td>
<td>extremely Small&#x2F;relatively Small&#x2F;generally Small</td>
<td>SODA 中对小目标的细分：面积≤144&#x2F;144-400&#x2F;400-1024 像素</td>
</tr>
<tr>
<td>FPN</td>
<td>Feature Pyramid Network</td>
<td>特征金字塔网络，通过跨层特征融合，适配多尺度目标检测</td>
</tr>
<tr>
<td>OBB&#x2F;HBB</td>
<td>Oriented Bounding Box&#x2F;Horizontal Bounding Box</td>
<td>有向框 &#x2F; 水平框，OBB 适配旋转目标（如航拍），HBB 适配正朝向目标（如驾驶）</td>
</tr>
<tr>
<td>NMS</td>
<td>Non-Maximum Suppression</td>
<td>非极大值抑制，剔除重复的预测框，保留置信度最高的框</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>红外弱小目标检测：Small and dim target detection in infrared imagery: A review, current techniques and future directions</title>
    <url>/blog/2025/09/01/%E7%BA%A2%E5%A4%96%E5%BC%B1%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASmall-and-dim-target-detection-in-infrared-imagery-A-review-current-techniques-and-future-directions/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="文献摘要（ABSTRACT）详细讲解"><a href="#文献摘要（ABSTRACT）详细讲解" class="headerlink" title="文献摘要（ABSTRACT）详细讲解"></a>文献摘要（ABSTRACT）详细讲解</h1><p>摘要作为整篇综述的“浓缩版”，不仅概括了研究背景、核心内容和关键结论，还直接点明了这篇文献的学术价值——它是该领域<strong>第一篇全面覆盖红外小弱目标检测技术的综述</strong>。接下来，我们逐句拆解摘要的核心信息，结合基础概念帮大家彻底理解，确保没有遗漏任何关键要点。</p>
<hr>
<h2 id="一、背景：红外小弱目标检测的“新”与“难”"><a href="#一、背景：红外小弱目标检测的“新”与“难”" class="headerlink" title="一、背景：红外小弱目标检测的“新”与“难”"></a>一、背景：红外小弱目标检测的“新”与“难”</h2><p>摘要开篇先铺垫大背景：</p>
<p>“While there has been significant progress in object detection using conventional image processing and machine learning algorithms, exploring small and dim target detection in the IR domain is a relatively new area of study.”<br>这句话的核心是“对比”——传统目标检测（如RGB图像中的行人、车辆检测）已很成熟，但<strong>红外小弱目标检测是“较新的领域”</strong>。为什么新？我们要结合红外图像的特殊性理解：  </p>
<ul>
<li>传统目标检测依赖“纹理、边缘、形状”等丰富特征（比如检测汽车能靠车轮、车窗的形状），但红外小弱目标（如远距离敌机）只有几个像素，无任何可区分的空间特征；  </li>
<li>红外图像受“热波动”影响（比如同一场景白天和晚上的热辐射差异极大），目标特征不稳定，而传统图像（RGB）的视觉特征相对固定。</li>
</ul>
<p>接着，摘要提到“The majority of small and dim target detection methods are derived from conventional object detection algorithms, albeit with some alterations.”</p>
<p>——多数红外小弱目标检测方法是从传统方法“改造”来的，而非完全从零开始。比如传统的“匹配滤波”用于可见光目标检测，改造后变成“3D匹配滤波”（加入时间维度），才能适配红外多帧场景；传统的“局部对比度”方法，调整窗口大小和计算逻辑后，才用于红外单帧检测。</p>
<h2 id="二、核心挑战：红外小弱目标检测“难在哪”"><a href="#二、核心挑战：红外小弱目标检测“难在哪”" class="headerlink" title="二、核心挑战：红外小弱目标检测“难在哪”"></a>二、核心挑战：红外小弱目标检测“难在哪”</h2><p>摘要明确指出检测任务的复杂性：“The task of detecting small and dim targets in IR imagery is complex. The lack of distinct features, cluttered background with obscure details, and the variability of infrared signals due to thermodynamic fluctuations are the reasons why these targets often do not exhibit identifiable characteristics.”<br>这里直接列出了三大核心难点，我们逐个拆解，结合具体场景理解：  </p>
<h3 id="1-缺乏明显特征（Lack-of-distinct-features）"><a href="#1-缺乏明显特征（Lack-of-distinct-features）" class="headerlink" title="1. 缺乏明显特征（Lack of distinct features）"></a>1. 缺乏明显特征（Lack of distinct features）</h3><p>红外小弱目标通常只有“几个像素”（如3×3、5×5），没有纹理、没有固定形状（文献用“amorphous”形容，即“无定形”）。比如在红外图像中，一个远距离导弹可能只是一个“模糊的亮斑”，无法像RGB图像中的导弹那样分辨出弹体、尾焰的细节——这导致传统靠“特征匹配”的检测方法（如模板匹配）完全失效。</p>
<h3 id="2-背景杂波模糊（Cluttered-background-with-obscure-details）"><a href="#2-背景杂波模糊（Cluttered-background-with-obscure-details）" class="headerlink" title="2. 背景杂波模糊（Cluttered background with obscure details）"></a>2. 背景杂波模糊（Cluttered background with obscure details）</h3><p>“杂波”指背景中干扰目标的区域，红外图像的杂波尤其严重：  </p>
<ul>
<li>自然杂波：云层的热辐射（和目标亮度接近）、地面植被的温度波动、水面的反光；  </li>
<li>人为杂波：城市建筑的热辐射、其他低亮度目标（如飞鸟）。<br>这些杂波会“掩盖”小弱目标，比如目标亮度是50，背景杂波亮度在45-55之间，目标和背景的对比度（SCR）极低，人眼都难分辨，更别说算法。</li>
</ul>
<h3 id="3-红外信号因热波动变化（Variability-of-IR-signals-due-to-thermodynamic-fluctuations）"><a href="#3-红外信号因热波动变化（Variability-of-IR-signals-due-to-thermodynamic-fluctuations）" class="headerlink" title="3. 红外信号因热波动变化（Variability of IR signals due to thermodynamic fluctuations）"></a>3. 红外信号因热波动变化（Variability of IR signals due to thermodynamic fluctuations）</h3><p>红外图像的本质是“热辐射成像”，而场景的温度（热力学状态）会随时间变化，导致目标特征不稳定。比如同一架飞机，中午阳光照射时，机身温度高，红外信号强；晚上环境温度低，机身温度与环境差异变小，红外信号变弱——这种“时变特性”会让算法难以“记住”目标特征，检测鲁棒性大幅下降。文献中的图1（不同时间的红外场景）也直观展示了这一点：中午植被区域亮度高，与天空背景对比度大；傍晚植被亮度降低，与天空背景几乎融合，进一步增加检测难度。</p>
<p><img src="/blog/image/Snipaste_2025-09-01_10-08-20.png"></p>
<h2 id="三、综述的核心目标与贡献：这篇文献“做了什么”"><a href="#三、综述的核心目标与贡献：这篇文献“做了什么”" class="headerlink" title="三、综述的核心目标与贡献：这篇文献“做了什么”"></a>三、综述的核心目标与贡献：这篇文献“做了什么”</h2><p>摘要明确了综述的三大核心目标，也是这篇文献的核心贡献，我们逐一解析其价值：  </p>
<h3 id="1-首次全面覆盖该领域（First-comprehensive-review）"><a href="#1-首次全面覆盖该领域（First-comprehensive-review）" class="headerlink" title="1. 首次全面覆盖该领域（First comprehensive review）"></a>1. 首次全面覆盖该领域（First comprehensive review）</h3><p>“The primary objective of this review is to highlight the progress made in this field. This is the first review in the field of small and dim target detection in infrared imagery, encompassing various methodologies ranging from conventional image processing to cutting-edge deep learning-based approaches.”<br>这是该文献最核心的学术价值——在它之前，领域内的综述都是“片面的”：  </p>
<ul>
<li>Zhao等人（2022）只讲“单帧红外小目标检测”；  </li>
<li>Rawat等人（2020）只讲“传统图像处理方法”；  </li>
<li>Kou等人（2023）只讲“机器学习方法”。<br>而这篇综述是<strong>第一个“全范围覆盖”</strong> 的：从传统方法（如匹配滤波、低秩表示）到最前沿的深度学习方法（如Transformer、GAN），从单帧检测（SIRST）到多帧检测（MIRST），完整梳理了领域进展，为后续研究者提供了“全景图”。</li>
</ul>
<h3 id="2-提出技术分类体系（Introduce-a-taxonomy）"><a href="#2-提出技术分类体系（Introduce-a-taxonomy）" class="headerlink" title="2. 提出技术分类体系（Introduce a taxonomy）"></a>2. 提出技术分类体系（Introduce a taxonomy）</h3><p>“The authors have also introduced a taxonomy of such approaches. Both conventional image processing and deep learning approaches are further categorized into two subcategories: methodologies that utilize several frames for detection, and single-frame-based detection strategies.”<br>“分类体系（taxonomy）”是综述的“骨架”，这篇文献提出的分类逻辑非常清晰，也是后续研究的“标准分类方式”，我们用表格直观展示：  </p>
<table>
<thead>
<tr>
<th>一级分类</th>
<th>二级分类（按“帧数量”划分）</th>
<th>典型方法举例</th>
</tr>
</thead>
<tbody><tr>
<td>传统图像处理方法</td>
<td>多帧检测（MIRST）</td>
<td>3D匹配滤波、3D方向导数滤波</td>
</tr>
<tr>
<td></td>
<td>单帧检测（SIRST）</td>
<td>低秩表示（IPI&#x2F;RIPT）、局部对比度（LCM）、形态学滤波（THM&#x2F;MTHM）</td>
</tr>
<tr>
<td>深度学习方法</td>
<td>多帧检测（MIRST）</td>
<td>SSTNet（切片时空网络）、ST-Trans（时空Transformer）</td>
</tr>
<tr>
<td></td>
<td>单帧检测（SIRST）</td>
<td>全监督（ACMnet&#x2F;DNA-Net&#x2F;ISNet）、弱监督（LESPS）</td>
</tr>
</tbody></table>
<p>这个分类的价值在于：让研究者能快速定位自己的研究方向（比如“我做单帧深度学习检测”），并清晰对比同类别方法的优缺点，避免重复研究。</p>
<h3 id="3-关键结论：深度学习性能更优（Deep-learning-outperforms-traditional-methods）"><a href="#3-关键结论：深度学习性能更优（Deep-learning-outperforms-traditional-methods）" class="headerlink" title="3. 关键结论：深度学习性能更优（Deep learning outperforms traditional methods）"></a>3. 关键结论：深度学习性能更优（Deep learning outperforms traditional methods）</h3><p>“Our findings suggest that deep learning methods exhibit superior performance, particularly in cluttered environments, compared to conventional image processing methods for both of the aforementioned subcategories.”<br>这是综述通过对比大量研究后得出的核心结论——<strong>无论单帧还是多帧场景，深度学习方法的性能都优于传统方法，尤其在复杂杂波环境下</strong>。为什么？  </p>
<ul>
<li>传统方法靠“手工设计特征”（如局部对比度、滤波核），一旦场景变化（比如从“天空背景”变成“城市背景”），手工特征就失效；  </li>
<li>深度学习方法能“自动从数据中学习特征”（比如CNN学习目标的亮度分布、Transformer学习目标与背景的全局关系），面对复杂杂波时，能自适应提取有效特征，减少漏检和虚警。<br>比如在NUAA-SIRST数据集（含云、城市、海洋背景）上，传统方法（如IPI）的检测概率（Pd）约82%，虚警率（Fa）约41%；而深度学习方法（如DNA-Net）的Pd达96%以上，Fa降至22%左右，优势明显。</li>
</ul>
<h3 id="4-附加价值：数据集汇总与未来方向（Dataset-compilation-future-gaps）"><a href="#4-附加价值：数据集汇总与未来方向（Dataset-compilation-future-gaps）" class="headerlink" title="4. 附加价值：数据集汇总与未来方向（Dataset compilation &amp; future gaps）"></a>4. 附加价值：数据集汇总与未来方向（Dataset compilation &amp; future gaps）</h3><p>摘要最后提到两个重要附加贡献：  </p>
<ul>
<li>“In addition, a comprehensive compilation of various available datasets has also been provided.”——汇总了当前所有公开&#x2F;私有数据集（如NUAA-SIRST、IRDST等），并标注了数据集的“图像类型（真实&#x2F;合成）、背景场景、标注方式”，解决了领域内“数据分散”的问题，方便研究者选择合适的数据集训练和测试算法；  </li>
<li>“Furthermore, this review identifies the gaps and limitations in existing techniques, paving the way for future research and development in this area.”——指出了现有技术的瓶颈（如深度学习需要大量标注数据、多帧方法缺乏时空规律数据集），为后续研究指明了方向（如无监督学习、多模态融合），避免研究者“盲目探索”。</li>
</ul>
<h2 id="四、摘要核心价值总结"><a href="#四、摘要核心价值总结" class="headerlink" title="四、摘要核心价值总结"></a>四、摘要核心价值总结</h2><p>最后，我们用三句话概括这篇摘要的核心价值，也是这篇综述的“灵魂”：  </p>
<ol>
<li><strong>定位领域现状</strong>：明确红外小弱目标检测是“新兴领域”，挑战源于“无特征、高杂波、时变信号”；  </li>
<li><strong>建立知识框架</strong>：首次提出“传统&#x2F;深度学习+单帧&#x2F;多帧”的分类体系，梳理了全领域技术；  </li>
<li><strong>提供实用价值</strong>：给出“深度学习更优”的关键结论，汇总数据集、指出未来方向，既是入门者的“指南”，也是研究者的“参考书”。</li>
</ol>
<p>理解了摘要，就等于掌握了整篇文献的“脉络”，后续学习具体方法时，就能更清晰地定位每种方法的“位置”和“价值”。</p>
<h1 id="文献“1-Introduction（引言）”详细讲解"><a href="#文献“1-Introduction（引言）”详细讲解" class="headerlink" title="文献“1. Introduction（引言）”详细讲解"></a>文献“1. Introduction（引言）”详细讲解</h1><p>同学们，引言是一篇综述的“开篇基石”——它会帮我们建立领域认知：先讲红外成像技术的价值，再聚焦“小弱目标检测”这个具体问题，接着分析为什么需要专门算法、当前面临哪些挑战，最后说明这篇综述的研究动机和核心贡献。我们沿着这个逻辑，结合文献原文逐节拆解，确保每个概念都讲透，同时标注对应的文献段落序号，方便大家回溯原文。</p>
<h2 id="一、引言开篇：红外成像技术的“不可替代性”"><a href="#一、引言开篇：红外成像技术的“不可替代性”" class="headerlink" title="一、引言开篇：红外成像技术的“不可替代性”"></a>一、引言开篇：红外成像技术的“不可替代性”</h2><p>文献引言的第一部分（1-17至1-20）先点明红外成像的核心地位——它是很多关键领域的“刚需技术”，尤其在传统光学传感器“失灵”的场景中。我们先梳理这部分的核心信息：</p>
<h3 id="1-红外成像的核心优势"><a href="#1-红外成像的核心优势" class="headerlink" title="1. 红外成像的核心优势"></a>1. 红外成像的核心优势</h3><p>红外（IR）图像的本质是“捕捉物体发射的热辐射”，这一特性让它具备两个传统光学（可见光）成像无法替代的优势：  </p>
<ul>
<li><strong>不受光照&#x2F;天气限制</strong>：白天黑夜、雾天雨天都能工作——比如夜间军事侦察、恶劣天气下的搜救，可见光相机看不清，但红外相机能捕捉物体的热辐射差异；  </li>
<li><strong>穿透部分遮挡</strong>：红外辐射能穿透烟雾、沙尘等，比如战场有烟雾时，可见光相机被遮挡，红外相机仍能检测到烟雾后的车辆或人员<RichMediaReference>。</li>
</ul>
<p>正因为这些优势，红外成像在<strong>监视（Surveillance）、侦察（Reconnaissance）、目标检测（Target Detection）</strong> 三大领域成为核心技术，比如军事上的“导弹逼近告警”、民用的“森林防火”都依赖它<RichMediaReference>。</p>
<h3 id="2-引出核心问题：“小弱目标检测”是红外成像的“关键挑战”"><a href="#2-引出核心问题：“小弱目标检测”是红外成像的“关键挑战”" class="headerlink" title="2. 引出核心问题：“小弱目标检测”是红外成像的“关键挑战”"></a>2. 引出核心问题：“小弱目标检测”是红外成像的“关键挑战”</h3><p>文献明确指出：红外成像领域的核心难题之一，就是“小弱目标检测（detection of small and dim targets）”<RichMediaReference>。为什么这个问题这么重要？因为它直接关系到很多高价值应用的成败——比如军事上，能否远距离检测到敌方的小尺寸导弹&#x2F;飞机，决定了防御系统的反应时间；搜救时，能否在复杂地形（如山区、海洋）中找到微弱热辐射的失踪人员，决定了救援效率<RichMediaReference>。</p>
<p>但这个任务的“难”，从一开始就被强调：小弱目标往往“热对比度差（poor thermal contrast）”——目标和背景的温度差异小，导致红外信号微弱；而且传感器接收的红外特征“细节模糊（subtle differences in IR signatures）”，目标很容易“融”进背景里<RichMediaReference>。再加上噪声（传感器自身热噪声）、杂波（如云层、地面植被的热辐射）、环境变化（如昼夜温度波动）的干扰，进一步增加了检测难度<RichMediaReference>。</p>
<h3 id="3-技术需求：多学科交叉是“破局关键”"><a href="#3-技术需求：多学科交叉是“破局关键”" class="headerlink" title="3. 技术需求：多学科交叉是“破局关键”"></a>3. 技术需求：多学科交叉是“破局关键”</h3><p>要解决“小弱目标检测”这个复杂问题，单一学科不够——文献提到需要“多学科融合”：既要懂信号处理（比如滤波去噪），也要懂机器学习&#x2F;深度学习（比如自动提取目标特征），还要懂计算机视觉（比如目标定位）<RichMediaReference>。这也解释了为什么这个领域的研究需要不同背景的学者合作，比如电子工程、计算机科学、光学工程的研究者共同攻关。</p>
<h2 id="二、1-1-红外成像基础：从“物理原理”到“波段划分”"><a href="#二、1-1-红外成像基础：从“物理原理”到“波段划分”" class="headerlink" title="二、1.1 红外成像基础：从“物理原理”到“波段划分”"></a>二、1.1 红外成像基础：从“物理原理”到“波段划分”</h2><p>1.1节（1-26至1-27）是红外成像的“基础知识课”——只有理解红外辐射的来源和波段特性，才能明白后续检测方法为什么要针对不同场景设计。我们分“物理原理”和“波段划分”两部分讲解：</p>
<h3 id="1-红外辐射的物理基础"><a href="#1-红外辐射的物理基础" class="headerlink" title="1. 红外辐射的物理基础"></a>1. 红外辐射的物理基础</h3><p>文献开篇就提了一个关键物理定律：<strong>所有温度高于绝对零度（-273.15℃）的物体，都会发射红外辐射</strong><RichMediaReference>。这是红外成像的“底层逻辑”——无论是人、车辆、飞机，甚至是云层、树木，只要有温度，就会向外辐射红外信号，红外传感器就是捕捉这些信号形成图像的。</p>
<p>这里补充一个历史背景：红外辐射的发现源于200多年前的实验——天文学家Frederick William Herschel用棱镜和温度传感器研究电磁波谱时，意外发现“红光外侧”的区域温度更高，这就是红外辐射的由来<RichMediaReference>。这个小知识能帮大家记住：红外是电磁波谱的一部分，不是“凭空产生”的。</p>
<h3 id="2-红外光谱的“五波段划分”：不同波段对应不同应用"><a href="#2-红外光谱的“五波段划分”：不同波段对应不同应用" class="headerlink" title="2. 红外光谱的“五波段划分”：不同波段对应不同应用"></a>2. 红外光谱的“五波段划分”：不同波段对应不同应用</h3><p>红外光谱的波长范围是<strong>700纳米（nm）到1毫米（mm）</strong>，但不是所有波段都适合成像——因为大气中的水、二氧化碳会吸收部分红外辐射，只有少数“大气窗口”波段能穿透大气，被传感器捕捉<RichMediaReference>。文献将红外光谱分为五个子波段，每个波段的特性和应用场景完全不同，这是后续“小弱目标检测”的核心前提（比如军事检测主要用中波红外），必须牢记：</p>
<table>
<thead>
<tr>
<th>波段名称</th>
<th>波长范围</th>
<th>核心特性</th>
<th>典型应用场景</th>
</tr>
</thead>
<tbody><tr>
<td>近红外（NIR）</td>
<td>0.7μm - 0.9μm</td>
<td>接近可见光，受光照影响小</td>
<td>夜视仪、人脸识别</td>
</tr>
<tr>
<td>短波红外（SWIR）</td>
<td>0.9μm - 2.5μm</td>
<td>穿透烟雾&#x2F; haze能力强，能看细节</td>
<td>工业缺陷检测、文物修复</td>
</tr>
<tr>
<td>中波红外（MWIR）</td>
<td>3μm - 5μm</td>
<td>军事核心波段，目标红外特征明显</td>
<td>IRST（红外搜索跟踪）、MAWS（导弹逼近告警）</td>
</tr>
<tr>
<td>长波红外（LWIR）</td>
<td>8μm - 12μm</td>
<td>捕捉地面物体稳态热辐射，不受光照影响</td>
<td>安防监控、森林防火</td>
</tr>
<tr>
<td>远红外（FIR）</td>
<td>＜1000μm</td>
<td>穿透性差，能量弱</td>
<td>天文观测、医学成像（少数）</td>
</tr>
</tbody></table>
<p><strong>关键提醒</strong>：中波红外（MWIR）是本文“小弱目标检测”的重点——因为军事场景中的空中目标（如导弹、飞机）在MWIR波段的红外辐射最强，最容易被传感器捕捉，所以绝大多数军事红外检测系统（如IRST、MAWS）都工作在这个波段<RichMediaReference>。后续讲到检测方法时，很多实验都是基于MWIR图像做的，根源就在这里。</p>
<h2 id="三、1-2-小弱目标的“定义”与“重要性”"><a href="#三、1-2-小弱目标的“定义”与“重要性”" class="headerlink" title="三、1.2 小弱目标的“定义”与“重要性”"></a>三、1.2 小弱目标的“定义”与“重要性”</h2><p>1.2节（1-28至1-34）回答两个核心问题：“什么是小弱目标”？“为什么检测它很重要”？这是我们后续理解检测方法的“靶心”——知道要检测的“对象”是什么、有什么特点，才能明白方法设计的逻辑。</p>
<h3 id="1-小目标的“官方定义”：按像素占比划分"><a href="#1-小目标的“官方定义”：按像素占比划分" class="headerlink" title="1. 小目标的“官方定义”：按像素占比划分"></a>1. 小目标的“官方定义”：按像素占比划分</h3><p>文献引用了国际光学工程学会（SPIE）和Zhang等人的研究，给出了明确的“小目标”定义：<strong>占据图像总像素数小于0.12%的目标</strong><RichMediaReference>。我们用具体例子理解这个定义：<br>如果是256×256像素的图像（总像素数&#x3D;256×256&#x3D;65536），那么“小目标”的像素数要小于65536×0.12%≈78.6，即<strong>小于80像素</strong>的目标就是“小目标”<RichMediaReference>。<br>实际场景中，远距离的目标往往更小——比如几百公里外的飞机，在红外传感器上可能只有3×3&#x3D;9像素，远小于80像素的阈值，属于典型的“小目标”。</p>
<h3 id="2-小弱目标检测的“核心应用场景”"><a href="#2-小弱目标检测的“核心应用场景”" class="headerlink" title="2. 小弱目标检测的“核心应用场景”"></a>2. 小弱目标检测的“核心应用场景”</h3><p>文献重点强调了三个领域，其中军事应用是“重中之重”：  </p>
<ul>
<li><strong>军事监视与防御</strong>：比如IRST系统需要检测远距离的敌方飞机&#x2F;导弹，MAWS系统需要实时告警逼近的导弹——这些目标在红外图像中都是“小弱目标”，如果检测不及时，会直接导致防御失败<RichMediaReference>；  </li>
<li><strong>红外制导与无人机（UAV）</strong>：导弹的红外制导系统需要锁定“小弱目标”（如敌方战机引擎），无人机的侦察模块需要在复杂背景中识别地面小目标（如车辆），这些都依赖小弱目标检测技术<RichMediaReference>；  </li>
<li><strong>搜索与救援&#x2F;环境监测</strong>：比如在海洋中寻找落水人员（热辐射微弱，像素少）、在森林中监测小火点（早期火势小，红外信号弱），这些场景中的目标也属于“小弱目标”<RichMediaReference>。</li>
</ul>
<h3 id="3-小弱目标的“关键特性”：为什么难检测？"><a href="#3-小弱目标的“关键特性”：为什么难检测？" class="headerlink" title="3. 小弱目标的“关键特性”：为什么难检测？"></a>3. 小弱目标的“关键特性”：为什么难检测？</h3><p>文献通过“远距离传输损耗”和“时变红外特征”两个点，进一步解释了小弱目标的“弱”和“难”：  </p>
<ul>
<li><strong>远距离导致信号衰减</strong>：即使目标本身红外辐射强（如飞机引擎），但远距离传输时，红外信号会被大气吸收、散射，到达传感器时已经很微弱——比如几百公里外的目标，传感器只能看到“几个像素的暗点”，对比度极低（SCR低）<RichMediaReference>；  </li>
<li><strong>时变红外特征增加复杂度</strong>：同一目标的红外信号会随时间变化——比如文献中的图1（1-32）展示了同一场景在不同时间（10:00-17:00）的红外图像：中午阳光照射时，植被区域温度高，红外亮度高，与天空背景对比度大；傍晚植被温度下降，与天空背景几乎融合，目标（如果存在）的红外特征也会随之变化，导致算法难以“稳定捕捉”<RichMediaReference>。<br>这种“时变特性”的根源是“场景热力学条件变化”——太阳位置移动导致环境温度分布改变，进而影响物体的红外辐射强度和分布<RichMediaReference>。</li>
</ul>
<h2 id="四、1-3-为什么需要“专门算法”？传统方法为什么不行？"><a href="#四、1-3-为什么需要“专门算法”？传统方法为什么不行？" class="headerlink" title="四、1.3 为什么需要“专门算法”？传统方法为什么不行？"></a>四、1.3 为什么需要“专门算法”？传统方法为什么不行？</h2><p>1.3节（1-35至1-42）是引言的“核心矛盾点”——它解释了“为什么不能直接用现成的目标检测算法”，必须为红外小弱目标设计专门方法。这部分要理解“传统图像处理”和“通用深度学习”的局限性，才能明白后续方法的创新方向。</p>
<h3 id="1-传统图像处理方法的“局限性”"><a href="#1-传统图像处理方法的“局限性”" class="headerlink" title="1. 传统图像处理方法的“局限性”"></a>1. 传统图像处理方法的“局限性”</h3><p>传统目标检测（如RGB图像中的行人检测）依赖“空间特征”——比如边缘、纹理、形状，通过手工设计的特征（如HOG、SIFT）来识别目标。但红外小弱目标完全没有这些特征，导致传统方法失效：  </p>
<ul>
<li>小弱目标“无空间特征”：尺寸小（几个像素）、无纹理、形状不规则（amorphous），传统方法依赖的“边缘、纹理”根本不存在——比如3×3像素的目标，连“边缘”都无法定义，更别说提取特征了<RichMediaReference>；  </li>
<li>无法处理复杂背景：传统方法（如阈值分割、简单滤波）只能抑制“均匀背景”（如干净的天空），但面对复杂背景（如云层+地面杂波）时，会产生大量虚警，检测率大幅下降<RichMediaReference>。</li>
</ul>
<h3 id="2-通用深度学习算法的“不适配性”"><a href="#2-通用深度学习算法的“不适配性”" class="headerlink" title="2. 通用深度学习算法的“不适配性”"></a>2. 通用深度学习算法的“不适配性”</h3><p>现在主流的目标检测算法（如RCNN系列、YOLO系列、SSD）在RGB图像中表现很好，但直接用在红外小弱目标检测上会“失效”，原因有两个：  </p>
<ul>
<li><strong>池化层导致目标丢失</strong>：CNN（卷积神经网络）中的池化层（如max-pooling）会缩小特征图尺寸，减少计算量——但小弱目标本身只有几个像素，经过1-2次池化后，目标特征会被“完全覆盖”，深层网络根本看不到目标<RichMediaReference>；  </li>
<li><strong>RGB与红外数据分布差异大</strong>：通用深度学习算法是在RGB图像（如ImageNet）上训练的，学习的是RGB图像的特征（如颜色、纹理），但红外图像只有“灰度值”（代表热辐射强度），数据分布完全不同——比如RGB图像的小目标检测方法（如多尺度学习、数据增强）直接用在红外图像上，性能会大幅下降<RichMediaReference>。</li>
</ul>
<p>文献特别提到Liangkui的研究：CNN的max-pooling层会“抑制或消除”红外小弱目标，因为池化操作会优先保留“大面积、高亮度”的背景特征，而小弱目标的特征被稀释<RichMediaReference>。这就是为什么必须设计“无池化层”或“改进池化层”的专门网络。</p>
<h3 id="3-红外与RGB小目标检测的“本质差异”"><a href="#3-红外与RGB小目标检测的“本质差异”" class="headerlink" title="3. 红外与RGB小目标检测的“本质差异”"></a>3. 红外与RGB小目标检测的“本质差异”</h3><p>最后，文献强调：红外小弱目标检测和RGB小弱目标检测“不是一回事”——RGB小目标检测的核心问题是“尺寸小”，可以通过“多尺度学习、上下文信息融合”解决；但红外小弱目标的核心问题是“无特征、低SCR、背景杂波复杂”，这些问题无法用RGB的方法解决，必须针对性设计<RichMediaReference>。</p>
<h2 id="五、1-4-核心挑战：当前技术面临的“四大难题”"><a href="#五、1-4-核心挑战：当前技术面临的“四大难题”" class="headerlink" title="五、1.4 核心挑战：当前技术面临的“四大难题”"></a>五、1.4 核心挑战：当前技术面临的“四大难题”</h2><p>1.4节（1-43至1-44）将前面提到的“难”总结为“四大挑战”，这些挑战也是后续综述中“方法创新”的“靶点”——算法都是为了解决这些挑战而设计的：</p>
<table>
<thead>
<tr>
<th>挑战类型</th>
<th>具体描述</th>
<th>对检测的影响</th>
</tr>
</thead>
<tbody><tr>
<td>1. 空间特征有限</td>
<td>军事MWIR系统中，远距离目标仅占少数像素（如3-5像素），无纹理&#x2F;形状特征</td>
<td>无法用传统“特征匹配”方法检测</td>
</tr>
<tr>
<td>2. 红外信号时变</td>
<td>场景热力学变化（如昼夜温度）、目标视角变化，导致红外特征不稳定</td>
<td>算法难以“稳定跟踪”目标，鲁棒性差</td>
</tr>
<tr>
<td>3. 高噪声与背景杂波</td>
<td>红外图像噪声高（传感器热噪声）、背景杂波多（云层、植被），掩盖目标信号</td>
<td>目标与背景对比度低（SCR低），易漏检&#x2F;虚警</td>
</tr>
<tr>
<td>4. 目标与背景相似度高</td>
<td>红外小弱目标的灰度值与背景杂波接近（SCR低），比RGB小目标更难区分</td>
<td>算法易将背景杂波误判为目标，虚警率高</td>
</tr>
</tbody></table>
<p>文献特别强调“低SCR”是核心挑战——红外小弱目标的SCR远低于RGB小目标，导致“目标与背景难以区分”，这也是后续方法（如低秩表示、注意力机制）重点解决的问题<RichMediaReference>。</p>
<h2 id="六、1-5-综述的“动机”与“贡献”：为什么这篇综述有价值？"><a href="#六、1-5-综述的“动机”与“贡献”：为什么这篇综述有价值？" class="headerlink" title="六、1.5 综述的“动机”与“贡献”：为什么这篇综述有价值？"></a>六、1.5 综述的“动机”与“贡献”：为什么这篇综述有价值？</h2><p>1.5节（1-45至1-54）是引言的“收尾”——它说明“为什么要写这篇综述”（动机）和“这篇综述做了什么”（贡献），这是理解整篇文献价值的关键。</p>
<h3 id="1-研究动机：现有综述的“局限性”"><a href="#1-研究动机：现有综述的“局限性”" class="headerlink" title="1. 研究动机：现有综述的“局限性”"></a>1. 研究动机：现有综述的“局限性”</h3><p>文献指出，在这篇综述之前，领域内的综述都是“片面的”，无法覆盖全领域技术：  </p>
<ul>
<li>Zhao等人（2022）的综述只关注“单帧红外小目标检测”，不涉及多帧方法<RichMediaReference>；  </li>
<li>Rawat等人（2020）的综述只讲“传统图像处理方法”，不包含深度学习方法<RichMediaReference>；  </li>
<li>Kou等人（2023）的综述只关注“机器学习方法”，不涵盖传统方法和最新深度学习技术<RichMediaReference>；</li>
</ul>
<p>而红外小弱目标检测领域需要一篇“全面综述”——既要覆盖“传统方法”到“深度学习方法”，也要包含“单帧检测”和“多帧检测”，还要汇总数据集、指出未来方向。这就是这篇综述的“写作动机”：填补领域空白，为研究者提供“全景图”<RichMediaReference>。</p>
<h3 id="2-综述的“核心贡献”：四大价值"><a href="#2-综述的“核心贡献”：四大价值" class="headerlink" title="2. 综述的“核心贡献”：四大价值"></a>2. 综述的“核心贡献”：四大价值</h3><p>文献明确列出了四个核心贡献，这也是整篇综述的“骨架”：  </p>
<ul>
<li><strong>首次全面覆盖全领域技术</strong>：这是第一篇涵盖“传统图像处理”到“前沿深度学习”的综述，包括单帧（SIRST）和多帧（MIRST）所有主流方法，解决了现有综述“片面”的问题<RichMediaReference>；  </li>
<li><strong>提出清晰的分类体系（Taxonomy）</strong>：将所有方法分为“传统图像处理”和“深度学习”两大类，每类再细分为“单帧检测（SIRST）”和“多帧检测（MIRST）”（如图3所示）——这个分类体系成为后续研究的“标准框架”，方便研究者定位自己的研究方向、对比同类别方法<RichMediaReference>；  </li>
<li><strong>汇总全领域数据集</strong>：整理了当前所有公开&#x2F;私有数据集（如NUAA-SIRST、NUDT-SIRST、IRDST），标注了数据集的“图像类型（真实&#x2F;合成）、背景场景、标注方式”，解决了领域内“数据分散”的问题，方便研究者选择合适的数据集训练和测试算法<RichMediaReference>；  </li>
<li><strong>梳理挑战与未来方向</strong>：通过分析现有技术的局限性（如传统方法鲁棒性差、深度学习需要大量标注数据），指出未来研究的突破口，为后续研究者提供“导航”<RichMediaReference>。</li>
</ul>
<h3 id="3-综述的“研究方法”与“结构安排”"><a href="#3-综述的“研究方法”与“结构安排”" class="headerlink" title="3. 综述的“研究方法”与“结构安排”"></a>3. 综述的“研究方法”与“结构安排”</h3><p>为了让综述更具可信度，文献还提到了“研究方法”：通过IEEE Xplore、Google Scholar等学术数据库，用“红外成像、小弱目标检测、深度学习”等关键词（1-15）检索相关文献，筛选时重点考虑“方法的影响力和实际适用性”，确保每个分类下都有“代表性算法”<RichMediaReference>。  </p>
<p>最后，文献预告了后续章节的结构（1-56）：第2-3章讲方法分类（传统+深度学习），第4章讲数据集，第5章讲性能评估指标，第6章讲挑战与未来方向，第7章是结论——这个结构逻辑清晰，我们后续也会按这个顺序讲解。</p>
<h2 id="七、引言核心内容总结"><a href="#七、引言核心内容总结" class="headerlink" title="七、引言核心内容总结"></a>七、引言核心内容总结</h2><p>同学们，我们用三句话总结引言的核心价值：  </p>
<ol>
<li><strong>建立领域认知</strong>：从红外成像原理→小弱目标定义→应用场景，帮我们明白“要解决什么问题”“为什么这个问题重要”；  </li>
<li><strong>指出核心矛盾</strong>：传统方法因“无空间特征”失效，通用深度学习因“池化层丢失目标”不适用，必须设计专门算法；  </li>
<li><strong>明确综述价值</strong>：这是第一篇全面覆盖全领域技术的综述，提出分类体系、汇总数据集、指出未来方向，是领域入门和研究的“核心参考书”。</li>
</ol>
<p>理解了引言，我们就掌握了整篇文献的“逻辑起点”——后续学习具体方法时，就能更清晰地定位每种方法“解决了什么问题”“属于哪个分类”“为什么有创新”。</p>
<h1 id="文献“2-Conventional-image-processing-based-approaches（传统图像处理方法）”详细讲解"><a href="#文献“2-Conventional-image-processing-based-approaches（传统图像处理方法）”详细讲解" class="headerlink" title="文献“2. Conventional image processing based approaches（传统图像处理方法）”详细讲解"></a>文献“2. Conventional image processing based approaches（传统图像处理方法）”详细讲解</h1><p>同学们，从这一节开始，我们正式进入“具体技术方法”的学习。传统图像处理方法是红外小弱目标检测的“早期基石”——它们依赖手工设计的信号处理规则或数学模型，核心优势是<strong>计算复杂度低</strong>（适合资源受限的早期硬件），但缺点也很明显：泛化能力差（换个场景性能就下降）、难以处理复杂背景（比如云层+地面杂波）、检测稳定性不如深度学习方法。  </p>
<p>文献将传统方法清晰地分为两大类别：<strong>多帧红外小目标检测（MIRST）</strong> 和<strong>单帧红外小目标检测（SIRST）</strong>——这个分类逻辑和引言里一致，前者用“多帧时空信息”补“单帧空间特征不足”，后者只靠“单帧空间信息”检测。我们沿着这个分类，逐类拆解具体算法，结合公式、实验结果和优缺点，确保大家理解每种方法的“设计逻辑”和“适用场景”。</p>
<h2 id="一、传统方法的“整体定位”：先明确核心特点"><a href="#一、传统方法的“整体定位”：先明确核心特点" class="headerlink" title="一、传统方法的“整体定位”：先明确核心特点"></a>一、传统方法的“整体定位”：先明确核心特点</h2><p>在讲具体算法前，我们先提炼文献对传统方法的整体评价（2-1至2-3），这是理解后续内容的前提：  </p>
<ol>
<li><strong>核心优势</strong>：计算复杂度低——不需要大量数据训练，靠固定的数学公式或滤波规则就能运行，早期军事设备（如老式IRST）算力有限，这类方法是唯一选择；  </li>
<li><strong>关键局限</strong>：  <ul>
<li>泛化性差：手工设计的规则只适配特定场景（如“干净天空背景”），遇到复杂背景（如城市+云层）就失效；  </li>
<li>背景抑制能力弱：只能处理“均匀背景”（如无云的天空），对“非均匀背景杂波”（如地面植被热辐射、云层纹理）抑制效果差；  </li>
<li>检测性能不稳定：相比深度学习方法，传统方法的<strong>检测率（Pd）更低、虚警率（Fa）更高</strong>——比如在复杂背景下，传统方法可能漏检30%以上的目标，或产生大量“误判为目标的背景杂波”。</li>
</ul>
</li>
</ol>
<p>接下来，我们分别讲解MIRST和SIRST的具体方法。</p>
<h2 id="二、2-1-多帧红外小目标检测（MIRST）：用“时间信息”补“空间不足”"><a href="#二、2-1-多帧红外小目标检测（MIRST）：用“时间信息”补“空间不足”" class="headerlink" title="二、2.1 多帧红外小目标检测（MIRST）：用“时间信息”补“空间不足”"></a>二、2.1 多帧红外小目标检测（MIRST）：用“时间信息”补“空间不足”</h2><p>MIRST方法的核心逻辑是：<strong>单帧图像中目标特征弱，但多帧连续观察时，目标会有“运动轨迹”（时间特征），而背景基本不动或缓慢变化</strong>——通过分析“时空联合特征”，就能把目标从背景中分离出来。文献将MIRST分为“匹配滤波类”和“正则流类”两类，我们逐一讲解。</p>
<h3 id="2-1-1-匹配滤波类方法：用“3D滤波器”捕捉“运动目标”"><a href="#2-1-1-匹配滤波类方法：用“3D滤波器”捕捉“运动目标”" class="headerlink" title="2.1.1 匹配滤波类方法：用“3D滤波器”捕捉“运动目标”"></a>2.1.1 匹配滤波类方法：用“3D滤波器”捕捉“运动目标”</h3><p>匹配滤波的本质是“设计一个滤波器，让目标信号通过时被增强，背景&#x2F;噪声被抑制”。由于MIRST处理多帧图像，滤波器需要同时考虑“空间（X-Y）”和“时间（T）”维度，因此是<strong>3D匹配滤波</strong>（2D空间+1D时间）。</p>
<h4 id="（1）经典3D匹配滤波（Reed-et-al-1988-31-）"><a href="#（1）经典3D匹配滤波（Reed-et-al-1988-31-）" class="headerlink" title="（1）经典3D匹配滤波（Reed et al., 1988 [31]）"></a>（1）经典3D匹配滤波（Reed et al., 1988 [31]）</h4><p>这是MIRST领域的“开创性方法”，文献2-26至2-29详细介绍了其原理：  </p>
<ul>
<li><strong>核心思想</strong>：把多帧红外图像看成一个“3D数据块”（X-Y平面是单帧空间，T轴是时间序列），目标在这个3D块中表现为“沿固定速度方向移动的亮斑”，而背景是“随机分布的噪声或缓慢变化的杂波”。  </li>
<li><strong>实现步骤</strong>：  <ol>
<li>定义目标的“先验特征”：包括目标的红外辐射特征（如亮度分布，假设为高斯光斑）和运动特征（速度大小+方向，比如“向右上方匀速移动”）；  </li>
<li>设计3D匹配滤波器：滤波器的“形状”要和目标的“空间亮度分布+时间运动轨迹”完全匹配——比如目标是3×3像素的高斯光斑，速度是“1像素&#x2F;帧向右”，那么滤波器在3D块中就是“沿T轴向右倾斜的3×3高斯核”；  </li>
<li>3D卷积运算：用设计好的滤波器与3D数据块做卷积，卷积结果中“峰值位置”就是目标所在的时空坐标（哪个帧、哪个像素）。</li>
</ol>
</li>
<li><strong>优点</strong>：能同时检测多帧中所有“运动特征匹配”的目标，在“低噪声、目标速度固定”的场景下效果好；  </li>
<li><strong>致命缺点</strong>：<strong>滤波器必须和目标速度完全匹配</strong>——如果目标速度变化（比如导弹机动、飞机转弯），滤波器就“失配”，检测率暴跌。<br>文献提到的解决方案是“滤波器组”：设计多个覆盖不同速度范围（如0.5-2像素&#x2F;帧）和方向（0°-360°）的滤波器，总有一个能匹配目标，但会增加计算量。</li>
</ul>
<h4 id="（2）3D方向导数滤波（3DDF-Porat-et-al-1990-32-）"><a href="#（2）3D方向导数滤波（3DDF-Porat-et-al-1990-32-）" class="headerlink" title="（2）3D方向导数滤波（3DDF, Porat et al., 1990 [32]）"></a>（2）3D方向导数滤波（3DDF, Porat et al., 1990 [32]）</h4><p>这是对经典3D匹配滤波的“改进方法”，解决“速度不确定性”问题，文献2-30至2-33介绍其核心：  </p>
<ul>
<li><strong>核心改进</strong>：不预设目标速度，而是对“每个可能的运动方向”单独设计滤波器，再用规则判断是否有目标；  <ul>
<li>具体做法：把3D数据块按“运动方向”切片（如0°、45°、90°、135°），对每个方向设计“3D方向导数滤波器”——该滤波器对“沿当前方向运动的目标”响应最强，对其他方向的杂波响应弱；  </li>
<li>判决规则：计算每个方向的滤波器输出信噪比（SNR），若某方向SNR超过阈值，则判定该方向存在目标。</li>
</ul>
</li>
<li><strong>关键优势</strong>：SNR随“积分时间（多帧数量）”线性提升——比如用10帧图像的积分时间，SNR比单帧2D滤波高10倍，这是因为多帧时间积分能累积目标能量，抑制随机噪声；  </li>
<li><strong>验证方式</strong>：作者通过“信号功率+噪声功率”的理论计算，证明了SNR提升的线性关系，且实验结果（文献图未展示，但原文有数据）与理论一致。</li>
</ul>
<h4 id="（3）3D双向滤波（3DDDF-Li-et-al-2005-33-）"><a href="#（3）3D双向滤波（3DDDF-Li-et-al-2005-33-）" class="headerlink" title="（3）3D双向滤波（3DDDF, Li et al., 2005 [33]）"></a>（3）3D双向滤波（3DDDF, Li et al., 2005 [33]）</h4><p>这是针对“复杂背景杂波”的进一步改进，文献2-34至2-36强调其在“云杂波场景”中的有效性：  </p>
<ul>
<li><strong>核心创新</strong>：在3D滤波前加“预白化处理”，同时用“双向滤波”增强目标能量；  <ol>
<li>预白化：用“3D时空自适应预测滤波器（TDSTAPF）”先抑制背景杂波——该滤波器能根据背景的时空相关性，预测“下一针背景的样子”，再用当前帧减去预测背景，提前去除大部分杂波；  </li>
<li>3D双向滤波：相比3DDF的“单向滤波”，3DDDF在“目标运动方向”和“垂直方向”都做滤波，进一步累积目标能量，提升目标与背景的对比度。</li>
</ol>
</li>
<li><strong>实验效果</strong>：在“含云杂波的红外序列”中（模拟真实军事场景），3DDDF能有效检测到“3×3像素的弱目标”，且性能优于3DDF——比如在相同SNR下，3DDDF的检测率比3DDF高15%-20%。</li>
</ul>
<h3 id="2-1-2-正则流类方法（Regularity-Flow）：用“时空规律”找目标"><a href="#2-1-2-正则流类方法（Regularity-Flow）：用“时空规律”找目标" class="headerlink" title="2.1.2 正则流类方法（Regularity Flow）：用“时空规律”找目标"></a>2.1.2 正则流类方法（Regularity Flow）：用“时空规律”找目标</h3><p>这类方法的核心逻辑是：<strong>目标的运动是“规律的”（如匀速直线），背景的运动是“杂乱的”（如云层飘动无规律）</strong>——通过提取“时空规律流”，就能定位目标。文献只重点介绍了一种代表性方法：</p>
<h4 id="Nikhil等人的霍夫变换方法（2016-42-）"><a href="#Nikhil等人的霍夫变换方法（2016-42-）" class="headerlink" title="Nikhil等人的霍夫变换方法（2016 [42]）"></a>Nikhil等人的霍夫变换方法（2016 [42]）</h4><p>文献2-37至2-40详细描述了其原理，这是一种“基于视频数据立方的轨迹检测方法”：  </p>
<ul>
<li><strong>核心突破</strong>：不直接在单帧的X-Y平面找目标，而是在“X-T切片”（X是水平像素，T是时间帧）中找目标的运动轨迹；  <ul>
<li>为什么用X-T切片？因为目标在X-T切片中是“一条直线”（匀速运动），这条直线覆盖的像素数远多于单帧X-Y平面中的目标像素数（比如单帧3×3像素，10帧X-T切片中轨迹是3×10&#x3D;30像素）——<strong>像素数增加会显著提升SNR</strong>，让目标更容易被检测；</li>
</ul>
</li>
<li><strong>实现步骤</strong>：  <ol>
<li>构建视频数据立方：把多帧图像堆叠成“X-Y-T”的3D立方；  </li>
<li>切分X-T切片：对每个Y坐标（垂直方向），切出一个“X-T”的2D切片；  </li>
<li>霍夫变换检测直线：在每个X-T切片中用霍夫变换（专门检测直线的算法）找“目标轨迹直线”——直线对应的X-T坐标就是目标的时空位置；</li>
</ol>
</li>
<li><strong>实验条件</strong>：作者用MWIR相机在5公里外拍摄“地面移动车辆”，由于距离远，车辆在图像中是“小目标”（5-10像素）；  </li>
<li><strong>优点</strong>：能有效处理“遮挡”（比如目标被短暂云层遮挡，轨迹直线仍能部分保留）和“背景杂波”（杂波在X-T切片中是杂乱点，不会形成直线）；  </li>
<li><strong>缺点</strong>：  <ul>
<li>仅适用于“固定相机”：如果相机移动（如机载相机），背景也会形成“伪轨迹”，需要先做“图像配准”（对齐多帧图像），但配准会增加计算复杂度；  </li>
<li>无空中目标数据：实验只测了地面目标，未验证空中目标（如飞机、导弹）的检测效果。</li>
</ul>
</li>
</ul>
<h3 id="2-1-3-MIRST方法的“共性局限”"><a href="#2-1-3-MIRST方法的“共性局限”" class="headerlink" title="2.1.3 MIRST方法的“共性局限”"></a>2.1.3 MIRST方法的“共性局限”</h3><p>文献2-41至2-42总结了所有MIRST方法的核心问题，这也是后续深度学习MIRST方法要解决的痛点：  </p>
<ol>
<li><strong>移动相机适配性差</strong>：如果相机移动（如机载、弹载场景），背景会随相机运动产生“伪运动”，必须先做“图像配准”——但配准算法本身有误差，且会增加计算量；  </li>
<li><strong>实时性差</strong>：需要积累多帧数据（比如10-20帧）才能分析轨迹，导致“检测延迟”——军事场景中，导弹逼近告警需要“毫秒级响应”，MIRST的延迟可能导致防御失效；  </li>
<li><strong>速度变化鲁棒性差</strong>：多数MIRST方法假设目标“匀速运动”，如果目标变速（如导弹机动），轨迹会偏离直线，检测率大幅下降。</li>
</ol>
<h2 id="三、2-2-单帧红外小目标检测（SIRST）：无时间信息时，靠“空间模型”分离目标与背景"><a href="#三、2-2-单帧红外小目标检测（SIRST）：无时间信息时，靠“空间模型”分离目标与背景" class="headerlink" title="三、2.2 单帧红外小目标检测（SIRST）：无时间信息时，靠“空间模型”分离目标与背景"></a>三、2.2 单帧红外小目标检测（SIRST）：无时间信息时，靠“空间模型”分离目标与背景</h2><p>SIRST方法只能用“单帧图像的空间信息”检测，核心思路是“假设目标和背景具有不同的空间数学特性”——比如背景是“低秩的”（像素间相关性强）、目标是“稀疏的”（只有少数像素是目标），通过数学模型分离二者。文献将SIRST分为“低秩表示类”“HVS类”“滤波类”三类，我们逐一讲解。</p>
<h3 id="2-2-1-低秩表示类方法：用“矩阵低秩-稀疏”分离背景与目标"><a href="#2-2-1-低秩表示类方法：用“矩阵低秩-稀疏”分离背景与目标" class="headerlink" title="2.2.1 低秩表示类方法：用“矩阵低秩+稀疏”分离背景与目标"></a>2.2.1 低秩表示类方法：用“矩阵低秩+稀疏”分离背景与目标</h3><p>这类方法的数学基础是：<strong>红外图像 &#x3D; 低秩背景 + 稀疏目标 + 随机噪声</strong>——背景像素间相关性强（比如天空背景的相邻像素亮度接近），所以背景矩阵是“低秩”（秩代表矩阵的独立信息维度，低秩意味着信息冗余度高）；目标只有少数像素，所以目标矩阵是“稀疏”（大部分元素为0）。通过“低秩矩阵恢复”算法，就能把背景和目标分开。</p>
<h4 id="（1）IR-Patch-Image模型（IPI-Gao-et-al-2013-29-）"><a href="#（1）IR-Patch-Image模型（IPI-Gao-et-al-2013-29-）" class="headerlink" title="（1）IR Patch-Image模型（IPI, Gao et al., 2013 [29]）"></a>（1）IR Patch-Image模型（IPI, Gao et al., 2013 [29]）</h4><p>这是SIRST领域“低秩表示方法的开山之作”，文献2-43至2-48详细介绍了其原理和公式，我们分“数学模型”“实现步骤”“实验效果”三部分讲解：  </p>
<h5 id="①-核心数学模型"><a href="#①-核心数学模型" class="headerlink" title="① 核心数学模型"></a>① 核心数学模型</h5><p>IPI的核心是“把单帧图像拆成patch，用patch矩阵的低秩+稀疏特性分离背景和目标”，对应的公式是文献中的式(1)和式(2)：  </p>
<ul>
<li><p>式(1)：单帧图像的像素级分解<br>[f_{D}(x,y) &#x3D; f_{T}(x,y) + f_{B}(x,y) + f_{N}(x,y)]<br>符号含义：  </p>
<ul>
<li>(f_D(x,y))：原始红外图像在像素(x,y)处的灰度值；  </li>
<li>(f_T(x,y))：目标图像（只有目标像素非0，其他为0，稀疏）；  </li>
<li>(f_B(x,y))：背景图像（像素间相关性强，低秩）；  </li>
<li>(f_N(x,y))：随机噪声（如传感器热噪声）。</li>
</ul>
</li>
<li><p>式(2)：patch矩阵的分解<br>[D &#x3D; B + T + N]<br>符号含义：  </p>
<ul>
<li>(D)：原始图像拆成的patch矩阵——把图像切成多个重叠的小patch（比如15×15像素），每个patch拉成一个列向量，所有列向量组成矩阵(D)（维度&#x3D;patch像素数×patch数量）；  </li>
<li>(B)：背景patch矩阵（低秩）；  </li>
<li>(T)：目标patch矩阵（稀疏）；  </li>
<li>(N)：噪声patch矩阵。</li>
</ul>
</li>
</ul>
<h5 id="②-实现步骤"><a href="#②-实现步骤" class="headerlink" title="② 实现步骤"></a>② 实现步骤</h5><p>IPI的关键是“求解式(2)，分离B和T”，具体步骤如下：  </p>
<ol>
<li><strong>拆patch</strong>：把原始图像(f_D)切成重叠的patch（重叠率通常50%-70%，确保背景相关性被保留），构建patch矩阵(D)；  </li>
<li><strong>低秩+稀疏优化</strong>：用“加速近邻梯度算法（Accelerated Proximal Gradient）”求解优化问题——最小化(rank(B) + \lambda|T|_1)（(rank(B))是B的秩，(|T|_1)是T的L1范数，λ是平衡参数），同时满足(D \approx B + T)（忽略噪声N）；  <ul>
<li>为什么用L1范数？因为L1范数对“稀疏矩阵”的惩罚更强，能迫使T只有少数元素非0（符合目标稀疏特性）；</li>
</ul>
</li>
<li><strong>图像重建</strong>：把分离后的背景patch矩阵(B)和目标patch矩阵(T)，分别还原成完整的背景图像(f_B)和目标图像(f_T)；  </li>
<li><strong>目标分割与后处理</strong>：对(f_T)用“动态阈值分割”（阈值根据噪声水平自动调整），再用“连通区域分析”去除小噪声点（比如面积＜3像素的连通区域判定为噪声），得到最终检测结果。</li>
</ol>
<h5 id="③-实验效果与缺点"><a href="#③-实验效果与缺点" class="headerlink" title="③ 实验效果与缺点"></a>③ 实验效果与缺点</h5><ul>
<li><strong>实验设置</strong>：作者用“真实红外背景+合成目标”构建数据集——背景来自不同杂波水平的真实红外序列（如天空、城市），目标是4个真实目标经“双三次插值”缩放后的小目标（5-37像素），数据集分10组（不同目标大小和数量）；  </li>
<li><strong>核心结果</strong>：检测概率（Pd）范围0.5-0.9，平均0.82——说明在“中等杂波”场景下效果较好；  </li>
<li><strong>缺点</strong>：  <ul>
<li>对“复杂背景”（如地面植被+云层）处理差：背景矩阵的秩会升高，低秩假设不成立，导致背景分离不彻底，虚警率高；  </li>
<li>计算速度慢：拆patch和矩阵优化的计算量较大，比滤波类方法慢1-2个数量级。</li>
</ul>
</li>
</ul>
<h4 id="（2）重加权IR-Patch-Tensor模型（RIPT-Dai-et-al-2017-30-）"><a href="#（2）重加权IR-Patch-Tensor模型（RIPT-Dai-et-al-2017-30-）" class="headerlink" title="（2）重加权IR Patch-Tensor模型（RIPT, Dai et al., 2017 [30]）"></a>（2）重加权IR Patch-Tensor模型（RIPT, Dai et al., 2017 [30]）</h4><p>这是对IPI的“升级改进”，文献2-49至2-53指出其核心创新是“把矩阵升级为张量，同时融入局部+非局部先验”：  </p>
<h5 id="①-核心改进点"><a href="#①-核心改进点" class="headerlink" title="① 核心改进点"></a>① 核心改进点</h5><ol>
<li><strong>从“矩阵”到“张量”</strong>：IPI用“2D patch矩阵”，丢失了图像的空间相关性（比如相邻patch的位置关系）；RIPT用“3D patch张量”——把图像按“空间位置”拆成patch，保留patch间的空间维度（如X-Y方向的patch排列），更贴合图像的空间结构；  </li>
<li><strong>融合双先验</strong>：  <ul>
<li>非局部自相关先验（背景）：背景的不同patch具有相似性（如天空背景的不同区域patch相似），用这个先验约束背景张量的低秩性；  </li>
<li>局部结构先验（目标）：目标的局部结构是“紧凑的亮斑”，用“结构张量”计算每个像素的权重——边缘像素（如云层边缘）权重低，避免被误判为目标；</li>
</ul>
</li>
<li><strong>重加权策略</strong>：对目标patch张量的元素做“重加权”，增强稀疏性——权重与元素大小成反比，小元素权重高、大元素权重低，迫使优化后只有目标像素（大元素）保留，其他元素（背景&#x2F;噪声）被抑制。</li>
</ol>
<h5 id="②-实验效果与缺点"><a href="#②-实验效果与缺点" class="headerlink" title="② 实验效果与缺点"></a>② 实验效果与缺点</h5><ul>
<li><strong>实验数据集</strong>：NUAA-SIRST（真实图像，427张）和NUDT-SIRST（合成图像，1327张）；  </li>
<li><strong>核心结果</strong>：对比IPI，RIPT的检测率（Pd）提升5%-10%，虚警率（Fa）降低15%-20%——比如在NUAA-SIRST上，RIPT的Pd&#x3D;85.55%，Fa&#x3D;11.47%（IPI的Pd≈75%，Fa≈40%）；  </li>
<li><strong>缺点</strong>：  <ul>
<li>仍有高虚警：在“含小不规则目标”（如飞鸟）的复杂背景中，目标的稀疏性假设不成立，会产生大量虚警；  </li>
<li>计算更复杂：张量优化的计算量比矩阵大，实时性更差。</li>
</ul>
</li>
</ul>
<h4 id="（3）低秩表示类方法的“性能对比”（表1）"><a href="#（3）低秩表示类方法的“性能对比”（表1）" class="headerlink" title="（3）低秩表示类方法的“性能对比”（表1）"></a>（3）低秩表示类方法的“性能对比”（表1）</h4><p>文献表1（2-54）汇总了IPI和RIPT在NUDT-SIRST、NUAA-SIRST数据集上的性能，核心指标是<strong>像素级IoU（交并比）</strong> 和<strong>目标级Pd（检测率）、Fa（虚警率）</strong>：  </p>
<ul>
<li>IoU：衡量分割精度（目标像素与真实目标的重叠度），RIPT的IoU（29.44%）高于IPI（25.67%），说明RIPT的目标分割更准；  </li>
<li>Pd：RIPT的Pd（91.85%）高于IPI（85.55%），说明RIPT漏检少；  </li>
<li>Fa：RIPT的Fa（344.33）低于IPI（41.23？注意表1格式可能有误，实际RIPT在NUAA-SIRST上的Fa更低），说明RIPT误检少。</li>
</ul>
<p><strong>关键结论</strong>：低秩表示方法能适配“低SCR”场景，但复杂背景下虚警率高、计算慢，只适合“均匀背景+中等杂波”场景。</p>
<h3 id="2-2-2-人类视觉系统（HVS）类方法：模仿人眼“找局部对比”"><a href="#2-2-2-人类视觉系统（HVS）类方法：模仿人眼“找局部对比”" class="headerlink" title="2.2.2 人类视觉系统（HVS）类方法：模仿人眼“找局部对比”"></a>2.2.2 人类视觉系统（HVS）类方法：模仿人眼“找局部对比”</h3><p>HVS方法的核心逻辑是“模仿人眼检测目标的方式”——人眼找目标靠“局部对比度”：比如在暗背景中看到一个亮点，是因为亮点与周围像素的亮度差（对比度）足够大。这类方法的代表是<strong>局部对比度方法（LCM, Chen et al., 2013 [34]）</strong>，文献2-55至2-61详细介绍了其原理。</p>
<h4 id="（1）LCM的核心思想"><a href="#（1）LCM的核心思想" class="headerlink" title="（1）LCM的核心思想"></a>（1）LCM的核心思想</h4><p>文献指出，小弱目标的HVS特性有两个：  </p>
<ol>
<li>目标是“局部均匀的紧凑区域”：比如3×3像素的目标，内部像素亮度接近，且区域小；  </li>
<li>目标与背景的“对比度不连续”：目标区域的亮度与周围背景区域的亮度差异显著。</li>
</ol>
<p>LCM的本质是“量化这种局部对比度”，超过阈值的区域就是目标。</p>
<h4 id="（2）实现步骤与公式"><a href="#（2）实现步骤与公式" class="headerlink" title="（2）实现步骤与公式"></a>（2）实现步骤与公式</h4><p>LCM的核心是“3×3网格划分”和“对比度计算”，具体步骤如下：  </p>
<ol>
<li><p><strong>划分3×3网格</strong>：把图像分成不重叠的3×3像素块（网格），每个网格包含9个“子块”——中心子块（记为0）是“目标候选区”，周围8个子块（记为1-8）是“背景参考区”；  </p>
</li>
<li><p><strong>计算关键参数</strong>：通过三个公式计算局部对比度（文献式(3)-(5)）：  </p>
<ul>
<li><p>式(3)：中心子块的最大亮度(L_n)<br>[L_n &#x3D; \max_{j&#x3D;1,2,…,N_0} I_0^j]<br>符号含义：(I_0^j)是中心子块第j个像素的灰度值，(N_0)是中心子块的像素数（通常3×3&#x3D;9），(L_n)代表中心子块的“最亮像素”（目标的核心特征）。  </p>
</li>
<li><p>式(4)：背景子块的平均亮度(m_i)<br>[m_i &#x3D; \frac{1}{N_u} \sum_{1}^{N_u} I_j^i]<br>符号含义：(I_j^i)是第i个背景子块第j个像素的灰度值，(N_u)是背景子块的像素数，(m_i)代表第i个背景子块的“平均亮度”（背景的整体特征）。  </p>
</li>
<li><p>式(5)：局部对比度(C_n)<br>[C_n &#x3D; \min_{i} \left( \frac{L_n^2}{m_i} \right)]<br>符号含义：取“中心最大亮度平方与每个背景子块平均亮度比值”的最小值——这个设计是为了“保守估计对比度”：只有当目标与所有背景子块的对比度都足够大时，(C_n)才会高，避免因个别背景子块亮度异常导致误判。</p>
</li>
</ul>
</li>
<li><p><strong>阈值分割</strong>：设定一个阈值(T_h)（通常根据图像噪声水平自动计算），若(C_n &gt; T_h)，则判定中心子块存在目标；否则为背景。</p>
</li>
</ol>
<h4 id="（3）实验效果与缺点"><a href="#（3）实验效果与缺点" class="headerlink" title="（3）实验效果与缺点"></a>（3）实验效果与缺点</h4><ul>
<li><strong>实验设置</strong>：作者用“自定义数据集”——在真实红外背景中加入“高斯白噪声”（噪声方差0.00001和0.00005，模拟不同噪声水平）；  </li>
<li><strong>核心结果（表2）</strong>：  <ul>
<li>噪声方差0.00001时，Pd&#x3D;86.67%，Fa&#x3D;0.2883（虚警少）；  </li>
<li>噪声方差0.00005时，Pd&#x3D;83.33%，Fa&#x3D;0.3333（噪声增加，Pd下降、Fa上升）；</li>
</ul>
</li>
<li><strong>优点</strong>：计算简单（只有加减乘除和极值运算），实时性好；  </li>
<li><strong>缺点</strong>：  <ul>
<li>对“低对比度目标”无效：如果目标与背景的亮度差小（SCR＜3），(C_n)会低于阈值，导致漏检；  </li>
<li>无法抑制“复杂背景杂波”：比如背景中有“局部亮斑”（如地面反光），会被误判为目标，虚警率飙升。</li>
</ul>
</li>
</ul>
<h3 id="2-2-3-滤波类方法：用“空间滤波”提取“高频目标”"><a href="#2-2-3-滤波类方法：用“空间滤波”提取“高频目标”" class="headerlink" title="2.2.3 滤波类方法：用“空间滤波”提取“高频目标”"></a>2.2.3 滤波类方法：用“空间滤波”提取“高频目标”</h3><p>滤波类方法是SIRST的“早期最常用技术”，核心假设是“目标是高频信号，背景是低频信号”——用“高通滤波”或“形态学滤波”去除低频背景，保留高频目标。文献介绍了6种代表性方法，我们结合表3（2-62）对比讲解，重点突出每种方法的“滤波逻辑”和“性能trade-off”。</p>
<h4 id="（1）滤波类方法的核心分类"><a href="#（1）滤波类方法的核心分类" class="headerlink" title="（1）滤波类方法的核心分类"></a>（1）滤波类方法的核心分类</h4><p>根据滤波原理，可分为“统计滤波”“形态学滤波”“梯度滤波”三类：  </p>
<table>
<thead>
<tr>
<th>方法类型</th>
<th>代表性方法</th>
<th>核心原理</th>
<th>关键参数&#x2F;结构元</th>
</tr>
</thead>
<tbody><tr>
<td>统计滤波</td>
<td>Max-Mean [40]、Max-Median [41]</td>
<td>滑动窗口内计算“方向统计量”（均值&#x2F;中位数），用最大值增强目标</td>
<td>窗口大小（通常5×5）、4个方向（水平&#x2F;垂直&#x2F;两对角线）</td>
</tr>
<tr>
<td>形态学滤波</td>
<td>THM [35]、MTHM [38,39]、CM [38,39]</td>
<td>用“结构元”对图像做“开&#x2F;闭操作”，突出比结构元小的亮目标</td>
<td>结构元形状&#x2F;大小（THM用圆形，MTHM用双环，CM用环形）</td>
</tr>
<tr>
<td>梯度滤波</td>
<td>MODD [38]</td>
<td>计算多方向一二阶导数，融合导数结果增强目标（目标导数大，背景导数小）</td>
<td>4个方向（0°&#x2F;45°&#x2F;-45°&#x2F;90°）、E滤波器（高斯导数核）</td>
</tr>
</tbody></table>
<h4 id="（2）重点方法详解"><a href="#（2）重点方法详解" class="headerlink" title="（2）重点方法详解"></a>（2）重点方法详解</h4><p>我们挑选3种最具代表性的方法，深入讲解其原理：  </p>
<h5 id="①-Max-Mean与Max-Median（统计滤波）"><a href="#①-Max-Mean与Max-Median（统计滤波）" class="headerlink" title="① Max-Mean与Max-Median（统计滤波）"></a>① Max-Mean与Max-Median（统计滤波）</h5><p>文献2-63至2-68介绍了这两种方法，它们是“滑动窗口统计滤波”的经典代表：  </p>
<ul>
<li><strong>Max-Mean原理</strong>：  <ol>
<li>用5×5滑动窗口遍历图像；  </li>
<li>在窗口内计算4个方向的“均值”：水平方向（第3行5个像素）、垂直方向（第3列5个像素）、主对角线（A11-A55）、副对角线（A15-A51），得到(Z_1-Z_4)（文献式(6)-(9)）；  </li>
<li>用4个均值的“最大值”替换窗口中心像素（A33）——目标区域的均值会高于背景，替换后目标会被增强，背景被抑制；</li>
</ol>
</li>
<li><strong>Max-Median原理</strong>：与Max-Mean几乎相同，只是把“均值”换成“中位数”——中位数对噪声更鲁棒（比如窗口内有个别噪声点，中位数不受影响）；  </li>
<li><strong>关键参数</strong>：窗口大小——窗口太小（如3×3）会受噪声影响大，窗口太大（如7×7）会模糊目标；实验表明5×5窗口是“平衡选择”；  </li>
<li><strong>性能（表3）</strong>：Max-Mean的Pd&#x3D;0.9964（漏检极少），但Fa&#x3D;2075（虚警极高）；Max-Median的Pd&#x3D;0.9948，Fa&#x3D;540.33（虚警比Max-Mean低，因为中位数抗噪声）。</li>
</ul>
<h5 id="②-Top-Hat-Morphology（THM，形态学滤波）"><a href="#②-Top-Hat-Morphology（THM，形态学滤波）" class="headerlink" title="② Top-Hat Morphology（THM，形态学滤波）"></a>② Top-Hat Morphology（THM，形态学滤波）</h5><p>文献2-69至2-71介绍了THM，它是“形态学滤波”在红外小目标检测中的经典应用：  </p>
<ul>
<li><strong>形态学操作基础</strong>：THM用“白顶帽变换”——白顶帽变换&#x3D;原始图像 - 图像的“开操作”；  <ul>
<li>开操作&#x3D;先腐蚀（用结构元“侵蚀”亮区域，去除小亮点）再膨胀（用相同结构元“扩大”亮区域，恢复背景）；</li>
</ul>
</li>
<li><strong>核心逻辑</strong>：开操作会“去除比结构元小的亮区域”（目标），保留大的背景区域；原始图像减去开操作结果，就能得到“被去除的小亮区域”（目标）；  </li>
<li><strong>结构元选择</strong>：通常用“圆形结构元”——圆形对目标的形状不敏感（适应不同形状的小目标）；  </li>
<li><strong>性能（表3）</strong>：THM的Pd&#x3D;0.9984（检测率最高），但Fa&#x3D;17942（虚警最高）——因为开操作会把背景中的“小杂波亮斑”也当成目标提取出来。</li>
</ul>
<h5 id="③-Modified-Top-Hat-Morphology（MTHM，改进形态学滤波）"><a href="#③-Modified-Top-Hat-Morphology（MTHM，改进形态学滤波）" class="headerlink" title="③ Modified Top-Hat Morphology（MTHM，改进形态学滤波）"></a>③ Modified Top-Hat Morphology（MTHM，改进形态学滤波）</h5><p>文献2-72至2-75介绍了MTHM，它是对THM的“抗虚警改进”：  </p>
<ul>
<li><strong>核心改进</strong>：用“双结构元”代替THM的“单结构元”——双结构元包括“内圈结构元（B_i）”和“外圈结构元（B_o）”，中间是环形结构（ΔB）；  <ul>
<li>原理：内圈结构元对应“目标大小”，外圈结构元对应“背景区域”；改进的白顶帽变换&#x3D;原始图像 - 图像对“双结构元的开操作”——这样能只提取“比内圈大、比外圈小”的亮区域，抑制背景杂波；</li>
</ul>
</li>
<li><strong>性能（表3）</strong>：MTHM的Pd&#x3D;0.981（比THM低），但Fa&#x3D;1.501（虚警率最低）——这是典型的“检测率-虚警率trade-off”：为了减少虚警，不得不接受一定的漏检。</li>
</ul>
<h4 id="（3）滤波类方法的“共性局限”"><a href="#（3）滤波类方法的“共性局限”" class="headerlink" title="（3）滤波类方法的“共性局限”"></a>（3）滤波类方法的“共性局限”</h4><p>文献2-76至2-80总结了滤波类方法的核心问题：  </p>
<ol>
<li><strong>仅能处理均匀背景</strong>：滤波类方法假设“背景是低频均匀的”，但真实场景中背景是“非均匀杂波”（如云层纹理、地面植被），这些杂波也是高频信号，会被滤波提取出来，导致高虚警；  </li>
<li><strong>手动调参依赖强</strong>：每种方法都有“关键参数”（如THM的结构元大小、MTHM的内圈直径、Max-Mean的窗口大小），参数需要根据场景手动调整——比如天空背景用5×5窗口，城市背景用7×7窗口；在自动化系统（如IRST）中，无法手动调参，性能会大幅下降；  </li>
<li><strong>复杂场景失效</strong>：当背景中有“多杂波+低SCR目标”时，滤波类方法无法区分“目标”和“杂波”，检测率会低于70%，虚警率高于1000。</li>
</ol>
<h2 id="四、传统图像处理方法的“整体总结”"><a href="#四、传统图像处理方法的“整体总结”" class="headerlink" title="四、传统图像处理方法的“整体总结”"></a>四、传统图像处理方法的“整体总结”</h2><p>最后，我们用一张表格汇总传统方法的核心特点，帮助大家建立“全局认知”：  </p>
<table>
<thead>
<tr>
<th>方法类别</th>
<th>子类</th>
<th>核心优势</th>
<th>核心局限</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>MIRST</td>
<td>匹配滤波、正则流</td>
<td>利用时间信息，低SCR场景下比SIRST好</td>
<td>实时性差、移动相机需配准</td>
<td>固定相机、目标匀速运动、低杂波</td>
</tr>
<tr>
<td>SIRST</td>
<td>低秩表示</td>
<td>能适配低SCR，背景分离较彻底</td>
<td>计算慢、复杂背景虚警高</td>
<td>均匀背景、中等杂波</td>
</tr>
<tr>
<td></td>
<td>HVS（LCM）</td>
<td>计算快、实时性好</td>
<td>低对比度目标漏检高</td>
<td>高对比度目标、低噪声</td>
</tr>
<tr>
<td></td>
<td>滤波类（THM&#x2F;MTHM）</td>
<td>实现简单、计算快</td>
<td>均匀背景依赖强、手动调参</td>
<td>简单均匀背景（如干净天空）</td>
</tr>
</tbody></table>
<p><strong>关键结论</strong>：传统图像处理方法是红外小弱目标检测的“早期探索”，它们在“简单场景+资源受限硬件”中有用，但面对“复杂背景+低SCR+实时性需求”的真实场景（如军事机载IRST），性能和鲁棒性都无法满足需求——这也正是“深度学习方法”崛起的原因：深度学习能自动学习复杂场景的特征，无需手动调参，且在复杂背景下的检测率和虚警率都远超传统方法。  </p>
<p>下一节，我们将进入“3. Deep learning based approaches”，看看深度学习是如何解决传统方法的这些痛点的。</p>
]]></content>
  </entry>
  <entry>
    <title>markdown和latex语法写作笔记</title>
    <url>/blog/2025/01/27/%E8%AF%AD%E6%B3%95%E5%86%99%E4%BD%9C%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="引用块"><a href="#引用块" class="headerlink" title="引用块"></a>引用块</h1><p>引用块用&gt; 中间有个空格，引用块里可以接二级引用块<br><em><strong>&#x3D;&#x3D;示例&#x3D;&#x3D;</strong></em></p>
<blockquote>
<p>一级引用块</p>
<blockquote>
<p>二级引用块</p>
<blockquote>
<p>三级引用块</p>
</blockquote>
</blockquote>
</blockquote>
<h1 id="代码段"><a href="#代码段" class="headerlink" title="代码段"></a>代码段</h1><p><strong>记住符号是键盘数字1左边的那个，不是enter左边的那个</strong></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="code">`中间的就是代码段`</span></span><br></pre></td></tr></table></figure>



<p><code>中间的就是代码段</code></p>
<p><code>hello world</code></p>
<p>hello world</p>
<h1 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h1><p>用3个&#96;和3个包围代码，前面的3个后面可接使用的代码语言，即可自动识别高亮</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">File</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,create_time=<span class="string">&#x27;today&#x27;</span></span>): <span class="comment">#对create_time设置默认值</span></span><br><span class="line">        <span class="variable language_">self</span>.name=name</span><br><span class="line">        <span class="variable language_">self</span>.create_time=create_time</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_info</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.name+<span class="string">&#x27;is created at&#x27;</span>+<span class="variable language_">self</span>.create_time</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Video</span>(<span class="title class_ inherited__">File</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,window_size=(<span class="params"><span class="number">640</span>,<span class="number">480</span></span>)</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(name=name,create_time=<span class="string">&#x27;today&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.window_size=window_size</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Text</span>(<span class="title class_ inherited__">File</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,name,laguage=<span class="string">&#x27;zh-cn&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(name=name,create_time=<span class="string">&#x27;today&#x27;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.laguage=laguage</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_more_info</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.get_info()+<span class="string">&#x27;,using laguage of &#x27;</span>+<span class="variable language_">self</span>.laguage</span><br><span class="line">v = Video(<span class="string">&quot;my_video&quot;</span>)   <span class="comment">#定义v的时候必须要输入__init__的参数，否则会报错</span></span><br><span class="line">t = Text(<span class="string">&quot;my_text&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(v.get_info())     <span class="comment"># 调用父类的功能</span></span><br><span class="line"><span class="built_in">print</span>(t.create_time)    <span class="comment"># 调用父类的属性</span></span><br><span class="line"><span class="built_in">print</span>(t.laguage)       <span class="comment"># 调用自己的属性</span></span><br><span class="line"><span class="built_in">print</span>(t.get_more_info()) <span class="comment"># 调用自己加工父类的功能</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="公式段和公式块（latex语法）"><a href="#公式段和公式块（latex语法）" class="headerlink" title="公式段和公式块（latex语法）"></a>公式段和公式块（latex语法）</h1><p>段：两个$$中间用latex语法</p>
<p>块：$$$$中间用latex语法</p>
<p>$\beta x$</p>
<p>$\beta$</p>
<p>$试试$</p>
<p>$ \beta $<br>$$<br>\beta \times x \geq 30<br>$$</p>
<p>$$<br>\varepsilon_r * &#x3D; \frac{1}{2(a_1 + 1)} \times 10^{-n+1}<br>$$</p>
<h2 id="一些latex代码"><a href="#一些latex代码" class="headerlink" title="一些latex代码"></a>一些latex代码</h2><h3 id="varepsilon"><a href="#varepsilon" class="headerlink" title="$\varepsilon$"></a>$\varepsilon$</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\varepsilon</span><br></pre></td></tr></table></figure>

<h3 id="上下标"><a href="#上下标" class="headerlink" title="上下标"></a>上下标</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">_&#123;下标内容&#125;^&#123;上标内容&#125; 或 ^&#123;上标内容&#125;_&#123;下标内容&#125;</span><br><span class="line">如果下标或上标的内容多于一个字符，需要用 &#123;&#125; 包裹，例如 x_&#123;ij&#125; 而不是 x_ij</span><br><span class="line">$$x_i^2 + y_j^3 = z_&#123;ij&#125;^&#123;n+1&#125;$$</span><br></pre></td></tr></table></figure>

<p>$$x_i^2 + y_j^3 &#x3D; z_{ij}^{n+1}$$</p>
<h3 id="绝对值"><a href="#绝对值" class="headerlink" title="绝对值"></a>绝对值</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">|x|</span><br></pre></td></tr></table></figure>

<p>$|x|$</p>
<h3 id="小于等于，大于等于"><a href="#小于等于，大于等于" class="headerlink" title="小于等于，大于等于"></a>小于等于，大于等于</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">小于等于：\leq</span><br><span class="line">大于等于：\geq</span><br><span class="line">$$a \leq b \geq c$$</span><br></pre></td></tr></table></figure>

<p>$$a\leq b \geq c$$</p>
<h3 id="xi"><a href="#xi" class="headerlink" title="$\xi$"></a>$\xi$</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\xi</span><br></pre></td></tr></table></figure>

<h3 id="中间的的顿号"><a href="#中间的的顿号" class="headerlink" title="中间的的顿号"></a>中间的的顿号</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\cdots</span><br></pre></td></tr></table></figure>

<p>$1 \cdots 100$</p>
<h3 id="求积符号-prod"><a href="#求积符号-prod" class="headerlink" title="求积符号$\prod$"></a>求积符号$\prod$</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$\prod$</span><br></pre></td></tr></table></figure>

<p>$\prod$</p>
<h3 id="求和符号-sum"><a href="#求和符号-sum" class="headerlink" title="求和符号$\sum$"></a>求和符号$\sum$</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\sum</span><br></pre></td></tr></table></figure>

<h3 id="公式间距调整"><a href="#公式间距调整" class="headerlink" title="公式间距调整"></a>公式间距调整</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\quad</span><br><span class="line">\qquad：是 \quad 的两倍宽度</span><br></pre></td></tr></table></figure>

<p>$$<br>a \quad b<br>a \qquad b<br>$$</p>
<h3 id="箭头"><a href="#箭头" class="headerlink" title="箭头"></a>箭头</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\rightarrow：生成向右的单线箭头（→）。</span><br><span class="line">\leftarrow：生成向左的单线箭头（←）。</span><br><span class="line">\Leftarrow：生成向左的双线箭头（⇐）。</span><br><span class="line">\leftrightarrow：生成双向的单线箭头（↔）。</span><br><span class="line">\Leftrightarrow：生成双向的双线箭头（⇔）。</span><br><span class="line">\Rightarrow :用于生成向右的双线箭头（⇒）</span><br></pre></td></tr></table></figure>

<p>$$<br>如果  A \Rightarrow B ，那么  B  是  A 的必要条件。<br>$$</p>
<h1 id="语法冲突示例"><a href="#语法冲突示例" class="headerlink" title="语法冲突示例"></a>语法冲突示例</h1><blockquote>
<p>1.\max、\sum需要下标时候，与下划线_不能放在一起,中间要有空格。后续验证只要是字母后接下划线也要空格。有时候空一格反而不好用了</p>
</blockquote>
<p>$$<br>|X|_\infty &#x3D; \max _{1 \leq i \leq n} |x_i|<br>$$</p>
<p>$$<br>|X|<em>\infty &#x3D; \max</em>{1 \leq i \leq n} |x_i|<br>$$</p>
<blockquote>
<p>2.加粗的时候不要把冒号：加进去</p>
</blockquote>
<p><strong>定义</strong>：向量序列 ${X^{(k)}}$ 收敛于向量 $ X^* $  是指对每一个 $ 1 \leq i \leq n $ 都有  —（正常显示）</p>
<p>**定义：*<em>向量序列 ${X^{(k)}}$ 收敛于向量 $ X^</em> $  是指对每一个 $ 1 \leq i \leq n $ 都有  —（异常显示）</p>
<blockquote>
<p>3.*和$符号不要连在一起，中间加空格</p>
</blockquote>
<h1 id="分隔符"><a href="#分隔符" class="headerlink" title="分隔符"></a>分隔符</h1><p>—后面不能接东西</p>
<hr>
<h1 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h1><p>建议用typora自带的&#x3D;&#x3D;<strong>Ctrl T</strong>&#x3D;&#x3D;快捷键</p>
<h1 id="分点"><a href="#分点" class="headerlink" title="分点"></a>分点</h1><h2 id="无序分点"><a href="#无序分点" class="headerlink" title="无序分点"></a>无序分点</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> 后面接文本</span><br></pre></td></tr></table></figure>

<ul>
<li><p>后面接文本</p>
<h2 id="有序分点"><a href="#有序分点" class="headerlink" title="有序分点"></a>有序分点</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 中间有空格</span><br><span class="line">2.</span><br></pre></td></tr></table></figure>

<ol>
<li>中间有空格</li>
<li>记住句号后面有空格</li>
</ol>
</li>
</ul>
<p>-英文这个符号后面接一个空格</p>
<ul>
<li>第一</li>
<li>第二</li>
</ul>
<h1 id="插入视频"><a href="#插入视频" class="headerlink" title="插入视频"></a>插入视频</h1><h1 id="文字样式"><a href="#文字样式" class="headerlink" title="文字样式"></a>文字样式</h1><h2 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;下划线演示&lt;/u&gt;</span><br></pre></td></tr></table></figure>

<p><u>试试下划线</u></p>
<p>这个不方便建议用<u>typora</u>的&#x3D;&#x3D;ctrl+u&#x3D;&#x3D;</p>
<h2 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h2><p>_ 要斜的字体（没有空格）_<br><em>斜体</em><br><strong>&#x3D;&#x3D;备注&#x3D;&#x3D;</strong>：斜体和加粗可以同时使用，如：<em><strong>字体</strong></em></p>
<p>建议用typora的&#x3D;&#x3D;Ctrl I&#x3D;&#x3D;</p>
<h2 id="加粗"><a href="#加粗" class="headerlink" title="加粗"></a>加粗</h2><p>** 要加粗的字体（星号与字体之间没有空格）**</p>
<p><em><strong>示例</strong></em></p>
<p><strong>加粗</strong></p>
<p>建议用&#x3D;&#x3D;Ctrl B&#x3D;&#x3D;快捷键</p>
<h2 id="高亮"><a href="#高亮" class="headerlink" title="高亮"></a>高亮</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">文本`高亮`演示</span><br><span class="line">==高亮部分==</span><br><span class="line">typora适用，markdown不适用，网页端无法正常显示</span><br></pre></td></tr></table></figure>

<p><code>高亮</code></p>
<p>&#x3D;&#x3D;两个等号夹中间&#x3D;&#x3D;</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">hello</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&quot;Hello World&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="文本删除线"><a href="#文本删除线" class="headerlink" title="文本删除线"></a>文本删除线</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">文本~~删除~~线演示</span><br></pre></td></tr></table></figure>

<p><del>两个波浪线</del></p>
<h2 id="大小"><a href="#大小" class="headerlink" title="大小"></a>大小</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-size:60px&quot;</span>&gt;</span>大小<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span style="font-size:40px">大小</span></p>
<h2 id="颜色"><a href="#颜色" class="headerlink" title="颜色"></a>颜色</h2><p>&#x3D;&#x3D;字体颜色支持16进制颜色与RGB颜色表，或者简单的red,blue这种&#x3D;&#x3D;</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color:blue&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color:rgb(116, 219, 38)&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;color:#FF0000&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><span style="color:blue">文本</span></p>
<p><span style="color:rgb(116, 219, 38)">文本</span></p>
<p><span style="color:#FF0000">文本</span></p>
<h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-family:Simsun&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span> #宋体</span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-family: &#x27;Microsoft YaHei&#x27;&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span> #微软雅黑</span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-family: &#x27;Times New Roman&#x27;&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span> #新罗马</span><br><span class="line"><span class="tag">&lt;<span class="name">span</span> <span class="attr">style</span>=<span class="string">&quot;font-family: &#x27;SimHei&#x27;&quot;</span>&gt;</span>文本<span class="tag">&lt;/<span class="name">span</span>&gt;</span> #黑体</span><br></pre></td></tr></table></figure>

<p><span style="font-family:Simsun">文本</span></p>
<p><span style="font-family: 'Microsoft YaHei'">文本</span> </p>
<p><span style="font-family: 'Times New Roman'">文本</span></p>
<h2 id="字体位置"><a href="#字体位置" class="headerlink" title="字体位置"></a>字体位置</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;div style=&quot;text-align: center;&quot;&gt;文本居中&lt;/div&gt;</span><br><span class="line">&lt;div style=&quot;text-align: right;&quot;&gt;文本居右&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<div style="text-align: center;">文本居中</div>

<div style="text-align: right;">文本居右</div>

<h1 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h1><p><a href="#%E8%A1%A8%E6%A0%BC">跳转</a></p>
<p><a href="##%E4%B8%8B%E5%88%92%E7%BA%BF">跳转到高亮</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">英文中括号+英文小括号，括号里是要跳转的地方</span><br><span class="line">[跳转链接名字，随意取](#大纲标题)  PS:#后面不接空格</span><br></pre></td></tr></table></figure>

<p><a href="##%E6%96%9C%E4%BD%93">跳转到斜体</a></p>
<p>建议用&#x3D;&#x3D;Ctrl K&#x3D;&#x3D;快捷键</p>
<h1 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h1><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> [ ] 记得取快递(-和[]间有空格，[ ]中间也有空格，[]和后面的文本也有空格)</span><br></pre></td></tr></table></figure>

<ul>
<li><ul>
<li><input checked="" disabled="" type="checkbox"> 记得取快递</li>
</ul>
</li>
</ul>
<h1 id="文章置顶"><a href="#文章置顶" class="headerlink" title="文章置顶"></a>文章置顶</h1><ul>
<li>你可以直接在文章的<code>front-matter</code>区域里添加<code>sticky: 1</code>属性来把这篇文章置顶。数值越大，置顶的优先级越大。</li>
</ul>
<h1 id="Post-Front-matter"><a href="#Post-Front-matter" class="headerlink" title="Post Front-matter"></a>Post Front-matter</h1><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title:</span><br><span class="line">date:</span><br><span class="line">updated:</span><br><span class="line">tags:</span><br><span class="line">categories:</span><br><span class="line">keywords:</span><br><span class="line">description:</span><br><span class="line">top<span class="emphasis">_img:</span></span><br><span class="line"><span class="emphasis">comments:</span></span><br><span class="line"><span class="emphasis">cover:</span></span><br><span class="line"><span class="emphasis">toc:</span></span><br><span class="line"><span class="emphasis">toc_</span>number:</span><br><span class="line">toc<span class="emphasis">_style_</span>simple:</span><br><span class="line">copyright:</span><br><span class="line">copyright<span class="emphasis">_author:</span></span><br><span class="line"><span class="emphasis">copyright_</span>author<span class="emphasis">_href:</span></span><br><span class="line"><span class="emphasis">copyright_</span>url:</span><br><span class="line">copyright<span class="emphasis">_info:</span></span><br><span class="line"><span class="emphasis">mathjax:</span></span><br><span class="line"><span class="emphasis">katex:</span></span><br><span class="line"><span class="emphasis">aplayer:</span></span><br><span class="line"><span class="emphasis">highlight_</span>shrink:</span><br><span class="line"><span class="section">aside:</span></span><br><span class="line"><span class="section">---</span></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>写法</th>
<th align="center">解释</th>
</tr>
</thead>
<tbody><tr>
<td>title</td>
<td align="center">【必需】文章标题</td>
</tr>
<tr>
<td>date</td>
<td align="center">【必需】文章创建日期</td>
</tr>
<tr>
<td>updated</td>
<td align="center">【可选】文章更新日期</td>
</tr>
<tr>
<td>tags</td>
<td align="center">【可选】文章标籤</td>
</tr>
<tr>
<td>categories</td>
<td align="center">【可选】文章分类</td>
</tr>
<tr>
<td>keywords</td>
<td align="center">【可选】文章关键字</td>
</tr>
<tr>
<td>description</td>
<td align="center">【可选】文章描述</td>
</tr>
<tr>
<td>top_img</td>
<td align="center">【可选】文章顶部图片</td>
</tr>
<tr>
<td>cover</td>
<td align="center">【可选】文章缩略图(如果没有设置top_img,文章页顶部将显示缩略图，可设为false&#x2F;图片地址&#x2F;留空)</td>
</tr>
<tr>
<td>comments</td>
<td align="center">【可选】显示文章评论模块(默认 true)</td>
</tr>
<tr>
<td>toc</td>
<td align="center">【可选】显示文章TOC(默认为设置中toc的enable配置)</td>
</tr>
<tr>
<td>toc_number</td>
<td align="center">【可选】显示toc_number(默认为设置中toc的number配置)</td>
</tr>
<tr>
<td>toc_style_simple</td>
<td align="center">【可选】显示 toc 简洁模式</td>
</tr>
<tr>
<td>copyright</td>
<td align="center">【可选】显示文章版权模块(默认为设置中post_copyright的enable配置)</td>
</tr>
<tr>
<td>copyright_author</td>
<td align="center">【可选】文章版权模块的文章作者</td>
</tr>
<tr>
<td>copyright_author_href</td>
<td align="center">【可选】文章版权模块的文章作者链接</td>
</tr>
<tr>
<td>copyright_url</td>
<td align="center">【可选】文章版权模块的文章连结链接</td>
</tr>
<tr>
<td>copyright_info</td>
<td align="center">【可选】文章版权模块的版权声明文字</td>
</tr>
<tr>
<td>mathjax</td>
<td align="center">【可选】显示mathjax(当设置mathjax的per_page: false时，才需要配置，默认 false)</td>
</tr>
<tr>
<td>katex</td>
<td align="center">【可选】显示katex(当设置katex的per_page: false时，才需要配置，默认 false)</td>
</tr>
<tr>
<td>aplayer</td>
<td align="center">【可选】在需要的页面加载aplayer的js和css,请参考文章下面的音乐 配置</td>
</tr>
<tr>
<td>highlight_shrink</td>
<td align="center">【可选】配置代码框是否展开(true&#x2F;false)(默认为设置中highlight_shrink的配置)</td>
</tr>
<tr>
<td>aside</td>
<td align="center">【可选】显示侧边栏 (默认 true)</td>
</tr>
</tbody></table>
<h1 id="图片插入"><a href="#图片插入" class="headerlink" title="图片插入"></a>图片插入</h1><p><img src="/blog/image/street.png"></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>markdown语法</tag>
      </tags>
  </entry>
  <entry>
    <title>论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks2</title>
    <url>/blog/2025/08/31/%E8%AE%BA%E6%96%87-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ATowards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="学习笔记-深度详尽版-《迈向大规模小目标检测：综述与基准》"><a href="#学习笔记-深度详尽版-《迈向大规模小目标检测：综述与基准》" class="headerlink" title="学习笔记 (深度详尽版): 《迈向大规模小目标检测：综述与基准》"></a>学习笔记 (深度详尽版): 《迈向大规模小目标检测：综述与基准》</h1><h2 id="摘要-Abstract-论文精髓"><a href="#摘要-Abstract-论文精髓" class="headerlink" title="摘要 (Abstract) - 论文精髓"></a>摘要 (Abstract) - 论文精髓</h2><ul>
<li><strong>现状</strong>: 通用目标检测在标准基准上已取得巨大成功，但对于<strong>小目标</strong>的检测性能仍<strong>严重不足</strong>。</li>
<li><strong>核心论点</strong>: 造成此瓶颈的关键原因有二：(1) 小目标自身固有的检测难度；(2) <strong>缺乏一个专门为小目标检测设计的大规模、高质量基准</strong>来驱动研究。</li>
<li><strong>本文贡献</strong>:<ol>
<li><strong>全面综述</strong>: 系统性地回顾了基于深度学习的小目标检测方法，并提出了一个包含六个类别的<strong>分类法</strong>。</li>
<li><strong>构建新基准</strong>: 发布了两个大规模、高质量的小目标检测数据集——<strong>SODA-D</strong> (驾驶场景) 和 <strong>SODA-A</strong> (航空场景)。</li>
<li><strong>深入评测</strong>: 在新数据集上对超过20种主流检测算法进行了全面的基准测试，分析了现有方法的瓶颈，并为未来研究指明了方向。</li>
</ol>
</li>
<li><strong>最终目标</strong>: 通过提供这份全面的综述和高质量的基准，推动小目标检测领域的发展。</li>
</ul>
<hr>
<h2 id="一、-引言-Introduction-问题的提出与工作的意义"><a href="#一、-引言-Introduction-问题的提出与工作的意义" class="headerlink" title="一、 引言 (Introduction) - 问题的提出与工作的意义"></a>一、 引言 (Introduction) - 问题的提出与工作的意义</h2><h3 id="1-1-背景：通用目标检测的成功与短板"><a href="#1-1-背景：通用目标检测的成功与短板" class="headerlink" title="1.1 背景：通用目标检测的成功与短板"></a>1.1 背景：通用目标检测的成功与短板</h3><ul>
<li><strong>成功</strong>: 在深度学习(CNN)的推动下，以Faster R-CNN, YOLO, RetinaNet, FCOS为代表的通用检测器在PASCAL VOC和MS COCO等数据集上取得了卓越的性能。</li>
<li><strong>短板</strong>: 这些先进的模型在处理<strong>小目标</strong>时，性能会发生<strong>急剧下降 (dramatic performance drop)</strong>。这个问题在自动驾驶、航空影像分析、智能监控等关键应用中尤为突出。</li>
</ul>
<h3 id="1-2-核心挑战：为什么小目标检测如此困难？"><a href="#1-2-核心挑战：为什么小目标检测如此困难？" class="headerlink" title="1.2 核心挑战：为什么小目标检测如此困难？"></a>1.2 核心挑战：为什么小目标检测如此困难？</h3><p>引言中将困难归结为几个“内在挑战” (Intrinsic Challenges)，这是理解所有后续方法设计思想的基础。</p>
<ol>
<li><strong>有限的表观信息 (Limited Appearance Information)</strong>: 小目标像素极少，缺乏足够的纹理、形状等细节来供模型学习和区分。</li>
<li><strong>网络下采样导致的信息丢失 (Information Loss during Subsampling)</strong>: CNN为获得高级语义特征而进行的多层下采样（如stride&#x3D;2的卷积或池化），会使小目标的特征信息在网络的深层被彻底“稀释”或“淹没”，导致后续检测头无法感知其存在。</li>
<li><strong>特征表示中的噪声干扰 (Noisy Representation in Feature Maps)</strong>: 由于感受野的存在，一个特征点会受其周围大片区域的影响。对于小目标而言，其特征表达很容易被周围的背景或其他大物体所主导和污染。</li>
<li><strong>定位容忍度低 (Low Tolerance for Bounding Box Perturbation)</strong>: 对于一个100x100的大目标，10个像素的定位误差可能还能接受 (IoU较高)。但对于一个10x10的小目标，2个像素的误差就可能导致IoU低于阈值，被判定为检测失败。</li>
</ol>
<h3 id="1-3-根源：研究基础设施的缺失"><a href="#1-3-根源：研究基础设施的缺失" class="headerlink" title="1.3 根源：研究基础设施的缺失"></a>1.3 根源：研究基础设施的缺失</h3><ul>
<li><strong>现有数据集的局限性</strong>:<ul>
<li><strong>MS COCO</strong>: 虽然被广泛使用，但其小目标的比例和多样性不足以专门评估和优化SOD算法。</li>
<li><strong>特定领域数据集</strong>: 如DOTA, VisDrone（航空影像）、WIDER FACE（人脸），它们虽然包含小目标，但要么场景单一，要么类别有限，要么图像分辨率不高，缺乏一个<strong>大规模、多类别、多场景</strong>的统一SOD基准。</li>
</ul>
</li>
<li><strong>结论</strong>: 缺乏好的“靶场”和“考纲”，是限制小目标检测领域发展的核心障碍。</li>
</ul>
<h3 id="1-4-本文贡献的详细阐述"><a href="#1-4-本文贡献的详细阐述" class="headerlink" title="1.4 本文贡献的详细阐述"></a>1.4 本文贡献的详细阐述</h3><ol>
<li><strong>一份系统的综述</strong>: 不只是罗列文献，而是<strong>构建了一个分类框架</strong>，将现有方法归纳为六大类，阐明了它们各自的动机和技术路径。</li>
<li><strong>两个全新的大规模数据集</strong>:<ul>
<li><strong>SODA-D</strong>: 专注于<strong>驾驶场景</strong>，使用<strong>水平边界框(HBB)</strong>，应对类别多样性、天气、光照变化等挑战。</li>
<li><strong>SODA-A</strong>: 专注于<strong>航空场景</strong>，使用<strong>有向&#x2F;旋转边界框(OBB)</strong>，应对极端的尺度变化、任意的物体方向和密集的物体排列等挑战。</li>
</ul>
</li>
<li><strong>一次深入的基准评测</strong>:<ul>
<li>在SODA上系统性地评估了<strong>20多种</strong>SOTA检测器。</li>
<li>提供了详尽的实验结果，揭示了现有算法在SOD任务上的<strong>真实性能和瓶颈</strong>。</li>
<li>基于实验分析，对未来的研究方向提出了<strong>宝贵的见解</strong>。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="二、-小目标检测方法综述-Review-on-Small-Object-Detection"><a href="#二、-小目标检测方法综述-Review-on-Small-Object-Detection" class="headerlink" title="二、 小目标检测方法综述 (Review on Small Object Detection)"></a>二、 小目标检测方法综述 (Review on Small Object Detection)</h2><p>这是论文的知识核心，将庞杂的研究清晰地划分为六条技术路线。</p>
<h3 id="2-1-样本导向方法-Sample-Oriented-Methods"><a href="#2-1-样本导向方法-Sample-Oriented-Methods" class="headerlink" title="2.1 样本导向方法 (Sample-Oriented Methods)"></a>2.1 样本导向方法 (Sample-Oriented Methods)</h3><ul>
<li><strong>动机</strong>: 直接解决训练数据中“小目标样本不足”和“正负样本严重不平衡”的问题。</li>
<li><strong>子路径1: 数据增强 (Data Augmentation)</strong><ul>
<li><strong>思想</strong>: 在不增加标注成本的情况下，人工创造更多的小目标训练样本。</li>
<li><strong>代表技术</strong>: <strong>“Copy-Pasting”</strong>。从数据集中裁切出小目标的实例，然后随机地粘贴到其他图像的背景上。这能有效增加小目标的出现频率和场景多样性。</li>
</ul>
</li>
<li><strong>子路径2: 优化标签分配 (Optimized Label Assignment)</strong><ul>
<li><strong>思想</strong>: 改进训练时为Anchor（或Anchor point）分配正负标签的策略，确保小目标能获得足够且高质量的正样本进行监督学习。</li>
<li><strong>背景</strong>: 传统的基于固定IoU阈值的分配策略对小目标非常苛刻。</li>
<li><strong>代表技术</strong>: <strong>ATSS (Adaptive Training Sample Selection)</strong>, <strong>SimOTA</strong> 等动态分配策略。它们会根据目标的统计特性（如尺寸、位置）自适应地调整分配标准，让小目标更容易被选为正样本。</li>
</ul>
</li>
</ul>
<h3 id="2-2-尺度感知方法-Scale-Aware-Methods"><a href="#2-2-尺度感知方法-Scale-Aware-Methods" class="headerlink" title="2.2 尺度感知方法 (Scale-Aware Methods)"></a>2.2 尺度感知方法 (Scale-Aware Methods)</h3><ul>
<li><strong>动机</strong>: 解决网络中不同尺度特征的有效表示和融合问题，特别是如何保留和利用对小目标至关重要的低层、高分辨率特征。</li>
<li><strong>代表技术</strong>:<ul>
<li><strong>特征金字塔网络 (FPN)</strong>: 里程碑式的工作。通过一个“自顶向下”的路径和“横向连接”，将高层的强语义信息与低层的精细空间信息相融合，使得每一层预测特征图都具备多尺度信息。</li>
<li><strong>PANet (Path Aggregation Network)</strong>: 在FPN的基础上，增加了一个“自底向上”的路径，进一步加强了低层特征向高层的传播。</li>
<li><strong>BiFPN</strong>: 提出了一种加权的双向特征融合机制，效率更高，效果更好。</li>
</ul>
</li>
<li><strong>核心思想</strong>: 建立网络内部的“信息高速公路”，让高层（看清“是什么”）和低层（看清“在哪里”）的特征能够充分交流。</li>
</ul>
<h3 id="2-3-注意力机制方法-Attention-Based-Methods"><a href="#2-3-注意力机制方法-Attention-Based-Methods" class="headerlink" title="2.3 注意力机制方法 (Attention-Based Methods)"></a>2.3 注意力机制方法 (Attention-Based Methods)</h3><ul>
<li><strong>动机</strong>: 模仿人类视觉系统，让模型学会“聚焦”，将计算资源集中在重要的区域或特征通道上，从而增强小目标的特征并抑制背景噪声。</li>
<li><strong>代表技术</strong>:<ul>
<li><strong>SE (Squeeze-and-Excitation) Net</strong>: 引入<strong>通道注意力</strong>，让模型学习不同特征通道的重要性权重。</li>
<li><strong>CBAM (Convolutional Block Attention Module)</strong>: 结合了<strong>通道注意力</strong>和<strong>空间注意力</strong>，让模型不仅知道“看什么特征”，还知道“看哪里”。</li>
</ul>
</li>
</ul>
<h3 id="2-4-特征模仿方法-Feature-Imitation-Methods"><a href="#2-4-特征模仿方法-Feature-Imitation-Methods" class="headerlink" title="2.4 特征模仿方法 (Feature-Imitation Methods)"></a>2.4 特征模仿方法 (Feature-Imitation Methods)</h3><ul>
<li><strong>动机</strong>: 小目标的特征是天然“低质量”的（模糊、信息少）。能否通过技术手段，将其转化为类似大目标的“高质量”特征？</li>
<li><strong>核心思想</strong>: “让模糊的变清晰”。</li>
<li><strong>代表技术</strong>: <strong>生成对抗网络 (GAN)</strong>。设计一个生成器网络，试图将小目标的低分辨率特征图“超分辨率”或“高清化”，使其在特征层面模仿大目标的清晰特征。同时用一个判别器网络来区分是真的大目标特征还是生成的假特征。通过对抗训练，提升小目标的特征质量。</li>
</ul>
<h3 id="2-5-上下文建模方法-Context-Modeling-Methods"><a href="#2-5-上下文建模方法-Context-Modeling-Methods" class="headerlink" title="2.5 上下文建模方法 (Context-Modeling Methods)"></a>2.5 上下文建模方法 (Context-Modeling Methods)</h3><ul>
<li><strong>动机</strong>: 当小目标自身信息不足以被识别时，其周围的“环境”或“场景”可以提供强有力的线索。</li>
<li><strong>思想</strong>: “物以类聚，境随物迁”。例如，一个“交通标志”大概率出现在“道路”旁边。</li>
<li><strong>代表技术</strong>:<ul>
<li><strong>扩大感受野</strong>: 使用空洞卷积（Dilated Convolution）等技术，在不增加计算量的前提下，让模型看到更广阔的上下文区域。</li>
<li><strong>关系网络 (Relation Networks)</strong>: 显式地建模图像中不同物体或区域之间的关系，利用这种关系来辅助识别。</li>
</ul>
</li>
</ul>
<h3 id="2-6-聚焦-检测方法-Focus-and-Detect-Methods"><a href="#2-6-聚焦-检测方法-Focus-and-Detect-Methods" class="headerlink" title="2.6 聚焦-检测方法 (Focus-and-Detect Methods)"></a>2.6 聚焦-检测方法 (Focus-and-Detect Methods)</h3><ul>
<li><strong>动机</strong>: 对于航空影像等超高分辨率图像，在全图上进行滑动窗口式的密集检测，计算成本极高且效率低下。</li>
<li><strong>思想</strong>: “先粗后精，两步走”。</li>
<li><strong>代表技术</strong>:<ul>
<li><strong>SNIP &#x2F; SNIPER</strong>: 先在不同尺度下对图像块进行筛选，只对那些尺寸适中的目标进行训练和检测。</li>
<li><strong>基于区域提议的方法</strong>: 先用一个轻量级的网络（如高效的分割网络）快速生成可能包含目标的候选区域，然后只在这些区域上运行一个重量级的、精确的检测器。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="三、-SODA-数据集：构建与详解"><a href="#三、-SODA-数据集：构建与详解" class="headerlink" title="三、 SODA 数据集：构建与详解"></a>三、 SODA 数据集：构建与详解</h2><h3 id="3-1-设计哲学与对比"><a href="#3-1-设计哲学与对比" class="headerlink" title="3.1 设计哲学与对比"></a>3.1 设计哲学与对比</h3><ul>
<li><strong>与现有数据集的对比</strong></li>
</ul>
<table>
<thead>
<tr>
<th align="left">数据集</th>
<th align="left">场景</th>
<th align="left">标注</th>
<th align="left">核心优势 &#x2F; 不足</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>MS COCO</strong></td>
<td align="left">通用</td>
<td align="left">HBB</td>
<td align="left">场景多样，但小目标占比和绝对数量不足</td>
</tr>
<tr>
<td align="left"><strong>DOTA</strong></td>
<td align="left">航空</td>
<td align="left">OBB</td>
<td align="left">航空场景，但类别较少，主要面向大中目标</td>
</tr>
<tr>
<td align="left"><strong>VisDrone</strong></td>
<td align="left">航空(无人机)</td>
<td align="left">HBB</td>
<td align="left">无人机视角，但图像分辨率相对较低</td>
</tr>
<tr>
<td align="left"><strong>SODA-D</strong></td>
<td align="left"><strong>驾驶</strong></td>
<td align="left"><strong>HBB</strong></td>
<td align="left"><strong>首个大规模、多类别驾驶场景SOD基准</strong></td>
</tr>
<tr>
<td align="left"><strong>SODA-A</strong></td>
<td align="left"><strong>航空</strong></td>
<td align="left"><strong>OBB</strong></td>
<td align="left"><strong>首个大规模、多类别、高分辨率航空旋转目标SOD基准</strong></td>
</tr>
</tbody></table>
<ul>
<li><strong>物体尺寸定义</strong>: 论文明确定义了多级尺寸，为评测提供了统一标准。<ul>
<li><strong>Tiny</strong>: <code>Area ∈ [2², 16²]</code></li>
<li><strong>Small</strong>: <code>Area ∈ [16², 32²]</code></li>
<li><strong>Medium</strong>: <code>Area ∈ [32², 96²]</code></li>
<li><em>注：SODA数据集中的“小目标”实例占比远超COCO等数据集。</em></li>
</ul>
</li>
</ul>
<h3 id="3-2-SODA-D-详解-驾驶场景"><a href="#3-2-SODA-D-详解-驾驶场景" class="headerlink" title="3.2 SODA-D 详解 (驾驶场景)"></a>3.2 SODA-D 详解 (驾驶场景)</h3><ul>
<li><strong>数据来源</strong>: Mapillary Vistas Dataset (MVD), 自行采集, 网络搜集。覆盖全球不同城市、不同天气和光照条件。</li>
<li><strong>类别</strong>: 9个常见类别，如行人、骑行者、汽车、卡车、交通标志等。</li>
<li><strong>标注</strong>: 使用<strong>水平边界框 (HBB)</strong>。因为在驾驶视角下，物体大多是竖直或水平的，HBB简洁高效。</li>
<li><strong>数据分割</strong>: 训练集 (14,720张), 验证集 (4,907张), 测试集 (4,906张)。</li>
</ul>
<h3 id="3-3-SODA-A-详解-航空场景"><a href="#3-3-SODA-A-详解-航空场景" class="headerlink" title="3.3 SODA-A 详解 (航空场景)"></a>3.3 SODA-A 详解 (航空场景)</h3><ul>
<li><strong>数据来源</strong>: Google Earth。覆盖全球数百个城市，图像分辨率极高 (可达 8000x8000 像素)。</li>
<li><strong>类别</strong>: 9个常见类别，如飞机、船舶、桥梁、港口、棒球场等。</li>
<li><strong>标注</strong>: 使用<strong>有向&#x2F;旋转边界框 (OBB)</strong>。因为在俯视视角下，物体方向任意，OBB能更紧凑、更精确地定位目标，减少背景干扰，这对于密集排列的物体尤为重要。</li>
<li><strong>数据处理</strong>: 由于原始图像过大，在训练时会将其裁剪成 800x800 的小块。</li>
<li><strong>数据分割</strong>: 训练集 (1,511张), 验证集 (504张), 测试集 (504张)。</li>
</ul>
<hr>
<h2 id="四、-实验与分析-Experiments-and-Analysis"><a href="#四、-实验与分析-Experiments-and-Analysis" class="headerlink" title="四、 实验与分析 (Experiments and Analysis)"></a>四、 实验与分析 (Experiments and Analysis)</h2><p>这部分是论文的“验证”环节，通过详实的实验数据揭示了SOD领域的真实现状。</p>
<h3 id="4-1-实验设置"><a href="#4-1-实验设置" class="headerlink" title="4.1 实验设置"></a>4.1 实验设置</h3><ul>
<li><strong>评测模型</strong>: 涵盖了主流的检测器家族，包括：<ul>
<li><strong>两阶段</strong>: Faster R-CNN</li>
<li><strong>一阶段 Anchor-based</strong>: RetinaNet, FSAF</li>
<li><strong>一阶段 Anchor-free</strong>: FCOS, ATSS, RepPoints</li>
<li><strong>OBB检测器</strong>: Rotated FCOS, S²A-Net</li>
</ul>
</li>
<li><strong>骨干网络</strong>: ResNet-50, ResNet-101</li>
<li><strong>评测指标</strong>:<ul>
<li><strong>SODA-D (HBB)</strong>: 标准COCO AP指标 ($AP, AP_{50}, AP_{75}, AP_S$)</li>
<li><strong>SODA-A (OBB)</strong>: 基于旋转IoU计算的AP指标。</li>
</ul>
</li>
</ul>
<h3 id="4-2-核心实验发现-Key-Findings"><a href="#4-2-核心实验发现-Key-Findings" class="headerlink" title="4.2 核心实验发现 (Key Findings)"></a>4.2 核心实验发现 (Key Findings)</h3><ol>
<li><p><strong>骨干网络并非越深越好</strong>:</p>
<ul>
<li><strong>现象</strong>: 在SODA数据集上，使用更深的ResNet-101相比ResNet-50，性能提升非常有限，甚至在某些情况下会下降。</li>
<li><strong>分析</strong>: 这印证了“信息丢失”理论。更深的网络意味着更多的下采样，这可能导致极小目标的特征信息被完全抹去，再强大的网络也无力回天。<strong>如何为小目标设计专门的、高效的浅层网络，是一个值得研究的方向。</strong></li>
</ul>
</li>
<li><p><strong>特征金字塔(FPN)的局限性</strong>:</p>
<ul>
<li><strong>现象</strong>: 所有基于FPN的检测器在SODA上表现平平。</li>
<li><strong>分析</strong>: 尽管FPN是多尺度检测的标配，但其简单的“相加”融合方式对于高层和低层之间巨大的语义鸿沟(semantic gap)可能处理不当。低层的细节特征可能被高层的强语义特征所“污染”。<strong>如何设计更优的特征融合策略来增强小目标的表示，是另一个关键研究点。</strong></li>
</ul>
</li>
<li><p><strong>标签分配策略是关键瓶颈</strong>:</p>
<ul>
<li><strong>现象</strong>: ATSS等先进的标签分配策略相比传统的固定IoU方法，在SOD任务上有显著提升。</li>
<li><strong>分析</strong>: 这表明如何为微小的目标在训练初期分配到稳定且高质量的正样本，对于模型最终的收敛和性能至关重要。<strong>针对极小目标的标签分配策略，是未来研究的重中之重。</strong></li>
</ul>
</li>
<li><p><strong>现有SOTA模型仍有巨大提升空间</strong>:</p>
<ul>
<li><strong>现象</strong>: 即使是当时最先进的检测器，在SODA数据集上的绝对性能值（AP）也普遍不高，远低于它们在COCO等通用数据集上的表现。</li>
<li><strong>结论</strong>: 小目标检测<strong>远未被解决 (far from being solved)</strong>。SODA数据集的提出，清晰地暴露了现有算法的短板，为社区提供了一个明确的、有待攻克的挑战。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="五、-结论与未来展望-Conclusion-and-Future-Work"><a href="#五、-结论与未来展望-Conclusion-and-Future-Work" class="headerlink" title="五、 结论与未来展望 (Conclusion and Future Work)"></a>五、 结论与未来展望 (Conclusion and Future Work)</h2><h3 id="5-1-结论"><a href="#5-1-结论" class="headerlink" title="5.1 结论"></a>5.1 结论</h3><ul>
<li>本文系统地梳理了小目标检测领域，提出了一个统一的分类框架。</li>
<li>通过构建SODA-D和SODA-A两个大规模、高质量的数据集，填补了该领域在基准上的空白。</li>
<li>全面的基准测试揭示了现有方法的瓶颈，证明了小目标检测仍是一个开放且具有挑战性的研究领域。</li>
</ul>
<h3 id="5-2-未来研究方向"><a href="#5-2-未来研究方向" class="headerlink" title="5.2 未来研究方向"></a>5.2 未来研究方向</h3><p>论文为未来的研究者指明了四条明确的道路：</p>
<ol>
<li><strong>专门为SOD设计的网络架构 (Novel Architectures for SOD)</strong>: 探索避免或减少下采样信息损失的新型骨干网络。</li>
<li><strong>改进的多尺度特征表示 (Improved Multi-Scale Feature Representation)</strong>: 研究更有效的特征融合机制，以更好地保留和利用小目标的细节特征。</li>
<li><strong>先进的标签分配策略 (Advanced Label Assignment Strategies)</strong>: 设计专门面向极小目标的、更鲁棒的样本分配方法。</li>
<li><strong>更合适的评估指标 (More Suitable Evaluation Metrics)</strong>: 探索除了AP之外，是否有更能反映SOD任务特性的新评估指标（例如，对微小定位误差不那么敏感的指标）。</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文：小目标检测：Deep learning-based small object detection: A survey</title>
    <url>/blog/2025/08/31/%E8%AE%BA%E6%96%87%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ADeep-learning-based-small-object-detection-A-survey/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Deep-learning-based-small-object-detection-A-survey"><a href="#Deep-learning-based-small-object-detection-A-survey" class="headerlink" title="Deep learning-based small object detection: A survey"></a>Deep learning-based small object detection: A survey</h1><h2 id="一、文献基本信息"><a href="#一、文献基本信息" class="headerlink" title="一、文献基本信息"></a>一、文献基本信息</h2><table>
<thead>
<tr>
<th>项目</th>
<th>内容</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>文章标题</td>
<td>Deep learning-based small object detection: A survey</td>
<td></td>
</tr>
<tr>
<td>作者</td>
<td>Qihan Feng¹, Xinzheng Xu¹, Zhixiao Wang¹,²,*</td>
<td></td>
</tr>
<tr>
<td>单位</td>
<td>¹ 中国矿业大学计算机科学与技术学院（徐州 221116）；² 教育部矿山数字化工程研究中心（徐州 221116）</td>
<td></td>
</tr>
<tr>
<td>通讯作者</td>
<td>Zhixiao Wang，邮箱：<a href="mailto:&#122;&#x68;&#x78;&#119;&#x61;&#110;&#x67;&#64;&#99;&#117;&#109;&#116;&#x2e;&#x65;&#100;&#x75;&#46;&#99;&#110;">zhxwang@cumt.edu.cn</a></td>
<td></td>
</tr>
<tr>
<td>发表期刊</td>
<td>Mathematical Biosciences and Engineering (MBE)</td>
<td>、</td>
</tr>
<tr>
<td>卷期页码</td>
<td>Volume 20, Issue 4, 6551-6590</td>
<td>、</td>
</tr>
<tr>
<td>DOI</td>
<td>10.3934&#x2F;mbe.2023282</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023 年 2 月 2 日（接收：2022.10.18；修回：2022.12.21；录用：2022.12.26）</td>
<td>、、、</td>
</tr>
<tr>
<td>文章类型</td>
<td>Survey（综述）</td>
<td></td>
</tr>
</tbody></table>
<h2 id="二、摘要（核心总览）"><a href="#二、摘要（核心总览）" class="headerlink" title="二、摘要（核心总览）"></a>二、摘要（核心总览）</h2><p><strong>小目标检测（SOD）的重要性</strong>：在刑事侦查、自动驾驶、遥感图像等实际场景中具有关键意义，但因小目标分辨率低、特征含噪声，成为计算机视觉领域的难点任务。</p>
<p><strong>研究角度</strong>：围绕 SOD 的难点，从 4 个维度分析深度学习 - based SOD 算法 —— 提升输入特征分辨率、尺度感知训练、融入上下文信息、数据增强。</p>
<p><strong>关键任务回顾</strong>：涵盖小脸检测、小行人检测、遥感图像目标检测三大核心 SOD 任务。</p>
<p><strong>实验评估</strong>：在 4 个主流小目标数据集上，对通用 SOD 算法及关键任务算法进行性能测试，结果显示 “提升输入特征分辨率” 的网络配置能显著提升 WIDER FACE（小脸）和 Tiny Person（小行人）数据集上的性能。</p>
<p><strong>未来方向</strong>：提出 SOD 领域未来潜在的研究方向。</p>
<h2 id="三、引言（背景与研究定位）"><a href="#三、引言（背景与研究定位）" class="headerlink" title="三、引言（背景与研究定位）"></a>三、引言（背景与研究定位）</h2><h3 id="3-1-目标检测（OD）基础"><a href="#3-1-目标检测（OD）基础" class="headerlink" title="3.1 目标检测（OD）基础"></a>3.1 目标检测（OD）基础</h3><ul>
<li><p><strong>定义</strong>：计算机视觉的基础任务，是目标跟踪、实例分割、动作识别、环境监控等任务的前提。</p>
</li>
<li><p><strong>深度学习推动</strong>：得益于深度卷积神经网络（CNNs）的强特征学习能力，近十年 OD 研究快速发展，分为两类模型：</p>
</li>
</ul>
<ol>
<li><p><strong>两阶段模型</strong>：先生成感兴趣区域（ROI），再对 ROI 微调以分类和定位边界框，代表模型有 R-CNN、Fast R-CNN、Faster R-CNN、SPPNet、特征金字塔网络（FPN）。</p>
</li>
<li><p><strong>单阶段模型</strong>：无需 ROI 阶段，直接从特征图分类和定位目标，代表模型有 YOLO、SSD，及无锚点模型（FSAF、CornerNet、FCOS、CenterNet）。</p>
</li>
</ol>
<h3 id="3-2-小目标检测（SOD）的定义与挑战"><a href="#3-2-小目标检测（SOD）的定义与挑战" class="headerlink" title="3.2 小目标检测（SOD）的定义与挑战"></a>3.2 小目标检测（SOD）的定义与挑战</h3><h4 id="3-2-1-小目标的两种定义方式"><a href="#3-2-1-小目标的两种定义方式" class="headerlink" title="3.2.1 小目标的两种定义方式"></a>3.2.1 小目标的两种定义方式</h4><table>
<thead>
<tr>
<th>定义类型</th>
<th>具体标准</th>
<th>示例</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>相对尺寸</td>
<td>目标边界框宽 &#x2F; 高与图像宽 &#x2F; 高比＜0.1；或目标面积与图像面积比＜0.03</td>
<td>1000×1000 图像中，100×100 的目标</td>
<td></td>
</tr>
<tr>
<td>绝对尺寸</td>
<td>COCO 数据集标准：目标尺寸＜32×32 像素</td>
<td>监控中远处 20×20 像素的人脸</td>
<td></td>
</tr>
</tbody></table>
<h4 id="3-2-2-SOD-的核心挑战"><a href="#3-2-2-SOD-的核心挑战" class="headerlink" title="3.2.2 SOD 的核心挑战"></a>3.2.2 SOD 的核心挑战</h4><p><strong>特征与定位难题</strong>：小目标分辨率低、像素占比少，CNN 的下采样和池化操作会导致空间位置信息丢失，检测头难以精准定位。</p>
<ul>
<li><ul>
<li>示例：SOTA 模型 Co-DETR 在 COCO 数据集上小目标 mAP 仅 48.4%，远低于中目标（67.1%）和大目标（77.3%）。</li>
</ul>
</li>
</ul>
<p><strong>数据集稀缺</strong>：现有小目标数据集多聚焦特定场景（如人脸、行人、交通场景），缺乏通用大规模数据集，模型泛化能力差。</p>
<h3 id="3-3-现有综述的不足"><a href="#3-3-现有综述的不足" class="headerlink" title="3.3 现有综述的不足"></a>3.3 现有综述的不足</h3><ul>
<li><p><strong>普通 OD 综述</strong>：如 Zhao 等（2019）、Li 等（2020），虽提及 SOD 难点，但重点在普通尺寸目标检测，未深入 SOD。</p>
</li>
<li><p><strong>SOD 相关综述</strong>：</p>
</li>
<li><ul>
<li>Chen 等（2020）：讨论 SOD 四大支柱，但未关联检测器基础模块设计与 SOD 挑战；</li>
</ul>
</li>
<li><ul>
<li>Tong 等（2020）：从 5 个角度综述 SOD，但仅覆盖通用 SOD，未涉及关键 SOD 任务；</li>
</ul>
</li>
<li><ul>
<li>Liu 等（2021）：总结 SOD 方法，但仅评估 Faster R-CNN、SSD、YOLO 等少数模型，性能评估不全面；</li>
</ul>
</li>
<li><ul>
<li>其他综述（如 Tong&amp;Wu 2022、Rekavandi 等 2022）：缺乏对 “关键 SOD 任务专用算法” 的全面梳理。</li>
</ul>
</li>
</ul>
<h3 id="3-4-本文的三大贡献"><a href="#3-4-本文的三大贡献" class="headerlink" title="3.4 本文的三大贡献"></a>3.4 本文的三大贡献</h3><p><strong>系统梳理 SOD 算法</strong>：结合 SOD 挑战，构建分类体系（提升分辨率、尺度感知、上下文、数据增强），并综述小脸、小行人、遥感图像三大关键 SOD 任务的方法。</p>
<p><strong>全面性能评估</strong>：不仅在通用数据集上测试通用 SOD 算法，还在三大关键 SOD 任务对应的数据集上评估 SOTA 方法。</p>
<p><strong>提出未来方向</strong>：基于算法分类和性能分析，指出 SOD 未来研究方向（如 SOD 专用优化指标、弱监督 SOD、多任务联合优化等）。</p>
<h3 id="3-5-文章结构"><a href="#3-5-文章结构" class="headerlink" title="3.5 文章结构"></a>3.5 文章结构</h3><ul>
<li><p>第 2 章：通用 SOD 算法（4 大角度）；</p>
</li>
<li><p>第 3 章：关键 SOD 任务（小脸、小行人、遥感）；</p>
</li>
<li><p>第 4 章：数据集与评估指标，及算法性能测试；</p>
</li>
<li><p>第 5 章：SOD 挑战与未来方向；</p>
</li>
<li><p>第 6 章：结论。</p>
</li>
</ul>
<h2 id="四、通用-SOD-算法（4-大核心思路）"><a href="#四、通用-SOD-算法（4-大核心思路）" class="headerlink" title="四、通用 SOD 算法（4 大核心思路）"></a>四、通用 SOD 算法（4 大核心思路）</h2><h3 id="4-1-思路-1：提升输入特征分辨率"><a href="#4-1-思路-1：提升输入特征分辨率" class="headerlink" title="4.1 思路 1：提升输入特征分辨率"></a>4.1 思路 1：提升输入特征分辨率</h3><h4 id="4-1-1-核心逻辑"><a href="#4-1-1-核心逻辑" class="headerlink" title="4.1.1 核心逻辑"></a>4.1.1 核心逻辑</h4><p>小目标定位难的根源是 CNN 下采样导致特征消失、高层特征图空间分辨率低，解决方案是 “用高分辨率特征图 &#x2F; 图像”，但需平衡精度与计算成本。</p>
<h4 id="4-1-2-典型算法与对比"><a href="#4-1-2-典型算法与对比" class="headerlink" title="4.1.2 典型算法与对比"></a>4.1.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>SSD</td>
<td>ECCV 2016</td>
<td>多尺度特征层级（无特征融合），不同层放不同尺度参考窗</td>
<td>可检测多尺度目标</td>
<td>低层预测特征图语义弱，小目标精度提升有限</td>
</tr>
<tr>
<td>FPN</td>
<td>CVPR 2017</td>
<td>网络前向传播生成 4 个多尺度特征图，高层特征上采样后与低层特征融合，每层仅预测一种尺度目标</td>
<td>显著提升 SOD 精度，保持 6 FPS 速度</td>
<td>不同尺度特征层语义差距大，特征表示能力下降</td>
</tr>
<tr>
<td>RetinaNet</td>
<td>ICCV 2017</td>
<td>FPN 基础 + Focal Loss（解决前景 - 背景类别不平衡）</td>
<td>缓解类别不平衡，单阶段模型精度首次超两阶段</td>
<td>-</td>
</tr>
<tr>
<td>FSSD</td>
<td>arXiv 2017</td>
<td>轻量级特征融合模块，下采样构建新特征金字塔</td>
<td>轻量融合，适配小目标</td>
<td>-</td>
</tr>
<tr>
<td>MDSSD</td>
<td>arXiv 2018</td>
<td>对高层语义特征图反卷积，再与低层特征融合</td>
<td>保留小目标空间细节和高语义表示</td>
<td>检测速度低于 SSD</td>
</tr>
<tr>
<td>HRDNet</td>
<td>arXiv 2020</td>
<td>多深度 backbone 接收多分辨率输入，高分辨率输入进浅层网络保位置信息</td>
<td>获取小目标更多细节</td>
<td>参数数量大</td>
</tr>
<tr>
<td>QueryDet</td>
<td>CVPR 2022</td>
<td>查询机制：预测小目标可能位置，仅在这些位置计算，避免全特征图冗余计算</td>
<td>稀疏查询加速推理</td>
<td>-</td>
</tr>
<tr>
<td>EFPN</td>
<td>TMM 2022</td>
<td>FPN 加超分层，提取区域纹理特征增强小目标特征</td>
<td>提升 SOD 精度</td>
<td>超分特征提取增加计算成本</td>
</tr>
<tr>
<td>EESRGAN</td>
<td>arXiv 2020</td>
<td>ESRGAN 加边缘增强子网络（EEN），生成器 + 判别器 + 检测器端到端训练</td>
<td>超分图像质量高，SOD 精度提升</td>
<td>-</td>
</tr>
</tbody></table>
<h4 id="4-1-3-关键技术细节"><a href="#4-1-3-关键技术细节" class="headerlink" title="4.1.3 关键技术细节"></a>4.1.3 关键技术细节</h4><ul>
<li><p><strong>Focal Loss 公式</strong>：<br>$$<br>FL(p)&#x3D;\begin{cases}   -\alpha (1-p)^{\gamma }log(p) &amp; if\ y&#x3D;1 \   -(1-\alpha )p^{\gamma }log(1-p) &amp; otherwise   \end{cases}<br>$$</p>
</li>
<li><ul>
<li>$y&#x3D;1$：正样本（含目标），$y&#x3D;0$：负样本（无目标）；</li>
</ul>
</li>
<li><ul>
<li>$p$：模型预测为正样本的概率；</li>
</ul>
</li>
<li><ul>
<li>$\alpha$：平衡系数，$\gamma$（≥0）：聚焦参数，降低简单背景样本的学习权重，让模型聚焦难样本。</li>
</ul>
</li>
<li><p><strong>EESRGAN 的损失函数</strong>：</p>
</li>
<li><ul>
<li>生成器相对论损失：$L_{G}^{Ra}&#x3D;-E_{I_{HR}}\big [log\big (1-D_{Ra}(I_{HR},I_{ISR})\big )\big ]-E_{I_{SR}}\big [log\big (D_{R\alpha }(I_{ISR},I_{HR})\big )\big ]$</li>
</ul>
</li>
<li><ul>
<li>判别器相对论损失：</li>
</ul>
</li>
<li><ul>
<li>(D_{Ra})：真实图像（(I_{HR})）比生成中间图像（(I_{ISR})）更真实的概率；(E)：计算 mini-batch 内图像的平均值。</li>
</ul>
</li>
</ul>
<h3 id="4-2-思路-2：尺度感知训练"><a href="#4-2-思路-2：尺度感知训练" class="headerlink" title="4.2 思路 2：尺度感知训练"></a>4.2 思路 2：尺度感知训练</h3><h4 id="4-2-1-核心逻辑"><a href="#4-2-1-核心逻辑" class="headerlink" title="4.2.1 核心逻辑"></a>4.2.1 核心逻辑</h4><p>CNN 对尺度变化鲁棒性差（如 COCO 数据集最大目标是最小目标的 20 倍），需通过训练让检测器适应尺度差异。</p>
<h4 id="4-2-2-典型算法与对比"><a href="#4-2-2-典型算法与对比" class="headerlink" title="4.2.2 典型算法与对比"></a>4.2.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>SNIP</td>
<td>CVPR 2018</td>
<td>图像金字塔训练，仅对 “目标尺寸在预定范围” 的样本反向传播损失</td>
<td>有效提升 SOD 性能</td>
<td>需输入图像金字塔，计算成本高</td>
</tr>
<tr>
<td>SNIPER</td>
<td>CVPR 2018</td>
<td>从金字塔每层选 512×512 固定分辨率芯片作为训练单元</td>
<td>支持更大 batch size，提升训练效率和精度</td>
<td>需输入图像金字塔，计算成本高</td>
</tr>
<tr>
<td>SAN</td>
<td>CVPR 2018</td>
<td>将不同尺度卷积特征映射到尺度不变子空间，仅学习通道间关系</td>
<td>增强 CNN 对尺度变化的鲁棒性，计算量增加少</td>
<td>-</td>
</tr>
<tr>
<td>Trident</td>
<td>ICCV 2019</td>
<td>多分支并行网络，每分支用合适膨胀率匹配目标尺寸的感受野，尺度敏感训练</td>
<td>感受野与目标尺寸对齐，提升尺度感知能力</td>
<td>各分支有效样本少，易过拟合</td>
</tr>
<tr>
<td>POD</td>
<td>ICCV 2019</td>
<td>全局尺度学习模块替代普通卷积模块，为不同层学习合适全局尺度</td>
<td>增强网络对尺度变化的敏感性</td>
<td>-</td>
</tr>
</tbody></table>
<h4 id="4-2-3-关键技术细节"><a href="#4-2-3-关键技术细节" class="headerlink" title="4.2.3 关键技术细节"></a>4.2.3 关键技术细节</h4><ul>
<li><strong>Trident 分支有效范围公式</strong>：(l_{i}\leq {\sqrt {wh}}\leq u_{i})，其中(\sqrt{wh})是目标尺寸，(l_i)、(u_i)是第(i)个分支的尺寸上下限。</li>
</ul>
<h3 id="4-3-思路-3：融入上下文信息"><a href="#4-3-思路-3：融入上下文信息" class="headerlink" title="4.3 思路 3：融入上下文信息"></a>4.3 思路 3：融入上下文信息</h3><h4 id="4-3-1-核心逻辑"><a href="#4-3-1-核心逻辑" class="headerlink" title="4.3.1 核心逻辑"></a>4.3.1 核心逻辑</h4><p>视觉目标常与周围环境存在关联，利用上下文信息可辅助检测特征模糊的小目标，分为 “图像级上下文”（全图环境）和 “实例级上下文”（目标间关系）。</p>
<h4 id="4-3-2-典型算法与对比"><a href="#4-3-2-典型算法与对比" class="headerlink" title="4.3.2 典型算法与对比"></a>4.3.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>ContextNet（Chen 等）</td>
<td>ACCV 2017</td>
<td>扩展 R-CNN，用小区域提议生成器 + ContextNet 融合上下文计算分类分数</td>
<td>提升 SOD 精度</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>ION</td>
<td>CVPR 2016</td>
<td>ROI 内：skip pooling 提取多尺度特征；ROI 外：空间 RNN 提取周围上下文</td>
<td>增强小目标特征表示，提升分类与回归性能</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DSSD</td>
<td>arXiv 2017</td>
<td>融合深层语义上下文与浅层特征</td>
<td>语义与细节结合，适配小目标</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>SMN</td>
<td>ICCV 2017</td>
<td>空间记忆网络：检测目标后 “记忆” 其特征，作为先验辅助检测漏检小目标</td>
<td>建模实例级上下文，减少漏检</td>
<td>推理信号与感知信号抵消时梯度消失</td>
<td></td>
</tr>
<tr>
<td>FA-SSD</td>
<td>ICAIIC 2021</td>
<td>F-SSD（高层上下文 + 低层特征拼接）+A-SSD（注意力屏蔽背景）</td>
<td>精度高于 SSD</td>
<td>低于 DSSD 精度</td>
<td>、</td>
</tr>
</tbody></table>
<h4 id="4-3-3-关键技术细节"><a href="#4-3-3-关键技术细节" class="headerlink" title="4.3.3 关键技术细节"></a>4.3.3 关键技术细节</h4><ul>
<li><strong>语义关联函数（Fu 等）</strong>：(s_{i j}’&#x3D;\sigma(i, j) . \phi\left(p_{i}^{o}\right) \phi\left(p_{j}^{o}\right)^{T})，其中(\sigma(i,j))是指示函数，(\phi)将初始区域特征(p_i^o)映射到 latent 表示，建模同类目标的语义共现关系。</li>
</ul>
<h3 id="4-4-思路-4：数据增强"><a href="#4-4-思路-4：数据增强" class="headerlink" title="4.4 思路 4：数据增强"></a>4.4 思路 4：数据增强</h3><h4 id="4-4-1-核心逻辑"><a href="#4-4-1-核心逻辑" class="headerlink" title="4.4.1 核心逻辑"></a>4.4.1 核心逻辑</h4><p>小目标数据集标注成本高、样本少，数据增强可丰富数据集多样性，缓解 “不同尺度目标分布不均” 导致的检测精度下降。</p>
<h4 id="4-4-2-典型算法与对比"><a href="#4-4-2-典型算法与对比" class="headerlink" title="4.4.2 典型算法与对比"></a>4.4.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>Kisantal 等</td>
<td>arXiv 2019</td>
<td>过采样含小目标图像，随机复制粘贴小目标</td>
<td>提升小目标检测精度</td>
<td>随机粘贴导致背景 &#x2F; 尺寸不匹配</td>
<td>、</td>
</tr>
<tr>
<td>RRNet</td>
<td>ICCV 2019</td>
<td>自适应重采样：语义分割网络确定合理区域，再粘贴小目标</td>
<td>解决背景不匹配，适配极小目标</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Ünel 等</td>
<td>CVPR 2019</td>
<td>切片增强：输入图像分割为重叠切片，增加小目标相对像素占比</td>
<td>精度与时间成本平衡好</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DST</td>
<td>arXiv 2020</td>
<td>反馈驱动：小目标损失比例低于阈值时，放大拼接图像补偿小目标</td>
<td>缓解尺度不变性问题</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Chen 等</td>
<td>CVPR 2021</td>
<td>尺度感知自动增强：图像 &#x2F; 框级增强搜索空间 + 帕累托尺度平衡指标</td>
<td>可迁移到其他数据集 &#x2F; 任务，尺度敏感</td>
<td>自动搜索时间成本高</td>
<td>、</td>
</tr>
</tbody></table>
<h3 id="4-5-其他补充策略"><a href="#4-5-其他补充策略" class="headerlink" title="4.5 其他补充策略"></a>4.5 其他补充策略</h3><table>
<thead>
<tr>
<th>策略</th>
<th>代表方法</th>
<th>核心技术</th>
<th>优势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>新标注技术</td>
<td>PPDet（BMVC 2020）</td>
<td>锚点无关，聚合单个特征预测减少标注噪声</td>
<td>降低无判别力特征的训练贡献</td>
<td>、</td>
</tr>
<tr>
<td>无锚点模型</td>
<td>CenterNet++（CVPR 2021）</td>
<td>用 “中心点 + 一对角点” 表示目标，适配任意几何形状</td>
<td>多分辨率下性能优</td>
<td>、</td>
</tr>
<tr>
<td>新评价指标</td>
<td>NWD（arXiv 2021）、RFLA（ECCV 2022）</td>
<td>用高斯分布相似度（NWD）、感受野距离（RFLA）替代 IoU</td>
<td>对小目标位置偏差更鲁棒</td>
<td>、</td>
</tr>
<tr>
<td>切片推理</td>
<td>SAHI（arXiv 2022）</td>
<td>输入图像分割为重叠切片检测，再合并结果</td>
<td>即插即用，无需预训练，提升 SOD 精度</td>
<td>、</td>
</tr>
</tbody></table>
<h2 id="五、关键-SOD-任务（三大实际场景）"><a href="#五、关键-SOD-任务（三大实际场景）" class="headerlink" title="五、关键 SOD 任务（三大实际场景）"></a>五、关键 SOD 任务（三大实际场景）</h2><h3 id="5-1-任务-1：小脸检测"><a href="#5-1-任务-1：小脸检测" class="headerlink" title="5.1 任务 1：小脸检测"></a>5.1 任务 1：小脸检测</h3><h4 id="5-1-1-挑战"><a href="#5-1-1-挑战" class="headerlink" title="5.1.1 挑战"></a>5.1.1 挑战</h4><p>小脸像素低（常＜32×32）、特征弱，易被遮挡，锚点与小脸匹配难度大。</p>
<h4 id="5-1-2-典型算法与对比"><a href="#5-1-2-典型算法与对比" class="headerlink" title="5.1.2 典型算法与对比"></a>5.1.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>多尺度建模</td>
<td>CVPR 2018</td>
<td>以 SSD 为基础，融合稀疏离散图像金字塔 + 多层特征融合</td>
<td>处理尺度偏移，增强小脸特征</td>
<td></td>
</tr>
<tr>
<td>S³FD</td>
<td>ICCV 2017</td>
<td>尺度均衡网络，按 “有效感受野 + 等比例间隔” 设计锚点，尺度补偿匹配</td>
<td>提升小脸召回率，降低误检率</td>
<td>、</td>
</tr>
<tr>
<td>Face-MagNet</td>
<td>ECCV 2018</td>
<td>ConvTranspose 层（kernel&#x3D;8，stride&#x3D;4）放大小脸特征图</td>
<td>增强小脸特征表示</td>
<td></td>
</tr>
<tr>
<td>TinaFace</td>
<td>arXiv 2020</td>
<td>RetinaNet 改进：DCN backbone（学几何变换）+Inception（多尺度）+DIoU 损失（小目标友好）+IoU 感知分支</td>
<td>AP 达 92.4%，Hard 集性能优</td>
<td></td>
</tr>
<tr>
<td>Zhu 等（EMO）</td>
<td>arXiv 2021</td>
<td>期望最大重叠（EMO）分数，增加小尺度锚点，随机移动人脸位置</td>
<td>提升锚点与小脸的 IoU，增加匹配概率</td>
<td>、</td>
</tr>
</tbody></table>
<h3 id="5-2-任务-2：小行人检测"><a href="#5-2-任务-2：小行人检测" class="headerlink" title="5.2 任务 2：小行人检测"></a>5.2 任务 2：小行人检测</h3><h4 id="5-2-1-挑战"><a href="#5-2-1-挑战" class="headerlink" title="5.2.1 挑战"></a>5.2.1 挑战</h4><p>小行人边界模糊、易遮挡，标注框含大量噪声背景，部分数据集（如 TinyPerson）行人像素＜20，宽高比差异大。</p>
<h4 id="5-2-2-典型算法与对比"><a href="#5-2-2-典型算法与对比" class="headerlink" title="5.2.2 典型算法与对比"></a>5.2.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>TLL 网络</td>
<td>ECCV 2018</td>
<td>拓扑线定位（检测行人躯干拓扑线）+ConvLSTM（时序特征聚合）+ 马尔可夫随机场（处理遮挡）</td>
<td>自动适配小尺度行人</td>
<td>未缓解小行人信息丢失</td>
<td>、</td>
</tr>
<tr>
<td>SaYwF</td>
<td>arXiv 2019</td>
<td>三阶段检测：区域分类器找候选区→定位行人→NMS 去冗余</td>
<td>精度与速度平衡好</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>CSP</td>
<td>CVPR 2019</td>
<td>卷积操作将检测转化为 “行人尺度预测 + 中心点预测”，1×1 卷积生成质心热图和尺度图</td>
<td>无需额外后处理</td>
<td>适配宽高比差异大的目标能力弱</td>
<td>、</td>
</tr>
<tr>
<td>FSAF</td>
<td>CVPR 2019</td>
<td>无锚点模块，训练时动态为实例选最优特征层（公式(l’&#x3D;\left\lfloor l_{0}+log _{2}\left(\frac{\sqrt{w h}}{224}\right)\right\rfloor)）</td>
<td>对尺度变化鲁棒性强</td>
<td>无锚点分支优势不及有锚点</td>
<td>、</td>
</tr>
<tr>
<td>Yu 等（TinyPerson）</td>
<td>WACV 2020</td>
<td>构建 TinyPerson 数据集，尺度匹配（公式(P_{(s, T(E)) \approx P_{(s, D)}})）统一预训练与任务数据集特征分布</td>
<td>充分利用已有标注数据</td>
<td>TinyPerson 数据集上性能一般</td>
<td>、</td>
</tr>
</tbody></table>
<h4 id="5-2-3-关键数据集：TinyPerson"><a href="#5-2-3-关键数据集：TinyPerson" class="headerlink" title="5.2.3 关键数据集：TinyPerson"></a>5.2.3 关键数据集：TinyPerson</h4><ul>
<li>聚焦海边行人（海上救援场景），行人像素多＜20，宽高比差异大，含 72,651 个标注小目标。</li>
</ul>
<h3 id="5-3-任务-3：遥感图像-SOD"><a href="#5-3-任务-3：遥感图像-SOD" class="headerlink" title="5.3 任务 3：遥感图像 SOD"></a>5.3 任务 3：遥感图像 SOD</h3><h4 id="5-3-1-挑战"><a href="#5-3-1-挑战" class="headerlink" title="5.3.1 挑战"></a>5.3.1 挑战</h4><p>遥感图像为俯视视角，目标旋转多变、场景密集、小目标占比高，背景复杂（云、植被干扰）。</p>
<h4 id="5-3-2-典型算法与对比"><a href="#5-3-2-典型算法与对比" class="headerlink" title="5.3.2 典型算法与对比"></a>5.3.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>S²A-Net</td>
<td>TGRS 2022</td>
<td>特征对齐模块 + 定向检测模块，保持分类分数与定位精度一致</td>
<td>定向目标检测性能优</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>SCRDet</td>
<td>ICCV 2019</td>
<td>监督多维注意力，突出小目标区域，降低背景噪声</td>
<td>抗干扰能力强</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Oriented R-CNN</td>
<td>ICCV 2021</td>
<td>轻量级 RPN 生成定向候选区</td>
<td>定向检测精度高，mAP 达 76.3</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>ReDet</td>
<td>arXiv 2021</td>
<td>旋转等变网络提取旋转等变特征，旋转不变 RoI Align 对齐特征</td>
<td>模型小，中小目标性能优，mAP 达 76.3</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DarkNet-RI</td>
<td>TGRS 2021</td>
<td>DarkNet53 backbone + 旋转不变层，提取多尺度旋转不变特征</td>
<td>对尺度 &#x2F; 旋转变化鲁棒</td>
<td>遮挡目标检测能力弱</td>
<td>、</td>
</tr>
<tr>
<td>DotD</td>
<td>CVPRW 2021</td>
<td>点距离（DotD）替代 IoU，定义正负锚点</td>
<td>适配定向小目标</td>
<td>-</td>
<td></td>
</tr>
</tbody></table>
<h4 id="5-3-3-关键数据集：DOTA"><a href="#5-3-3-关键数据集：DOTA" class="headerlink" title="5.3.3 关键数据集：DOTA"></a>5.3.3 关键数据集：DOTA</h4><ul>
<li>遥感图像目标检测数据集，DOTA-v1.0 含 2806 张遥感图、188,282 个实例，覆盖 15 类目标（飞机、桥梁、车辆等）。</li>
</ul>
<h2 id="六、SOD-评估（数据集、指标与实验结果）"><a href="#六、SOD-评估（数据集、指标与实验结果）" class="headerlink" title="六、SOD 评估（数据集、指标与实验结果）"></a>六、SOD 评估（数据集、指标与实验结果）</h2><h3 id="6-1-核心数据集"><a href="#6-1-核心数据集" class="headerlink" title="6.1 核心数据集"></a>6.1 核心数据集</h3><table>
<thead>
<tr>
<th>数据集</th>
<th>类型</th>
<th>年份</th>
<th>关键信息</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>MS COCO</td>
<td>通用 OD</td>
<td>2014</td>
<td>80 类检测目标，32.8 万张图，250 万个标注实例，小目标占比 31.62%，背景复杂</td>
<td>、</td>
</tr>
<tr>
<td>WIDER FACE</td>
<td>小脸检测</td>
<td>2016</td>
<td>大规模人脸数据集，从 WIDER 数据集筛选，分 Easy&#x2F;Medium&#x2F;Hard 三难度</td>
<td></td>
</tr>
<tr>
<td>TinyPerson</td>
<td>小行人检测</td>
<td>2020</td>
<td>海边小行人，72,651 个标注小目标，像素多＜20</td>
<td></td>
</tr>
<tr>
<td>DOTA</td>
<td>遥感 SOD</td>
<td>2018</td>
<td>DOTA-v1.0 含 15 类目标，2806 张图，188,282 个实例</td>
<td></td>
</tr>
</tbody></table>
<h3 id="6-2-评估指标"><a href="#6-2-评估指标" class="headerlink" title="6.2 评估指标"></a>6.2 评估指标</h3><table>
<thead>
<tr>
<th>指标</th>
<th>定义与计算</th>
<th>用途</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>FPS（帧 &#x2F; 秒）</td>
<td>每秒处理图像数量，衡量检测速度</td>
<td>评估实时性</td>
<td></td>
</tr>
<tr>
<td>IoU（交并比）</td>
<td>(IoU&#x3D;\frac{ Area \left( bbox _{pred } \cap bbox _{GT} \right)}{ Area \left( bbox _{pred } \cup bbox _{GT} \right)})，预测框与真实框的重叠度</td>
<td>衡量定位精度</td>
<td></td>
</tr>
<tr>
<td>AP（平均精度）</td>
<td>1. 定义正负样本（置信度阈值区分）；2. 计算精确率（(precision&#x3D;\frac{TP}{TP+FP})）和召回率（(recall&#x3D;\frac{TP}{TP+FN})）；3. P-R 曲线下面积（(AP&#x3D;\int_{0}^{1} P(R) dR)）</td>
<td>单类目标检测精度</td>
<td>、</td>
</tr>
<tr>
<td>mAP（平均 AP）</td>
<td>所有类别 AP 的平均值（(mAP&#x3D;\frac{\sum AP}{N})）</td>
<td>多类目标检测精度</td>
<td></td>
</tr>
<tr>
<td>MR（漏检率）</td>
<td>未检测到的真实目标比例，衡量漏检程度</td>
<td>小行人检测常用</td>
<td></td>
</tr>
</tbody></table>
<h4 id="补充：COCO-特殊指标"><a href="#补充：COCO-特殊指标" class="headerlink" title="补充：COCO 特殊指标"></a>补充：COCO 特殊指标</h4><ul>
<li><p>IoU 阈值：0.5-0.95（步长 0.05）；</p>
</li>
<li><p>分尺度 AP：(AP_s)（小目标，面积＜32²）、(AP_m)（中目标，32²＜面积＜96²）、(AP_l)（大目标，面积＞96²）。</p>
</li>
</ul>
<h3 id="6-3-关键实验结果"><a href="#6-3-关键实验结果" class="headerlink" title="6.3 关键实验结果"></a>6.3 关键实验结果</h3><h4 id="6-3-1-通用-SOD（COCO-数据集）"><a href="#6-3-1-通用-SOD（COCO-数据集）" class="headerlink" title="6.3.1 通用 SOD（COCO 数据集）"></a>6.3.1 通用 SOD（COCO 数据集）</h4><ul>
<li><p>最优模型：IENet（AP&#x3D;51.2，(AP_s&#x3D;34.5)）；</p>
</li>
<li><p>提升分辨率有效：HRDNet（(AP_s&#x3D;32.1)）优于 MRCenterNet（(AP_s&#x3D;27.8)）；</p>
</li>
<li><p>速度与精度权衡：YOLOv7-tiny（286 FPS，AP&#x3D;38.7）快但精度低；EESRGAN（3 FPS，(AP_s&#x3D;31.2)）精度高但慢。</p>
</li>
</ul>
<h4 id="6-3-2-小脸检测（WIDER-FACE-数据集）"><a href="#6-3-2-小脸检测（WIDER-FACE-数据集）" class="headerlink" title="6.3.2 小脸检测（WIDER FACE 数据集）"></a>6.3.2 小脸检测（WIDER FACE 数据集）</h4><ul>
<li><p>最优模型：TinaFace（Easy AP&#x3D;96.3，Medium AP&#x3D;95.7，Hard AP&#x3D;92.1）；</p>
</li>
<li><p>关键因素：提升特征分辨率 + 融入上下文（TinaFace、IENet 均采用）。</p>
</li>
</ul>
<h4 id="6-3-3-小行人检测（TinyPerson-数据集）"><a href="#6-3-3-小行人检测（TinyPerson-数据集）" class="headerlink" title="6.3.3 小行人检测（TinyPerson 数据集）"></a>6.3.3 小行人检测（TinyPerson 数据集）</h4><ul>
<li><p>最低漏检率：FCOS（MR50&#x3D;96.12）；</p>
</li>
<li><p>最优小目标 AP：FPN（(AP_{50}^{tiny}&#x3D;47.35)）、Grid R-CNN（(AP_{25}&#x3D;68.89)，(AP_{75}&#x3D;6.38)）。</p>
</li>
</ul>
<h4 id="6-3-4-遥感-SOD（DOTA-数据集）"><a href="#6-3-4-遥感-SOD（DOTA-数据集）" class="headerlink" title="6.3.4 遥感 SOD（DOTA 数据集）"></a>6.3.4 遥感 SOD（DOTA 数据集）</h4><ul>
<li><p>最优 mAP：ReDet、Oriented R-CNN（均为 76.3）；</p>
</li>
<li><p>关键因素：定向检测 + 旋转不变特征（适配遥感目标旋转特性）。</p>
</li>
</ul>
<h4 id="6-3-5-核心结论"><a href="#6-3-5-核心结论" class="headerlink" title="6.3.5 核心结论"></a>6.3.5 核心结论</h4><p><strong>提升输入特征分辨率是当前最有效、最普适的 SOD 优化策略</strong>，可显著提升各类 SOD 任务性能；其他策略（上下文、数据增强）可作为辅助，但无法替代分辨率提升。</p>
<table>
<thead>
<tr>
<th>对应文档段落</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="七、SOD-的挑战与未来方向"><a href="#七、SOD-的挑战与未来方向" class="headerlink" title="七、SOD 的挑战与未来方向"></a>七、SOD 的挑战与未来方向</h2><h3 id="7-1-五大核心挑战"><a href="#7-1-五大核心挑战" class="headerlink" title="7.1 五大核心挑战"></a>7.1 五大核心挑战</h3><ol>
<li><p><strong>特征带噪声</strong>：小目标特征易被背景噪声污染，遮挡 &#x2F; 聚类场景下难分辨边界。</p>
</li>
<li><p><strong>信息丢失不可逆</strong>：CNN 下采样导致小目标特征几乎消失，现有方法仅能缓解，无法完全恢复。</p>
</li>
<li><p><strong>感受野不匹配</strong>：深层网络感受野大，易将小目标误判为背景；浅层感受野小，语义弱。</p>
</li>
<li><p><strong>位置偏差敏感</strong>：IoU 类指标对小目标位置偏差极敏感，难选合适阈值区分正负样本。</p>
</li>
<li><p><strong>数据集稀缺</strong>：通用大规模小目标数据集少，标注成本高，COCO 等数据集小目标占比低且分布不均。</p>
</li>
</ol>
<h3 id="7-2-四大未来方向"><a href="#7-2-四大未来方向" class="headerlink" title="7.2 四大未来方向"></a>7.2 四大未来方向</h3><ol>
<li><p><strong>弱监督 &#x2F; 无监督 &#x2F; 自监督 SOD</strong>：减少对 bounding box 标注的依赖（如用图像级标签、对比学习），降低标注成本。</p>
</li>
<li><p><strong>SOD 专用指标</strong>：设计对小目标位置 &#x2F; 旋转偏差鲁棒的指标（如 NWD 的改进），替代 IoU 类指标。</p>
</li>
<li><p><strong>多任务联合优化</strong>：融合 SOD 与超分、语义分割、目标跟踪等任务，联合训练提升性能。</p>
</li>
<li><p><strong>开放世界 &#x2F; 少样本 SOD</strong>：解决 “未知小目标识别”（开放世界）和 “少量标注样本训练”（少样本）问题，适配实际场景。</p>
</li>
</ol>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol>
<li><p>系统综述了深度学习 - based SOD 算法，从 “提升分辨率、尺度感知、上下文、数据增强”4 个维度梳理，并总结三大关键 SOD 任务的方法。</p>
</li>
<li><p>实验验证 “提升输入特征分辨率” 是最优 SOD 优化策略。</p>
</li>
<li><p>指出 SOD 的五大挑战与四大未来研究方向，为领域发展提供参考。</p>
</li>
</ol>
<h2 id="九、致谢与其他"><a href="#九、致谢与其他" class="headerlink" title="九、致谢与其他"></a>九、致谢与其他</h2><ul>
<li><p><strong>基金支持</strong>：国家自然科学基金（61876186）、徐州市科技项目（KC21300）。</p>
</li>
<li><p><strong>利益冲突</strong>：作者声明无利益冲突。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读：Zero-Shot Detection</title>
    <url>/blog/2025/10/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AZero-Shot-Detection/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><p><strong>1）动机：检测要走向“长尾、开放世界”</strong></p>
<p>在大规模应用里（想象自动驾驶、通用机器人、视频理解），<strong>不可能</strong>为每一个可能的目标类别都收集充足的“框+类别”标注。</p>
<p>传统检测（如 YOLOv2、Faster R-CNN）需要大量带框监督，这在规模化时不可持续。因此，研究界从<strong>零样本学习（ZSL）里借力：用语义</strong>（属性词、词向量、文本描述等）把“没见过的类”与“见过的类”连接起来，从而在<strong>训练时没见过</strong>某些类别、<strong>测试时要识别检测</strong>它们。</p>
<ul>
<li>不过，过往 ZSL 多是“分类”问题（图像里物体已被很好地裁出来，只需认类）。现实却是更难的“<strong>检测</strong>”：不仅要认，还要<strong>找</strong>（定位边界框）。这正是本文定义并要解决的<strong>零样本检测（ZSD）</strong>。</li>
</ul>
<hr>
<p><strong>2）传统检测器在“未见类”上为什么会失手？</strong></p>
<p>以 YOLOv2 为例，性能高的一个关键是：它在训练中学到一套<strong>非常判别的视觉特征</strong>，并通过“<strong>目标性（objectness）置信度</strong>”的损失把背景强力压下，只保留与“<strong>见过的类</strong>”相似的候选框。<br> 副作用来了：<strong>“未见类”往往被当作背景压掉</strong>。原因是这些类的视觉外观没有出现在训练中，检测器学到的“目标感”其实是围绕“见过类”的。因此一到开放世界，<strong>召回率（recall）大幅下降</strong>——框根本不报，后面的分类就无从谈起。</p>
<hr>
<p><strong>3）关键洞见：把“语义”灌进“视觉”的学习里</strong></p>
<p>作者提出一个核心主张：<strong>想要召回未见类，必须让视觉特征在训练期就“感知到语义亲缘性”</strong>。<br> 做法不是测试时再去找语义，而是<strong>训练时把语义属性作为副任务</strong>，让网络的视觉通道在求解检测时，同时被语义相似性“牵引”。这样，测试时即便来了<strong>语义上接近</strong>（但训练没见过）的新物体，网络也倾向于给它<strong>较高的目标性</strong>，从而<strong>不把它压成背景</strong>。</p>
<hr>
<p><strong>4）方法总览：ZS-YOLO（在 YOLOv2 上“语义注入”）</strong></p>
<p>ZS-YOLO 仍沿用 YOLOv2 的单阶段、端到端、高速框架，但加了两件事：</p>
<ul>
<li><strong>语义属性预测支路</strong>：每个候选框不仅预测位置，还预测一个<strong>属性向量</strong>（例如 Pascal VOC 用 64 维属性）。这一支路的损失会反向影响主干特征，使视觉表征更贴近语义结构。</li>
<li><strong>多模态置信度预测</strong>：最终的“目标性置信度”<strong>不再只看视觉特征</strong>，而是把<u>视觉特征 + 语义属性预测 + 候选框几何（坐标&#x2F;尺寸）</u>拼在一起，再预测“这个框里是不是有前景目标”。</li>
<li><strong>训练时，网络用一个多任务损失</strong>同时优化：定位损失（框的回归）、语义损失（前景框的属性要像其真值、背景框不要像任一见过类属性）、以及目标性损失（前景高、背景低）。<br> <strong>测试时一个重要点</strong>：模型<strong>不需要</strong>知道“未见类的语义向量”，也不需要外部语义库来运行检测——语义支路在测试阶段更像是<strong>帮助学到“有目标”的感觉</strong>，而非用来对齐到具体的未见类别名称；它提升的是**“报出前景”&#x2F;召回<strong>这一步。若你希望进一步给报出的框</strong>贴上类名**，那就可以<strong>在检测之后</strong>再接任一零样本识别器（最近邻到语义原型、或更强的 gZSL 分类器）去做分类。</li>
</ul>
<hr>
<p><strong>5）为什么不做“检测器 + 零样本分类器”的简单级联？</strong></p>
<p>直觉上，你也许会想：先用 YOLOv2 报框，再丢去零样本分类器就好了。作者指出：<em><em>这级联并不能解决“YOLOv2 不报未见框”<em>的问题。因为第一阶段就漏掉了</em></em>，后一阶段无框可分。问题的关键在</em><em>召回</em><em>，而不是最后一步的*<em>判类</em></em>。ZS-YOLO 正是通过把语义信号<strong>前置到目标性学习里</strong>，来“唤起”未见类的目标性，让它们首先<strong>被报出来</strong>。</p>
<hr>
<p>6）与识别任务（ZSL&#x2F;gZSL）的关系</p>
<p>作者这篇工作<strong>聚焦检测</strong>（提出前景框），并说明<strong>完全可以</strong>在此基础上“外接”零样本识别模块，把未见前景进一步标类。之所以先聚焦检测：</p>
<ul>
<li>现实数据里，<strong>没标注的未见类</strong>广泛存在，<strong>检测的漏报</strong>是瓶颈；</li>
<li>语义用于<strong>提升目标性与召回</strong>，这是当前数据条件下<strong>更紧迫也更可评估</strong>的一步。</li>
</ul>
<hr>
<p>7）实验端给出的直观成效（作者在导论中已预告）</p>
<p>作者在 VOC &#x2F; COCO 上报告：在<strong>高置信度</strong>阈值下（例如 0.9），未见类的<strong>召回率</strong>大幅提高（导论处举例：从 ~18.6% 提到 ~48.2%）；在 VOC 的 10&#x2F;10 拆分上，未见类**平均精度（AP）**也从 ~56.4% 提升到 ~60.1%。这些数字传达的要点是：<strong>我们需要的首先是“报得出来”</strong>，而语义注入正帮助网络把“没见过但语义相近”的目标看成“像目标”，不被当背景压掉。</p>
<blockquote>
<p>小结：ZS-YOLO把“语义—视觉融合”发生在<strong>训练期和目标性层面</strong>，从根上解决<strong>未见类被当背景</strong>的问题；这与事后再分类的级联方案不同。</p>
</blockquote>
<hr>
<p>8）总结</p>
<ol>
<li>现实世界太大，给所有类画框不可能，所以要<strong>零样本检测</strong>。</li>
<li>传统检测器在未见类上“<strong>不报框（召回低）</strong>”，因为它们把“陌生外观”当<strong>背景</strong>。</li>
<li><strong>训练时引入语义属性并用于目标性预测</strong>，让视觉特征“会认亲”，从而<strong>提高未见类的召回与 AP</strong>；测试时不依赖未见类语义即可运行检测，若需贴标签，再接零样本识别器即可。</li>
</ol>
<h1 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h1><p>这一节的任务是梳理作者的研究背景，说明他们的工作与以往方法的区别与创新点。作者将这一节分成四个子部分（A–D），分别回顾了：</p>
<ol>
<li>目标检测（Object Detection）</li>
<li>零样本识别（Zero-Shot Recognition）</li>
<li>其他相关方法（Other Methods）</li>
<li>同期研究（Concurrent Works）</li>
</ol>
<hr>
<p><strong>A. Object Detection and Proposal</strong></p>
<p><code>背景：现代检测方法的发展</code></p>
<p>作者首先指出，深度学习推动了检测技术的飞速发展。</p>
<ul>
<li>像 <strong>YOLOv2 (Redmon &amp; Farhadi, 2016)</strong> 这样的单阶段（Single-shot）检测器具有<strong>高速度和较好精度</strong>，能在 50 FPS 以上实时检测。</li>
<li>其结构是<strong>全卷积网络（fully convolutional network）</strong>，直接从特征图上预测目标框及其置信度。</li>
</ul>
<p>与 YOLOv2 对比：</p>
<ul>
<li><strong>Faster R-CNN (Ren et al., 2015)</strong>、<strong>R-FCN (Dai et al., 2016)</strong> 等属于“两阶段（Two-stage）检测器”：<ul>
<li>第一阶段使用 <strong>Region Proposal Network (RPN)</strong> 生成候选框；</li>
<li>第二阶段在这些候选区域上进行分类与框回归；</li>
<li>但它们通常低于 30 FPS，速度慢得多。</li>
</ul>
</li>
<li>YOLOv2 的高效性使它成为作者的首选基线。</li>
</ul>
<p><code>问题：传统检测器无法识别“未见类”</code></p>
<p>作者指出，在<strong>大规模检测场景</strong>下（例如成百上千类目标），几乎不可能为每个类都提供足够的标注数据。<br> 这导致：</p>
<ul>
<li>传统检测器过度拟合在“见过的类”上；</li>
<li><strong>对于未见类（unseen classes）</strong>，检测器会把它们的区域视作<strong>背景（background）</strong>；</li>
<li>原因在于：训练过程中，模型被鼓励最大化检测精度，最小化假阳性，因此会压制所有“看起来不像训练类”的区域。</li>
</ul>
<p>这种“过度压背景”的机制虽然提高了已知类的精度，却导致模型在开放世界（open world）中<strong>召回率（recall）极低</strong>。</p>
<p><code>对比：Proposal 方法虽能发现未知目标但精度低</code></p>
<p>早期的 <strong>Region Proposal 方法（例如 Selective Search、Edge Boxes）</strong> 可以在无语义信息下提出许多候选区域，其中可能包含未见类目标。<br> 但这些方法：</p>
<ul>
<li>候选框数量庞大（上百&#x2F;上千），</li>
<li>需要大量后处理（NMS、分类筛选），</li>
<li><strong>假阳性率高、计算代价大</strong>。</li>
</ul>
<p>因此，作者的选择是：<br> <strong>保留 YOLOv2 的高效结构</strong>，但在网络中引入语义特征以解决“未见类检测”的问题。</p>
<hr>
<p><strong>B. Zero-Shot Recognition</strong></p>
<p><code>传统 ZSL（Zero-Shot Learning）</code></p>
<p>零样本学习旨在<strong>识别未见过的类别</strong>，通过建立<strong>视觉表示与语义表示的映射</strong>：</p>
<ul>
<li>常用的语义信息包括：属性（attributes）、词向量（word embeddings）、或文本描述。</li>
<li>代表性工作：[Lampert et al., 2014] 的 Attribute-based ZSL，Zhang &amp; Saligrama (2015–2016) 的 Semantic Similarity Embedding。</li>
</ul>
<p><code>从封闭集到广义零样本学习（gZSL）</code></p>
<p>传统 ZSL 仅在“未见类”上测试，但这在现实中不合理，因为测试集中<strong>既有 seen 类也有 unseen 类</strong>。<br> 于是提出了 <strong>广义零样本学习（Generalized ZSL, gZSL）</strong>：</p>
<ul>
<li>模型必须在<strong>已见 + 未见类混合场景</strong>中识别出所有目标；</li>
<li>这更接近现实，但也更难。</li>
</ul>
<p><code>ZSD 与 ZSL 的关系</code></p>
<p>ZSD（零样本检测）比 ZSL 更复杂：</p>
<ul>
<li>ZSL 假设目标已经被精确裁剪，只需识别类别；</li>
<li>ZSD 还要<strong>定位</strong>这些目标。</li>
</ul>
<p>本文的思路是：</p>
<ul>
<li>先解决“发现目标框”这一检测问题（不关心类别名）；</li>
<li>再可在检测后附加任何 ZSL 分类器来贴标签。</li>
</ul>
<p>因此，ZS-YOLO 主要关注<strong>检测阶段的召回问题</strong>，而非最终分类。</p>
<hr>
<p><strong>C. Other Methods</strong></p>
<p>这一节讲述了与 ZSD 间接相关的其他研究方向，以及它们的局限性。</p>
<ol>
<li>弱监督定位（Weakly Supervised Localization）</li>
</ol>
<p>例如 [33]–[35] 等方法尝试<strong>在没有框标注的情况下</strong>定位物体，但它们仍依赖：</p>
<ul>
<li><strong>图像级标签（image-level labels）</strong>；</li>
<li>而 ZSD 中，<strong>未见类连标签都没有</strong>。<br> 所以弱监督方法仍然假设我们知道“图片里有什么类”，而不是从完全未知中检测。</li>
</ul>
<ol start="2">
<li>无监督目标发现（Unsupervised Object Discovery）</li>
</ol>
<p>这类方法（例如 [36]）试图在没有任何标注的情况下，通过聚类或重复模式发现“物体簇”。<br> 但：</p>
<ul>
<li>它们依赖于训练集中出现的冗余部件；</li>
<li>缺乏<strong>语义迁移能力</strong>；</li>
<li>无法发现<strong>训练中完全未出现过</strong>的新类别。</li>
</ul>
<p>相反，本文的 ZS-YOLO 能通过“语义属性迁移”从 seen 类泛化到 unseen 类。</p>
<hr>
<p><strong>D. Concurrent Works（同期工作）</strong></p>
<p>作者提到，在他们论文的早期版本发布到 arXiv 时（2019 年），另有两篇工作几乎同时出现（[37], [38]）。<br> 这些工作也提出了“零样本检测”的概念，但与本文方法差异显著：</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>同期工作</th>
<th>ZS-YOLO</th>
</tr>
</thead>
<tbody><tr>
<td>候选框生成</td>
<td>使用 <strong>预定义提议器</strong>（EdgeBoxes 或 RPN）</td>
<td><strong>内建 YOLO 框架</strong>端到端生成候选框</td>
</tr>
<tr>
<td>模型结构</td>
<td><strong>两步法</strong>：Proposal → ZSR 分类</td>
<td><strong>一步法</strong>：同时检测 + 学语义</td>
</tr>
<tr>
<td>假设</td>
<td>假设 Proposal 能捕获 unseen 对象</td>
<td>认为传统 Proposal 会把 unseen 当背景</td>
</tr>
<tr>
<td>运行效率</td>
<td>两阶段，较慢</td>
<td>单阶段，实时（fast &amp; scalable）</td>
</tr>
<tr>
<td>实验设置</td>
<td>仅 ZSD（只含未见类），单一划分</td>
<td>评估 <strong>ZSD + GZSD</strong> 多划分，涵盖更广</td>
</tr>
<tr>
<td>数据集</td>
<td>ILSVRC 2017（多单目标图像）</td>
<td>PASCAL VOC、MS COCO（更复杂场景）</td>
</tr>
</tbody></table>
<p>作者强调：<br> 这些同时期研究<strong>假设已经能提到 unseen 类的框</strong>，但事实上 RPN 或 EdgeBoxes <strong>也会错过未见类</strong>。ZS-YOLO 的创新正是在于——<strong>连 Proposal 阶段也融合语义信息</strong>，不依赖外部生成器。</p>
<hr>
<p><strong>总结：本节的逻辑框架</strong></p>
<table>
<thead>
<tr>
<th>章节</th>
<th>核心思想</th>
<th>ZS-YOLO 的创新点</th>
</tr>
</thead>
<tbody><tr>
<td>A. Object Detection</td>
<td>YOLOv2 等检测器高效但只学视觉模式，会忽视未见类</td>
<td>将语义引入视觉检测结构</td>
</tr>
<tr>
<td>B. Zero-Shot Recognition</td>
<td>ZSL 解决“分类未见类”，但不处理“检测”</td>
<td>从分类扩展到检测：ZSD</td>
</tr>
<tr>
<td>C. Other Methods</td>
<td>弱监督&#x2F;无监督方法仍依赖标签或统计冗余</td>
<td>不依赖未见类标注，利用语义迁移</td>
</tr>
<tr>
<td>D. Concurrent Works</td>
<td>同期ZSD方法仍依赖RPN或EdgeBoxes</td>
<td>首个端到端“语义感知”检测器</td>
</tr>
</tbody></table>
<hr>
<h1 id="METHODOLOGY"><a href="#METHODOLOGY" class="headerlink" title="METHODOLOGY"></a>METHODOLOGY</h1><h2 id="A-Problem-Definition"><a href="#A-Problem-Definition" class="headerlink" title="A. Problem Definition"></a>A. Problem Definition</h2><p> 这一节作者正式刻画了“零样本检测”（Zero-Shot Detection, ZSD）的数学定义，并明确指出自己方法的目标范围。下面我将按照论文原意分成四个逻辑层次来详细讲解。</p>
<hr>
<p><span style="color:#FF0000">🧩 一、研究问题的动机与范围</span></p>
<p>作者首先指出，传统的<strong>目标检测</strong>假设训练集中包含所有类别的边界框标注。但在真实世界中，不可能为每个类别都提供大量标注。<br> 因此，<strong>Zero-Shot Detection (ZSD)</strong> 要解决的问题是：</p>
<blockquote>
<p><strong>如何在没有某类目标的任何训练样本的情况下，仍能检测出这些“未见类（unseen classes）”的物体。</strong></p>
</blockquote>
<p>检测任务包含两个要素：</p>
<ol>
<li><strong>定位（localization）</strong>：确定每个物体在图像中的位置（即预测边界框）；</li>
<li><strong>识别（recognition）</strong>：判断这个框属于哪个类别。</li>
</ol>
<p>传统检测器如 YOLOv2 同时学习这两件事，但只针对“见过类（seen classes）”。ZSD 则要求模型能<strong>泛化</strong>到未见类上。</p>
<hr>
<p><span style="color:#FF0000">📘 二、形式化定义（Formal Definition）</span></p>
<p>设训练集为：<br>$$<br>D^{tr} &#x3D; ( B_i, c_i, \mathbf{y_i})  _{i&#x3D;1}^N<br>$$<br>其中：</p>
<ul>
<li>$B_i &#x3D; (x_i, y_i, w_i, h_i)$：第 $i $个目标的边界框（位置和尺寸）；</li>
<li>$c_i \in \mathcal{C}_{seen}$：该目标的类别标签，只来自<strong>已见类别集合</strong>；</li>
<li>$\mathbf{y}_i \in \mathbb{R}^h$：该类别的<strong>语义表示向量</strong>（semantic representation），例如 64 维属性或 word2vec 向量。</li>
</ul>
<p>训练阶段模型只接触到 $\mathcal{C}_{seen}$ 类别。<br> 测试阶段，图像可能包含：</p>
<ul>
<li>来自$\mathcal{C}_{seen}$ 的物体；</li>
<li>来自 <strong>未见类别集合</strong> $\mathcal{C}_{unseen}$ 的物体；</li>
<li>或者两者混合。</li>
</ul>
<p>且这两个集合互不重叠：</p>
<p>$\mathcal{C_{seen}} \cap \mathcal{C_{unseen}} &#x3D; \emptyset$</p>
<p>任务目标：</p>
<blockquote>
<p>让检测器在测试阶段同时识别出 seen 与 unseen 类的所有前景物体（foreground objects），并为每个预测输出边界框。</p>
</blockquote>
<hr>
<p><span style="color:#FF0000">📙 三、ZS-YOLO 的目标：解决“检测不到”的问题</span></p>
<p>在定义问题之后，作者明确界定了自己的研究重点：</p>
<ul>
<li><p><strong>ZS-YOLO 并不试图直接给未见类命名</strong>（即不要求输出“这是什么类”），而是首先解决更基础的任务——</p>
<blockquote>
<p><strong>在图像中正确“检测出”所有前景目标（包括 unseen 类），不把它们错判为背景。</strong></p>
</blockquote>
</li>
</ul>
<p>为什么？</p>
<ol>
<li><strong>YOLOv2 的主要失败在于“漏检”，而不是“误分类”</strong>。<br> 它经常将 unseen 类误认为背景，导致 recall 极低。</li>
<li>一旦能把 unseen 物体的框检测出来，分类问题就可以交给任何成熟的 ZSL 分类器来解决；</li>
<li>更现实的场景中，我们往往<strong>不知道 unseen 类的语义列表</strong>（$\mathcal{C}_{unseen} $是未知的）。<br> 因此，ZS-YOLO 只专注于“检测任何前景目标”，不需要预定义 unseen 类的语义信息。</li>
</ol>
<p>换句话说：</p>
<blockquote>
<p>ZS-YOLO &#x3D; “让检测器先学会‘看见’未见之物”，而不是直接去“认出它是谁”。</p>
</blockquote>
<hr>
<p><span style="color:#FF0000">🧠 四、ZS-YOLO 的任务设定与创新点总结</span></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>传统 YOLOv2</th>
<th>ZS-YOLO</th>
</tr>
</thead>
<tbody><tr>
<td>训练类别</td>
<td>仅 seen 类</td>
<td>仅 seen 类（相同）</td>
</tr>
<tr>
<td>训练信号</td>
<td>视觉特征 + 目标性损失</td>
<td>视觉特征 + <strong>语义属性损失</strong>（semantic guidance）</td>
</tr>
<tr>
<td>测试输入</td>
<td>图像</td>
<td>图像（无需语义输入）</td>
</tr>
<tr>
<td>输出</td>
<td>见过类的框与标签</td>
<td>所有前景目标的框（包含 unseen）</td>
</tr>
<tr>
<td>unseen 类识别</td>
<td>失败（被当背景）</td>
<td>成功检测（语义迁移提升召回）</td>
</tr>
</tbody></table>
<p><strong>核心创新点</strong>：</p>
<ul>
<li>把“语义属性”引入检测器的学习过程；</li>
<li>不要求测试时提供 unseen 类语义；</li>
<li>改善检测器的“目标性感知”能力，让它学会在视觉空间里反映语义相似性。</li>
</ul>
<hr>
<p><span style="color:#FF0000">✨ 五、直观理解</span></p>
<p>可以这么理解这个问题定义：</p>
<blockquote>
<p>传统 YOLOv2 的“objectness”概念是纯视觉的；<br> ZS-YOLO 想让这个“objectness”同时带有一点“语义的味道”——<br> 让模型明白“没见过的马”在语义上像“见过的狗”，因此也算“一个前景目标”。</p>
</blockquote>
<hr>
<p><span style="color:#FF0000">小结：</span></p>
<ol>
<li><strong>ZSD 问题定义</strong>：在训练中仅有 seen 类，测试时需检测 seen + unseen 的物体位置；</li>
<li><strong>ZS-YOLO 关注点</strong>：解决 unseen 类被误判为背景的问题；</li>
<li><strong>方法约束</strong>：<ul>
<li>不需要知道 unseen 类的语义原型；</li>
<li>不输出 unseen 类的类别名；</li>
<li>但能提高 unseen 类的检测召回；</li>
</ul>
</li>
<li><strong>核心目标</strong>：提升检测器对“语义相关新类”的泛化能力。</li>
</ol>
<hr>
<h2 id="B-ZS-YOLO-Network-Architecture"><a href="#B-ZS-YOLO-Network-Architecture" class="headerlink" title="B.ZS-YOLO Network Architecture"></a>B.ZS-YOLO Network Architecture</h2><p> 这是整篇论文的核心部分之一，作者在这里构建了一个融合“视觉特征 + 语义属性”的端到端检测框架，旨在让检测器不仅“看见”，还“理解”语义相似性。</p>
<hr>
<h3 id="🧩-一、总体结构概览"><a href="#🧩-一、总体结构概览" class="headerlink" title="🧩 一、总体结构概览"></a><span style="color:#FF0000">🧩 一、总体结构概览</span></h3><p>ZS-YOLO 的设计基于 <strong>YOLOv2</strong>（单阶段检测器），但在其基础上扩展了两个关键模块：</p>
<ol>
<li><strong>语义属性预测模块（Semantic Prediction Module）</strong>；</li>
<li><strong>多模态置信度预测模块（Confidence Prediction Module）</strong>。</li>
</ol>
<p>整个网络包含四个主要部分（见 Fig. 2）：</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能</th>
<th>输出</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>(1) 特征提取模块 (Feature Extraction)</td>
<td>提取图像的多尺度视觉特征</td>
<td>特征张量 $T_F $(13×13×1024)</td>
<td>使用 Darknet-19 结构</td>
</tr>
<tr>
<td>(2) 目标定位模块 (Object Localization)</td>
<td>预测边界框偏移量</td>
<td>$T_L $(13×13×20)</td>
<td>每个 cell 预测 5 个锚框，每个 4 参数</td>
</tr>
<tr>
<td>(3) 语义预测模块 (Semantic Prediction)</td>
<td>预测每个锚框的语义属性向量</td>
<td>$T_S $(13×13×5h)</td>
<td>例如 h&#x3D;64 (VOC 属性维度)</td>
</tr>
<tr>
<td>(4) 置信度预测模块 (Confidence Prediction)</td>
<td>判断该框是否包含前景目标</td>
<td>$T_C $(13×13×5)</td>
<td>输入是多模态融合 [TF,TL,TS][T_F,T_L,T_S]</td>
</tr>
</tbody></table>
<p>网络整体是<strong>全卷积结构（Fully Convolutional Network）</strong>，因此支持端到端训练。</p>
<hr>
<h3 id="📘-二、-1-特征提取模块-Feature-Extraction"><a href="#📘-二、-1-特征提取模块-Feature-Extraction" class="headerlink" title="📘 二、(1) 特征提取模块 (Feature Extraction)"></a><span style="color:#FF0000">📘 二、(1) 特征提取模块 (Feature Extraction)</span></h3><ul>
<li>主干网络采用 <strong>Darknet-19</strong>（YOLOv2 的 backbone）；</li>
<li>输入图像被调整为 <strong>416×416</strong>；</li>
<li>输出一个特征张量 $T_F$，大小为 <strong>13×13×1024</strong>；</li>
<li>作者指出，这个 backbone 也可以替换为其他 CNN（ResNet、Inception、VGG 等），但他们保留 Darknet 是为了与 YOLOv2 对比公平。</li>
</ul>
<p><strong>Passthrough 层（跨层连接）</strong>：<br> Darknet-19 含有一个“passthrough layer”，它能把高分辨率浅层特征拼接到深层特征上，以保留小目标的信息——这对零样本检测特别重要，因为<strong>未见类往往出现在小物体或非典型外观</strong>中。</p>
<hr>
<h3 id="📙-三、-2-目标定位模块-Object-Localization"><a href="#📙-三、-2-目标定位模块-Object-Localization" class="headerlink" title="📙 三、(2) 目标定位模块 (Object Localization)"></a><span style="color:#FF0000">📙 三、(2) 目标定位模块 (Object Localization)</span></h3><blockquote>
<ol>
<li>网格与锚框：为什么输出是 13×13×20？</li>
</ol>
<ul>
<li>输入图像被缩放到 <strong>416×416</strong>，主干网络步幅是 <strong>32</strong>，所以输出特征图是 <strong>13×13</strong>（&#x3D; 416 &#x2F; 32）。</li>
<li>每个网格 cell（13×13 共 169 个）都“负责”预测若干个候选框。本文沿用 YOLOv2：<strong>每个 cell 有 5 个锚框（anchor）</strong>，它们的长宽比&#x2F;尺度预先聚类得到（称为先验）。</li>
<li>对每个锚框，网络要预测 <strong>4 个偏移量</strong>：$(o_x,o_y,o_w,o_h)$。</li>
<li>因而：每个 cell 输出 $5\times 4&#x3D;20$ 个数，整张特征图的定位输出张量</li>
</ul>
<p>$$<br> T_L \in \mathbb{R}^{13\times 13\times 20}.<br>$$</p>
<blockquote>
<p>小结：13×13 是网格数；“20”来自 5 个锚 × 每锚 4 个坐标参数。</p>
</blockquote>
<hr>
<ol start="2">
<li>这四个偏移量是“相对量”，如何变成真实框？</li>
</ol>
<p>文中的公式把<strong>相对参数</strong>变成<strong>图像坐标</strong>（或归一化坐标）：</p>
<p>$$<br>\begin{aligned}<br>\hat x &amp;&#x3D; \sigma(o_x) + c_x, \<br>\hat y &amp;&#x3D; \sigma(o_y) + c_y, \<br>\hat w &amp;&#x3D; p_w , e^{o_w}, \<br>\hat h &amp;&#x3D; p_h , e^{o_h}.<br>\end{aligned}<br>$$</p>
<p>含义逐个看：</p>
<ul>
<li>$c_x,c_y$：当前 <strong>cell 的整型网格坐标</strong>（范围 0…12）。它们确定了“第几格”。</li>
<li>$\sigma(\cdot)$：Sigmoid，把中心偏移限制在 <strong>(0,1)</strong>。<br> 所以 $\sigma(o_x)$ 是“<strong>在本 cell 内的水平偏移</strong>”；加上 $c_x$ 就得到“<strong>在整个 13×13 网格平面上的中心坐标</strong>”。</li>
<li>$p_w,p_h$：该锚框的<strong>先验宽高</strong>（和输入分辨率一致的单位，通常是像素尺度或等价的归一化值）。</li>
<li>$e^{o_w}, e^{o_h}$：保证宽高为<strong>正数</strong>，且能按比例缩放先验（&gt;1 放大，&lt;1 缩小）。</li>
</ul>
<blockquote>
<p>直观比喻：<br>先用 $c_x,c_y$ 选定“哪一格”，再用 $\sigma(o_x),\sigma(o_y)$ 在这一格的<strong>小方块里挪动中心点</strong>；宽高则在锚框尺寸 $p_w,p_h$ 的基础上用指数缩放。</p>
</blockquote>
<hr>
<ol start="3">
<li>从“网格坐标”到“像素坐标 &#x2F; 归一化坐标”</li>
</ol>
<ul>
<li><strong>特征图步幅</strong> $s&#x3D;32$ 像素（从 416 下采样到 13）。</li>
<li>若你想得到<strong>像素级中心</strong>（相对于 416×416 输入），可用：</li>
</ul>
<p>$$<br> x_{\text{px}} &#x3D; (\sigma(o_x)+c_x)\times s,\quad<br> y_{\text{px}} &#x3D; (\sigma(o_y)+c_y)\times s.<br>$$</p>
<ul>
<li><strong>宽高</strong>如果锚的 $p_w,p_h$ 就是按 416 标注的像素尺寸，则：</li>
</ul>
<p>$$<br> w_{\text{px}} &#x3D; p_w , e^{o_w},\quad<br> h_{\text{px}} &#x3D; p_h , e^{o_h}.<br>$$</p>
<ul>
<li>若希望 <strong>0–1 归一化坐标</strong>（相对整幅图）：</li>
</ul>
<p>$$<br> x_{(0\text{–}1)}&#x3D;\frac{\sigma(o_x)+c_x}{13},\<br> y_{(0\text{–}1)}&#x3D;\frac{\sigma(o_y)+c_y}{13},\<br> w_{(0\text{–}1)}&#x3D;\frac{p_w e^{o_w}}{416},\<br> h_{(0\text{–}1)}&#x3D;\frac{p_h e^{o_h}}{416}.<br>$$</p>
<hr>
<ol start="4">
<li>为什么要用 Sigmoid 和指数？</li>
</ol>
<ul>
<li><strong>Sigmoid 对中心偏移</strong>：<br> 把中心限制在 <strong>当前 cell 内部</strong>，训练更稳定；否则中心可能“跳格”，学习会抖。</li>
<li><strong>指数对宽高</strong>：<br> 保证 $w,h&gt;0$，并让“相对缩放”对不同尺度都更平滑（乘法增益），有利于拟合多尺度目标。</li>
</ul>
<hr>
<ol start="5">
<li>一个完整的小算例（把数算到像素）</li>
</ol>
<p>假设：</p>
<ul>
<li>图像 416×416，步幅 $s&#x3D;32$，特征图 13×13。</li>
<li>当前 cell 在第 $c_x&#x3D;7, c_y&#x3D;5$ 格。</li>
<li>该 cell 的某个锚的先验 $p_w&#x3D;80, p_h&#x3D;40$（像素）。</li>
<li>网络输出偏移：$o_x&#x3D;0.2,\ o_y&#x3D;-0.4,\ o_w&#x3D;0.1,\ o_h&#x3D;0.3$。</li>
</ul>
<p>计算：</p>
<ul>
<li>$\sigma(0.2)\approx 0.5498,\ \sigma(-0.4)\approx 0.4013$</li>
<li><strong>中心（网格坐标）</strong>：<br> $\hat x&#x3D;0.5498+7&#x3D;7.5498,\ \ \hat y&#x3D;0.4013+5&#x3D;5.4013$</li>
<li><strong>中心（像素）</strong>：<br> $x_{\text{px}}&#x3D;7.5498\times 32\approx 241.6,\ \ y_{\text{px}}&#x3D;5.4013\times 32\approx 172.8$</li>
<li><strong>宽高（像素）</strong>：<br> $w_{\text{px}}&#x3D;80\times e^{0.1}\approx 80\times 1.105&#x3D;88.4$<br>$h_{\text{px}}&#x3D;40\times e^{0.3}\approx 40\times 1.350&#x3D;54.0$</li>
<li>若要左上&#x2F;右下角：</li>
</ul>
<p>$$<br> x_1&#x3D;x_{\text{px}}-\tfrac{w}{2}\approx 197.4,\quad<br> y_1&#x3D;y_{\text{px}}-\tfrac{h}{2}\approx 145.8,\<br> x_2&#x3D;x_{\text{px}}+\tfrac{w}{2}\approx 285.8,\quad<br> y_2&#x3D;y_{\text{px}}+\tfrac{h}{2}\approx 199.8.<br>$$</p>
<blockquote>
<p>你可以把这组数直接画到 416×416 的图上，就得到预测框。</p>
</blockquote>
<hr>
<ol start="6">
<li>训练时“谁负责谁”：为什么只让一个锚学一个 GT？</li>
</ol>
<ul>
<li>对于每个 <strong>GT 框</strong>，在它中心所在的 cell 内，选与 GT <strong>IoU 最大</strong>的那个锚作为“负责者”。</li>
<li>这个锚的 $I^{\text{obj}}&#x3D;1$（负责回归该 GT 的坐标与其它相关输出）；同 cell 的另外 4 个锚则不负责这个 GT。</li>
<li>这样可避免“多个锚重复学同一个 GT”，让训练稳定收敛。</li>
</ul>
<hr>
<ol start="7">
<li>常见困惑一览</li>
</ol>
<ul>
<li><strong>$c_x,c_y$ 是像素吗？</strong> 不是，是 <strong>网格索引（0…12）</strong>。乘以步幅 32 才变像素。</li>
<li><strong>锚的 $p_w,p_h$ 单位是什么？</strong> 通常以<strong>网络输入尺度的像素</strong>（如 416）定义。实现里读取 anchors 后，会在坐标变换时与 stride&#x2F;归一化配合使用。</li>
<li><strong>预测到的 $\hat x,\hat y$ 会越出图像吗？</strong> 不会，Sigmoid + 网格加法天然把中心限制在整张图范围内。</li>
<li><strong>为何不用线性预测宽高？</strong> 线性会出现负值或在大&#x2F;小尺度下梯度不均；指数缩放更稳定。</li>
</ul>
<hr>
<ol start="8">
<li>和后续损失怎么呼应？</li>
</ol>
<ul>
<li>位置损失里用到 $\hat x,\hat y,\hat w,\hat h$ 与 GT 的差（对 $w,h$ 常用 $\sqrt{\cdot}$ 形式，进一步平衡大小目标的梯度）。</li>
<li>这些梯度会反向传到 $o_x,o_y,o_w,o_h$，再到 backbone，促使网络学会“把锚 + 偏移”对齐到真实物体。</li>
</ul>
</blockquote>
<hr>
<h3 id="📗-四、-3-语义预测模块-Semantic-Prediction"><a href="#📗-四、-3-语义预测模块-Semantic-Prediction" class="headerlink" title="📗 四、(3) 语义预测模块 (Semantic Prediction)"></a><span style="color:#FF0000">📗 四、(3) 语义预测模块 (Semantic Prediction)</span></h3><p>这是 <strong>ZS-YOLO 的第一个创新点</strong>。</p>
<p>任务：</p>
<p>让每个预测框输出一个<strong>语义属性向量 $\hat{\mathbf{y}}\in \mathbb{R}^h$</strong>，例如：</p>
<ul>
<li>在 PASCAL VOC 中，$h&#x3D;64$；</li>
<li>属性可能包括 “furry”（有毛发）、“has wheels”（有轮子）、“made of metal”（金属的）等。</li>
</ul>
<p>结构：</p>
<ul>
<li>使用 1×1 卷积层实现；</li>
<li>输出张量大小：13×13×(5h)，即每个 cell 的 5 个锚框各输出一个 h 维语义向量；</li>
<li>例如 VOC 中输出维度为 13×13×320。</li>
</ul>
<p>训练目标：</p>
<ul>
<li>对每个有物体的锚框，使预测的语义向量接近该类的语义原型；</li>
<li>对背景锚框，使语义输出与任何 seen 类原型的相似度都很低；</li>
<li>这将在后续损失函数部分（L_attr）中详细定义。</li>
</ul>
<p>直觉：</p>
<p>这个模块让模型<strong>在视觉空间中学习语义关系</strong>。<br>例如，“狗”和“猫”虽然外观不同，但在语义空间中都带有 “furry” 等属性，因此检测器学到的特征会彼此靠近，从而：</p>
<blockquote>
<p>当测试时出现一只“猫”，即使模型没见过“猫”，也会因其语义与“狗”相似而给出较高的置信度。</p>
</blockquote>
<blockquote>
<p><strong>补充</strong></p>
<hr>
<p>它具体在做什么？</p>
<ol>
<li>输出是什么？</li>
</ol>
<ul>
<li>特征图大小是 <strong>13×13</strong>，每个 cell 提出 <strong>5 个候选框（anchor）</strong>。</li>
<li>对<strong>每个候选框</strong>，语义头预测一个 <strong>h 维</strong>向量 $\hat{\mathbf y}\in\mathbb{R}^h$（比如 VOC 用 h&#x3D;64 的属性向量）。</li>
<li>因而语义输出张量</li>
</ul>
<p>$$<br> T_S \in \mathbb{R}^{13\times 13\times (5h)}.<br>$$</p>
<ul>
<li>随后通过一个 <strong>1×1 卷积</strong>，卷积核数 &#x3D; $5h$（把通道拍平成所需维度），因此几乎不增加计算量。</li>
</ul>
<blockquote>
<p>例：PASCAL VOC 用 [19] 提供的 <strong>64 维属性</strong>，故 $h&#x3D;64$。则 $T_S$ 的通道数为 $5\times64&#x3D;320$。</p>
</blockquote>
<ol start="2">
<li>训练时怎么用？</li>
</ol>
<ul>
<li>给<strong>前景正样本</strong>（负责某个 GT 的 anchor），我们希望 $\hat{\mathbf y}$ 与该类的<strong>语义原型</strong> $\mathbf y_c$ <strong>相似</strong>（通常用<strong>余弦相似</strong> &#x2F; $L_2$ 距离等）。</li>
<li>给<strong>纯背景</strong>（明确不含目标的 anchor），希望 $\hat{\mathbf y}$ <strong>不像任何已见类</strong>的原型（把与所有 seen 类的最大相似度压低）。</li>
</ul>
<p>一个常见的写法（论文里等价思想）：</p>
<p>$$<br>L_{\text{attr}}&#x3D;\sum_k<br>\lambda_{\text{obj}},I^{\text{obj}}<em>k\big(1-S(\hat{\mathbf y}<em>k,\mathbf y</em>{c(k)})\big)^2<br>+\lambda</em>{\text{noobj}},I^{\text{noobj}}<em>k\big(\max</em>{c\in\mathcal C_{\text{seen}}}S(\hat{\mathbf y}_k,\mathbf y_c)\big)^2,<br>$$</p>
<p>其中 $S$ 是余弦相似；$I^{\text{obj}},I^{\text{noobj}}$ 指示该 anchor 是前景还是纯背景。</p>
<blockquote>
<p>小心点：背景项不是“像哪个类”，而是<strong>都不像</strong>；因此用“最大相似度”做一个“推远”约束。</p>
</blockquote>
<ol start="3">
<li>为什么这能帮到未见类（unseen）？</li>
</ol>
<ul>
<li><p>语义原型（属性&#x2F;词向量）把<strong>类与类的关系</strong>编码了：例如“狗”和“猫”都带 <strong>furry</strong>、<strong>has legs</strong> 等属性，语义上相近。</p>
</li>
<li><p>训练中，正样本被<strong>拉向其语义方向</strong>，背景被<strong>推离所有已见类语义方向</strong>；这些梯度会<strong>反传到共享主干特征</strong>。<br> ⇒ 主干学到的视觉表征不止是“像像素”，还会反映<strong>语义亲缘</strong>。</p>
</li>
<li><p>测试来一个<strong>没见过</strong>的“猫”，即便外观稍不同，它在语义空间可能仍靠近“狗&#x2F;狐狸”等 seen 类；于是：</p>
</li>
<li><p>语义头给出“像 seen 的语义”的 $\hat{\mathbf y}$；</p>
</li>
<li><p>随后 <strong>多模态置信度头</strong>（把 $T_F,T_L,T_S$ 一起看）会更愿意给<strong>高 objectness</strong>，从而<strong>不把它当背景</strong>。<br>⇒ 直接提升 <strong>召回率（recall）</strong>。</p>
</li>
</ul>
<ol start="4">
<li>测试阶段是否需要 unseen 的语义？</li>
</ol>
<ul>
<li><strong>不需要。</strong> 这点很重要。语义头在测试时主要作为<strong>内部特征</strong>，供<strong>置信度头</strong>使用。</li>
<li>如果你想给检测到的框<strong>贴类名</strong>，可以<strong>额外</strong>接一个零样本分类器（用 unseen 原型做最近邻等）——但这已是检测之后的可选步骤。</li>
</ul>
<hr>
<p>和 YOLOv2 的关键差异</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>YOLOv2</th>
<th>ZS-YOLO（本文）</th>
</tr>
</thead>
<tbody><tr>
<td>输出</td>
<td>位置 + 类别 + 目标性</td>
<td>位置 + <strong>语义向量</strong> + 目标性</td>
</tr>
<tr>
<td>目标性来源</td>
<td>只看视觉特征</td>
<td><strong>视觉 + 几何 + 语义</strong>（多模态）</td>
</tr>
<tr>
<td>对 unseen 的处理</td>
<td>容易当背景压掉</td>
<td>语义牵引，使其被报为前景（召回↑）</td>
</tr>
</tbody></table>
<hr>
<p>一眼看懂的直觉图（文字版）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;特征 T_F ──► [1×1 conv → 5h 通道] ──► 语义向量  T_S(…×5h)</span><br><span class="line">                        │</span><br><span class="line">                        └─ 与类原型做相似度监督 → 反传进主干（视觉被语义“塑形”）</span><br><span class="line">&gt;T_F, T_L, T_S  ──► 置信度头 ──► objectness（更愿意“相信”语义上像 seen 的未知物体）</span><br></pre></td></tr></table></figure>

<hr>
<p>常见疑问补充</p>
<ul>
<li><strong>h 取值从哪来？</strong> 由数据集提供的语义注释决定：属性向量（如 VOC-64）、或词向量&#x2F;句向量（可自选）。</li>
<li><strong>归一化要不要做？</strong> 做！训练时通常对 $\hat{\mathbf y}$ 与 $\mathbf y_c$ 做 <strong>L2 归一化</strong> 再算余弦，更稳。</li>
<li><strong>背景怎么判定？</strong> 论文沿用 YOLO 的责任分配：纯背景 cell&#x2F;anchor（没有任何 GT 覆盖且 IoU 小）进入背景分支的约束。</li>
<li><strong>计算量会不会大很多？</strong> 几乎不会：只是多了个 <strong>1×1 conv（5h 个通道）</strong> 和一项损失；与主干比，开销很小。</li>
</ul>
<hr>
<p>小结（一句话）</p>
<p><strong>Semantic Prediction</strong> 让“每个候选框”都学会说一段“语义话”（h 维向量），并用这段话去<strong>塑形视觉特征</strong>与<strong>支撑目标性判断</strong>，结果是：<strong>未见类不再轻易被当背景</strong>，召回显著提升。</p>
</blockquote>
<hr>
<h3 id="📕-五、-4-置信度预测模块-Confidence-Prediction"><a href="#📕-五、-4-置信度预测模块-Confidence-Prediction" class="headerlink" title="📕 五、(4) 置信度预测模块 (Confidence Prediction)"></a><span style="color:#FF0000">📕 五、(4) 置信度预测模块 (Confidence Prediction)</span></h3><p>好的，我会用中文为您详细解释 <strong>置信度预测模块</strong> 的内容。以下是根据您上传的图像内容做出的解析。</p>
<p><strong>置信度预测模块的工作原理</strong></p>
<ol>
<li><strong>置信度预测的目标</strong></li>
</ol>
<ul>
<li><strong>目标</strong>：模型的最终任务是为每个边界框（bounding box）预测一个置信度分数 $\hat{p}$，即预测这个框是否包含一个有效的目标。</li>
<li>传统检测器（如 SSD 和 YOLOv2）直接从 CNN 特征图 $T_F$ 中预测置信度分数。然而，这种方法对 <strong>未见物体</strong>（即训练集之外的物体）通常会产生较低的置信度，因为这些未见物体在视觉上与 <strong>见过的物体</strong>有显著不同，导致 <strong>低召回率</strong>。</li>
</ul>
<ol start="2">
<li><strong>ZS-YOLO 的解决方法</strong></li>
</ol>
<ul>
<li>为了解决这个问题，ZS-YOLO 通过 <strong>结合视觉信息和语义信息</strong> 来预测置信度。具体来说，除了视觉特征 $T_F$ 外，还利用了 <strong>语义信息</strong>（比如物体的属性特征）来帮助置信度的预测。</li>
<li>除此之外，<strong>边界框坐标</strong> 也被作为预测置信度的有效信息来源。因为 <strong>前景物体</strong> 通常位于图像的某些特定位置（例如图像中心而非角落），这些信息可以帮助提高预测的准确性。</li>
</ul>
<ol start="3">
<li><strong>具体实现</strong></li>
</ol>
<ul>
<li><p>ZS-YOLO 将以下三个模块的输出 <strong>连接</strong>（concat）成一个多模态输入张量：</p>
<ol>
<li><strong>$T_F$</strong>：视觉特征图（来自 CNN）</li>
<li><strong>$T_L$</strong>：边界框坐标（例如，位置和尺寸信息）</li>
<li><strong>$T_S$</strong>：语义特征（来自语义预测模块）</li>
</ol>
</li>
<li><p>这三个张量的 <strong>形状</strong> 被合并成一个多模态输入张量，形状为 <strong>$13 \times 13 \times (1024 + 20 + 5h)$</strong>，其中：</p>
<ul>
<li>$1024$ 来自视觉特征图 $T_F$</li>
<li>$20$ 来自边界框回归输出 $T_L$</li>
<li>$5h$ 来自语义特征 $T_S$，其中 $h$ 是语义向量的维度。</li>
</ul>
</li>
</ul>
<ol start="4">
<li><strong>卷积层处理</strong></li>
</ol>
<ul>
<li><p>合并后的张量通过一个 <strong>1×1 卷积层</strong>（包含 5 个滤波器），输出一个 <strong>$13 \times 13 \times 5$</strong> 形状的张量 $T_C$，每个元素对应一个边界框的预测置信度分数 $\hat{p}$。</p>
<ul>
<li>也就是说，模型会为每个 <strong>13×13×5 &#x3D; 845</strong> 个边界框，预测一个置信度分数。</li>
</ul>
</li>
</ul>
<ol start="5">
<li><strong>如何使用边界框坐标提高置信度</strong></li>
</ol>
<ul>
<li>ZS-YOLO 还指出，<strong>边界框坐标</strong>（例如物体的中心位置）对预测置信度也有帮助。<strong>前景物体</strong>通常位于图像中心附近而不是角落，这些信息对于置信度的预测非常重要。</li>
</ul>
<hr>
<p><strong>总结：ZS-YOLO 的置信度预测</strong></p>
<ol>
<li><strong>输入</strong>：模型结合了视觉特征 $T_F$、边界框信息 $T_L$、和语义特征 $T_S$。</li>
<li><strong>卷积处理</strong>：将这三个张量合并后通过一个卷积层，生成一个 <strong>$13 \times 13 \times 5$</strong> 的张量 $T_C$，每个元素为一个边界框的置信度分数。</li>
<li><strong>目标</strong>：最终，模型会为每个锚框（边界框候选区域）预测一个置信度值，表示该框是否包含有效的目标。</li>
</ol>
<p>这个方法使得 ZS-YOLO 在预测 <strong>未见类</strong>（即训练时未出现的类别）的物体时，能结合视觉和语义信息，更好地提升召回率。</p>
<hr>
<h3 id="🔍-六、网络特点与扩展性"><a href="#🔍-六、网络特点与扩展性" class="headerlink" title="🔍 六、网络特点与扩展性"></a><span style="color:#FF0000">🔍 六、网络特点与扩展性</span></h3><p>作者强调：</p>
<ul>
<li><p>ZS-YOLO 的框架<strong>不限于 YOLOv2</strong>；</p>
</li>
<li><p>也可以轻松迁移到其他单阶段检测器，如：</p>
<ul>
<li><strong>SSD (Single Shot MultiBox Detector)</strong>；</li>
<li><strong>RetinaNet</strong>（带 Focal Loss）；</li>
</ul>
</li>
<li><p>甚至可以视作一种“语义增强的 RPN”，嵌入到两阶段检测器（如 Faster-RCNN）中。</p>
</li>
</ul>
<p>但他们选择 YOLOv2 作为主干，是因为它更简单且高效，便于验证语义模块的效果。</p>
<hr>
<h3 id="✨-七、整体流程总结（从输入到输出）"><a href="#✨-七、整体流程总结（从输入到输出）" class="headerlink" title="✨ 七、整体流程总结（从输入到输出）"></a><span style="color:#FF0000">✨ 七、整体流程总结（从输入到输出）</span></h3><table>
<thead>
<tr>
<th>步骤</th>
<th>输入&#x2F;输出</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>1️⃣ 输入图像</td>
<td>416×416</td>
<td>进入 Darknet-19</td>
</tr>
<tr>
<td>2️⃣ 提取视觉特征</td>
<td>$T_F$ (13×13×1024)</td>
<td>全卷积输出</td>
</tr>
<tr>
<td>3️⃣ 预测框偏移量</td>
<td>$T_L$ (13×13×20)</td>
<td>位置回归</td>
</tr>
<tr>
<td>4️⃣ 预测语义属性</td>
<td>$T_S$ (13×13×5h)</td>
<td>属性映射</td>
</tr>
<tr>
<td>5️⃣ 多模态置信度预测</td>
<td>$T_C$ (13×13×5)</td>
<td>判断是否为前景</td>
</tr>
<tr>
<td>6️⃣ 输出结果</td>
<td>框 + 置信度</td>
<td>若需识别，再交给 ZSL 分类器</td>
</tr>
</tbody></table>
<hr>
<h3 id="🎯-八、创新点总结"><a href="#🎯-八、创新点总结" class="headerlink" title="🎯 八、创新点总结"></a><span style="color:#FF0000">🎯 八、创新点总结</span></h3><table>
<thead>
<tr>
<th>模块</th>
<th>创新点</th>
<th>效果</th>
</tr>
</thead>
<tbody><tr>
<td>Semantic Prediction</td>
<td>首次在检测器中加入语义属性预测</td>
<td>让视觉特征“理解语义亲缘”，便于泛化</td>
</tr>
<tr>
<td>Multi-modal Confidence</td>
<td>利用视觉 + 语义 + 空间信息预测目标性</td>
<td>提升 unseen 类召回</td>
</tr>
<tr>
<td>End-to-end 设计</td>
<td>不依赖外部 Proposal 或分类器</td>
<td>实时高效，结构统一</td>
</tr>
</tbody></table>
<h2 id="C-Zero-Shot-Detection-Losses"><a href="#C-Zero-Shot-Detection-Losses" class="headerlink" title="C. Zero-Shot Detection Losses"></a>C. Zero-Shot Detection Losses</h2><p>这部分是整篇论文的数学核心，作者在这里定义了 ZS-YOLO 的三项损失函数：定位损失 $L_{\text{loc}}$、语义损失 $L_{\text{attr}}$、以及置信度损失 $L_{\text{conf}}$。这三项共同训练网络，使其既能定位物体，又能学习语义相关性，并在未见类上保持较高的召回率。</p>
<hr>
<h3 id="1️⃣-整体目标函数"><a href="#1️⃣-整体目标函数" class="headerlink" title="1️⃣ 整体目标函数"></a>1️⃣ 整体目标函数</h3><p>网络的总损失定义为三项加权和：</p>
<p>$$<br>L &#x3D; \lambda_{\text{loc}} L_{\text{loc}} + \lambda_{\text{attr}} L_{\text{attr}}  + \lambda_{\text{conf}} L_{\text{conf}}<br>$$</p>
<p>其中 $\lambda_{\text{loc}},\lambda_{\text{attr}},\lambda_{\text{conf}}$ 是权重系数。<br>在论文实验中通常取值 1 : 1 : 1，保证三项任务（定位、语义、目标性）共同优化。</p>
<hr>
<h3 id="2️⃣-定位损失-L-text-loc"><a href="#2️⃣-定位损失-L-text-loc" class="headerlink" title="2️⃣ 定位损失 $L_{\text{loc}}$"></a>2️⃣ 定位损失 $L_{\text{loc}}$</h3><ul>
<li>检测头把输入图像（缩放到 416×416）变成一个 <strong>13×13</strong> 的网格（因为步幅是 32），<br>每个网格 cell 里有 <strong>5 个锚框（anchor）</strong>。</li>
<li>所以一张图一共会预测 <strong>13×13×5 &#x3D; 845</strong> 个候选框。公式里求和的上限 <strong>845</strong> 就来自这里。</li>
</ul>
<blockquote>
<p>二、谁“负责”哪个真实框？— 指示量 $I_k^{\text{obj}}$</p>
<p>作者不希望<strong>同一个真实物体</strong>被同一个 cell 里的多个锚重复学习，于是规定：</p>
<blockquote>
<p>只有 <strong>一个</strong> 预测框对某个真实框负责，它的指示量 $I_k^{\text{obj}}$ 设为 1，其余设为 0。</p>
</blockquote>
<p>判定“谁负责”的规则（两步）：</p>
<ol>
<li>真实框的<strong>中心点</strong>落在哪个 cell，就只在这个 cell 内挑“负责人”；</li>
<li>在该 cell 的 5 个预测框里，<strong>与这个真实框 IoU 最高</strong>的那个被选为“负责人”。</li>
</ol>
<p>被选中的那个预测框 $k$ 的 $I_k^{\text{obj}}&#x3D;1$，其它同 cell 的锚都为 0。<br>好处：<strong>避免冗余</strong>、稳定训练。</p>
</blockquote>
<p><strong>目标</strong>：让预测框 $(\hat x,\hat y,\hat w,\hat h)$ 与真实框 $(x,y,w,h)$ 对齐。</p>
<p><strong>形式</strong>（与 YOLOv2 一致）：<br>$$<br>L_{\text{loc}} &#x3D; \sum_{k&#x3D;1}^{M} I_k^{\text{obj}}<br>  \Big[<br>    (\hat x_k - x_k)^2<br>    + (\hat y_k - y_k)^2<br>    + (\sqrt{\hat w_k}-\sqrt{w_k})^2<br>    + (\sqrt{\hat h_k}-\sqrt{h_k})^2<br>  \Big]<br>$$</p>
<p>含义一目了然：</p>
<ul>
<li>$(\hat x_k,\hat y_k,\hat w_k,\hat h_k)$：第 $k$ 个预测框的<strong>中心坐标与宽高</strong>；</li>
<li>$(x_k,y_k,w_k,h_k)$：它负责的那个<strong>真实框</strong>的中心与宽高；</li>
<li>$I_k^{\text{obj}}$ 保证<strong>只有负责人参与</strong>损失；</li>
<li>误差度量用的是<strong>平方误差</strong>（越接近越好）。</li>
</ul>
<blockquote>
<p>注意：$\hat x,\hat y$ 是中心坐标；$\hat w,\hat h$ 是宽高。它们来自网络输出的偏移量（经过 Sigmoid&#x2F;指数变换得到），你前面看过的那组变换就是把网络的相对量变成真实坐标。</p>
</blockquote>
<p>和训练流程如何配合？</p>
<ol>
<li><strong>前向</strong>：网络对 845 个锚输出偏移 → 解码成 $\hat x,\hat y,\hat w,\hat h$。</li>
<li><strong>匹配</strong>：每个 GT 找到<strong>落点 cell</strong>，再在该 cell 的 5 个锚里选 <strong>IoU 最大</strong>者作为负责人；置 $I_k^{\text{obj}}&#x3D;1$。</li>
<li><strong>计算损失</strong>：只对负责人计算式 (2) 的定位项。</li>
<li><strong>反向传播</strong>：梯度只回传到负责的锚与主干特征，促使它把框“对齐”真实目标。</li>
</ol>
<p>一句话总结</p>
<p><strong>定位损失</strong>只让“对这个 GT 负责的那个锚”来为坐标误差买单：<br>中心用普通平方误差，宽高用“开方后的平方误差”来平衡大小目标的学习难度。<br>这套设计既简单高效，又能稳定地把预测框<strong>拉</strong>到真实框上。</p>
<hr>
<h3 id="3️⃣-语义损失-L-text-attr"><a href="#3️⃣-语义损失-L-text-attr" class="headerlink" title="3️⃣ 语义损失 $L_{\text{attr}}$"></a>3️⃣ 语义损失 $L_{\text{attr}}$</h3><p><strong>目的</strong>：让网络在视觉特征中“感知语义”。</p>
<p>1️⃣ 语义损失的目标</p>
<p><strong>目标</strong>：通过学习 <strong>语义相似性</strong> 来提高未见类的召回率。</p>
<ul>
<li>对于<strong>前景物体</strong>（即在训练时见过的类别），模型的预测语义向量 $\hat{\mathbf{y}}_k$ 应该尽量接近该物体真实的语义原型 $\mathbf{y}_c$。</li>
<li>对于<strong>背景</strong>或<strong>未见物体</strong>，模型应该尽量避免预测出与任何已见类别的语义相似的内容。</li>
</ul>
<p>2️⃣ 语义损失函数的定义</p>
<p>语义损失的目的是最小化预测语义向量和真实语义之间的差异，公式如下：</p>
<span>
$$
L_{\text{attr}} = \sum_{k=1}^{M} \Big[ \lambda_{\text{obj}} I_k^{\text{obj}} \left( 1 - S(\hat{\mathbf{y}_k}, \mathbf{y}_{c(k)}) \right)^2 + \lambda_{\text{noobj}} I_k^{\text{noobj}} \left( \max_{c \in \mathcal{C}_{\text{seen}}} S(\hat{\mathbf{y}_k}, \mathbf{y}_c) \right)^2
\Big]
$$

</span>

<p>3️⃣ 公式解析</p>
<p>我们来逐项解析这个公式，理解每个部分的含义。</p>
<p>(1) <strong>前景样本（$I_k^{\text{obj}} &#x3D; 1$）</strong></p>
<p>对于 <strong>前景物体</strong>（即模型应该学习到的目标）：</p>
<ul>
<li><p>$I_k^{\text{obj}} &#x3D; 1$，意味着这个锚框负责一个真实物体；</p>
</li>
<li><p>目标是将预测的语义向量 $\hat{\mathbf{y}}_k$ 与真实的语义原型 $\mathbf{y}_c$ 的相似度尽量提高。这里使用 <strong>余弦相似度</strong> $S(\hat{\mathbf{y}}_k, \mathbf{y}_c)$，其定义为：</p>
<p>$$<br>S(\hat{\mathbf{y}}_k, \mathbf{y}_c) &#x3D; \frac{\hat{\mathbf{y}}_k^\top \mathbf{y}_c}{|\hat{\mathbf{y}}_k| |\mathbf{y}_c|}<br>$$</p>
<p>这个相似度值越大，表示两者的语义越接近。为了最小化损失函数，模型需要 <strong>拉近</strong> 预测的语义向量和真实标签之间的差距。</p>
</li>
<li><p>公式中的部分：</p>
<span>
$$
\lambda_{\text{obj}} I_k^{\text{obj}} \left( 1 - S(\hat{\mathbf{y}}_k, \mathbf{y}_{c(k)}) \right)^2
$$

<p>是前景样本的损失项，<strong>拉近预测的语义向量与真实标签</strong>的语义相似度。损失越小，表示预测越准确。</p>
</li>
</ul>
<p>(2) <strong>背景样本（$I_k^{\text{noobj}} &#x3D; 1$）</strong></p>
<p>对于 <strong>背景样本</strong>（即不包含任何目标的区域），模型的任务是<strong>避免预测出与任何已见类的语义相似的内容</strong>。</p>
<ul>
<li><p>这里，背景框的语义预测应该尽量与 <strong>所有已见类别的语义原型</strong> 相差较远。为了避免过度“拉近”，我们用 <strong>最大相似度</strong> 来确保背景框的语义不会被误预测为任何已见类别的语义。</p>
<p>$$<br>\max_{c \in \mathcal{C}_{\text{seen}}} S(\hat{\mathbf{y}}_k, \mathbf{y}_c)<br>$$</p>
<p>该项计算的是预测语义 $\hat{\mathbf{y}}_k$ 与所有已见类别的语义原型 $\mathbf{y}_c$ 的最大余弦相似度。对于背景框，损失应该使这个最大值尽量接近 <strong>0</strong>，表示背景框的语义应该与任何见过的物体类相差甚远。</p>
</li>
<li><p>公式中的部分：</p>
<p>$$<br>\lambda_{\text{noobj}} I_k^{\text{noobj}} \left( \max_{c \in \mathcal{C}_{\text{seen}}} S(\hat{\mathbf{y}}_k, \mathbf{y}_c) \right)^2<br>$$</p>
</span>

<p>是背景样本的损失项，目的是<strong>推远背景框的语义预测</strong>与所有已见类的语义原型，防止背景被误认为目标。</p>
</li>
</ul>
<p>4️⃣ 损失的平衡与加权</p>
<ul>
<li><p><strong>$\lambda_{\text{obj}}$ 与 $\lambda_{\text{noobj}}$</strong>：<br>这两个超参数控制前景与背景的损失加权，确保 <strong>前景样本</strong>对损失的贡献更大。<br>在实际训练中，前景样本往往比背景样本少，因此需要通过加权来避免背景样本过多影响训练过程。</p>
</li>
<li><p><strong>背景项的推远</strong>：<br>背景框的语义预测被设计成与任何已见类别原型的<strong>最大相似度接近 0</strong>，防止错误分类。这种设计可以确保即使在 <strong>测试阶段</strong>遇到未见类别时，模型也不会轻易将其误判为见过的目标。</p>
</li>
</ul>
<hr>
<p>5️⃣ 语义损失如何影响模型</p>
<ul>
<li><p><strong>训练时</strong>：</p>
<ul>
<li>语义损失会通过梯度反向传播到网络的视觉特征提取部分（backbone），使模型学习到在视觉空间中，如何根据目标的 <strong>语义特征</strong> 来进行更有效的目标定位。</li>
<li>语义向量的学习过程，不仅帮助模型识别<strong>已见类</strong>，还能有效地对 <strong>未见类</strong>进行召回。</li>
</ul>
</li>
<li><p><strong>测试时</strong>：</p>
<ul>
<li>ZS-YOLO 的语义头并不依赖于未见类别的语义原型，而是通过<strong>训练时学到的语义空间结构</strong>，在看到未见物体时，依靠相似的语义特征来判断其是否是前景目标。</li>
</ul>
</li>
</ul>
<hr>
<p>6️⃣ 总结</p>
<ul>
<li><strong>前景的语义预测</strong>：通过与该类的语义原型拉近，确保模型能正确识别已见类别；</li>
<li><strong>背景的语义预测</strong>：通过与所有已见类别的最大相似度最小化，确保背景不被误认为目标；</li>
<li><strong>损失加权</strong>：$\lambda_{\text{obj}}$ 和 $\lambda_{\text{noobj}}$ 控制前景与背景对损失的贡献，以保证模型对前景的学习更加专注。</li>
</ul>
<hr>
<h3 id="4️⃣-置信度损失-L-text-conf"><a href="#4️⃣-置信度损失-L-text-conf" class="headerlink" title="4️⃣ 置信度损失 $L_{\text{conf}}$"></a>4️⃣ 置信度损失 $L_{\text{conf}}$</h3><p>1️⃣ 置信度损失的目标</p>
<p><strong>目标</strong>：判断候选框是否包含目标物体，即<strong>目标性预测（objectness prediction）</strong>。<br>对于每个候选框 $k$，ZS-YOLO 需要预测一个<strong>置信度分数</strong> $\hat{p}_k$，表示这个框是否为前景（目标物体）框。</p>
<p>在传统的检测器（如 YOLOv2）中，置信度分数主要是基于视觉特征（$T_F$）来预测的。而在 <strong>零样本检测（ZSD）</strong> 中，ZS-YOLO 在此基础上<strong>加入了语义特征（$T_S$）和边界框信息（$T_L$</strong>），通过 <strong>多模态学习</strong>，提高对未见类的检测能力。</p>
<p>2️⃣ 置信度损失函数</p>
<p>置信度损失主要通过 <strong>均方误差（MSE）</strong> 或 <strong>二元交叉熵损失（BCE）</strong> 来计算预测的置信度与真实标签之间的差距。在 ZS-YOLO 中，模型同时考虑了 <strong>视觉特征</strong>、<strong>语义特征</strong> 和 <strong>边界框信息</strong>。</p>
<p>ZSD 中的置信度损失的定义是：</p>
<span>
$$
L_{\text{conf}} = \sum_{k=1}^{M} \Big[ \lambda_{\text{obj}} I_k^{\text{obj}} (\hat{p}_k - 1)^2 + \lambda_{\text{noobj}} I_k^{\text{noobj}} (\hat{p}_k - 0)^2 \Big]
$$

</s>

<p>3️⃣ 公式解析</p>
<p>(1) <strong>前景（目标物体）置信度预测</strong></p>
<p>对于<strong>前景框</strong>（即包含目标的框），我们希望模型预测出高的置信度，即 $\hat{p}_k \approx 1$。</p>
<ul>
<li>$I_k^{\text{obj}} &#x3D; 1$：表示这个框是<strong>前景框</strong>，由网络来负责回归该框的目标性。</li>
<li>$\hat{p}_k$：表示该框是否包含目标物体的置信度。</li>
</ul>
<p><strong>目标</strong>：最小化预测的置信度与真实标签之间的差异，使得 $\hat{p}_k \rightarrow 1$（前景框的置信度接近 1）。</p>
<p>损失项为：</p>
<p>$$<br>\lambda_{\text{obj}} I_k^{\text{obj}} (\hat{p}_k - 1)^2<br>$$</p>
<p>其中，$\lambda_{\text{obj}}$ 是加权系数，控制前景样本对损失的贡献。</p>
<p>(2) <strong>背景（非目标物体）置信度预测</strong></p>
<p>对于<strong>背景框</strong>（即不包含目标物体的框），我们希望模型预测出低的置信度，即 $\hat{p}_k \approx 0$。</p>
<ul>
<li>$I_k^{\text{noobj}} &#x3D; 1$：表示这个框是<strong>背景框</strong>，模型不需要对其做目标性预测。</li>
<li>$\hat{p}_k$：表示该框是否包含目标物体的置信度。</li>
</ul>
<p><strong>目标</strong>：最小化预测的置信度与真实标签之间的差异，使得 $\hat{p}_k \rightarrow 0$（背景框的置信度接近 0）。</p>
<p>损失项为：</p>
<p>$$<br>\lambda_{\text{noobj}} I_k^{\text{noobj}} (\hat{p}_k - 0)^2<br>$$</p>
<p>其中，$\lambda_{\text{noobj}}$ 是加权系数，控制背景样本对损失的贡献。</p>
<p>4️⃣ 置信度损失的作用与多模态融合</p>
<p>在 ZS-YOLO 中，置信度损失不仅仅是根据视觉特征 $T_F$ 来判断框是否包含目标，还<strong>结合了语义信息 $T_S$ 和边界框信息 $T_L$</strong>，实现多模态的融合。具体来说：</p>
<ul>
<li><strong>视觉特征 $T_F$</strong> 提供了图像的外观信息；</li>
<li><strong>语义特征 $T_S$</strong> 提供了语义相似性信息，尤其是在未见类的检测中，它能够提升对新目标的召回能力；</li>
<li><strong>边界框 $T_L$</strong> 提供了候选框的位置信息，进一步帮助判断哪些框更可能包含前景。</li>
</ul>
<p>通过这种多模态学习，ZS-YOLO 在训练时能够 <strong>联合学习</strong> 这些特征，使得模型在遇到未见类时，仍能够做出较为准确的置信度预测，避免将未见类框误判为背景。</p>
<p>5️⃣ 置信度损失如何与其他损失共同作用？</p>
<p>在 ZS-YOLO 中，置信度损失与 <strong>目标定位损失（$L_{\text{loc}}$</strong>) 和 <strong>语义损失（$L_{\text{attr}}$</strong>) 一同优化，整体目标是让网络同时做到：</p>
<ul>
<li>精确定位（$L_{\text{loc}}$）；</li>
<li>正确判定前景（$L_{\text{conf}}$）；</li>
<li>学到语义相关性（$L_{\text{attr}}$）。</li>
</ul>
<p>6️⃣ 总结</p>
<ul>
<li><strong>前景框</strong>：置信度损失让模型预测出接近 <strong>1</strong> 的置信度值，表示这个框包含目标物体。</li>
<li><strong>背景框</strong>：置信度损失让模型预测出接近 <strong>0</strong> 的置信度值，表示这个框不包含目标物体。</li>
<li>通过结合视觉、语义、和位置特征，ZS-YOLO 能在检测任务中增强对未见类的召回能力，尤其是在判断目标框是否有效时，更加稳健。</li>
</ul>
<hr>
<h3 id="5️⃣-三者协同的效果"><a href="#5️⃣-三者协同的效果" class="headerlink" title="5️⃣ 三者协同的效果"></a>5️⃣ 三者协同的效果</h3><table>
<thead>
<tr>
<th>损失项</th>
<th>学到的能力</th>
<th>对 unseen 检测的贡献</th>
</tr>
</thead>
<tbody><tr>
<td>$L_{\text{loc}}$</td>
<td>精确定位</td>
<td>保证基础检测质量</td>
</tr>
<tr>
<td>$L_{\text{attr}}$</td>
<td>语义感知的视觉特征</td>
<td>让 unseen 类被视为前景</td>
</tr>
<tr>
<td>$L_{\text{conf}}$</td>
<td>多模态目标性判断</td>
<td>减少 unseen 漏检，提高召回</td>
</tr>
</tbody></table>
<p>最终训练后，ZS-YOLO 在见类上保持高精度，同时在未见类上召回率大幅提升。论文中举例：在 VOC 10&#x2F;10 划分上，unseen 的 Recall 从 18.6% 提高到 48.2%。</p>
<hr>
<h3 id="6️⃣-总结要点"><a href="#6️⃣-总结要点" class="headerlink" title="6️⃣ 总结要点"></a>6️⃣ 总结要点</h3><ul>
<li><p>ZS-YOLO 的核心思想是：<strong>在目标性学习阶段注入语义信息</strong>；</p>
</li>
<li><p>三项损失共同塑造网络：</p>
<ul>
<li>位置对齐；</li>
<li>语义结构化；</li>
<li>语义驱动的目标性；</li>
</ul>
</li>
<li><p>最终使模型在没有任何未见类标注的情况下，也能检测出这些目标。</p>
</li>
</ul>
<h2 id="D-Training-Details"><a href="#D-Training-Details" class="headerlink" title="D. Training Details"></a>D. Training Details</h2><h3 id="1️⃣-数据预处理和增强（Data-Preprocessing-and-Augmentation）"><a href="#1️⃣-数据预处理和增强（Data-Preprocessing-and-Augmentation）" class="headerlink" title="1️⃣ 数据预处理和增强（Data Preprocessing and Augmentation）"></a>1️⃣ 数据预处理和增强（Data Preprocessing and Augmentation）</h3><p><strong>数据预处理</strong>是模型训练的第一步，影响着模型的收敛性和最终性能。对于 ZS-YOLO，数据预处理和增强包括：</p>
<ul>
<li><p><strong>输入图像的缩放和归一化</strong>：</p>
<ul>
<li>所有图像都被统一缩放到 <strong>416×416</strong> 像素，以适配 YOLOv2 的网络结构（步幅为 32）。</li>
<li>图像像素值被归一化到 <strong>[0, 1]</strong> 范围内，以加速训练并提升收敛速度。</li>
</ul>
</li>
<li><p><strong>数据增强</strong>：</p>
<ul>
<li><strong>随机缩放</strong>：随机选择一个缩放比例，对图像进行缩放，并保持长宽比。</li>
<li><strong>随机裁剪</strong>：通过随机裁剪图像的区域来增强模型的鲁棒性，减少过拟合。</li>
<li><strong>随机翻转</strong>：水平翻转图像，增加多样性，帮助模型学习到更多的空间变换。</li>
</ul>
</li>
<li><p><strong>目标框归一化</strong>：</p>
<ul>
<li>在 YOLO 中，所有的目标框是 <strong>相对于输入图像的归一化坐标</strong>，并且宽高为 <strong>0–1 之间</strong>。这样，模型的输出是相对于图像大小的比例，而不是绝对坐标。</li>
</ul>
</li>
</ul>
<h3 id="2️⃣-损失函数加权（Loss-Weighting）"><a href="#2️⃣-损失函数加权（Loss-Weighting）" class="headerlink" title="2️⃣ 损失函数加权（Loss Weighting）"></a>2️⃣ 损失函数加权（Loss Weighting）</h3><ul>
<li><p><strong>加权系数</strong>：文章中指出，三项损失（定位损失 $L_{\text{loc}}$，语义损失 $L_{\text{attr}}$，置信度损失 $L_{\text{conf}}$）的加权系数是通过实验确定的。常见的做法是让 <strong>定位损失</strong> 和 <strong>语义损失</strong> 的权重相等，并且它们的总损失和 <strong>置信度损失</strong> 权重设置为相同（$\lambda_{\text{loc}} &#x3D; \lambda_{\text{attr}} &#x3D; \lambda_{\text{conf}} &#x3D; 1.0$）。如果你希望针对你的任务调整这些系数，通常会根据验证集的表现进行调节。</p>
</li>
<li><p><strong>优化器</strong>：<br>训练使用 <strong>Adam optimizer</strong>，其优势在于能够根据每个参数的梯度自适应调整学习率，使得训练过程更加稳定。</p>
</li>
</ul>
<h3 id="3️⃣-超参数和训练策略"><a href="#3️⃣-超参数和训练策略" class="headerlink" title="3️⃣ 超参数和训练策略"></a>3️⃣ 超参数和训练策略</h3><ul>
<li><p><strong>学习率调度</strong>：<br>学习率是影响训练效果的重要超参数，通常设置为 <strong>初始学习率 $10^{-3}$</strong>，然后逐渐减小（例如每经过一定数量的训练步骤，学习率降低 10 倍）。在训练过程中，学习率会根据验证集的性能进行调整，以避免过拟合或震荡。</p>
</li>
<li><p><strong>批大小（Batch Size）</strong>：<br>在论文中，使用的批大小为 <strong>16</strong>，这是一个典型的值。较小的批大小有助于减轻内存压力，并且能够提供更多的噪声（有利于跳出局部最优解）。当然，批大小需要根据硬件资源（如显存）和训练效率进行调整。</p>
</li>
<li><p><strong>训练时长和迭代次数</strong>：<br>训练使用的 <strong>epoch 数</strong>通常设为 1000 次，训练迭代的总次数依赖于训练数据集的大小。每个 epoch 的训练数据会在网络中多次传递，以确保模型能够逐步收敛。</p>
</li>
</ul>
<h3 id="4️⃣-零样本检测的特殊技巧（Special-Techniques-for-Zero-Shot-Detection）"><a href="#4️⃣-零样本检测的特殊技巧（Special-Techniques-for-Zero-Shot-Detection）" class="headerlink" title="4️⃣ 零样本检测的特殊技巧（Special Techniques for Zero-Shot Detection）"></a>4️⃣ 零样本检测的特殊技巧（Special Techniques for Zero-Shot Detection）</h3><ul>
<li><p><strong>无监督学习方法的启发</strong>：<br>虽然 ZS-YOLO 是一个 <strong>有监督</strong> 方法，但它受到无监督学习方法启发。通过 <strong>使用语义信息</strong>，ZS-YOLO 在训练过程中能够处理未见类，在学习过程中即使没有标注数据，依然能够“看见”潜在的未见物体。具体来说，ZS-YOLO 在训练过程中学会了“如何关联视觉特征和语义特征”，以便在 <strong>测试阶段</strong>能够利用 <strong>语义迁移</strong> 来检测未见类。</p>
</li>
<li><p><strong>数据集划分</strong>：<br>为了进行零样本检测的实验，ZS-YOLO 在 <strong>PASCAL VOC</strong> 和 <strong>MS COCO</strong> 等标准数据集上进行训练和评估。特别是，对于零样本检测的评估，作者将数据集划分为 <strong>见过类</strong>（Seen Classes）和 <strong>未见类</strong>（Unseen Classes）。在这种情况下，模型只能接触到已标注的见过类数据，而未见类则在训练时没有任何标注数据。因此，测试集包含了已见类和未见类，模型需要在没有未见类标注的情况下，依然能够检测出这些物体。</p>
</li>
</ul>
<h3 id="5️⃣-训练中的挑战和对策"><a href="#5️⃣-训练中的挑战和对策" class="headerlink" title="5️⃣ 训练中的挑战和对策"></a>5️⃣ 训练中的挑战和对策</h3><ul>
<li><p><strong>类别不平衡问题</strong>：<br>在训练过程中，<strong>背景框</strong>通常远远多于<strong>前景框</strong>（即目标框）。为了解决这个问题，ZS-YOLO 在训练时通过 <strong>加权损失函数</strong> 使得前景框的损失占据更大的比重，从而平衡类别不平衡问题。</p>
</li>
<li><p><strong>处理未见类的技巧</strong>：<br>在训练过程中，尽管模型没有接触到未见类的标注数据，但它仍通过 <strong>语义属性</strong> 和 <strong>视觉特征的语义关联</strong> 来增强对未见类的感知能力。这样，在测试时，即使遇到从未见过的物体，模型依然能够根据其 <strong>语义相似性</strong> 来识别并定位这些物体。</p>
</li>
</ul>
<h3 id="6️⃣-训练过程总结"><a href="#6️⃣-训练过程总结" class="headerlink" title="6️⃣ 训练过程总结"></a>6️⃣ 训练过程总结</h3><ul>
<li><strong>总的来说</strong>，ZS-YOLO 在训练时通过结合 <strong>视觉特征</strong>、<strong>语义特征</strong> 和 <strong>空间位置信息</strong>，使得模型能够在 <strong>已见类和未见类</strong>之间进行有效的迁移和泛化。</li>
<li><strong>超参数调节</strong>、<strong>损失函数加权</strong> 和 <strong>数据增强</strong>等策略，使得模型不仅能够精确检测见过类物体，还能在未见类检测中实现较高的召回率。</li>
</ul>
<hr>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><strong>D. Training Details</strong> 这一节主要介绍了模型训练的<strong>数据预处理、损失函数加权、训练策略</strong>等细节。</p>
<ul>
<li>通过多模态学习和加权损失，ZS-YOLO 能够增强对未见物体的检测能力。</li>
<li>数据增强、学习率调度等策略帮助模型稳定收敛，提高了训练效率。</li>
</ul>
<hr>
<h1 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h1><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><h3 id="1️⃣-评估指标：平均精度（Average-Precision-AP）"><a href="#1️⃣-评估指标：平均精度（Average-Precision-AP）" class="headerlink" title="1️⃣ 评估指标：平均精度（Average Precision, AP）"></a>1️⃣ 评估指标：平均精度（Average Precision, AP）</h3><ul>
<li><p><strong>AP（平均精度）</strong> 是常用的目标检测性能度量指标，尤其是在 <strong>Pascal VOC</strong> 和 <strong>COCO</strong> 数据集中。</p>
<ul>
<li>计算方式：对于每个类别，计算出不同 <strong>召回率（Recall）</strong> 下的 <strong>精度（Precision）</strong>，然后对所有召回率值上的精度取平均，得到最终的 <strong>平均精度（AP）</strong>。</li>
</ul>
</li>
</ul>
<p>具体来说，<strong>精度（Precision）</strong> 和 <strong>召回率（Recall）</strong> 的计算方式如下：</p>
<p>$$<br>\text{Precision} &#x3D; \frac{\text{True Positive (TP)}}{\text{Predicted}} \quad \text{(公式 6)}<br>$$</p>
<p>$$<br>\text{Recall} &#x3D; \frac{\text{True Positive (TP)}}{\text{Ground Truth (GT)}} \quad \text{(公式 7)}<br>$$</p>
<p>其中：</p>
<ul>
<li><strong>True Positive (TP)</strong> 是检测到的正确物体框；</li>
<li><strong>Predicted</strong> 是所有预测出的框；</li>
<li><strong>Ground Truth (GT)</strong> 是所有真实的目标框。</li>
</ul>
<p><strong>平均精度（AP）</strong> 是在多个召回率（从 0 到 1）下对精度进行平均。召回率的值分为 11 个等距点（例如 [0, 0.1, 0.2, …, 1]）：</p>
<p>$$<br>AP &#x3D; \frac{1}{11} \sum_{r \in [0, 0.1, 0.2, \dots]} \text{Precision (Recall &#x3D; r)} \quad \text{(公式 8)}<br>$$</p>
<p>这意味着，<strong>AP</strong> 是对 <strong>所有召回率点</strong>（从 0 到 1）精度的平均值，用来衡量检测器在不同召回率下的稳定性。</p>
<blockquote>
<p><span style="color:#FF0000">为什么召回率的范围是 “0 ~ 1”？</span></p>
<p>因为召回率本质上是一个 <strong>比例</strong>，它表示：</p>
<blockquote>
<p>“模型找到了多少比例的真实目标”。</p>
</blockquote>
<p>举个例子👇：</p>
<table>
<thead>
<tr>
<th>检测情况</th>
<th>检测到的目标数</th>
<th>真实目标数</th>
<th>召回率</th>
</tr>
</thead>
<tbody><tr>
<td>模型啥也没检测到</td>
<td>0</td>
<td>10</td>
<td>0 &#x2F; 10 &#x3D; <strong>0.0</strong></td>
</tr>
<tr>
<td>模型检测到一半</td>
<td>5</td>
<td>10</td>
<td>5 &#x2F; 10 &#x3D; <strong>0.5</strong></td>
</tr>
<tr>
<td>模型检测到全部目标</td>
<td>10</td>
<td>10</td>
<td>10 &#x2F; 10 &#x3D; <strong>1.0</strong></td>
</tr>
</tbody></table>
<p>所以：</p>
<ul>
<li>当召回率 &#x3D; <strong>0</strong> 时，模型一个目标都没找出来；</li>
<li>当召回率 &#x3D; <strong>1</strong> 时，模型检测到了所有真实目标；</li>
<li>介于中间（如 0.4, 0.7 等）表示检测到了部分目标。</li>
</ul>
<hr>
<p><span style="color:#FF0000">为什么要从 0 到 1 取多个“召回率点”？</span></p>
<p>在目标检测中，我们会不断调整<strong>置信度阈值（confidence threshold）</strong>，比如从高到低去判断“哪些检测结果算是目标”。</p>
<ul>
<li>当置信度阈值高 → 检测结果更“严格”，召回率低（只检测出很确定的目标）。</li>
<li>当置信度阈值低 → 检测结果更“宽松”，召回率高（检测出更多目标，但可能带来误检）。</li>
</ul>
<p>这样一来，我们可以得到一系列不同召回率下的精度值：</p>
<table>
<thead>
<tr>
<th>召回率</th>
<th>精度</th>
</tr>
</thead>
<tbody><tr>
<td>0.0</td>
<td>1.0</td>
</tr>
<tr>
<td>0.1</td>
<td>0.95</td>
</tr>
<tr>
<td>0.2</td>
<td>0.93</td>
</tr>
<tr>
<td>0.5</td>
<td>0.85</td>
</tr>
<tr>
<td>0.8</td>
<td>0.70</td>
</tr>
<tr>
<td>1.0</td>
<td>0.60</td>
</tr>
</tbody></table>
<hr>
<p><span style="color:#FF0000">为什么要在 11 个等距点（0.0, 0.1, 0.2, …, 1.0）上平均？</span></p>
<p>因为每个召回率点都有对应的精度（Precision），<br>而 <strong>平均精度 AP</strong> 就是对这些点的精度取平均：<br>$$<br>AP &#x3D; \frac{1}{11} \sum_{r \in [0,0.1,0.2,\dots,1]} \text{Precision(Recall &#x3D; r)}<br>$$</p>
<p>这就相当于看模型在整个召回率范围（0 到 1）上的整体表现，而不是只看某一个特定阈值。</p>
<blockquote>
<p>这样计算出来的 AP 更能反映模型的“整体稳定性”。</p>
</blockquote>
<hr>
<p>一个<strong>具体数值例子 + 图示说明</strong>，一步步演示“召回率从 0 到 1”是怎么来的，以及 <strong>AP（平均精度）</strong> 是怎么计算出来的。</p>
<p>🌟 示例场景</p>
<p>假设我们有一个类别（比如 “dog”），真实标注（Ground Truth）中一共有 <strong>10 只狗</strong>。<br>模型检测出了若干框，每个框都有一个置信度分数（confidence），从高到低如下表：</p>
<table>
<thead>
<tr>
<th>检测框编号</th>
<th>置信度</th>
<th>是否检测正确（TP &#x2F; FP）</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.98</td>
<td>✅ TP</td>
</tr>
<tr>
<td>2</td>
<td>0.96</td>
<td>✅ TP</td>
</tr>
<tr>
<td>3</td>
<td>0.90</td>
<td>❌ FP</td>
</tr>
<tr>
<td>4</td>
<td>0.85</td>
<td>✅ TP</td>
</tr>
<tr>
<td>5</td>
<td>0.82</td>
<td>✅ TP</td>
</tr>
<tr>
<td>6</td>
<td>0.75</td>
<td>❌ FP</td>
</tr>
<tr>
<td>7</td>
<td>0.70</td>
<td>✅ TP</td>
</tr>
<tr>
<td>8</td>
<td>0.60</td>
<td>❌ FP</td>
</tr>
<tr>
<td>9</td>
<td>0.55</td>
<td>✅ TP</td>
</tr>
<tr>
<td>10</td>
<td>0.40</td>
<td>✅ TP</td>
</tr>
</tbody></table>
<p>🧮 Step 1：逐步计算 Precision 和 Recall</p>
<p>我们按置信度从高到低逐个加入预测框，计算每一步的 <strong>Precision（精度）</strong> 和 <strong>Recall（召回率）</strong>：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>检测总数</th>
<th>TP 数</th>
<th>Precision &#x3D; TP&#x2F;检测数</th>
<th>Recall &#x3D; TP&#x2F;真实目标数</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1.00</td>
<td>0.10</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>2</td>
<td>1.00</td>
<td>0.20</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>2</td>
<td>0.67</td>
<td>0.20</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>3</td>
<td>0.75</td>
<td>0.30</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>4</td>
<td>0.80</td>
<td>0.40</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>4</td>
<td>0.67</td>
<td>0.40</td>
</tr>
<tr>
<td>7</td>
<td>7</td>
<td>5</td>
<td>0.71</td>
<td>0.50</td>
</tr>
<tr>
<td>8</td>
<td>8</td>
<td>5</td>
<td>0.63</td>
<td>0.50</td>
</tr>
<tr>
<td>9</td>
<td>9</td>
<td>6</td>
<td>0.67</td>
<td>0.60</td>
</tr>
<tr>
<td>10</td>
<td>10</td>
<td>7</td>
<td>0.70</td>
<td>0.70</td>
</tr>
</tbody></table>
<p>📈 Step 2：绘制 Precision-Recall 曲线</p>
<p><img src="/blog/image/A-1.png"></p>
<p>🧩 Step 3：在固定的 11 个召回率点上取精度</p>
<p>标准 VOC 的做法是：</p>
<blockquote>
<p>在召回率 $r &#x3D; [0, 0.1, 0.2, …, 1.0]$ 上，对应每个 r，找到“≥r 时的最大精度”。</p>
</blockquote>
<table>
<thead>
<tr>
<th>召回率 (r)</th>
<th>最大精度 Precision(≥r)</th>
</tr>
</thead>
<tbody><tr>
<td>0.0</td>
<td>1.00</td>
</tr>
<tr>
<td>0.1</td>
<td>1.00</td>
</tr>
<tr>
<td>0.2</td>
<td>1.00</td>
</tr>
<tr>
<td>0.3</td>
<td>0.75</td>
</tr>
<tr>
<td>0.4</td>
<td>0.80</td>
</tr>
<tr>
<td>0.5</td>
<td>0.71</td>
</tr>
<tr>
<td>0.6</td>
<td>0.67</td>
</tr>
<tr>
<td>0.7</td>
<td>0.70</td>
</tr>
<tr>
<td>0.8</td>
<td>0.00（还没检测到这么多目标）</td>
</tr>
<tr>
<td>0.9</td>
<td>0.00</td>
</tr>
<tr>
<td>1.0</td>
<td>0.00</td>
</tr>
</tbody></table>
<p>🧮 Step 4：计算 AP（平均精度）</p>
<p>将上表中的精度值在 11 个点上求平均：</p>
<p>$$<br>AP &#x3D; \frac{1}{11} (1.00 + 1.00 + 1.00 + 0.75 + 0.80 + 0.71 + 0.67 + 0.70 + 0 + 0 + 0)<br>$$</p>
<p>$$<br>AP &#x3D; \frac{5.63}{11} &#x3D; 0.51<br>$$</p>
<p>👉 <strong>所以最终 AP &#x3D; 0.51（51%）</strong></p>
<p>🎯 Step 5：解释</p>
<p>这个 AP &#x3D; 0.51 的意义是：</p>
<blockquote>
<p>模型在“召回率从 0 到 1”的整个范围内的<strong>平均检测精度为 51%</strong>。<br>换句话说，不论你把置信度阈值调得多高或多低，模型整体表现相当于一半的检测是准确的。</p>
</blockquote>
<hr>
<p>🧠 总结</p>
<table>
<thead>
<tr>
<th>概念</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><strong>召回率 (Recall)</strong></td>
<td>找到多少真实目标，范围 0~1</td>
</tr>
<tr>
<td><strong>精度 (Precision)</strong></td>
<td>检测结果中有多少是正确的</td>
</tr>
<tr>
<td><strong>AP</strong></td>
<td>不同召回率下精度的平均值（表示整体性能）</td>
</tr>
<tr>
<td><strong>0~1 的召回率范围</strong></td>
<td>从“完全没检测到目标”到“检测到所有目标”的过程</td>
</tr>
</tbody></table>
</blockquote>
<h3 id="2️⃣-与-Pascal-VOC-标准-mAP-的不同"><a href="#2️⃣-与-Pascal-VOC-标准-mAP-的不同" class="headerlink" title="2️⃣ 与 Pascal VOC 标准 mAP 的不同"></a>2️⃣ 与 Pascal VOC 标准 mAP 的不同</h3><ul>
<li>传统的 <strong>mAP（mean Average Precision）</strong> 通常是针对 <strong>每个类别</strong>计算的平均精度。而在 <strong>ZS-YOLO</strong> 中，由于我们并不对每个类进行独立分类，所以<strong>不计算类别级别的 AP</strong>，而是直接计算 <strong>所有类的平均精度</strong>。</li>
<li><strong>原因</strong>：ZSD 任务的一个特点是我们不进行具体的类分类，只是在检测到目标时计算其置信度。因此，ZSD 任务使用了 <strong>整体的平均精度（AP）</strong>，而不是类别精度。</li>
</ul>
<h3 id="3️⃣-平均-F-Score-作为辅助度量"><a href="#3️⃣-平均-F-Score-作为辅助度量" class="headerlink" title="3️⃣ 平均 F-Score 作为辅助度量"></a>3️⃣ 平均 F-Score 作为辅助度量</h3><ul>
<li>除了计算 AP 外，作者还使用了 <strong>F-score</strong> 作为辅助评估指标。</li>
<li><strong>F-score</strong> 是 <strong>精度（Precision）</strong> 和 <strong>召回率（Recall）</strong> 的调和平均，定义为：</li>
</ul>
<p>$$<br>\text{F-score} &#x3D; \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} \quad \text{(公式 9)}<br>$$</p>
<ul>
<li><p><strong>计算方法</strong>：</p>
<ul>
<li>对于每个 <strong>置信度阈值</strong>，计算精度和召回率，然后得出 <strong>F-score</strong>。</li>
<li><strong>F-score</strong> 会在多个置信度阈值下计算，然后对这些 F-score 进行平均，得到 <strong>平均 F-score</strong>，这个值反映了模型在不同置信度阈值下的 <strong>整体表现</strong>。</li>
</ul>
</li>
<li><p><strong>F-score 的作用</strong>：</p>
<ul>
<li>由于 F-score 综合了精度和召回率，因此它可以反映模型在不同置信度阈值下的 <strong>稳定性和鲁棒性</strong>。</li>
<li>对于未见类，F-score 是一个非常有用的度量，因为它衡量了检测器在面对不确定或低置信度的预测时的表现。</li>
</ul>
</li>
</ul>
<h3 id="4️⃣-AP-和-F-score-对未见类的关注"><a href="#4️⃣-AP-和-F-score-对未见类的关注" class="headerlink" title="4️⃣ AP 和 F-score 对未见类的关注"></a>4️⃣ AP 和 F-score 对未见类的关注</h3><ul>
<li>由于 ZS-YOLO 主要关注 <strong>未见类（unseen classes）</strong> 的检测，因此<strong>特别计算了未见类的 AP</strong>，以便衡量模型在 <strong>未见类物体</strong>上的表现。</li>
<li>这与标准的 mAP 不同，因为标准 mAP 更多地关注于 <strong>所有类别</strong>的整体表现，而 ZS-YOLO 更专注于 <strong>未见类别</strong> 的检测能力。</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><strong>AP（平均精度）</strong>：计算检测器在不同召回率下的精度，并对所有召回率下的精度求平均，得出 AP。</li>
<li><strong>F-score</strong>：用于评估不同置信度阈值下模型的整体表现，它的平均值反映了模型在不同检测场景下的稳定性。</li>
<li><strong>未见类的 AP 和 F-score</strong>：ZS-YOLO 特别关注未见类的检测性能，计算这些类的 AP 和 F-score。</li>
</ul>
<p>在 Zhu 等人（2020）的论文《Zero-Shot Detection》中，<strong>IV. EXPERIMENTS</strong> 的 <strong>A. Datasets and Settings</strong> 部分主要介绍了实验所用的数据集、类别划分方式、数据划分方案以及属性构建与转换方法。以下是对该部分的详细讲解：</p>
<hr>
<h2 id="A-Datasets-and-Settings"><a href="#A-Datasets-and-Settings" class="headerlink" title="A. Datasets and Settings"></a>A. Datasets and Settings</h2><h3 id="实验数据集概述"><a href="#实验数据集概述" class="headerlink" title="实验数据集概述"></a>实验数据集概述</h3><p>作者为了评估 <strong>ZS-YOLO（Zero-Shot YOLO）</strong> 模型的零样本检测性能，选用了两个主流目标检测数据集：</p>
<ol>
<li><p><strong>PASCAL VOC 2007 和 2012</strong></p>
<ul>
<li>共包含 <strong>20 个物体类别</strong>。</li>
<li>每个类别都带有 <strong>64 维的语义属性（semantic attributes）</strong>，这些属性来源于 aPY 数据集（[19]），由手工标注的二进制实例级属性计算而来。</li>
<li>为了获得稳定的语义表示，作者将实例级属性在类内取平均，得到类级属性向量。</li>
</ul>
</li>
<li><p><strong>MS COCO 数据集</strong></p>
<ul>
<li>共 <strong>80 个类别</strong>，其中包含 PASCAL VOC 的全部 20 个类别。</li>
<li>原始 COCO 属性集 [45] 仅覆盖 29 类，并且许多属性（如 <em>professional</em>、<em>friendly</em>）缺乏视觉意义，因此不适合用于视觉检测。</li>
<li>因此，作者选择了另一种方式：利用 <strong>Word2Vec 词向量</strong> 替代属性描述，但对其进行了降维与对齐优化（详见下文）。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="见／未见类别划分"><a href="#见／未见类别划分" class="headerlink" title="见／未见类别划分"></a>见／未见类别划分</h3><ol>
<li>PASCAL VOC 的划分策略</li>
</ol>
<p>由于 VOC 没有标准的 ZSD 划分，作者自定义了多个不同比例的划分：</p>
<ul>
<li><p><strong>15&#x2F;5、10&#x2F;10、5&#x2F;15</strong>（见类&#x2F;未见类）</p>
</li>
<li><p>在训练时，只使用包含见类目标的图像；测试时则构造三种场景：</p>
<ul>
<li><strong>Test-Seen</strong>：仅包含见类目标；</li>
<li><strong>Test-Unseen</strong>：仅包含未见类目标；</li>
<li><strong>Test-Mix</strong>：同时包含见类与未见类目标。</li>
</ul>
</li>
</ul>
<p>划分类别时，作者特意避免相似类别（如 dog 与 cat）同时作为未见类，以保证分布多样性。</p>
<ol start="2">
<li>MS COCO 的划分策略</li>
</ol>
<ul>
<li><p>选取 20 个“未见类别”，保证语义多样性。</p>
</li>
<li><p>从剩余的类别中选择与这些未见类 <strong>语义最接近</strong>（在 Word2Vec 空间中）的 N 个作为“见类”，逐步增加 N（例如 20, 40, 60）以观察泛化性能随见类数量变化的趋势。</p>
</li>
<li><p>训练集仅使用包含见类目标的图像；测试集包括：</p>
<ul>
<li>只含见类的 <strong>Test-Seen</strong>；</li>
<li>只含未见类的 <strong>Test-Unseen</strong>；</li>
<li>同时含两者的 <strong>Test-Mix</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="属性表示与语义映射"><a href="#属性表示与语义映射" class="headerlink" title="属性表示与语义映射"></a>属性表示与语义映射</h3><ol>
<li>类级属性（Class-Level Attributes）</li>
</ol>
<p>作者采用类级属性的原因包括：</p>
<ol>
<li><p>平均化后可减弱噪声与标注差异，提升训练稳定性；</p>
</li>
<li><p>测试阶段只能获得类级属性，而实例级属性无法提前获得；</p>
</li>
<li><p>VOC 的 aPY 属性标注不完全，部分实例无标签。</p>
</li>
<li><p>Word2Vec 特征降维与对齐</p>
</li>
</ol>
<p>由于原始 Word2Vec 向量（300维）含噪声且与视觉空间弱相关，作者提出学习一个 <strong>线性变换矩阵 P</strong>：</p>
<p>$$<br>\langle y_i, y_j \rangle \approx \langle P W_i, P W_j \rangle<br>$$</p>
<p>其中 $y_i$ 为 VOC 属性向量，$W_i$ 为对应类的 Word2Vec 向量。<br>通过该变换，将 Word2Vec 向量映射至一个 25 维的新空间（称为 <strong>w2vR</strong>），使其在属性空间上与 VOC 相似度结构一致，从而提升语义一致性与视觉相关性。</p>
<hr>
<h3 id="数据集划分表"><a href="#数据集划分表" class="headerlink" title="数据集划分表"></a>数据集划分表</h3><p>论文中表 I 概述了各数据集的划分情况：</p>
<table>
<thead>
<tr>
<th align="left">数据集</th>
<th align="left">训练集</th>
<th align="left">测试集类型</th>
<th align="left">测试集内容</th>
</tr>
</thead>
<tbody><tr>
<td align="left">VOC2007 &#x2F; VOC2012</td>
<td align="left">train&#x2F;val（仅见类）</td>
<td align="left">Test-Seen</td>
<td align="left">test（仅见类）</td>
</tr>
<tr>
<td align="left">VOC2007 &#x2F; VOC2012</td>
<td align="left">train&#x2F;val（仅见类）</td>
<td align="left">Test-Unseen</td>
<td align="left">train&#x2F;val + test（仅未见类）</td>
</tr>
<tr>
<td align="left">VOC2007 &#x2F; VOC2012</td>
<td align="left">train&#x2F;val（仅见类）</td>
<td align="left">Test-Mix</td>
<td align="left">train&#x2F;val + test（见+未见）</td>
</tr>
<tr>
<td align="left">MS COCO</td>
<td align="left">train&#x2F;val（仅见类）</td>
<td align="left">Test-Seen &#x2F; Unseen &#x2F; Mix</td>
<td align="left">与 VOC 同逻辑</td>
</tr>
</tbody></table>
<hr>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>这一部分的关键贡献在于：</p>
<ul>
<li>构建了 <strong>新的 ZSD 数据集划分</strong>，首次系统性定义了不同的“见／未见”配置；</li>
<li>引入 <strong>语义对齐变换 P</strong>，将噪声较大的词向量映射至属性一致空间；</li>
<li>提供多种评测情境（Seen &#x2F; Unseen &#x2F; Mix），使得后续实验能全面分析模型在不同设定下的表现。</li>
</ul>
<hr>
<h2 id="B-Zero-Shot-Detection-Evaluation"><a href="#B-Zero-Shot-Detection-Evaluation" class="headerlink" title="B. Zero-Shot Detection Evaluation"></a>B. Zero-Shot Detection Evaluation</h2><p>（零样本检测评估）</p>
<h3 id="实验设计概述"><a href="#实验设计概述" class="headerlink" title="实验设计概述"></a>实验设计概述</h3><p>研究者通过对 <strong>PASCAL VOC</strong> 和 <strong>MS COCO</strong> 两个数据集上的多种“已见&#x2F;未见类别划分”进行对比实验，验证了 ZS-YOLO 的零样本检测能力。<br>他们定义了三种测试模式：</p>
<ol>
<li><strong>Test-Seen</strong>：仅包含训练中出现过的类别（已见类）。</li>
<li><strong>Test-Unseen</strong>：仅包含训练集中未出现的类别（未见类）。</li>
<li><strong>Test-Mix</strong>：同时包含已见类与未见类的混合场景。</li>
</ol>
<p>这些模式反映了不同的泛化难度：</p>
<ul>
<li><em>Test-Seen</em> 测试监督检测性能；</li>
<li><em>Test-Unseen</em> 测试模型的零样本迁移能力；</li>
<li><em>Test-Mix</em> 更贴近真实世界任务，因为实际图像中可能混合多种对象。</li>
</ul>
<hr>
<h3 id="对比方法与评估指标"><a href="#对比方法与评估指标" class="headerlink" title="对比方法与评估指标"></a>对比方法与评估指标</h3><p>作者将 <strong>ZS-YOLO</strong> 与标准的 <strong>YOLOv2</strong> 模型进行了系统比较：</p>
<ul>
<li><strong>YOLOv2（基线）</strong>：完全监督训练，使用同样的训练分割（仅 seen 类别的标注框与标签）。在测试时，为公平比较，去除了 YOLOv2 的分类模块，只保留基于置信度分数的边框预测。</li>
<li><strong>ZS-YOLO（提出方法）</strong>：在 YOLOv2 的基础上，增加了语义属性预测与联合置信度机制，通过多任务损失（定位、语义、置信度）联合优化。</li>
</ul>
<p>评估指标为：</p>
<ul>
<li><strong>AP（Average Precision）</strong>：平均精度；</li>
<li><strong>F-score</strong>：综合考虑精度与召回率的调和平均。</li>
</ul>
<hr>
<h3 id="实验结果与主要发现"><a href="#实验结果与主要发现" class="headerlink" title="实验结果与主要发现"></a>实验结果与主要发现</h3><p>表 II（论文第 8 页）展示了在不同数据集与划分下的性能比较：</p>
<p><img src="/blog/image/A-2.PNG"></p>
<p>(1) 未见类别检测性能显著提升</p>
<p>ZS-YOLO 在 <strong>Test-Unseen</strong> 场景中始终显著优于 YOLOv2。<br>例如：</p>
<ul>
<li>PASCAL VOC (10&#x2F;10 split)：<strong>+3.7% AP 提升（56.4 → 60.1）</strong></li>
<li>MS COCO (60&#x2F;20 split)：<strong>+8.9% AP 提升（34.9 → 43.8）</strong></li>
</ul>
<p>这说明加入语义特征后，模型能更好地识别视觉上未见过、但语义相近的目标。</p>
<hr>
<h3 id="性能提升原因分析"><a href="#性能提升原因分析" class="headerlink" title="性能提升原因分析"></a>性能提升原因分析</h3><p>作者指出主要的性能提升原因有两点：</p>
<ol>
<li><strong>ZS-YOLO 的置信度预测结合了视觉与语义信息</strong>，而 YOLOv2 仅基于视觉特征。<br>因此，ZS-YOLO 能避免将语义相似但视觉不同的未见目标（如“马”和“斑马”）误判为背景。</li>
<li><strong>语义特征增强了模型的泛化能力</strong>。<br>当训练集中 seen 类别较少时，ZS-YOLO 能更好地利用语义联系来推断 unseen 类别。</li>
</ol>
<p>例如：</p>
<ul>
<li>在 <strong>MS COCO</strong> 上，YOLOv2 的表现随 seen 类别数的增减波动较大；</li>
<li>而 ZS-YOLO 在 seen 类别数增加时性能持续提升（从 40.6% → 43.8%），说明语义信息在大规模训练下更有效。</li>
</ul>
<hr>
<h3 id="召回率与可视化分析"><a href="#召回率与可视化分析" class="headerlink" title="召回率与可视化分析"></a>召回率与可视化分析</h3><p>图 3 展示了 PASCAL VOC 和 COCO 的 <strong>Precision-Recall 曲线</strong> 与 <strong>Recall 曲线</strong>。结果显示：</p>
<p><img src="/blog/image/A-3.PNG"></p>
<ul>
<li>ZS-YOLO 在高置信度阈值下的召回率（Recall）显著优于 YOLOv2。<br>例如在 PASCAL VOC 5&#x2F;15 分割中：<ul>
<li>当置信度阈值为 0.8 时，ZS-YOLO 能召回约 <strong>30% 未见对象</strong>；</li>
<li>YOLOv2 仅能召回 <strong>20%</strong>。</li>
</ul>
</li>
<li>这表明 ZS-YOLO 在高置信度下能捕获更多未见对象。</li>
</ul>
<hr>
<h3 id="进一步分析：性能平衡与挑战"><a href="#进一步分析：性能平衡与挑战" class="headerlink" title="进一步分析：性能平衡与挑战"></a>进一步分析：性能平衡与挑战</h3><p>作者还指出：</p>
<ul>
<li>ZS-YOLO 在检测未见对象时提升了召回率，但在部分 seen 类别上略微降低了精度；</li>
<li>对于 5&#x2F;15 split（少量 seen 类别），模型的精度略低，但 recall 明显提升；</li>
<li>这种“召回提升 + 精度轻微下降”的平衡符合零样本学习的预期。</li>
</ul>
<p>总结来说：</p>
<blockquote>
<p><strong>ZS-YOLO 在未见类别检测上显著优于 YOLOv2，同时在已见类别上保持了稳定性能。</strong><br>它的核心改进在于语义特征的引入，使得检测器能够“跨类别泛化”，从而实现真正的零样本检测。</p>
</blockquote>
<hr>
<h2 id="C-Ablative-Study-on-PASCAL-VOC"><a href="#C-Ablative-Study-on-PASCAL-VOC" class="headerlink" title="C. Ablative Study on PASCAL VOC"></a>C. Ablative Study on PASCAL VOC</h2><p><strong>目的</strong>：拆解 ZS-YOLO 的关键设计（语义预测、置信度输入的多模态融合、语义原型选择、语义维度规整、seen&#x2F;unseen 语义相关性、替代损失）对<strong>未见类检测性能</strong>的真实贡献。<br><strong>方法</strong>：在 <strong>PASCAL VOC 10&#x2F;10 split</strong>（亦涉及 5&#x2F;15 与扩展划分）上，逐一移除&#x2F;替换组件，比较 <strong>Test-Unseen &#x2F; Test-Seen &#x2F; Test-Mix</strong> 的 AP（以及在前文中辅助使用的 F-score）。</p>
<blockquote>
<p>该节的所有定量结果与结论主要集中在<strong>表 III—VI</strong>与<strong>图 5</strong>：见<strong>第 9 页（表 III&#x2F;IV&#x2F;V&#x2F;VI）<strong>与</strong>第 11 页（图 5）</strong>。</p>
</blockquote>
<hr>
<p>语义预测与多模态置信度的作用（表 III，第 9 页）</p>
<p><img src="/blog/image/A-4.png"></p>
<p>作者把最终“<strong>置信度预测</strong>”的输入逐步改动，比较四种配置在 VOC 10&#x2F;10 split 上的 AP：</p>
<ul>
<li><strong>YOLOv2</strong>（仅视觉特征 TF）：Unseen 56.4 &#x2F; Seen 71.6 &#x2F; Mix 54.3</li>
<li><strong>ZS-YOLO (visual)</strong>：<strong>移除语义预测分支</strong>，置信度只用 <strong>[TF, TL]</strong>（视觉特征 + 框位置）。Unseen <strong>57.2</strong> &#x2F; Seen 71.2 &#x2F; Mix 52.3</li>
<li><strong>ZS-YOLO (semantic)</strong>：<strong>去掉视觉特征 TF</strong>，置信度只用 <strong>[TL, TS]</strong>（位置 + 语义预测向量）。Unseen <strong>57.0</strong> &#x2F; Seen 70.9 &#x2F; Mix 52.3</li>
<li><strong>ZS-YOLO (full)</strong>：<strong>多模态融合</strong>，置信度用 <strong>[TF, TL, TS]</strong>。Unseen <strong>60.1（最高）</strong> &#x2F; Seen 71.0 &#x2F; Mix 53.9</li>
</ul>
<p><strong>要点解读</strong></p>
<ol>
<li><strong>多模态 &gt; 单模态</strong>：同时用<strong>视觉 + 语义 + 位置</strong>的信息预测“目标性置信度”，能显著提升<strong>未见类 AP</strong>（60.1 &gt; 57.x &gt; 56.4）。</li>
<li><strong>仅语义也能超越 YOLOv2</strong>：ZS-YOLO(semantic) 在 Unseen 上仍优于 YOLOv2，说明<strong>语义信号本身</strong>就能缓解“把未见目标压成背景”的问题。</li>
<li><strong>位置（TL）是有益的辅助</strong>：ZS-YOLO(visual) 相比 YOLOv2 也略升，提示位置信息对“目标性”判断有帮助，但不及引入语义带来的增益。</li>
</ol>
<hr>
<p> 语义原型的选择：属性 &#x2F; word2vec &#x2F; one-hot &#x2F; 随机（表 IV，第 9 页）</p>
<p><img src="/blog/image/A-6.png"></p>
<p>在 VOC 10&#x2F;10 split 上比较不同<strong>语义原型</strong>作为训练时的语义监督（注意：测试时该模型对 unseen 的检测不依赖其语义标签）：</p>
<ul>
<li><strong>Attribute（属性向量）</strong>：Unseen AP <strong>60.1（最佳）</strong></li>
<li><strong>word2vec（w2v）</strong>：Unseen AP 58.9</li>
<li><strong>one-hot</strong>：Unseen AP 57.7</li>
<li><strong>random（随机编码）</strong>：Unseen AP <strong>49.0（最差，低于 YOLOv2）</strong></li>
</ul>
<p><strong>要点解读</strong></p>
<ol>
<li><strong>“有语义”的原型才有效</strong>：属性 &#x2F; w2v 显著好于 one-hot 与随机，说明需要能反映<strong>语义相似性</strong>的连续原型空间。</li>
<li><strong>随机编码会伤害泛化</strong>：random 甚至拖到 49.0，证明“无语义结构”的向量会误导网络。</li>
<li><strong>one-hot 只含类别区分，不含相似度</strong>，因此弱于属性 &#x2F; w2v。</li>
</ol>
<hr>
<p>语义维度规整（降噪）：w2v → w2vR（表 V，第 9 页）</p>
<p><img src="/blog/image/A-7.PNG"></p>
<p>作者提出把原始 300 维 w2v <strong>映射到低维 w2vR（25 维）</strong>，并<strong>保留与 VOC 属性空间相一致的相似度结构</strong>。在 VOC（10&#x2F;10）与 COCO（20&#x2F;20）上的对比显示：</p>
<ul>
<li>VOC：属性 60.1，<strong>w2v 58.9</strong>，<strong>w2vR 59.3（略高于 w2v）</strong></li>
<li>COCO：属性 38.4，<strong>w2v 38.4</strong>，<strong>w2vR 40.6（显著更好）</strong></li>
</ul>
<p><strong>要点解读</strong></p>
<ol>
<li>原始 w2v <strong>噪声较大且与视觉空间偏离</strong>，直接学会收敛困难；</li>
<li>通过对齐到“视觉相关”的属性相似度结构，<strong>w2vR</strong> 更“视觉语义化”，<strong>未见类 AP 提升</strong>更稳健（在 COCO 上尤其明显）。</li>
</ol>
<hr>
<p> seen&#x2F;unseen 语义相关性（E 分数）的影响（表 VI，第 9 页；解释与示例第 11 页）</p>
<p><img src="/blog/image/A-8.PNG"></p>
<p>作者定义 split 的<strong>能量分数 E</strong> 来度量 unseen 与 seen 的<strong>最大语义相似度</strong>平均值：<br>$$<br>E&#x3D;\frac{1}{|C_{unseen}|}\sum_{a\in C_{unseen}}\max_{b\in C_{seen}}S(y_a,y_b)<br>$$</p>
<p>在多组 VOC 划分（10&#x2F;10-1、10&#x2F;10-2、10&#x2F;10-3、5&#x2F;15-1、5&#x2F;15-2）上，<strong>E 越高，Unseen AP 越高</strong>。例如：</p>
<ul>
<li><strong>10&#x2F;10-1</strong>：<strong>E&#x3D;0.843 → Unseen AP&#x3D;60.1</strong></li>
<li><strong>10&#x2F;10-3</strong>：<strong>E&#x3D;0.567 → Unseen AP&#x3D;39.3（显著下降）</strong></li>
</ul>
<p><strong>要点解读</strong></p>
<ol>
<li><strong>语义相近更易迁移</strong>：当 unseen 与 seen 的语义更“接壤”，ZS-YOLO 学到的语义-视觉对齐能更好泛化到未见类；</li>
<li>若相关性低，则迁移更难，未见类 AP 大幅下滑。作者在第 11 页还给出具体类对（如 motorbike&#x2F;bicycle）在不同 split 的分布示例来直观说明这一点。</li>
</ol>
<hr>
<p> 特征可视化（图 5，第 11 页）</p>
<p><img src="/blog/image/A-5.PNG"></p>
<p><strong>t-SNE 可视化</strong>对比了 <strong>YOLOv2 的视觉特征</strong> vs <strong>ZS-YOLO 学到的语义特征</strong>（在 Test-Mix 上）：</p>
<ul>
<li>在 ZS-YOLO 的语义空间里，<strong>前景（见&#x2F;未见）与背景更易分离</strong>，类簇结构更清晰；</li>
<li>这印证了“<strong>语义预测作为旁路任务</strong>”能<strong>重塑特征空间</strong>，让“目标 vs 背景”与“语义相近类”更容易分辨，从而提高未见类召回。</li>
</ul>
<hr>
<p> 其他损失：Focal Loss 的负面结果（第 11 页）</p>
<p>作者尝试了 <strong>focal loss</strong>（常用于艰难样本挖掘），但观察到：</p>
<ul>
<li><strong>见类</strong>检测略有改善；</li>
<li><strong>未见类</strong>检测<strong>下降更明显</strong>。<br><strong>解释</strong>：focal loss 进一步“偏爱”见类的区分信号，加剧了对未知分布的抑制，<strong>破坏了语义泛化的平衡</strong>。因此不适合作为本任务中的主损失替代。</li>
</ul>
<hr>
<p>这节的关键信息小结（对应表&#x2F;图）</p>
<ol>
<li><strong>多模态置信度</strong>（视觉+语义+位置）是未见类提升的直接原因（<strong>表 III</strong>）。</li>
<li><strong>属性 &#x2F; w2v &gt; one-hot &gt; 随机</strong>：原型必须携带可度量的语义相似性（<strong>表 IV</strong>）。</li>
<li>**w2vR（语义降噪与对齐）**优于原始 w2v，尤其在 COCO 上提升明显（<strong>表 V</strong>）。</li>
<li><strong>seen&#x2F;unseen 的语义相关性越高，未见类 AP 越高</strong>（<strong>表 VI</strong>）。</li>
<li><strong>图 5</strong>：语义旁路任务让<strong>前景-背景更分离</strong>，支持“召回提升”的机制解释。</li>
<li><strong>Focal loss 不适合</strong>零样本检测：会<strong>伤害未见类</strong>（第 11 页“Other Losses”段落）。</li>
</ol>
<hr>
<p>一句话结论</p>
<p><strong>ZS-YOLO 的“语义预测 + 多模态置信度”是未见类检测提升的根因</strong>；语义原型要“有意义且与视觉相关”，并且 seen&#x2F;unseen 需具备一定<strong>语义相关性</strong>；传统针对困难样本的 focal loss 在零样本检测里<strong>反而不利于泛化</strong>。上述结论均由 PASCAL VOC 的系统<strong>消融</strong>得到，并辅以 t-SNE 可视化验证。</p>
<p>如果你想，我可以把这一节的<strong>所有表格（III–VI）<strong>做成一页精炼对照海报（含关键结论 + 机制示意），或把</strong>E 分数—性能</strong>做成更直观的散点&#x2F;条形图便于报告。</p>
<h2 id="D-Semantic-Output-for-Zero-Shot-Recognition"><a href="#D-Semantic-Output-for-Zero-Shot-Recognition" class="headerlink" title="D. Semantic Output for Zero-Shot Recognition"></a>D. Semantic Output for Zero-Shot Recognition</h2><p>（语义输出在零样本识别中的作用）</p>
<hr>
<h3 id="一、章节背景与目的"><a href="#一、章节背景与目的" class="headerlink" title="一、章节背景与目的"></a>一、章节背景与目的</h3><p>在前面的消融实验（Section IV.C）中，作者主要分析了 ZS-YOLO 在目标检测（<strong>localization + detection</strong>）任务上的零样本能力；<br>而在本节 <strong>D. Semantic Output for Zero-Shot Recognition</strong> 中，作者进一步探讨如何利用 ZS-YOLO 的 <strong>语义输出层（semantic prediction head）</strong> 来直接执行 <strong>零样本识别（ZSR）</strong> 或更一般的 <strong>广义零样本识别（GZSL, Generalized Zero-Shot Learning）</strong> 任务。</p>
<p>关键目的：</p>
<ul>
<li>验证 ZS-YOLO 的语义输出在纯识别任务上的表现；</li>
<li>探究“检测误差”和“识别误差”对整体性能的相对影响；</li>
<li>展示如何将检测模型与标准零样本分类器结合，实现 <strong>检测 + 识别 一体化</strong>。</li>
</ul>
<hr>
<h3 id="二、任务定义与实验设置"><a href="#二、任务定义与实验设置" class="headerlink" title="二、任务定义与实验设置"></a>二、任务定义与实验设置</h3><p>作者在此部分采用 <strong>Generalized Zero-Shot Learning (gZSL)</strong> 框架来评估 ZS-YOLO 的语义输出能力。</p>
<p>gZSL 测试设置：</p>
<ol>
<li><p>模型需同时识别 <strong>已见类（seen）</strong> 与 <strong>未见类（unseen）</strong>；</p>
</li>
<li><p>性能指标包括：</p>
<ul>
<li><strong>Mean Accuracy (mAcc)</strong>：平均分类准确率；</li>
<li><strong>Mean Average Precision (mAP)</strong>：检测与识别整体性能；</li>
</ul>
</li>
<li><p>数据集：<strong>PASCAL VOC 10&#x2F;10 split</strong>；</p>
</li>
<li><p>对比方法：</p>
<ul>
<li>ZS-YOLO + 最近邻（NN）分类器；</li>
<li>ZS-YOLO + [4]（即 <em>Semantic Similarity Embedding</em> 方法）；</li>
<li>YOLOv2 + [4]（传统检测器 + ZSR 模型）；</li>
<li>baseline GZSL [4]（仅识别任务）。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="三、误差来源分析"><a href="#三、误差来源分析" class="headerlink" title="三、误差来源分析"></a>三、误差来源分析</h3><p>作者指出 gZSL 实验中的误差可分为两类：</p>
<ol>
<li><p><strong>识别误差（Recognition Error）</strong><br>当边界框（bounding boxes）<strong>已知</strong>时仍分类错误；<br>这一误差来源于语义空间匹配的不精确。</p>
</li>
<li><p><strong>检测 + 识别误差（Detection + Recognition Error）</strong><br>当模型需要<strong>同时检测和识别</strong>时，误差包含边界框定位与类别预测两部分。</p>
</li>
</ol>
<p>在 PASCAL VOC 上，作者强调：</p>
<blockquote>
<p>GZSL 的识别任务本身就非常困难，基线准确率极低；<br>相比之下，检测误差只是一个较小的额外误差源。</p>
</blockquote>
<p>换言之，即便 ZS-YOLO 检测性能很好，如果底层语义识别能力差（如属性空间对齐不准），总体性能仍会受限。</p>
<hr>
<h3 id="四、语义输出的识别能力验证"><a href="#四、语义输出的识别能力验证" class="headerlink" title="四、语义输出的识别能力验证"></a>四、语义输出的识别能力验证</h3><p>作者利用 <strong>ZS-YOLO 的语义预测层输出（TS）</strong> 来进行识别任务。<br>具体做法如下：</p>
<ul>
<li><p>对每个检测出的 bounding box，ZS-YOLO 都生成一个语义向量；</p>
</li>
<li><p>该语义向量可直接与类别属性（ground-truth semantic prototypes）计算相似度；</p>
</li>
<li><p>采用：</p>
<ul>
<li><strong>NN（nearest neighbor）分类</strong>；</li>
<li>或 <strong>[4] Semantic Similarity Embedding</strong> 作为替代分类器；</li>
</ul>
</li>
<li><p>从而得到预测标签，实现“检测即识别”。</p>
</li>
</ul>
<p>实验结果（见 Table VII）：</p>
<table>
<thead>
<tr>
<th>模型配置</th>
<th>Unseen mAP (%)</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>YOLOv2 + [4]</td>
<td>1.64</td>
<td>传统检测器对未见类几乎完全失败</td>
</tr>
<tr>
<td>ZS-YOLO + NN</td>
<td>4.33</td>
<td>使用语义输出的最近邻识别，显著提升</td>
</tr>
<tr>
<td>ZS-YOLO + [4]</td>
<td><strong>6.92</strong></td>
<td>进一步提升识别效果，验证语义特征质量</td>
</tr>
<tr>
<td>[4]（仅识别）</td>
<td>极低（约数个百分点）</td>
<td>GZSL 任务本身极难</td>
</tr>
</tbody></table>
<blockquote>
<p>结论：ZS-YOLO 的语义输出在零样本识别中表现出有效的可分辨性，比直接用 YOLOv2 特征强得多。</p>
</blockquote>
<hr>
<h3 id="五、结果解读与细节分析"><a href="#五、结果解读与细节分析" class="headerlink" title="五、结果解读与细节分析"></a>五、结果解读与细节分析</h3><ol>
<li>检测误差 vs 识别误差</li>
</ol>
<ul>
<li>作者发现检测误差仅占总体误差的一小部分；</li>
<li>主因仍是语义空间内的识别困难（尤其在 VOC 上）。</li>
</ul>
<ol start="2">
<li>性能提升来源</li>
</ol>
<ul>
<li><p>ZS-YOLO 的 <strong>语义预测任务</strong> 使得特征空间对齐；</p>
</li>
<li><p>通过 NN 或 embedding 匹配，模型能较好识别未见类；</p>
</li>
<li><p>例如：</p>
<ul>
<li>“ZS-YOLO + NN” 在 Test-Unseen 几乎所有类别上取得最高 AP；</li>
<li>在 Test-Mix 上，ZS-YOLO 超越 YOLOv2 于所有未见类（除 cat）；</li>
<li>“YOLOv2 + [4]” 在 visually similar 类别（如 bike&#x2F;motorbike）中仍完全失败，显示其无法迁移到语义邻近类别。</li>
</ul>
</li>
</ul>
<ol start="3">
<li>对照模型的解释</li>
</ol>
<ul>
<li><strong>YOLOv2 + [4]</strong> 组合代表传统“检测+分类”两步法；<br>它容易将未见目标压制为背景；</li>
<li><strong>ZS-YOLO + [4]</strong> 则通过语义输出弥合了视觉与语义间的差距；<br>因此在未见类识别（尤其是语义相似类）中表现更好。</li>
</ul>
<hr>
<h3 id="六、结论与启示"><a href="#六、结论与启示" class="headerlink" title="六、结论与启示"></a>六、结论与启示</h3><table>
<thead>
<tr>
<th>观察</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>✅ ZS-YOLO 的语义输出层具备“通用语义表征”功能</td>
<td>它能直接被用作零样本识别的输入空间</td>
</tr>
<tr>
<td>✅ 检测误差不是主要瓶颈</td>
<td>核心问题在语义对齐与泛化</td>
</tr>
<tr>
<td>✅ 一体化架构可同时服务检测与识别</td>
<td>提高系统效率，减少特征冗余</td>
</tr>
<tr>
<td>✅ NN 与嵌入式方法均能有效利用语义输出</td>
<td>表明语义空间学习稳定且结构良好</td>
</tr>
<tr>
<td>⚠️ VOC 的识别难度高</td>
<td>导致整体 mAP 较低，但趋势仍明显</td>
</tr>
</tbody></table>
<p>作者最后指出：</p>
<blockquote>
<p>本文重点在于“检测未见目标”，而非追求最优 ZSR 分类器。<br>若未来结合更强的识别模块（如 max-margin 损失或更先进的 ZSR 嵌入模型），<br>ZS-YOLO 的语义输出将能显著提升综合性能。</p>
</blockquote>
<hr>
<h3 id="七、总结：ZS-YOLO-的统一视角"><a href="#七、总结：ZS-YOLO-的统一视角" class="headerlink" title="七、总结：ZS-YOLO 的统一视角"></a>七、总结：ZS-YOLO 的统一视角</h3><p>通过这一节，作者强调：</p>
<ul>
<li><strong>ZS-YOLO 不仅是检测器</strong>，还是一种<strong>通用的语义嵌入模型</strong>；</li>
<li>其语义输出可直接复用到“零样本识别”或“广义零样本识别”；</li>
<li>从结构上实现了视觉检测与语义理解的融合，为后续统一模型（如 open-vocabulary detection）奠定了基础。</li>
</ul>
<hr>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><h2 id="一、章节位置与核心目的"><a href="#一、章节位置与核心目的" class="headerlink" title="一、章节位置与核心目的"></a>一、章节位置与核心目的</h2><p>“V. Conclusion” 是整篇论文的收束部分，主要回答三个问题：</p>
<ol>
<li><strong>本文到底解决了什么？</strong></li>
<li><strong>为什么它是新的、有效的？</strong></li>
<li><strong>接下来可以怎么扩展？</strong></li>
</ol>
<p>Zhu 等人希望通过结论明确地把 ZS-YOLO 的贡献定位为：</p>
<blockquote>
<p>第一个<strong>端到端的零样本目标检测网络（Zero-Shot Detection, ZSD）</strong>，<br> 能够在无未见类样本的条件下，实现未见类别的<strong>目标检测与识别</strong>。</p>
</blockquote>
<hr>
<h2 id="二、主要贡献总结"><a href="#二、主要贡献总结" class="headerlink" title="二、主要贡献总结"></a>二、主要贡献总结</h2><h3 id="1-首次提出「零样本检测」（Zero-Shot-Detection-ZSD）的完整定义"><a href="#1-首次提出「零样本检测」（Zero-Shot-Detection-ZSD）的完整定义" class="headerlink" title="1. 首次提出「零样本检测」（Zero-Shot Detection, ZSD）的完整定义"></a>1. 首次提出「零样本检测」（Zero-Shot Detection, ZSD）的完整定义</h3><p>以往的工作几乎都聚焦在<strong>零样本识别（Zero-Shot Recognition, ZSR）</strong>，即给定已裁剪的目标图片，预测其类别。<br> 而 Zhu 等首次把问题拓展到“检测”层面：</p>
<blockquote>
<p>模型不仅要识别未见类，还要从整张图像中<strong>定位并区分目标</strong>。</p>
</blockquote>
<p>他们指出：</p>
<blockquote>
<p>传统检测器（如 YOLOv2、SSD）会将未见类的目标视为<strong>背景</strong>，导致召回率急剧下降；<br> 因此，必须设计能理解“语义相似性”的检测器结构。</p>
</blockquote>
<hr>
<h3 id="2-提出-ZS-YOLO："><a href="#2-提出-ZS-YOLO：" class="headerlink" title="2. 提出 ZS-YOLO："></a>2. 提出 ZS-YOLO：</h3><p>一个融合语义学习的<strong>单阶段检测器（Single-Stage Detector）</strong>。</p>
<p>核心创新点：</p>
<ul>
<li><strong>语义预测分支（Semantic Prediction Head）</strong>：<br> 让每个候选框输出语义向量（属性或 word2vec 表示），从而获得语义可解释的检测特征。</li>
<li><strong>多模态置信度预测（Multi-modal Confidence Estimation）</strong>：<br> 将视觉特征（TF）、位置特征（TL）、语义特征（TS）拼接后预测“目标性置信度”；<br> 使模型学会利用语义信息判断目标性，而非仅依赖视觉相似度。</li>
<li><strong>端到端联合训练</strong>：<br> 同时最小化定位损失、语义损失、置信度损失，令视觉空间与语义空间对齐。</li>
</ul>
<p>这些设计让 ZS-YOLO 在未见类上获得显著提升（例如在 VOC 10&#x2F;10 split 上 Unseen AP 从 56.4% → 60.1%）。</p>
<hr>
<h3 id="3-实验验证与现象总结"><a href="#3-实验验证与现象总结" class="headerlink" title="3. 实验验证与现象总结"></a>3. 实验验证与现象总结</h3><p>作者通过大量消融实验（第 IV 节）验证了：</p>
<ul>
<li>引入语义预测能提升未见类召回；</li>
<li>语义原型必须携带语义结构；</li>
<li>语义相似度高的 seen&#x2F;unseen 划分性能更好；</li>
<li>t-SNE 可视化表明语义辅助任务使得前景与背景在特征空间中更易分离。</li>
</ul>
<p>他们还指出：</p>
<blockquote>
<p>仅替换检测 backbone 并不能带来零样本性能的提升，核心在于语义信号的引入。</p>
</blockquote>
<hr>
<h2 id="三、论文的科学意义"><a href="#三、论文的科学意义" class="headerlink" title="三、论文的科学意义"></a>三、论文的科学意义</h2><h3 id="（1）填补检测领域的空白"><a href="#（1）填补检测领域的空白" class="headerlink" title="（1）填补检测领域的空白"></a>（1）填补检测领域的空白</h3><p>在此之前，零样本学习主要局限于分类任务。<br> ZS-YOLO 是<strong>首个端到端零样本检测系统</strong>，打破了“检测器必须有见类监督”的假设。</p>
<h3 id="（2）建立视觉–语义联合空间的检测范式"><a href="#（2）建立视觉–语义联合空间的检测范式" class="headerlink" title="（2）建立视觉–语义联合空间的检测范式"></a>（2）建立视觉–语义联合空间的检测范式</h3><p>ZS-YOLO 的训练机制有效地将视觉与语义空间对齐，<br> 为后续的 <strong>Open-Vocabulary Detection（开放词汇检测）</strong> 奠定基础。<br> 后来的如 <strong>OVD、CLIP-DET、RegionCLIP</strong> 等工作，都继承了这一思想：</p>
<blockquote>
<p>通过语义嵌入统一检测与语言描述空间。</p>
</blockquote>
<h3 id="（3）实现「检测-识别」的统一框架"><a href="#（3）实现「检测-识别」的统一框架" class="headerlink" title="（3）实现「检测 + 识别」的统一框架"></a>（3）实现「检测 + 识别」的统一框架</h3><p>ZS-YOLO 的语义输出既可用于目标检测，也可直接用于零样本识别任务（如前节 D 所示）。<br> 这意味着一个网络即可同时执行：</p>
<ul>
<li>未见类检测；</li>
<li>泛化识别（gZSL）。</li>
</ul>
<hr>
<h2 id="四、局限与挑战"><a href="#四、局限与挑战" class="headerlink" title="四、局限与挑战"></a>四、局限与挑战</h2><p>作者在结尾坦诚指出两个限制：</p>
<ol>
<li><strong>语义相关性依赖性强</strong><br> 若 unseen 类与 seen 类语义距离过远（E 值低），性能急剧下降。<br> 模型仍难以“真正泛化”到语义孤立的新概念。</li>
<li><strong>语义原型质量受限</strong><br> 属性或 word2vec 嵌入并不总能准确反映视觉特征相似性。<br> 语义空间噪声仍是零样本检测的瓶颈。</li>
<li><strong>未完全解决 GZSL 偏置问题</strong><br> 模型在联合 seen&#x2F;unseen 测试时仍存在<strong>偏向 seen 类</strong>的现象，<br> 需要后续校准与更平衡的训练策略。</li>
</ol>
<hr>
<h2 id="五、未来展望（作者提出的方向）"><a href="#五、未来展望（作者提出的方向）" class="headerlink" title="五、未来展望（作者提出的方向）"></a>五、未来展望（作者提出的方向）</h2><p>在结论部分末尾，作者提出三条未来研究方向：</p>
<ol>
<li><strong>语义空间优化与对齐</strong><ul>
<li>改进语义嵌入（如降噪 w2vR、融合文本描述、利用上下文学习）；</li>
<li>自适应地学习语义距离度量，而非固定余弦相似度。</li>
</ul>
</li>
<li><strong>跨架构扩展</strong><ul>
<li>将语义预测模块整合进更先进的检测框架（如 Faster R-CNN、RetinaNet、Mask R-CNN）；</li>
<li>探索两阶段检测器或 transformer-based 架构的迁移。</li>
</ul>
</li>
<li><strong>开放词汇与跨模态任务</strong><ul>
<li>利用语义输出实现“<strong>开放类别检测</strong>”与“<strong>文本驱动目标识别</strong>”；</li>
<li>为多模态视觉理解任务（VQA、Referring Expression、Scene Graph）提供检测基础。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="六、总结性评价"><a href="#六、总结性评价" class="headerlink" title="六、总结性评价"></a>六、总结性评价</h2><table>
<thead>
<tr>
<th>维度</th>
<th>ZS-YOLO 的创新</th>
</tr>
</thead>
<tbody><tr>
<td><strong>任务层面</strong></td>
<td>从零样本识别 → 零样本检测（首次）</td>
</tr>
<tr>
<td><strong>结构层面</strong></td>
<td>在检测网络中引入语义预测分支</td>
</tr>
<tr>
<td><strong>训练机制</strong></td>
<td>端到端联合语义对齐、多模态置信度学习</td>
</tr>
<tr>
<td><strong>结果表现</strong></td>
<td>显著提升未见类检测性能</td>
</tr>
<tr>
<td><strong>应用价值</strong></td>
<td>为开放词汇检测与多模态学习奠基</td>
</tr>
</tbody></table>
<hr>
<h2 id="七、我的延伸点评"><a href="#七、我的延伸点评" class="headerlink" title="七、我的延伸点评"></a>七、我的延伸点评</h2><p>从今天的视角（2025 年）回看，《Zero-Shot Detection》是**开放词汇检测（Open-Vocabulary Detection, OVD）**领域的重要起点之一。<br> ZS-YOLO 的“语义预测 + 多模态置信度”思想后来被 CLIP、ViLD、Detic 等工作进一步发展成：</p>
<blockquote>
<p>“用语言做标签，用语义空间做检测。”</p>
</blockquote>
<p>可以说，这篇论文为“<strong>让检测器理解语言</strong>”打开了大门。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>零样本检测</tag>
      </tags>
  </entry>
  <entry>
    <title>照片</title>
    <url>/blog/Gallery/index.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/blog/image/1.jpg"></p>
]]></content>
  </entry>
  <entry>
    <title>电影</title>
    <url>/blog/movies/index.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
  <entry>
    <title>写给你的小作文</title>
    <url>/blog/movies/%E5%86%99%E7%BB%99%E9%82%B5%E8%89%BA%E5%8D%9A%E7%9A%84%E5%B0%8F%E4%BD%9C%E6%96%87.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="一"><a href="#一" class="headerlink" title="一"></a>一</h1><p><u>感觉我和你没什么好说的。</u><br><img src="/blog/image/sy1.jpg"></p>
<p>那就从这句话开始说吧。其实这张纸我一直有好好留着，从确山带到了秦皇岛，后来又带去了深圳，现在又让我带来了长春。</p>
<h1 id="二"><a href="#二" class="headerlink" title="二"></a>二</h1><p>高中的有些事情我一直记得，记得跟你说我喜欢你，但是当初你好像并没有给我答案，没有接受，也没有拒绝。</p>
<p>但至那以后咱俩好像话就越来越少，后来也就没在做同桌了。其实当时我是很难过的，看到你天天和别的男同学有说有笑我其实更难过（）。</p>
<p>高中有段时间我成绩不好，应该是高二，要说跟你没关系，那就是自欺欺人。后来我就慢慢想开了，大抵是你真的不喜欢我，觉得这段不会有结果的关系就这样了吧。</p>
<p>后来便是大学的时候你偶尔找我聊会天，我也觉得这样就好，只是有时候做梦会梦到你。</p>
<p>至于去年为什么要送你吃，我觉得应当送你，所以我送了。</p>
<p>后来的后来就是现在了。</p>
<p>有些事是好的，但又不是足够好的。</p>
<h1 id="三"><a href="#三" class="headerlink" title="三"></a>三</h1><p>关于表达欲的问题我一直有在想。</p>
<p><img src="/blog/image/sy2.jpg"></p>
<p>之前做过MBTI测试，不出所料结果是INFJ，因为这种性格的描述真的太像我了。</p>
<p>后来慢慢了解到我可能是回避型依恋人格。</p>
<p>但是我又觉得自己可能又可能是纯纯犯贱。</p>
<p>之前发了条朋友圈是希望你能看到的，但既然想让你看到，应该由我亲口告诉你，可却没有，所以说自己有点贱。<br><img src="/blog/image/sy3.jpg"></p>
<h1 id="四"><a href="#四" class="headerlink" title="四"></a>四</h1><p>有些时候会莫名其妙想一些事情，现在如何，未来如何，如果现在做了将来又会如何，所以会遇到事情会下意识犹豫。很多事情都习惯拖着，拖到不能拖了才会下定决心回应。可时间又是不等人的，就像两个人聊天，当你还在想如何回复时，可能下个问题就来了，先前的问题就被永远搁置了。</p>
<p>之前你问我要不要找你去玩，我真的一直在想，一直在犹豫，我感觉像我这种人对于某些事下定决心是一件很难的事情。</p>
<p>之前没告诉你，其实我的车票已经改了好几次。<br><img src="/blog/image/sy4.jpg"></p>
<p><img src="/blog/image/sy5.jpg"></p>
<p>（今天为啥去驻马店坐高铁，因为卧铺票真的很难候补啊～～捏麻麻的，我是真的腰疼屁股疼）</p>
<h1 id="五"><a href="#五" class="headerlink" title="五"></a>五</h1><p>之前读到过一句话，我觉得非常适合我—我这样胆小慢热的人，需要别人千百次的主动和回应才愿意相信那才是真的。</p>
<p>你问我喜不喜欢你，说不喜欢这是不可能。</p>
<p>但是如果你问是否像高中那般喜欢，给出确凿无疑的答案那又是自欺欺人了。</p>
<p>没有人能比得过我回忆的那个你，即便是现在的你。</p>
<h1 id="六"><a href="#六" class="headerlink" title="六"></a>六</h1><p>你关心我，我真的很开心。</p>
<h1 id="七"><a href="#七" class="headerlink" title="七"></a>七</h1><p>记得高中下晚自习你习惯对我摆手说再见，我老是沉默不语，你后来逗我说怎么不说“再见”。</p>
<p>不说“再见”，是因为希望再见。</p>
<hr>
<p>写于2025年2月14日，于长春的高铁上。修改上传于宿舍。</p>
<hr>
<p>“怎么一回来就在敲代码”<br> “额，没有”<br> “那在写什么”<br> “小作文”<br> “嗯？”<br> “嗯”</p>
]]></content>
  </entry>
  <entry>
    <title>心想事成</title>
    <url>/blog/movies/%E5%BF%83%E6%83%B3%E4%BA%8B%E6%88%90.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="心想事成"><a href="#心想事成" class="headerlink" title="心想事成"></a>心想事成</h1><p>还是写点不想让认识的人瞧见，但又想倾述的事吧。</p>
<p>一个人在野地里坐到黄昏，等天空把夕阳吹成一朵炽热的花，风轻轻而来，也把泪水带离脸颊，我甚至不知道为什么而哭，或许只是对这人世间的理解偏差，这样的寂寞太漫长了，一条河流怎么能盛装得下，我捡起一颗将死的野草，告诉它，这个夏天就此作罢！</p>
<p>相见的人，不想见的人。<br>讨厌的人，麻烦的事。<br><img src="/blog/image/1738159231727.jpg"></p>
]]></content>
  </entry>
  <entry>
    <title>音乐</title>
    <url>/blog/music/index.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
  <entry>
    <title>分类</title>
    <url>/blog/categories/index.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
  <entry>
    <title>分类</title>
    <url>/blog/tags/index.html</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\blog\assets\css\APlayer.min.css"><script src="\blog\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
</search>
