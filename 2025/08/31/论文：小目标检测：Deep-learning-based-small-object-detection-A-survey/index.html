<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>论文：小目标检测：Deep learning-based small object detection: A survey | 且离且安的碎碎念</title><meta name="author" content="lian"><meta name="copyright" content="lian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Deep learning-based small object detection: A survey一、文献基本信息   项目 内容 对应文档段落    文章标题 Deep learning-based small object detection: A survey    作者 Qihan Feng¹, Xinzheng Xu¹, Zhixiao Wang¹,²,*    单位 ¹ 中国矿业">
<meta property="og:type" content="article">
<meta property="og:title" content="论文：小目标检测：Deep learning-based small object detection: A survey">
<meta property="og:url" content="https://qieliqiean.github.io/blog/2025/08/31/%E8%AE%BA%E6%96%87%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ADeep-learning-based-small-object-detection-A-survey/index.html">
<meta property="og:site_name" content="且离且安的碎碎念">
<meta property="og:description" content="Deep learning-based small object detection: A survey一、文献基本信息   项目 内容 对应文档段落    文章标题 Deep learning-based small object detection: A survey    作者 Qihan Feng¹, Xinzheng Xu¹, Zhixiao Wang¹,²,*    单位 ¹ 中国矿业">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qieliqiean.github.io/blog/image/Date%EF%BC%9A20250817154338.jpg">
<meta property="article:published_time" content="2025-08-31T08:25:55.000Z">
<meta property="article:modified_time" content="2025-09-01T01:46:57.010Z">
<meta property="article:author" content="lian">
<meta property="article:tag" content="论文阅读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qieliqiean.github.io/blog/image/Date%EF%BC%9A20250817154338.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "论文：小目标检测：Deep learning-based small object detection: A survey",
  "url": "https://qieliqiean.github.io/blog/2025/08/31/%E8%AE%BA%E6%96%87%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ADeep-learning-based-small-object-detection-A-survey/",
  "image": "https://qieliqiean.github.io/blog/image/Date%EF%BC%9A20250817154338.jpg",
  "datePublished": "2025-08-31T08:25:55.000Z",
  "dateModified": "2025-09-01T01:46:57.010Z",
  "author": [
    {
      "@type": "Person",
      "name": "lian",
      "url": "https://qieliqiean.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/image/1.jpg"><link rel="canonical" href="https://qieliqiean.github.io/blog/2025/08/31/%E8%AE%BA%E6%96%87%EF%BC%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ADeep-learning-based-small-object-detection-A-survey/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文：小目标检测：Deep learning-based small object detection: A survey',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/image/Date：20250817154338.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><img class="site-icon" src="/blog/image/background1.png" alt="Logo"><span class="site-name">且离且安的碎碎念</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">论文：小目标检测：Deep learning-based small object detection: A survey</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/blog/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/blog/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/blog/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">论文：小目标检测：Deep learning-based small object detection: A survey</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-31T08:25:55.000Z" title="发表于 2025-08-31 16:25:55">2025-08-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-01T01:46:57.010Z" title="更新于 2025-09-01 09:46:57">2025-09-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">5.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Deep-learning-based-small-object-detection-A-survey"><a href="#Deep-learning-based-small-object-detection-A-survey" class="headerlink" title="Deep learning-based small object detection: A survey"></a>Deep learning-based small object detection: A survey</h1><h2 id="一、文献基本信息"><a href="#一、文献基本信息" class="headerlink" title="一、文献基本信息"></a>一、文献基本信息</h2><table>
<thead>
<tr>
<th>项目</th>
<th>内容</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>文章标题</td>
<td>Deep learning-based small object detection: A survey</td>
<td></td>
</tr>
<tr>
<td>作者</td>
<td>Qihan Feng¹, Xinzheng Xu¹, Zhixiao Wang¹,²,*</td>
<td></td>
</tr>
<tr>
<td>单位</td>
<td>¹ 中国矿业大学计算机科学与技术学院（徐州 221116）；² 教育部矿山数字化工程研究中心（徐州 221116）</td>
<td></td>
</tr>
<tr>
<td>通讯作者</td>
<td>Zhixiao Wang，邮箱：<a href="mailto:&#122;&#104;&#120;&#x77;&#97;&#x6e;&#103;&#64;&#x63;&#x75;&#x6d;&#116;&#46;&#101;&#x64;&#x75;&#x2e;&#99;&#x6e;">zhxwang@cumt.edu.cn</a></td>
<td></td>
</tr>
<tr>
<td>发表期刊</td>
<td>Mathematical Biosciences and Engineering (MBE)</td>
<td>、</td>
</tr>
<tr>
<td>卷期页码</td>
<td>Volume 20, Issue 4, 6551-6590</td>
<td>、</td>
</tr>
<tr>
<td>DOI</td>
<td>10.3934&#x2F;mbe.2023282</td>
<td></td>
</tr>
<tr>
<td>发表时间</td>
<td>2023 年 2 月 2 日（接收：2022.10.18；修回：2022.12.21；录用：2022.12.26）</td>
<td>、、、</td>
</tr>
<tr>
<td>文章类型</td>
<td>Survey（综述）</td>
<td></td>
</tr>
</tbody></table>
<h2 id="二、摘要（核心总览）"><a href="#二、摘要（核心总览）" class="headerlink" title="二、摘要（核心总览）"></a>二、摘要（核心总览）</h2><p><strong>小目标检测（SOD）的重要性</strong>：在刑事侦查、自动驾驶、遥感图像等实际场景中具有关键意义，但因小目标分辨率低、特征含噪声，成为计算机视觉领域的难点任务。</p>
<p><strong>研究角度</strong>：围绕 SOD 的难点，从 4 个维度分析深度学习 - based SOD 算法 —— 提升输入特征分辨率、尺度感知训练、融入上下文信息、数据增强。</p>
<p><strong>关键任务回顾</strong>：涵盖小脸检测、小行人检测、遥感图像目标检测三大核心 SOD 任务。</p>
<p><strong>实验评估</strong>：在 4 个主流小目标数据集上，对通用 SOD 算法及关键任务算法进行性能测试，结果显示 “提升输入特征分辨率” 的网络配置能显著提升 WIDER FACE（小脸）和 Tiny Person（小行人）数据集上的性能。</p>
<p><strong>未来方向</strong>：提出 SOD 领域未来潜在的研究方向。</p>
<h2 id="三、引言（背景与研究定位）"><a href="#三、引言（背景与研究定位）" class="headerlink" title="三、引言（背景与研究定位）"></a>三、引言（背景与研究定位）</h2><h3 id="3-1-目标检测（OD）基础"><a href="#3-1-目标检测（OD）基础" class="headerlink" title="3.1 目标检测（OD）基础"></a>3.1 目标检测（OD）基础</h3><ul>
<li><p><strong>定义</strong>：计算机视觉的基础任务，是目标跟踪、实例分割、动作识别、环境监控等任务的前提。</p>
</li>
<li><p><strong>深度学习推动</strong>：得益于深度卷积神经网络（CNNs）的强特征学习能力，近十年 OD 研究快速发展，分为两类模型：</p>
</li>
</ul>
<ol>
<li><p><strong>两阶段模型</strong>：先生成感兴趣区域（ROI），再对 ROI 微调以分类和定位边界框，代表模型有 R-CNN、Fast R-CNN、Faster R-CNN、SPPNet、特征金字塔网络（FPN）。</p>
</li>
<li><p><strong>单阶段模型</strong>：无需 ROI 阶段，直接从特征图分类和定位目标，代表模型有 YOLO、SSD，及无锚点模型（FSAF、CornerNet、FCOS、CenterNet）。</p>
</li>
</ol>
<h3 id="3-2-小目标检测（SOD）的定义与挑战"><a href="#3-2-小目标检测（SOD）的定义与挑战" class="headerlink" title="3.2 小目标检测（SOD）的定义与挑战"></a>3.2 小目标检测（SOD）的定义与挑战</h3><h4 id="3-2-1-小目标的两种定义方式"><a href="#3-2-1-小目标的两种定义方式" class="headerlink" title="3.2.1 小目标的两种定义方式"></a>3.2.1 小目标的两种定义方式</h4><table>
<thead>
<tr>
<th>定义类型</th>
<th>具体标准</th>
<th>示例</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>相对尺寸</td>
<td>目标边界框宽 &#x2F; 高与图像宽 &#x2F; 高比＜0.1；或目标面积与图像面积比＜0.03</td>
<td>1000×1000 图像中，100×100 的目标</td>
<td></td>
</tr>
<tr>
<td>绝对尺寸</td>
<td>COCO 数据集标准：目标尺寸＜32×32 像素</td>
<td>监控中远处 20×20 像素的人脸</td>
<td></td>
</tr>
</tbody></table>
<h4 id="3-2-2-SOD-的核心挑战"><a href="#3-2-2-SOD-的核心挑战" class="headerlink" title="3.2.2 SOD 的核心挑战"></a>3.2.2 SOD 的核心挑战</h4><p><strong>特征与定位难题</strong>：小目标分辨率低、像素占比少，CNN 的下采样和池化操作会导致空间位置信息丢失，检测头难以精准定位。</p>
<ul>
<li><ul>
<li>示例：SOTA 模型 Co-DETR 在 COCO 数据集上小目标 mAP 仅 48.4%，远低于中目标（67.1%）和大目标（77.3%）。</li>
</ul>
</li>
</ul>
<p><strong>数据集稀缺</strong>：现有小目标数据集多聚焦特定场景（如人脸、行人、交通场景），缺乏通用大规模数据集，模型泛化能力差。</p>
<h3 id="3-3-现有综述的不足"><a href="#3-3-现有综述的不足" class="headerlink" title="3.3 现有综述的不足"></a>3.3 现有综述的不足</h3><ul>
<li><p><strong>普通 OD 综述</strong>：如 Zhao 等（2019）、Li 等（2020），虽提及 SOD 难点，但重点在普通尺寸目标检测，未深入 SOD。</p>
</li>
<li><p><strong>SOD 相关综述</strong>：</p>
</li>
<li><ul>
<li>Chen 等（2020）：讨论 SOD 四大支柱，但未关联检测器基础模块设计与 SOD 挑战；</li>
</ul>
</li>
<li><ul>
<li>Tong 等（2020）：从 5 个角度综述 SOD，但仅覆盖通用 SOD，未涉及关键 SOD 任务；</li>
</ul>
</li>
<li><ul>
<li>Liu 等（2021）：总结 SOD 方法，但仅评估 Faster R-CNN、SSD、YOLO 等少数模型，性能评估不全面；</li>
</ul>
</li>
<li><ul>
<li>其他综述（如 Tong&amp;Wu 2022、Rekavandi 等 2022）：缺乏对 “关键 SOD 任务专用算法” 的全面梳理。</li>
</ul>
</li>
</ul>
<h3 id="3-4-本文的三大贡献"><a href="#3-4-本文的三大贡献" class="headerlink" title="3.4 本文的三大贡献"></a>3.4 本文的三大贡献</h3><p><strong>系统梳理 SOD 算法</strong>：结合 SOD 挑战，构建分类体系（提升分辨率、尺度感知、上下文、数据增强），并综述小脸、小行人、遥感图像三大关键 SOD 任务的方法。</p>
<p><strong>全面性能评估</strong>：不仅在通用数据集上测试通用 SOD 算法，还在三大关键 SOD 任务对应的数据集上评估 SOTA 方法。</p>
<p><strong>提出未来方向</strong>：基于算法分类和性能分析，指出 SOD 未来研究方向（如 SOD 专用优化指标、弱监督 SOD、多任务联合优化等）。</p>
<h3 id="3-5-文章结构"><a href="#3-5-文章结构" class="headerlink" title="3.5 文章结构"></a>3.5 文章结构</h3><ul>
<li><p>第 2 章：通用 SOD 算法（4 大角度）；</p>
</li>
<li><p>第 3 章：关键 SOD 任务（小脸、小行人、遥感）；</p>
</li>
<li><p>第 4 章：数据集与评估指标，及算法性能测试；</p>
</li>
<li><p>第 5 章：SOD 挑战与未来方向；</p>
</li>
<li><p>第 6 章：结论。</p>
</li>
</ul>
<h2 id="四、通用-SOD-算法（4-大核心思路）"><a href="#四、通用-SOD-算法（4-大核心思路）" class="headerlink" title="四、通用 SOD 算法（4 大核心思路）"></a>四、通用 SOD 算法（4 大核心思路）</h2><h3 id="4-1-思路-1：提升输入特征分辨率"><a href="#4-1-思路-1：提升输入特征分辨率" class="headerlink" title="4.1 思路 1：提升输入特征分辨率"></a>4.1 思路 1：提升输入特征分辨率</h3><h4 id="4-1-1-核心逻辑"><a href="#4-1-1-核心逻辑" class="headerlink" title="4.1.1 核心逻辑"></a>4.1.1 核心逻辑</h4><p>小目标定位难的根源是 CNN 下采样导致特征消失、高层特征图空间分辨率低，解决方案是 “用高分辨率特征图 &#x2F; 图像”，但需平衡精度与计算成本。</p>
<h4 id="4-1-2-典型算法与对比"><a href="#4-1-2-典型算法与对比" class="headerlink" title="4.1.2 典型算法与对比"></a>4.1.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>SSD</td>
<td>ECCV 2016</td>
<td>多尺度特征层级（无特征融合），不同层放不同尺度参考窗</td>
<td>可检测多尺度目标</td>
<td>低层预测特征图语义弱，小目标精度提升有限</td>
</tr>
<tr>
<td>FPN</td>
<td>CVPR 2017</td>
<td>网络前向传播生成 4 个多尺度特征图，高层特征上采样后与低层特征融合，每层仅预测一种尺度目标</td>
<td>显著提升 SOD 精度，保持 6 FPS 速度</td>
<td>不同尺度特征层语义差距大，特征表示能力下降</td>
</tr>
<tr>
<td>RetinaNet</td>
<td>ICCV 2017</td>
<td>FPN 基础 + Focal Loss（解决前景 - 背景类别不平衡）</td>
<td>缓解类别不平衡，单阶段模型精度首次超两阶段</td>
<td>-</td>
</tr>
<tr>
<td>FSSD</td>
<td>arXiv 2017</td>
<td>轻量级特征融合模块，下采样构建新特征金字塔</td>
<td>轻量融合，适配小目标</td>
<td>-</td>
</tr>
<tr>
<td>MDSSD</td>
<td>arXiv 2018</td>
<td>对高层语义特征图反卷积，再与低层特征融合</td>
<td>保留小目标空间细节和高语义表示</td>
<td>检测速度低于 SSD</td>
</tr>
<tr>
<td>HRDNet</td>
<td>arXiv 2020</td>
<td>多深度 backbone 接收多分辨率输入，高分辨率输入进浅层网络保位置信息</td>
<td>获取小目标更多细节</td>
<td>参数数量大</td>
</tr>
<tr>
<td>QueryDet</td>
<td>CVPR 2022</td>
<td>查询机制：预测小目标可能位置，仅在这些位置计算，避免全特征图冗余计算</td>
<td>稀疏查询加速推理</td>
<td>-</td>
</tr>
<tr>
<td>EFPN</td>
<td>TMM 2022</td>
<td>FPN 加超分层，提取区域纹理特征增强小目标特征</td>
<td>提升 SOD 精度</td>
<td>超分特征提取增加计算成本</td>
</tr>
<tr>
<td>EESRGAN</td>
<td>arXiv 2020</td>
<td>ESRGAN 加边缘增强子网络（EEN），生成器 + 判别器 + 检测器端到端训练</td>
<td>超分图像质量高，SOD 精度提升</td>
<td>-</td>
</tr>
</tbody></table>
<h4 id="4-1-3-关键技术细节"><a href="#4-1-3-关键技术细节" class="headerlink" title="4.1.3 关键技术细节"></a>4.1.3 关键技术细节</h4><ul>
<li><p><strong>Focal Loss 公式</strong>：<br>$$<br>FL(p)&#x3D;\begin{cases}   -\alpha (1-p)^{\gamma }log(p) &amp; if\ y&#x3D;1 \   -(1-\alpha )p^{\gamma }log(1-p) &amp; otherwise   \end{cases}<br>$$</p>
</li>
<li><ul>
<li>$y&#x3D;1$：正样本（含目标），$y&#x3D;0$：负样本（无目标）；</li>
</ul>
</li>
<li><ul>
<li>$p$：模型预测为正样本的概率；</li>
</ul>
</li>
<li><ul>
<li>$\alpha$：平衡系数，$\gamma$（≥0）：聚焦参数，降低简单背景样本的学习权重，让模型聚焦难样本。</li>
</ul>
</li>
<li><p><strong>EESRGAN 的损失函数</strong>：</p>
</li>
<li><ul>
<li>生成器相对论损失：$L_{G}^{Ra}&#x3D;-E_{I_{HR}}\big [log\big (1-D_{Ra}(I_{HR},I_{ISR})\big )\big ]-E_{I_{SR}}\big [log\big (D_{R\alpha }(I_{ISR},I_{HR})\big )\big ]$</li>
</ul>
</li>
<li><ul>
<li>判别器相对论损失：</li>
</ul>
</li>
<li><ul>
<li>(D_{Ra})：真实图像（(I_{HR})）比生成中间图像（(I_{ISR})）更真实的概率；(E)：计算 mini-batch 内图像的平均值。</li>
</ul>
</li>
</ul>
<h3 id="4-2-思路-2：尺度感知训练"><a href="#4-2-思路-2：尺度感知训练" class="headerlink" title="4.2 思路 2：尺度感知训练"></a>4.2 思路 2：尺度感知训练</h3><h4 id="4-2-1-核心逻辑"><a href="#4-2-1-核心逻辑" class="headerlink" title="4.2.1 核心逻辑"></a>4.2.1 核心逻辑</h4><p>CNN 对尺度变化鲁棒性差（如 COCO 数据集最大目标是最小目标的 20 倍），需通过训练让检测器适应尺度差异。</p>
<h4 id="4-2-2-典型算法与对比"><a href="#4-2-2-典型算法与对比" class="headerlink" title="4.2.2 典型算法与对比"></a>4.2.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
</tr>
</thead>
<tbody><tr>
<td>SNIP</td>
<td>CVPR 2018</td>
<td>图像金字塔训练，仅对 “目标尺寸在预定范围” 的样本反向传播损失</td>
<td>有效提升 SOD 性能</td>
<td>需输入图像金字塔，计算成本高</td>
</tr>
<tr>
<td>SNIPER</td>
<td>CVPR 2018</td>
<td>从金字塔每层选 512×512 固定分辨率芯片作为训练单元</td>
<td>支持更大 batch size，提升训练效率和精度</td>
<td>需输入图像金字塔，计算成本高</td>
</tr>
<tr>
<td>SAN</td>
<td>CVPR 2018</td>
<td>将不同尺度卷积特征映射到尺度不变子空间，仅学习通道间关系</td>
<td>增强 CNN 对尺度变化的鲁棒性，计算量增加少</td>
<td>-</td>
</tr>
<tr>
<td>Trident</td>
<td>ICCV 2019</td>
<td>多分支并行网络，每分支用合适膨胀率匹配目标尺寸的感受野，尺度敏感训练</td>
<td>感受野与目标尺寸对齐，提升尺度感知能力</td>
<td>各分支有效样本少，易过拟合</td>
</tr>
<tr>
<td>POD</td>
<td>ICCV 2019</td>
<td>全局尺度学习模块替代普通卷积模块，为不同层学习合适全局尺度</td>
<td>增强网络对尺度变化的敏感性</td>
<td>-</td>
</tr>
</tbody></table>
<h4 id="4-2-3-关键技术细节"><a href="#4-2-3-关键技术细节" class="headerlink" title="4.2.3 关键技术细节"></a>4.2.3 关键技术细节</h4><ul>
<li><strong>Trident 分支有效范围公式</strong>：(l_{i}\leq {\sqrt {wh}}\leq u_{i})，其中(\sqrt{wh})是目标尺寸，(l_i)、(u_i)是第(i)个分支的尺寸上下限。</li>
</ul>
<h3 id="4-3-思路-3：融入上下文信息"><a href="#4-3-思路-3：融入上下文信息" class="headerlink" title="4.3 思路 3：融入上下文信息"></a>4.3 思路 3：融入上下文信息</h3><h4 id="4-3-1-核心逻辑"><a href="#4-3-1-核心逻辑" class="headerlink" title="4.3.1 核心逻辑"></a>4.3.1 核心逻辑</h4><p>视觉目标常与周围环境存在关联，利用上下文信息可辅助检测特征模糊的小目标，分为 “图像级上下文”（全图环境）和 “实例级上下文”（目标间关系）。</p>
<h4 id="4-3-2-典型算法与对比"><a href="#4-3-2-典型算法与对比" class="headerlink" title="4.3.2 典型算法与对比"></a>4.3.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>ContextNet（Chen 等）</td>
<td>ACCV 2017</td>
<td>扩展 R-CNN，用小区域提议生成器 + ContextNet 融合上下文计算分类分数</td>
<td>提升 SOD 精度</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>ION</td>
<td>CVPR 2016</td>
<td>ROI 内：skip pooling 提取多尺度特征；ROI 外：空间 RNN 提取周围上下文</td>
<td>增强小目标特征表示，提升分类与回归性能</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DSSD</td>
<td>arXiv 2017</td>
<td>融合深层语义上下文与浅层特征</td>
<td>语义与细节结合，适配小目标</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>SMN</td>
<td>ICCV 2017</td>
<td>空间记忆网络：检测目标后 “记忆” 其特征，作为先验辅助检测漏检小目标</td>
<td>建模实例级上下文，减少漏检</td>
<td>推理信号与感知信号抵消时梯度消失</td>
<td></td>
</tr>
<tr>
<td>FA-SSD</td>
<td>ICAIIC 2021</td>
<td>F-SSD（高层上下文 + 低层特征拼接）+A-SSD（注意力屏蔽背景）</td>
<td>精度高于 SSD</td>
<td>低于 DSSD 精度</td>
<td>、</td>
</tr>
</tbody></table>
<h4 id="4-3-3-关键技术细节"><a href="#4-3-3-关键技术细节" class="headerlink" title="4.3.3 关键技术细节"></a>4.3.3 关键技术细节</h4><ul>
<li><strong>语义关联函数（Fu 等）</strong>：(s_{i j}’&#x3D;\sigma(i, j) . \phi\left(p_{i}^{o}\right) \phi\left(p_{j}^{o}\right)^{T})，其中(\sigma(i,j))是指示函数，(\phi)将初始区域特征(p_i^o)映射到 latent 表示，建模同类目标的语义共现关系。</li>
</ul>
<h3 id="4-4-思路-4：数据增强"><a href="#4-4-思路-4：数据增强" class="headerlink" title="4.4 思路 4：数据增强"></a>4.4 思路 4：数据增强</h3><h4 id="4-4-1-核心逻辑"><a href="#4-4-1-核心逻辑" class="headerlink" title="4.4.1 核心逻辑"></a>4.4.1 核心逻辑</h4><p>小目标数据集标注成本高、样本少，数据增强可丰富数据集多样性，缓解 “不同尺度目标分布不均” 导致的检测精度下降。</p>
<h4 id="4-4-2-典型算法与对比"><a href="#4-4-2-典型算法与对比" class="headerlink" title="4.4.2 典型算法与对比"></a>4.4.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>Kisantal 等</td>
<td>arXiv 2019</td>
<td>过采样含小目标图像，随机复制粘贴小目标</td>
<td>提升小目标检测精度</td>
<td>随机粘贴导致背景 &#x2F; 尺寸不匹配</td>
<td>、</td>
</tr>
<tr>
<td>RRNet</td>
<td>ICCV 2019</td>
<td>自适应重采样：语义分割网络确定合理区域，再粘贴小目标</td>
<td>解决背景不匹配，适配极小目标</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Ünel 等</td>
<td>CVPR 2019</td>
<td>切片增强：输入图像分割为重叠切片，增加小目标相对像素占比</td>
<td>精度与时间成本平衡好</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DST</td>
<td>arXiv 2020</td>
<td>反馈驱动：小目标损失比例低于阈值时，放大拼接图像补偿小目标</td>
<td>缓解尺度不变性问题</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Chen 等</td>
<td>CVPR 2021</td>
<td>尺度感知自动增强：图像 &#x2F; 框级增强搜索空间 + 帕累托尺度平衡指标</td>
<td>可迁移到其他数据集 &#x2F; 任务，尺度敏感</td>
<td>自动搜索时间成本高</td>
<td>、</td>
</tr>
</tbody></table>
<h3 id="4-5-其他补充策略"><a href="#4-5-其他补充策略" class="headerlink" title="4.5 其他补充策略"></a>4.5 其他补充策略</h3><table>
<thead>
<tr>
<th>策略</th>
<th>代表方法</th>
<th>核心技术</th>
<th>优势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>新标注技术</td>
<td>PPDet（BMVC 2020）</td>
<td>锚点无关，聚合单个特征预测减少标注噪声</td>
<td>降低无判别力特征的训练贡献</td>
<td>、</td>
</tr>
<tr>
<td>无锚点模型</td>
<td>CenterNet++（CVPR 2021）</td>
<td>用 “中心点 + 一对角点” 表示目标，适配任意几何形状</td>
<td>多分辨率下性能优</td>
<td>、</td>
</tr>
<tr>
<td>新评价指标</td>
<td>NWD（arXiv 2021）、RFLA（ECCV 2022）</td>
<td>用高斯分布相似度（NWD）、感受野距离（RFLA）替代 IoU</td>
<td>对小目标位置偏差更鲁棒</td>
<td>、</td>
</tr>
<tr>
<td>切片推理</td>
<td>SAHI（arXiv 2022）</td>
<td>输入图像分割为重叠切片检测，再合并结果</td>
<td>即插即用，无需预训练，提升 SOD 精度</td>
<td>、</td>
</tr>
</tbody></table>
<h2 id="五、关键-SOD-任务（三大实际场景）"><a href="#五、关键-SOD-任务（三大实际场景）" class="headerlink" title="五、关键 SOD 任务（三大实际场景）"></a>五、关键 SOD 任务（三大实际场景）</h2><h3 id="5-1-任务-1：小脸检测"><a href="#5-1-任务-1：小脸检测" class="headerlink" title="5.1 任务 1：小脸检测"></a>5.1 任务 1：小脸检测</h3><h4 id="5-1-1-挑战"><a href="#5-1-1-挑战" class="headerlink" title="5.1.1 挑战"></a>5.1.1 挑战</h4><p>小脸像素低（常＜32×32）、特征弱，易被遮挡，锚点与小脸匹配难度大。</p>
<h4 id="5-1-2-典型算法与对比"><a href="#5-1-2-典型算法与对比" class="headerlink" title="5.1.2 典型算法与对比"></a>5.1.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>多尺度建模</td>
<td>CVPR 2018</td>
<td>以 SSD 为基础，融合稀疏离散图像金字塔 + 多层特征融合</td>
<td>处理尺度偏移，增强小脸特征</td>
<td></td>
</tr>
<tr>
<td>S³FD</td>
<td>ICCV 2017</td>
<td>尺度均衡网络，按 “有效感受野 + 等比例间隔” 设计锚点，尺度补偿匹配</td>
<td>提升小脸召回率，降低误检率</td>
<td>、</td>
</tr>
<tr>
<td>Face-MagNet</td>
<td>ECCV 2018</td>
<td>ConvTranspose 层（kernel&#x3D;8，stride&#x3D;4）放大小脸特征图</td>
<td>增强小脸特征表示</td>
<td></td>
</tr>
<tr>
<td>TinaFace</td>
<td>arXiv 2020</td>
<td>RetinaNet 改进：DCN backbone（学几何变换）+Inception（多尺度）+DIoU 损失（小目标友好）+IoU 感知分支</td>
<td>AP 达 92.4%，Hard 集性能优</td>
<td></td>
</tr>
<tr>
<td>Zhu 等（EMO）</td>
<td>arXiv 2021</td>
<td>期望最大重叠（EMO）分数，增加小尺度锚点，随机移动人脸位置</td>
<td>提升锚点与小脸的 IoU，增加匹配概率</td>
<td>、</td>
</tr>
</tbody></table>
<h3 id="5-2-任务-2：小行人检测"><a href="#5-2-任务-2：小行人检测" class="headerlink" title="5.2 任务 2：小行人检测"></a>5.2 任务 2：小行人检测</h3><h4 id="5-2-1-挑战"><a href="#5-2-1-挑战" class="headerlink" title="5.2.1 挑战"></a>5.2.1 挑战</h4><p>小行人边界模糊、易遮挡，标注框含大量噪声背景，部分数据集（如 TinyPerson）行人像素＜20，宽高比差异大。</p>
<h4 id="5-2-2-典型算法与对比"><a href="#5-2-2-典型算法与对比" class="headerlink" title="5.2.2 典型算法与对比"></a>5.2.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>TLL 网络</td>
<td>ECCV 2018</td>
<td>拓扑线定位（检测行人躯干拓扑线）+ConvLSTM（时序特征聚合）+ 马尔可夫随机场（处理遮挡）</td>
<td>自动适配小尺度行人</td>
<td>未缓解小行人信息丢失</td>
<td>、</td>
</tr>
<tr>
<td>SaYwF</td>
<td>arXiv 2019</td>
<td>三阶段检测：区域分类器找候选区→定位行人→NMS 去冗余</td>
<td>精度与速度平衡好</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>CSP</td>
<td>CVPR 2019</td>
<td>卷积操作将检测转化为 “行人尺度预测 + 中心点预测”，1×1 卷积生成质心热图和尺度图</td>
<td>无需额外后处理</td>
<td>适配宽高比差异大的目标能力弱</td>
<td>、</td>
</tr>
<tr>
<td>FSAF</td>
<td>CVPR 2019</td>
<td>无锚点模块，训练时动态为实例选最优特征层（公式(l’&#x3D;\left\lfloor l_{0}+log _{2}\left(\frac{\sqrt{w h}}{224}\right)\right\rfloor)）</td>
<td>对尺度变化鲁棒性强</td>
<td>无锚点分支优势不及有锚点</td>
<td>、</td>
</tr>
<tr>
<td>Yu 等（TinyPerson）</td>
<td>WACV 2020</td>
<td>构建 TinyPerson 数据集，尺度匹配（公式(P_{(s, T(E)) \approx P_{(s, D)}})）统一预训练与任务数据集特征分布</td>
<td>充分利用已有标注数据</td>
<td>TinyPerson 数据集上性能一般</td>
<td>、</td>
</tr>
</tbody></table>
<h4 id="5-2-3-关键数据集：TinyPerson"><a href="#5-2-3-关键数据集：TinyPerson" class="headerlink" title="5.2.3 关键数据集：TinyPerson"></a>5.2.3 关键数据集：TinyPerson</h4><ul>
<li>聚焦海边行人（海上救援场景），行人像素多＜20，宽高比差异大，含 72,651 个标注小目标。</li>
</ul>
<h3 id="5-3-任务-3：遥感图像-SOD"><a href="#5-3-任务-3：遥感图像-SOD" class="headerlink" title="5.3 任务 3：遥感图像 SOD"></a>5.3 任务 3：遥感图像 SOD</h3><h4 id="5-3-1-挑战"><a href="#5-3-1-挑战" class="headerlink" title="5.3.1 挑战"></a>5.3.1 挑战</h4><p>遥感图像为俯视视角，目标旋转多变、场景密集、小目标占比高，背景复杂（云、植被干扰）。</p>
<h4 id="5-3-2-典型算法与对比"><a href="#5-3-2-典型算法与对比" class="headerlink" title="5.3.2 典型算法与对比"></a>5.3.2 典型算法与对比</h4><table>
<thead>
<tr>
<th>算法</th>
<th>发表会议 &#x2F; 年份</th>
<th>核心技术</th>
<th>优势</th>
<th>劣势</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>S²A-Net</td>
<td>TGRS 2022</td>
<td>特征对齐模块 + 定向检测模块，保持分类分数与定位精度一致</td>
<td>定向目标检测性能优</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>SCRDet</td>
<td>ICCV 2019</td>
<td>监督多维注意力，突出小目标区域，降低背景噪声</td>
<td>抗干扰能力强</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>Oriented R-CNN</td>
<td>ICCV 2021</td>
<td>轻量级 RPN 生成定向候选区</td>
<td>定向检测精度高，mAP 达 76.3</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>ReDet</td>
<td>arXiv 2021</td>
<td>旋转等变网络提取旋转等变特征，旋转不变 RoI Align 对齐特征</td>
<td>模型小，中小目标性能优，mAP 达 76.3</td>
<td>-</td>
<td>、</td>
</tr>
<tr>
<td>DarkNet-RI</td>
<td>TGRS 2021</td>
<td>DarkNet53 backbone + 旋转不变层，提取多尺度旋转不变特征</td>
<td>对尺度 &#x2F; 旋转变化鲁棒</td>
<td>遮挡目标检测能力弱</td>
<td>、</td>
</tr>
<tr>
<td>DotD</td>
<td>CVPRW 2021</td>
<td>点距离（DotD）替代 IoU，定义正负锚点</td>
<td>适配定向小目标</td>
<td>-</td>
<td></td>
</tr>
</tbody></table>
<h4 id="5-3-3-关键数据集：DOTA"><a href="#5-3-3-关键数据集：DOTA" class="headerlink" title="5.3.3 关键数据集：DOTA"></a>5.3.3 关键数据集：DOTA</h4><ul>
<li>遥感图像目标检测数据集，DOTA-v1.0 含 2806 张遥感图、188,282 个实例，覆盖 15 类目标（飞机、桥梁、车辆等）。</li>
</ul>
<h2 id="六、SOD-评估（数据集、指标与实验结果）"><a href="#六、SOD-评估（数据集、指标与实验结果）" class="headerlink" title="六、SOD 评估（数据集、指标与实验结果）"></a>六、SOD 评估（数据集、指标与实验结果）</h2><h3 id="6-1-核心数据集"><a href="#6-1-核心数据集" class="headerlink" title="6.1 核心数据集"></a>6.1 核心数据集</h3><table>
<thead>
<tr>
<th>数据集</th>
<th>类型</th>
<th>年份</th>
<th>关键信息</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>MS COCO</td>
<td>通用 OD</td>
<td>2014</td>
<td>80 类检测目标，32.8 万张图，250 万个标注实例，小目标占比 31.62%，背景复杂</td>
<td>、</td>
</tr>
<tr>
<td>WIDER FACE</td>
<td>小脸检测</td>
<td>2016</td>
<td>大规模人脸数据集，从 WIDER 数据集筛选，分 Easy&#x2F;Medium&#x2F;Hard 三难度</td>
<td></td>
</tr>
<tr>
<td>TinyPerson</td>
<td>小行人检测</td>
<td>2020</td>
<td>海边小行人，72,651 个标注小目标，像素多＜20</td>
<td></td>
</tr>
<tr>
<td>DOTA</td>
<td>遥感 SOD</td>
<td>2018</td>
<td>DOTA-v1.0 含 15 类目标，2806 张图，188,282 个实例</td>
<td></td>
</tr>
</tbody></table>
<h3 id="6-2-评估指标"><a href="#6-2-评估指标" class="headerlink" title="6.2 评估指标"></a>6.2 评估指标</h3><table>
<thead>
<tr>
<th>指标</th>
<th>定义与计算</th>
<th>用途</th>
<th>对应文档段落</th>
</tr>
</thead>
<tbody><tr>
<td>FPS（帧 &#x2F; 秒）</td>
<td>每秒处理图像数量，衡量检测速度</td>
<td>评估实时性</td>
<td></td>
</tr>
<tr>
<td>IoU（交并比）</td>
<td>(IoU&#x3D;\frac{ Area \left( bbox _{pred } \cap bbox _{GT} \right)}{ Area \left( bbox _{pred } \cup bbox _{GT} \right)})，预测框与真实框的重叠度</td>
<td>衡量定位精度</td>
<td></td>
</tr>
<tr>
<td>AP（平均精度）</td>
<td>1. 定义正负样本（置信度阈值区分）；2. 计算精确率（(precision&#x3D;\frac{TP}{TP+FP})）和召回率（(recall&#x3D;\frac{TP}{TP+FN})）；3. P-R 曲线下面积（(AP&#x3D;\int_{0}^{1} P(R) dR)）</td>
<td>单类目标检测精度</td>
<td>、</td>
</tr>
<tr>
<td>mAP（平均 AP）</td>
<td>所有类别 AP 的平均值（(mAP&#x3D;\frac{\sum AP}{N})）</td>
<td>多类目标检测精度</td>
<td></td>
</tr>
<tr>
<td>MR（漏检率）</td>
<td>未检测到的真实目标比例，衡量漏检程度</td>
<td>小行人检测常用</td>
<td></td>
</tr>
</tbody></table>
<h4 id="补充：COCO-特殊指标"><a href="#补充：COCO-特殊指标" class="headerlink" title="补充：COCO 特殊指标"></a>补充：COCO 特殊指标</h4><ul>
<li><p>IoU 阈值：0.5-0.95（步长 0.05）；</p>
</li>
<li><p>分尺度 AP：(AP_s)（小目标，面积＜32²）、(AP_m)（中目标，32²＜面积＜96²）、(AP_l)（大目标，面积＞96²）。</p>
</li>
</ul>
<h3 id="6-3-关键实验结果"><a href="#6-3-关键实验结果" class="headerlink" title="6.3 关键实验结果"></a>6.3 关键实验结果</h3><h4 id="6-3-1-通用-SOD（COCO-数据集）"><a href="#6-3-1-通用-SOD（COCO-数据集）" class="headerlink" title="6.3.1 通用 SOD（COCO 数据集）"></a>6.3.1 通用 SOD（COCO 数据集）</h4><ul>
<li><p>最优模型：IENet（AP&#x3D;51.2，(AP_s&#x3D;34.5)）；</p>
</li>
<li><p>提升分辨率有效：HRDNet（(AP_s&#x3D;32.1)）优于 MRCenterNet（(AP_s&#x3D;27.8)）；</p>
</li>
<li><p>速度与精度权衡：YOLOv7-tiny（286 FPS，AP&#x3D;38.7）快但精度低；EESRGAN（3 FPS，(AP_s&#x3D;31.2)）精度高但慢。</p>
</li>
</ul>
<h4 id="6-3-2-小脸检测（WIDER-FACE-数据集）"><a href="#6-3-2-小脸检测（WIDER-FACE-数据集）" class="headerlink" title="6.3.2 小脸检测（WIDER FACE 数据集）"></a>6.3.2 小脸检测（WIDER FACE 数据集）</h4><ul>
<li><p>最优模型：TinaFace（Easy AP&#x3D;96.3，Medium AP&#x3D;95.7，Hard AP&#x3D;92.1）；</p>
</li>
<li><p>关键因素：提升特征分辨率 + 融入上下文（TinaFace、IENet 均采用）。</p>
</li>
</ul>
<h4 id="6-3-3-小行人检测（TinyPerson-数据集）"><a href="#6-3-3-小行人检测（TinyPerson-数据集）" class="headerlink" title="6.3.3 小行人检测（TinyPerson 数据集）"></a>6.3.3 小行人检测（TinyPerson 数据集）</h4><ul>
<li><p>最低漏检率：FCOS（MR50&#x3D;96.12）；</p>
</li>
<li><p>最优小目标 AP：FPN（(AP_{50}^{tiny}&#x3D;47.35)）、Grid R-CNN（(AP_{25}&#x3D;68.89)，(AP_{75}&#x3D;6.38)）。</p>
</li>
</ul>
<h4 id="6-3-4-遥感-SOD（DOTA-数据集）"><a href="#6-3-4-遥感-SOD（DOTA-数据集）" class="headerlink" title="6.3.4 遥感 SOD（DOTA 数据集）"></a>6.3.4 遥感 SOD（DOTA 数据集）</h4><ul>
<li><p>最优 mAP：ReDet、Oriented R-CNN（均为 76.3）；</p>
</li>
<li><p>关键因素：定向检测 + 旋转不变特征（适配遥感目标旋转特性）。</p>
</li>
</ul>
<h4 id="6-3-5-核心结论"><a href="#6-3-5-核心结论" class="headerlink" title="6.3.5 核心结论"></a>6.3.5 核心结论</h4><p><strong>提升输入特征分辨率是当前最有效、最普适的 SOD 优化策略</strong>，可显著提升各类 SOD 任务性能；其他策略（上下文、数据增强）可作为辅助，但无法替代分辨率提升。</p>
<table>
<thead>
<tr>
<th>对应文档段落</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="七、SOD-的挑战与未来方向"><a href="#七、SOD-的挑战与未来方向" class="headerlink" title="七、SOD 的挑战与未来方向"></a>七、SOD 的挑战与未来方向</h2><h3 id="7-1-五大核心挑战"><a href="#7-1-五大核心挑战" class="headerlink" title="7.1 五大核心挑战"></a>7.1 五大核心挑战</h3><ol>
<li><p><strong>特征带噪声</strong>：小目标特征易被背景噪声污染，遮挡 &#x2F; 聚类场景下难分辨边界。</p>
</li>
<li><p><strong>信息丢失不可逆</strong>：CNN 下采样导致小目标特征几乎消失，现有方法仅能缓解，无法完全恢复。</p>
</li>
<li><p><strong>感受野不匹配</strong>：深层网络感受野大，易将小目标误判为背景；浅层感受野小，语义弱。</p>
</li>
<li><p><strong>位置偏差敏感</strong>：IoU 类指标对小目标位置偏差极敏感，难选合适阈值区分正负样本。</p>
</li>
<li><p><strong>数据集稀缺</strong>：通用大规模小目标数据集少，标注成本高，COCO 等数据集小目标占比低且分布不均。</p>
</li>
</ol>
<h3 id="7-2-四大未来方向"><a href="#7-2-四大未来方向" class="headerlink" title="7.2 四大未来方向"></a>7.2 四大未来方向</h3><ol>
<li><p><strong>弱监督 &#x2F; 无监督 &#x2F; 自监督 SOD</strong>：减少对 bounding box 标注的依赖（如用图像级标签、对比学习），降低标注成本。</p>
</li>
<li><p><strong>SOD 专用指标</strong>：设计对小目标位置 &#x2F; 旋转偏差鲁棒的指标（如 NWD 的改进），替代 IoU 类指标。</p>
</li>
<li><p><strong>多任务联合优化</strong>：融合 SOD 与超分、语义分割、目标跟踪等任务，联合训练提升性能。</p>
</li>
<li><p><strong>开放世界 &#x2F; 少样本 SOD</strong>：解决 “未知小目标识别”（开放世界）和 “少量标注样本训练”（少样本）问题，适配实际场景。</p>
</li>
</ol>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><ol>
<li><p>系统综述了深度学习 - based SOD 算法，从 “提升分辨率、尺度感知、上下文、数据增强”4 个维度梳理，并总结三大关键 SOD 任务的方法。</p>
</li>
<li><p>实验验证 “提升输入特征分辨率” 是最优 SOD 优化策略。</p>
</li>
<li><p>指出 SOD 的五大挑战与四大未来研究方向，为领域发展提供参考。</p>
</li>
</ol>
<h2 id="九、致谢与其他"><a href="#九、致谢与其他" class="headerlink" title="九、致谢与其他"></a>九、致谢与其他</h2><ul>
<li><p><strong>基金支持</strong>：国家自然科学基金（61876186）、徐州市科技项目（KC21300）。</p>
</li>
<li><p><strong>利益冲突</strong>：作者声明无利益冲突。</p>
</li>
</ul>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blog/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></div><div class="post-share"><div class="social-share" data-image="/blog/image/Date%EF%BC%9A20250817154338.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/08/31/%E8%AE%BA%E6%96%87-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ATowards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks2/" title="论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks2"><img class="cover" src="/blog/image/Date%EF%BC%9A20250817154337(1).jpg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks2</div></div><div class="info-2"><div class="info-item-1">学习笔记 (深度详尽版): 《迈向大规模小目标检测：综述与基准》摘要 (Abstract) - 论文精髓 现状: 通用目标检测在标准基准上已取得巨大成功，但对于小目标的检测性能仍严重不足。 核心论点: 造成此瓶颈的关键原因有二：(1) 小目标自身固有的检测难度；(2) 缺乏一个专门为小目标检测设计的大规模、高质量基准来驱动研究。 本文贡献: 全面综述: 系统性地回顾了基于深度学习的小目标检测方法，并提出了一个包含六个类别的分类法。 构建新基准: 发布了两个大规模、高质量的小目标检测数据集——SODA-D (驾驶场景) 和 SODA-A (航空场景)。 深入评测: 在新数据集上对超过20种主流检测算法进行了全面的基准测试，分析了现有方法的瓶颈，并为未来研究指明了方向。   最终目标: 通过提供这份全面的综述和高质量的基准，推动小目标检测领域的发展。   一、 引言 (Introduction) - 问题的提出与工作的意义1.1 背景：通用目标检测的成功与短板 成功: 在深度学习(CNN)的推动下，以Faster R-CNN, YOLO, RetinaNet,...</div></div></div></a><a class="pagination-related" href="/blog/2025/09/01/%E7%BA%A2%E5%A4%96%E5%BC%B1%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ASmall-and-dim-target-detection-in-infrared-imagery-A-review-current-techniques-and-future-directions/" title="红外弱小目标检测：Small and dim target detection in infrared imagery: A review, current techniques and future directions"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">红外弱小目标检测：Small and dim target detection in infrared imagery: A review, current techniques and future directions</div></div><div class="info-2"><div class="info-item-1">文献摘要（ABSTRACT）详细讲解摘要作为整篇综述的“浓缩版”，不仅概括了研究背景、核心内容和关键结论，还直接点明了这篇文献的学术价值——它是该领域第一篇全面覆盖红外小弱目标检测技术的综述。接下来，我们逐句拆解摘要的核心信息，结合基础概念帮大家彻底理解，确保没有遗漏任何关键要点。  一、背景：红外小弱目标检测的“新”与“难”摘要开篇先铺垫大背景： “While there has been significant progress in object detection using conventional image processing and machine learning algorithms, exploring small and dim target detection in the IR domain is a relatively new area of study.”这句话的核心是“对比”——传统目标检测（如RGB图像中的行人、车辆检测）已很成熟，但红外小弱目标检测是“较新的领域”。为什么新？我们要结合红外图像的特殊性理解： ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blog/2025/08/31/%E8%AE%BA%E6%96%87-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ATowards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks/" title="论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks"><img class="cover" src="/blog/image/Date%EF%BC%9A20250817154338.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-31</div><div class="info-item-2">论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks</div></div><div class="info-2"><div class="info-item-1">Towards Large-Scale Small Object Detection: Survey and Benchmarks一、文章基础信息 期刊 &#x2F; 年份：IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE (TPAMI)，2023 年 11 月  核心主题：小目标检测（Small Object Detection, SOD）的系统综述、两大专用大规模基准数据集（SODA）构建、主流算法评估  作者单位：西北工业大学自动化学院  开源资源：数据集与代码地址：https://shaunyuan22.github.io/SODA；补充材料地址：https://doi.org/10.1109/TPAMI.2023.3290594   二、摘要（核心浓缩）1. 领域背景 深度卷积神经网络（DCNN）推动目标检测显著进步，但小目标检测（SOD）仍是计算机视觉公认难点—— 核心原因：小目标固有结构导致 “视觉外观差（细节模糊）” 和 “特征噪声多（易与背景混淆）”。  关键瓶颈：缺乏用于评估 SOD...</div></div></div></a><a class="pagination-related" href="/blog/2025/08/31/%E8%AE%BA%E6%96%87-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%9ATowards-Large-Scale-Small-Object-Detection-Survey-and-Benchmarks2/" title="论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks2"><img class="cover" src="/blog/image/Date%EF%BC%9A20250817154337(1).jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-31</div><div class="info-item-2">论文-小目标检测：Towards Large-Scale Small Object Detection:  Survey and Benchmarks2</div></div><div class="info-2"><div class="info-item-1">学习笔记 (深度详尽版): 《迈向大规模小目标检测：综述与基准》摘要 (Abstract) - 论文精髓 现状: 通用目标检测在标准基准上已取得巨大成功，但对于小目标的检测性能仍严重不足。 核心论点: 造成此瓶颈的关键原因有二：(1) 小目标自身固有的检测难度；(2) 缺乏一个专门为小目标检测设计的大规模、高质量基准来驱动研究。 本文贡献: 全面综述: 系统性地回顾了基于深度学习的小目标检测方法，并提出了一个包含六个类别的分类法。 构建新基准: 发布了两个大规模、高质量的小目标检测数据集——SODA-D (驾驶场景) 和 SODA-A (航空场景)。 深入评测: 在新数据集上对超过20种主流检测算法进行了全面的基准测试，分析了现有方法的瓶颈，并为未来研究指明了方向。   最终目标: 通过提供这份全面的综述和高质量的基准，推动小目标检测领域的发展。   一、 引言 (Introduction) - 问题的提出与工作的意义1.1 背景：通用目标检测的成功与短板 成功: 在深度学习(CNN)的推动下，以Faster R-CNN, YOLO, RetinaNet,...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">lian</div><div class="author-info-description">太平山上修真我，祖师堂中续香火</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:2895014608@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">QQ-2895014608</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-learning-based-small-object-detection-A-survey"><span class="toc-number">1.</span> <span class="toc-text">Deep learning-based small object detection: A survey</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%96%87%E7%8C%AE%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF"><span class="toc-number">1.1.</span> <span class="toc-text">一、文献基本信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%91%98%E8%A6%81%EF%BC%88%E6%A0%B8%E5%BF%83%E6%80%BB%E8%A7%88%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">二、摘要（核心总览）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%BC%95%E8%A8%80%EF%BC%88%E8%83%8C%E6%99%AF%E4%B8%8E%E7%A0%94%E7%A9%B6%E5%AE%9A%E4%BD%8D%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">三、引言（背景与研究定位）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88OD%EF%BC%89%E5%9F%BA%E7%A1%80"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 目标检测（OD）基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88SOD%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 小目标检测（SOD）的定义与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9A%E4%B9%89%E6%96%B9%E5%BC%8F"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">3.2.1 小目标的两种定义方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-SOD-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%8C%91%E6%88%98"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">3.2.2 SOD 的核心挑战</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E7%8E%B0%E6%9C%89%E7%BB%BC%E8%BF%B0%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 现有综述的不足</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%9C%AC%E6%96%87%E7%9A%84%E4%B8%89%E5%A4%A7%E8%B4%A1%E7%8C%AE"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 本文的三大贡献</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%96%87%E7%AB%A0%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.5 文章结构</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E9%80%9A%E7%94%A8-SOD-%E7%AE%97%E6%B3%95%EF%BC%884-%E5%A4%A7%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF%EF%BC%89"><span class="toc-number">1.4.</span> <span class="toc-text">四、通用 SOD 算法（4 大核心思路）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%80%9D%E8%B7%AF-1%EF%BC%9A%E6%8F%90%E5%8D%87%E8%BE%93%E5%85%A5%E7%89%B9%E5%BE%81%E5%88%86%E8%BE%A8%E7%8E%87"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 思路 1：提升输入特征分辨率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">4.1.1 核心逻辑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">4.1.2 典型算法与对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">4.1.3 关键技术细节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%80%9D%E8%B7%AF-2%EF%BC%9A%E5%B0%BA%E5%BA%A6%E6%84%9F%E7%9F%A5%E8%AE%AD%E7%BB%83"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 思路 2：尺度感知训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">4.2.1 核心逻辑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">4.2.2 典型算法与对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">4.2.3 关键技术细节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E6%80%9D%E8%B7%AF-3%EF%BC%9A%E8%9E%8D%E5%85%A5%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 思路 3：融入上下文信息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">4.3.1 核心逻辑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.3.2.</span> <span class="toc-text">4.3.2 典型算法与对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-3-%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.4.3.3.</span> <span class="toc-text">4.3.3 关键技术细节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%80%9D%E8%B7%AF-4%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 思路 4：数据增强</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-1-%E6%A0%B8%E5%BF%83%E9%80%BB%E8%BE%91"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">4.4.1 核心逻辑</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">4.4.2 典型算法与对比</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%85%B6%E4%BB%96%E8%A1%A5%E5%85%85%E7%AD%96%E7%95%A5"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 其他补充策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E5%85%B3%E9%94%AE-SOD-%E4%BB%BB%E5%8A%A1%EF%BC%88%E4%B8%89%E5%A4%A7%E5%AE%9E%E9%99%85%E5%9C%BA%E6%99%AF%EF%BC%89"><span class="toc-number">1.5.</span> <span class="toc-text">五、关键 SOD 任务（三大实际场景）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E4%BB%BB%E5%8A%A1-1%EF%BC%9A%E5%B0%8F%E8%84%B8%E6%A3%80%E6%B5%8B"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 任务 1：小脸检测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-1-%E6%8C%91%E6%88%98"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">5.1.1 挑战</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">5.1.2 典型算法与对比</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E4%BB%BB%E5%8A%A1-2%EF%BC%9A%E5%B0%8F%E8%A1%8C%E4%BA%BA%E6%A3%80%E6%B5%8B"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 任务 2：小行人检测</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1-%E6%8C%91%E6%88%98"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">5.2.1 挑战</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">5.2.2 典型算法与对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-3-%E5%85%B3%E9%94%AE%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9ATinyPerson"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">5.2.3 关键数据集：TinyPerson</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E4%BB%BB%E5%8A%A1-3%EF%BC%9A%E9%81%A5%E6%84%9F%E5%9B%BE%E5%83%8F-SOD"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 任务 3：遥感图像 SOD</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-1-%E6%8C%91%E6%88%98"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">5.3.1 挑战</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-2-%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E4%B8%8E%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.3.2.</span> <span class="toc-text">5.3.2 典型算法与对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-3-%E5%85%B3%E9%94%AE%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9ADOTA"><span class="toc-number">1.5.3.3.</span> <span class="toc-text">5.3.3 关键数据集：DOTA</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81SOD-%E8%AF%84%E4%BC%B0%EF%BC%88%E6%95%B0%E6%8D%AE%E9%9B%86%E3%80%81%E6%8C%87%E6%A0%87%E4%B8%8E%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%EF%BC%89"><span class="toc-number">1.6.</span> <span class="toc-text">六、SOD 评估（数据集、指标与实验结果）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 核心数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%EF%BC%9ACOCO-%E7%89%B9%E6%AE%8A%E6%8C%87%E6%A0%87"><span class="toc-number">1.6.2.1.</span> <span class="toc-text">补充：COCO 特殊指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E5%85%B3%E9%94%AE%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">1.6.3.</span> <span class="toc-text">6.3 关键实验结果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-1-%E9%80%9A%E7%94%A8-SOD%EF%BC%88COCO-%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%89"><span class="toc-number">1.6.3.1.</span> <span class="toc-text">6.3.1 通用 SOD（COCO 数据集）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-2-%E5%B0%8F%E8%84%B8%E6%A3%80%E6%B5%8B%EF%BC%88WIDER-FACE-%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%89"><span class="toc-number">1.6.3.2.</span> <span class="toc-text">6.3.2 小脸检测（WIDER FACE 数据集）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-3-%E5%B0%8F%E8%A1%8C%E4%BA%BA%E6%A3%80%E6%B5%8B%EF%BC%88TinyPerson-%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%89"><span class="toc-number">1.6.3.3.</span> <span class="toc-text">6.3.3 小行人检测（TinyPerson 数据集）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-4-%E9%81%A5%E6%84%9F-SOD%EF%BC%88DOTA-%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%89"><span class="toc-number">1.6.3.4.</span> <span class="toc-text">6.3.4 遥感 SOD（DOTA 数据集）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-3-5-%E6%A0%B8%E5%BF%83%E7%BB%93%E8%AE%BA"><span class="toc-number">1.6.3.5.</span> <span class="toc-text">6.3.5 核心结论</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81SOD-%E7%9A%84%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">1.7.</span> <span class="toc-text">七、SOD 的挑战与未来方向</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E4%BA%94%E5%A4%A7%E6%A0%B8%E5%BF%83%E6%8C%91%E6%88%98"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 五大核心挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E5%9B%9B%E5%A4%A7%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2 四大未来方向</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">1.8.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E8%87%B4%E8%B0%A2%E4%B8%8E%E5%85%B6%E4%BB%96"><span class="toc-number">1.9.</span> <span class="toc-text">九、致谢与其他</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AZero-Shot-Detection/" title="论文阅读：Zero-Shot Detection"><img src="/blog/image/62aa03063f117eaad7c77592e3b98d7f05b0a86329e44a-TuUO3E.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="论文阅读：Zero-Shot Detection"/></a><div class="content"><a class="title" href="/blog/2025/10/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AZero-Shot-Detection/" title="论文阅读：Zero-Shot Detection">论文阅读：Zero-Shot Detection</a><time datetime="2025-10-20T11:34:17.000Z" title="发表于 2025-10-20 19:34:17">2025-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/17/Zero-Shot-Object-Detection/" title="Zero-Shot Object Detection"><img src="/blog/image/5268d877a2a04864b36b4961ab793f4f.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="Zero-Shot Object Detection"/></a><div class="content"><a class="title" href="/blog/2025/10/17/Zero-Shot-Object-Detection/" title="Zero-Shot Object Detection">Zero-Shot Object Detection</a><time datetime="2025-10-17T10:22:18.000Z" title="发表于 2025-10-17 18:22:18">2025-10-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/17/DeViSE-A-Deep-Visual-Semantic-Embedding-Model/" title="DeViSE: A Deep Visual-Semantic Embedding Model"><img src="/blog/image/2aa2662f-d453-4a09-8890-87440bd087b8.png" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="DeViSE: A Deep Visual-Semantic Embedding Model"/></a><div class="content"><a class="title" href="/blog/2025/10/17/DeViSE-A-Deep-Visual-Semantic-Embedding-Model/" title="DeViSE: A Deep Visual-Semantic Embedding Model">DeViSE: A Deep Visual-Semantic Embedding Model</a><time datetime="2025-10-17T06:20:10.000Z" title="发表于 2025-10-17 14:20:10">2025-10-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blog/2025/09/23/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" title="小样本目标检测">小样本目标检测</a><time datetime="2025-09-23T08:06:54.000Z" title="发表于 2025-09-23 16:06:54">2025-09-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/blog/2025/09/17/keywords%E9%9B%86%E5%90%88/" title="keywords集合">keywords集合</a><time datetime="2025-09-17T01:27:17.000Z" title="发表于 2025-09-17 09:27:17">2025-09-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 By lian</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">岁岁平，岁岁安，岁岁平安</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="{&quot;site_uv&quot;:true,&quot;site_pv&quot;:true,&quot;page_pv&quot;:true}"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>