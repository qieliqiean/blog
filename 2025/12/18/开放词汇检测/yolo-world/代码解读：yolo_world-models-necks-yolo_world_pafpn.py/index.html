<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>代码解读：yolo_world-models-necks-yolo_world_pafpn.py | 且离且安的碎碎念</title><meta name="author" content="lian"><meta name="copyright" content="lian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#fdfcf8"><meta name="description" content="系列文章   &#x2F;   开放词汇检测 &#x2F; yolo-world  class YOLOWorldPAFPN(YOLOv8PAFPN) def init 1234567891011121314151617@MODELS.register_module()def __init__(self,             in_channels: List[int],             out_c">
<meta property="og:type" content="article">
<meta property="og:title" content="代码解读：yolo_world-models-necks-yolo_world_pafpn.py">
<meta property="og:url" content="https://qieliqiean.github.io/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/index.html">
<meta property="og:site_name" content="且离且安的碎碎念">
<meta property="og:description" content="系列文章   &#x2F;   开放词汇检测 &#x2F; yolo-world  class YOLOWorldPAFPN(YOLOv8PAFPN) def init 1234567891011121314151617@MODELS.register_module()def __init__(self,             in_channels: List[int],             out_c">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qieliqiean.github.io/blog/image/A1-2.jpg">
<meta property="article:published_time" content="2025-12-18T02:04:06.000Z">
<meta property="article:modified_time" content="2026-02-18T11:58:50.441Z">
<meta property="article:author" content="lian">
<meta property="article:tag" content="Yolo-World">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qieliqiean.github.io/blog/image/A1-2.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "代码解读：yolo_world-models-necks-yolo_world_pafpn.py",
  "url": "https://qieliqiean.github.io/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/",
  "image": "https://qieliqiean.github.io/blog/image/A1-2.jpg",
  "datePublished": "2025-12-18T02:04:06.000Z",
  "dateModified": "2026-02-18T11:58:50.441Z",
  "author": [
    {
      "@type": "Person",
      "name": "lian",
      "url": "https://qieliqiean.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/image/1.jpg"><link rel="canonical" href="https://qieliqiean.github.io/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0f172a')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fdfcf8')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')
          
          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6b5d1303d19816191830cd73eccfdb1e";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '代码解读：yolo_world-models-necks-yolo_world_pafpn.py',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=LXGW+WenKai:wght@400;700&family=Noto+Serif+SC:wght@400;600;700&display=swap" rel="stylesheet"><link rel="stylesheet" href="/blog/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/easter-egg/"><i class="fa-fw fas fa-egg"></i><span> 彩蛋</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/image/A1-2.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><img class="site-icon" src="/blog/image/background1.png" alt="Logo"><span class="site-name">且离且安的碎碎念</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">代码解读：yolo_world-models-necks-yolo_world_pafpn.py</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/easter-egg/"><i class="fa-fw fas fa-egg"></i><span> 彩蛋</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">代码解读：yolo_world-models-necks-yolo_world_pafpn.py</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-18T02:04:06.000Z" title="发表于 2025-12-18 10:04:06">2025-12-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-18T11:58:50.441Z" title="更新于 2026-02-18 19:58:50">2026-02-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">9.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>38分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><nav class="series-breadcrumb" aria-label="系列导航">
  <a href="/blog/series/">系列文章</a>
  <span class="series-breadcrumb__sep">/</span>
  <a href="/blog/series/5byA5pS-6K-N5rGH5qOA5rWLIC8geW9sby13b3JsZA/">开放词汇检测 / yolo-world</a>
</nav>
<h1 id="class-YOLOWorldPAFPN-YOLOv8PAFPN"><a class="header-anchor" href="#class-YOLOWorldPAFPN-YOLOv8PAFPN"></a>class YOLOWorldPAFPN(YOLOv8PAFPN)</h1>
<h2 id="def-init"><a class="header-anchor" href="#def-init"></a>def <strong>init</strong></h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             in_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             out_channels: <span class="type">Union</span>[<span class="type">List</span>[<span class="built_in">int</span>], <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             guide_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             embed_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             num_heads: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             deepen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             widen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             num_csp_blocks: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">             freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             block_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;CSPLayerWithTwoConv&#x27;</span></span>),</span></span><br><span class="line"><span class="params">             norm_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                                         momentum=<span class="number">0.03</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                                         eps=<span class="number">0.001</span></span>),</span></span><br><span class="line"><span class="params">             act_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;SiLU&#x27;</span>, inplace=<span class="literal">True</span></span>),</span></span><br><span class="line"><span class="params">             init_cfg: OptMultiConfig = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOWorldPAFPN</span>(<span class="title class_ inherited__">YOLOv8PAFPN</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Path Aggregation Network used in YOLO World</span></span><br><span class="line"><span class="string">    Following YOLOv8 PAFPN, including text to image fusion</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>第 1 行</strong>：<code>@MODELS.register_module()</code> 是 MMEngine 的装饰器，将这个类注册到 <code>MODELS</code> 注册表中，方便通过配置文件进行实例化。</p>
</li>
<li>
<p><strong>第 2 行</strong>：<code>YOLOWorldPAFPN</code> 继承自 <code>YOLOv8PAFPN</code>。这意味着它保留了 YOLOv8 经典的双向特征融合结构（Top-down + Bottom-up），但在其基础上增加了“文本到图像融合”的功能。</p>
</li>
</ul>
<p><img src="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/yw1.png" alt=""></p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             in_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             out_channels: <span class="type">Union</span>[<span class="type">List</span>[<span class="built_in">int</span>], <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             guide_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             embed_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             num_heads: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             deepen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             widen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             num_csp_blocks: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">             freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             block_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;CSPLayerWithTwoConv&#x27;</span></span>),</span></span><br><span class="line"><span class="params">             norm_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                                         momentum=<span class="number">0.03</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                                         eps=<span class="number">0.001</span></span>),</span></span><br><span class="line"><span class="params">             act_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;SiLU&#x27;</span>, inplace=<span class="literal">True</span></span>),</span></span><br><span class="line"><span class="params">             init_cfg: OptMultiConfig = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<p>接下来是参数列表，注意看新出现的“面孔”：</p>
<ul>
<li>
<p><strong><code>in_channels: List[int]</code></strong></p>
<p>表示来自 backbone 的多尺度特征通道数列表，比如 <code>[256, 512, 1024]</code>（有几层 FPN/PAFPN 就给几项）。</p>
</li>
<li>
<p><strong><code>out_channels: Union[List[int], int]</code></strong></p>
<p>PAFPN 最终输出每个尺度的通道数。既支持传一个 <code>int</code>（通常表示每层输出同一通道数），也支持传一个列表（每层不同）。</p>
</li>
<li>
<p><strong><code>guide_channels</code> (关键)</strong>：<strong>引导特征（guide）</strong> 的通道数。YOLO-World 里通常就是文本特征 <code>txt_feats</code> 的维度（或经过某层投影后的维度）。这个参数是“图文融合”会用到的关键输入维度。</p>
</li>
<li>
<p><code>embed_channels: List[int]</code></p>
<p>在融合模块里会把图像特征投影到一个用于注意力/相似度计算的embedding 维度。这里是按层给一个列表（每个尺度一个）。</p>
</li>
<li>
<p><strong><code>num_heads</code></strong>：如果交互层使用了注意力机制，这里指定了多头注意力的头数。</p>
</li>
<li>
<p><code>deepen_factor / widen_factor</code></p>
<p>YOLO 系列常用的“深度/宽度缩放系数”：</p>
<ul>
<li>
<p><code>widen_factor</code> 会影响通道数（如 <code>make_divisible</code> 后的通道）</p>
</li>
<li>
<p><code>deepen_factor</code> 会影响 block 的重复次数（如 <code>make_round</code> 后的 <code>num_blocks</code>）</p>
</li>
</ul>
</li>
<li>
<p><code>num_csp_blocks</code></p>
<p>CSP/CSPLayer 类 block 内部堆叠的基本块数量（随后会被 <code>deepen_factor</code> 缩放）。</p>
</li>
<li>
<p><code>freeze_all</code></p>
<p>交给父类（YOLOv8PAFPN）去做“冻结所有参数/BN”等逻辑（具体冻结细节在父类里实现）。</p>
</li>
<li>
<p><code>block_cfg / norm_cfg / act_cfg / init_cfg</code></p>
<p>典型 MMEngine/MMYOLO 的模块配置：</p>
<ul>
<li>
<p><code>block_cfg</code>：top-down / bottom-up 用的块类型（默认 <code>CSPLayerWithTwoConv</code>）</p>
</li>
<li>
<p><code>norm_cfg</code>：BN 的配置（momentum/eps）</p>
</li>
<li>
<p><code>act_cfg</code>：激活函数配置（SiLU）</p>
</li>
<li>
<p><code>init_cfg</code>：初始化策略（可能为空）</p>
</li>
</ul>
</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.guide_channels = guide_channels</span><br><span class="line"><span class="variable language_">self</span>.embed_channels = embed_channels</span><br><span class="line"><span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line"><span class="variable language_">self</span>.block_cfg = block_cfg</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>这四行</strong>：将 YOLO-World 特有的跨模态参数保存为类实例变量。这非常重要，因为后续在 <code>build_top_down_layer</code>（构建自顶向下层）和 <code>build_bottom_up_layer</code>（构建自底向上层）中，这些参数会被用来动态创建支持文本交互的卷积块。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.guide_channels：告诉融合层“外部 guide（文本）特征是多少维”</span><br><span class="line">self.embed_channels：每个尺度融合时的 embedding 维度</span><br><span class="line">self.num_heads：每个尺度融合时的 head 数</span><br><span class="line">self.block_cfg：后面 build_top_down_layer() / build_bottom_up_layer() 会 copy.deepcopy 这个配置并补齐参数，然后 MODELS.build(...) 构建具体模块</span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__(in_channels=in_channels,</span><br><span class="line">                 out_channels=out_channels,</span><br><span class="line">                 deepen_factor=deepen_factor,</span><br><span class="line">                 widen_factor=widen_factor,</span><br><span class="line">                 num_csp_blocks=num_csp_blocks,</span><br><span class="line">                 freeze_all=freeze_all,</span><br><span class="line">                 norm_cfg=norm_cfg,</span><br><span class="line">                 act_cfg=act_cfg,</span><br><span class="line">                 init_cfg=init_cfg)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>这句非常关键：<strong>YOLOWorldPAFPN 继承自 YOLOv8PAFPN</strong>，大部分 PAFPN 的骨架结构（reduce_layers、upsample_layers、downsample_layers、out_layers 等）都是在父类里统一搭好的。</p>
<p>这里传进去的参数主要作用：</p>
<ul>
<li>
<p>把通道、深宽缩放、CSP block 数、freeze、norm/act/init 等“通用 FPN/PAFPN 构建参数”交给父类处理</p>
</li>
<li>
<p>而 YOLOWorldPAFPN 的“差异点”在于：父类在构建 top-down/bottom-up 的具体 block 时，会调用子类覆写的 <code>build_top_down_layer()</code> 和 <code>build_bottom_up_layer()</code>，这样就能把 <strong>txt_feats 引入融合 block</strong>（你在后面的 <code>forward()</code> 也能看到 top_down_layers/bottom_up_layers 的调用多了 <code>txt_feats</code> 参数）。</p>
</li>
</ul>
</li>
</ul>
<h2 id="def-build-top-down-layer"><a class="header-anchor" href="#def-build-top-down-layer"></a>def build_top_down_layer</h2>
<p>它负责<strong>构建 PAFPN 的 top-down 融合块</strong>：把上采样后的高层特征和当前层特征 concat 后，再过一个 CSP/融合模块；YOLO-World 版本还会把 <code>txt_feats</code> 的维度配置塞进去。</p>
<hr>
<h3 id="代码原文"><a class="header-anchor" href="#代码原文"></a>代码原文</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_top_down_layer</span>(<span class="params">self, idx: <span class="built_in">int</span></span>) -&gt; nn.Module:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;build top down layer.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        idx (int): layer idx.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        nn.Module: The top down layer.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    block_cfg = copy.deepcopy(<span class="variable language_">self</span>.block_cfg)</span><br><span class="line">    block_cfg.update(</span><br><span class="line">        <span class="built_in">dict</span>(in_channels=make_divisible(</span><br><span class="line">            (<span class="variable language_">self</span>.in_channels[idx - <span class="number">1</span>] + <span class="variable language_">self</span>.in_channels[idx]),</span><br><span class="line">            <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             out_channels=make_divisible(<span class="variable language_">self</span>.out_channels[idx - <span class="number">1</span>],</span><br><span class="line">                                         <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             guide_channels=<span class="variable language_">self</span>.guide_channels,</span><br><span class="line">             embed_channels=make_round(<span class="variable language_">self</span>.embed_channels[idx - <span class="number">1</span>],</span><br><span class="line">                                       <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             num_heads=make_round(<span class="variable language_">self</span>.num_heads[idx - <span class="number">1</span>],</span><br><span class="line">                                  <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             num_blocks=make_round(<span class="variable language_">self</span>.num_csp_blocks,</span><br><span class="line">                                   <span class="variable language_">self</span>.deepen_factor),</span><br><span class="line">             add_identity=<span class="literal">False</span>,</span><br><span class="line">             norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">             act_cfg=<span class="variable language_">self</span>.act_cfg))</span><br><span class="line">    <span class="keyword">return</span> MODELS.build(block_cfg)</span><br></pre></td></tr></table></figure>
<h3 id="1-函数头"><a class="header-anchor" href="#1-函数头"></a>1) 函数头</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_top_down_layer</span>(<span class="params">self, idx: <span class="built_in">int</span></span>) -&gt; nn.Module:</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>idx</code> 是“当前要构建哪一层 top-down 模块”的索引（通常对应 FPN 的某个尺度位置）。</p>
</li>
<li>
<p>top-down 的典型数据流：更高层特征（语义强、分辨率低）<strong>上采样</strong> → 与 <code>idx-1</code> 这一层特征 <strong>concat</strong> → 过一个融合 block。</p>
</li>
<li>
<p>返回值是一个 <code>nn.Module</code>：就是这一层要用的融合模块（在 YOLO-World 里通常是带“文本引导/注意力”的 CSP 变体）。</p>
</li>
</ul>
<hr>
<h3 id="2-深拷贝-block-配置，避免污染全局配置"><a class="header-anchor" href="#2-深拷贝-block-配置，避免污染全局配置"></a>2) 深拷贝 block 配置，避免污染全局配置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block_cfg = copy.deepcopy(<span class="variable language_">self</span>.block_cfg)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.block_cfg</code> 在 <code>__init__</code> 里默认是 <code>dict(type='CSPLayerWithTwoConv')</code>（或你配置的别的 block 类型）。</p>
</li>
<li>
<p><code>deepcopy</code> 的意义：<strong>每一层都会基于同一个模板改参数</strong>，但不能互相影响；深拷贝能避免某层 <code>update()</code> 后把别层也改了。</p>
</li>
</ul>
<hr>
<h3 id="3-用-update-把“这一层”需要的关键超参数补齐"><a class="header-anchor" href="#3-用-update-把“这一层”需要的关键超参数补齐"></a>3) 用 update() 把“这一层”需要的关键超参数补齐</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block_cfg.update(<span class="built_in">dict</span>(...))</span><br></pre></td></tr></table></figure>
<p>这里是核心：把 block 的输入输出通道、文本引导维度、embedding/head 数、block 数、norm/act 等一次性写入配置。</p>
<hr>
<h4 id="3-1-计算-in-channels：来自-concat-的通道数"><a class="header-anchor" href="#3-1-计算-in-channels：来自-concat-的通道数"></a>3.1 计算 in_channels：来自 concat 的通道数</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">in_channels=make_divisible(</span><br><span class="line">    (<span class="variable language_">self</span>.in_channels[idx - <span class="number">1</span>] + <span class="variable language_">self</span>.in_channels[idx]),</span><br><span class="line">    <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>top-down 融合前通常会做 concat：</p>
<p><strong>(来自 idx 的上采样特征) + (来自 idx-1 的横向特征)</strong></p>
<p>所以输入通道数是两者通道相加：<code>self.in_channels[idx-1] + self.in_channels[idx]</code></p>
</li>
<li>
<p><code>make_divisible(..., self.widen_factor)</code>：</p>
<p>先按 <code>widen_factor</code> 做宽度缩放，并把通道数调整到某个“可整除/硬件友好”的数（常见是 8 的倍数之类），保证模型结构规整、推理更友好。</p>
</li>
</ul>
<blockquote>
<p>例如</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.in_channels = [<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#当 idx = 2 时：</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.in_channels[idx - <span class="number">1</span>] = <span class="variable language_">self</span>.in_channels[<span class="number">1</span>] = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.in_channels[idx] = <span class="variable language_">self</span>.in_channels[<span class="number">2</span>] = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.in_channels[idx - <span class="number">1</span>] + <span class="variable language_">self</span>.in_channels[idx] = <span class="number">1536</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p><code>make_divisible(..., self.widen_factor)</code></p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">widen_factor = <span class="number">1.0</span>   <span class="comment"># 默认</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#控制模型宽度缩放,YOLO 系列经典超参（n / s / m / l / x）</span></span><br><span class="line"></span><br><span class="line">make_divisible(x, factor)</span><br><span class="line"></span><br><span class="line">≈ <span class="built_in">round</span>(x * factor) 并对齐到 <span class="number">8</span> 或 <span class="number">16</span> 的倍数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p>目的有三：</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<ol>
<li><strong>按模型规模缩放通道数</strong></li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li><strong>避免奇怪的通道数</strong></li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li><strong>对 GPU / NPU 更友好（SIMD 对齐）</strong></li>
</ol>
</blockquote>
<blockquote></blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.in_channels = [<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]</span><br><span class="line"></span><br><span class="line">idx = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">widen_factor = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">in_channels=make_divisible(</span><br><span class="line"></span><br><span class="line">    (<span class="variable language_">self</span>.in_channels[idx - <span class="number">1</span>] + <span class="variable language_">self</span>.in_channels[idx]),</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>.widen_factor)</span><br><span class="line"></span><br><span class="line"><span class="comment">#in_channels : (512 + 1024)x0.5=768 → 768（已是 16 的倍数）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#in_channels = 768</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote></blockquote>
<blockquote></blockquote>
<hr>
<h4 id="3-2-计算-out-channels：输出到-idx-1-尺度的通道"><a class="header-anchor" href="#3-2-计算-out-channels：输出到-idx-1-尺度的通道"></a>3.2 计算 out_channels：输出到 idx-1 尺度的通道</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_channels=make_divisible(<span class="variable language_">self</span>.out_channels[idx - <span class="number">1</span>], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>top-down 融合完的结果，是给更高分辨率那一层（<code>idx-1</code>）用的，所以输出通道对齐 <code>self.out_channels[idx-1]</code>。</p>
</li>
<li>
<p>同样经过 <code>widen_factor + make_divisible</code> 处理。</p>
</li>
</ul>
<hr>
<h4 id="3-3-YOLO-World-特有：guide-channels（文本-引导特征维度）"><a class="header-anchor" href="#3-3-YOLO-World-特有：guide-channels（文本-引导特征维度）"></a>3.3 YOLO-World 特有：guide_channels（文本/引导特征维度）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">guide_channels=<span class="variable language_">self</span>.guide_channels,</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>这就是 YOLO-World 相比普通 YOLOv8 PAFPN 的关键扩展：</p>
<p><strong>融合块内部会接收 <code>txt_feats</code></strong>（或某种 guide 特征），这里把它的通道维度告诉模块，用于构建投影层/注意力层。</p>
</li>
</ul>
<hr>
<h4 id="3-4-embedding-维度：每个尺度一个"><a class="header-anchor" href="#3-4-embedding-维度：每个尺度一个"></a>3.4 embedding 维度：每个尺度一个</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">embed_channels=make_round(<span class="variable language_">self</span>.embed_channels[idx - <span class="number">1</span>], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>表示在该尺度融合时使用的 embedding 维度（比如做多头注意力前的投影维度）。</p>
</li>
<li>
<p><code>make_round(..., widen_factor)</code>：按宽度系数缩放后取整（和 <code>make_divisible</code> 类似，但语义偏“缩放后取整”，不强调整除约束）。</p>
</li>
</ul>
<hr>
<h4 id="3-5-多头数：每个尺度一个"><a class="header-anchor" href="#3-5-多头数：每个尺度一个"></a>3.5 多头数：每个尺度一个</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_heads=make_round(<span class="variable language_">self</span>.num_heads[idx - <span class="number">1</span>], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>表示该尺度融合模块里多头结构的 head 数（注意这里也按 widen_factor 缩放取整）。</p>
</li>
<li>
<p>这意味着：当你用更大模型（更宽）时，可能 head 数也随之增大。</p>
</li>
</ul>
<hr>
<h4 id="3-6-CSP-内部堆叠次数：受-deepen-factor-影响"><a class="header-anchor" href="#3-6-CSP-内部堆叠次数：受-deepen-factor-影响"></a>3.6 CSP 内部堆叠次数：受 deepen_factor 影响</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_blocks=make_round(<span class="variable language_">self</span>.num_csp_blocks, <span class="variable language_">self</span>.deepen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.num_csp_blocks</code> 是基础值（默认 3）。</p>
</li>
<li>
<p><code>deepen_factor</code> 控制“深度缩放”：越大代表 block 内重复次数越多（更深）。</p>
</li>
</ul>
<hr>
<h4 id="3-7-add-identity-False：关闭残差捷径"><a class="header-anchor" href="#3-7-add-identity-False：关闭残差捷径"></a>3.7 add_identity=False：关闭残差捷径</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_identity=<span class="literal">False</span>,</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>这通常是对 CSP/残差结构的一个开关。</p>
</li>
<li>
<p>这里显式关掉，代表该 block 不使用 identity shortcut（具体影响取决于 block 类型的实现）。</p>
</li>
</ul>
<hr>
<h4 id="3-8-norm-act：把规范化和激活配置传进去"><a class="header-anchor" href="#3-8-norm-act：把规范化和激活配置传进去"></a>3.8 norm/act：把规范化和激活配置传进去</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">act_cfg=<span class="variable language_">self</span>.act_cfg</span><br></pre></td></tr></table></figure>
<ul>
<li>让 block 使用和整个网络一致的 BN/激活配置（<code>BN(momentum=0.03, eps=0.001)</code> + <code>SiLU</code>）。</li>
</ul>
<hr>
<h3 id="4-由注册表构建模块实例"><a class="header-anchor" href="#4-由注册表构建模块实例"></a>4) 由注册表构建模块实例</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> MODELS.build(block_cfg)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>MMEngine/MMYOLO 的典型写法：把 <code>block_cfg</code>（包含 <code>type</code> 和各种参数）交给注册表工厂，返回一个真正的 <code>nn.Module</code>。</p>
</li>
<li>
<p>也就是说：<strong>这一层 top-down 用的到底是哪个类</strong>，由 <code>block_cfg[&quot;type&quot;]</code> 决定（YOLO-World 往往会用“支持 txt_feats 输入”的 block 实现）。</p>
</li>
</ul>
<hr>
<h2 id="def-build-bottom-up-layer"><a class="header-anchor" href="#def-build-bottom-up-layer"></a>def build_bottom_up_layer</h2>
<p>它做的事和 <code>build_top_down_layer</code> 很像，但<strong>方向相反</strong>：bottom-up（PAN）阶段是“更高分辨率 → 下采样 → 与更低分辨率特征 concat → 过融合块”。</p>
<hr>
<h3 id="代码原文-2"><a class="header-anchor" href="#代码原文-2"></a>代码原文</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_bottom_up_layer</span>(<span class="params">self, idx: <span class="built_in">int</span></span>) -&gt; nn.Module:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;build bottom up layer.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        idx (int): layer idx.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        nn.Module: The bottom up layer.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    block_cfg = copy.deepcopy(<span class="variable language_">self</span>.block_cfg)</span><br><span class="line">    block_cfg.update(</span><br><span class="line">        <span class="built_in">dict</span>(in_channels=make_divisible(</span><br><span class="line">            (<span class="variable language_">self</span>.out_channels[idx] + <span class="variable language_">self</span>.out_channels[idx + <span class="number">1</span>]),</span><br><span class="line">            <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             out_channels=make_divisible(<span class="variable language_">self</span>.out_channels[idx + <span class="number">1</span>],</span><br><span class="line">                                         <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             guide_channels=<span class="variable language_">self</span>.guide_channels,</span><br><span class="line">             embed_channels=make_round(<span class="variable language_">self</span>.embed_channels[idx],</span><br><span class="line">                                       <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             num_heads=make_round(<span class="variable language_">self</span>.num_heads[idx], <span class="variable language_">self</span>.widen_factor),</span><br><span class="line">             num_blocks=make_round(<span class="variable language_">self</span>.num_csp_blocks,</span><br><span class="line">                                   <span class="variable language_">self</span>.deepen_factor),</span><br><span class="line">             add_identity=<span class="literal">False</span>,</span><br><span class="line">             norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">             act_cfg=<span class="variable language_">self</span>.act_cfg))</span><br><span class="line">    <span class="keyword">return</span> MODELS.build(block_cfg)</span><br></pre></td></tr></table></figure>
<h3 id="1-函数头-2"><a class="header-anchor" href="#1-函数头-2"></a>1) 函数头</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">build_bottom_up_layer</span>(<span class="params">self, idx: <span class="built_in">int</span></span>) -&gt; nn.Module:</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>idx</code> 表示当前要构建哪一层 bottom-up 融合块。</p>
</li>
<li>
<p>bottom-up 的典型数据流：</p>
<p><strong>第 idx 层输出（高分辨率）</strong> → 先经过 <code>downsample_layers[idx]</code> 下采样 → 与 <strong>第 idx+1 层输出（低分辨率）</strong> concat → 过一个融合 block。</p>
</li>
<li>
<p>返回值：这一层 bottom-up 用的 <code>nn.Module</code>。</p>
</li>
</ul>
<hr>
<h3 id="2-深拷贝-block-模板配置"><a class="header-anchor" href="#2-深拷贝-block-模板配置"></a>2) 深拷贝 block 模板配置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block_cfg = copy.deepcopy(<span class="variable language_">self</span>.block_cfg)</span><br></pre></td></tr></table></figure>
<p>和 top-down 一样：每一层都从同一个模板出发补参数，深拷贝避免互相污染。</p>
<hr>
<h3 id="3-关键：给这一层补齐构建参数"><a class="header-anchor" href="#3-关键：给这一层补齐构建参数"></a>3) 关键：给这一层补齐构建参数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block_cfg.update(<span class="built_in">dict</span>(...))</span><br></pre></td></tr></table></figure>
<p>这里决定了 bottom-up 融合块的输入/输出通道、文本引导维度、embedding/head 数、block 深度、norm/act 等。</p>
<hr>
<h4 id="3-1-bottom-up-的-in-channels：来自-concat（两个都是-out-channels）"><a class="header-anchor" href="#3-1-bottom-up-的-in-channels：来自-concat（两个都是-out-channels）"></a>3.1 bottom-up 的 in_channels：来自 concat（两个都是 out_channels）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">in_channels=make_divisible(</span><br><span class="line">    (<span class="variable language_">self</span>.out_channels[idx] + <span class="variable language_">self</span>.out_channels[idx + <span class="number">1</span>]),</span><br><span class="line">    <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<p>这行是 bottom-up 与 top-down 最大的差异点之一：</p>
<ul>
<li>
<p><strong>top-down</strong>：concat 的两路来源通常还是 backbone 对应层的 <code>in_channels[...]</code>（再加上上采样的高层特征）。</p>
</li>
<li>
<p><strong>bottom-up</strong>：concat 的两路来源通常是<strong>已经经过 top-down 融合后的输出特征</strong>，因此用的是 <code>self.out_channels[...]</code>。</p>
</li>
</ul>
<p>更具体点：</p>
<ul>
<li>
<p>一路是 <code>idx</code> 尺度（更高分辨率）的输出：<code>self.out_channels[idx]</code></p>
</li>
<li>
<p>另一路是 <code>idx+1</code> 尺度（更低分辨率）的输出：<code>self.out_channels[idx+1]</code></p>
</li>
<li>
<p>两路 concat，所以输入通道相加。</p>
</li>
<li>
<p><code>make_divisible(..., widen_factor)</code>：做宽度缩放并规整通道数。</p>
</li>
</ul>
<hr>
<h4 id="3-2-out-channels：对齐到更低分辨率那层（idx-1）"><a class="header-anchor" href="#3-2-out-channels：对齐到更低分辨率那层（idx-1）"></a>3.2 out_channels：对齐到更低分辨率那层（idx+1）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_channels=make_divisible(<span class="variable language_">self</span>.out_channels[idx + <span class="number">1</span>], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<p>bottom-up 融合后的结果，是要输出到 <strong>更低分辨率/更高语义层</strong>（<code>idx+1</code>）那一路上，所以输出通道对齐 <code>self.out_channels[idx+1]</code>，再做 <code>make_divisible</code>。</p>
<hr>
<h4 id="3-3-YOLO-World-特有：文本引导维度"><a class="header-anchor" href="#3-3-YOLO-World-特有：文本引导维度"></a>3.3 YOLO-World 特有：文本引导维度</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">guide_channels=<span class="variable language_">self</span>.guide_channels,</span><br></pre></td></tr></table></figure>
<p>和 top-down 一样：告诉融合模块，外部传入的 <code>txt_feats</code>（guide 特征）是多少维，便于模块内部做投影/注意力。</p>
<hr>
<h4 id="3-4-embed-channels：注意这里用的是-embed-channels-idx"><a class="header-anchor" href="#3-4-embed-channels：注意这里用的是-embed-channels-idx"></a>3.4 embed_channels：注意这里用的是 embed_channels[idx]</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">embed_channels=make_round(<span class="variable language_">self</span>.embed_channels[idx], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<p>对比一下：</p>
<ul>
<li>
<p>top-down 用的是 <code>embed_channels[idx - 1]</code></p>
</li>
<li>
<p>bottom-up 用的是 <code>embed_channels[idx]</code></p>
</li>
</ul>
<p>原因直观理解：bottom-up 这一步的“主干尺度”是从 <code>idx</code> 往 <code>idx+1</code> 推进，因此这一层融合块的 embedding 配置通常按 <code>idx</code> 对齐（实现里就是这么定义的）。</p>
<p>同样按 <code>widen_factor</code> 缩放后取整。</p>
<hr>
<h4 id="3-5-num-heads：同样按-idx-取"><a class="header-anchor" href="#3-5-num-heads：同样按-idx-取"></a>3.5 num_heads：同样按 idx 取</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_heads=make_round(<span class="variable language_">self</span>.num_heads[idx], <span class="variable language_">self</span>.widen_factor),</span><br></pre></td></tr></table></figure>
<p>同理，bottom-up 的 head 数也跟随 <code>idx</code> 这层的配置，并按 <code>widen_factor</code> 缩放取整。</p>
<hr>
<h4 id="3-6-num-blocks：CSP-堆叠数按-deepen-factor-缩放"><a class="header-anchor" href="#3-6-num-blocks：CSP-堆叠数按-deepen-factor-缩放"></a>3.6 num_blocks：CSP 堆叠数按 deepen_factor 缩放</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_blocks=make_round(<span class="variable language_">self</span>.num_csp_blocks, <span class="variable language_">self</span>.deepen_factor),</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>基础 <code>num_csp_blocks</code>（默认 3）</p>
</li>
<li>
<p><code>deepen_factor</code> 决定“变深多少”：更大模型会堆更多层。</p>
</li>
</ul>
<hr>
<h4 id="3-7-add-identity-False"><a class="header-anchor" href="#3-7-add-identity-False"></a>3.7 add_identity=False</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_identity=<span class="literal">False</span>,</span><br></pre></td></tr></table></figure>
<p>关闭 identity shortcut（是否有残差捷径取决于具体 block 实现；这里统一关掉）。</p>
<hr>
<h4 id="3-8-规范化与激活配置"><a class="header-anchor" href="#3-8-规范化与激活配置"></a>3.8 规范化与激活配置</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">act_cfg=<span class="variable language_">self</span>.act_cfg</span><br></pre></td></tr></table></figure>
<p>保证 bottom-up 融合块使用同一套 BN/激活设定。</p>
<hr>
<h3 id="4-用注册表真正实例化模块"><a class="header-anchor" href="#4-用注册表真正实例化模块"></a>4) 用注册表真正实例化模块</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> MODELS.build(block_cfg)</span><br></pre></td></tr></table></figure>
<p>把 <code>block_cfg</code> 交给 MMEngine 的注册表工厂，根据 <code>block_cfg[&quot;type&quot;]</code> 构建模块并返回。</p>
<hr>
<h3 id="bottom-up-vs-top-down-的核心差异"><a class="header-anchor" href="#bottom-up-vs-top-down-的核心差异"></a>bottom-up vs top-down 的核心差异</h3>
<ul>
<li>
<p><strong>top-down</strong>：<code>in_channels</code> 用 <code>self.in_channels[...]</code> 做拼接；<code>embed_channels/num_heads</code> 用 <code>idx-1</code> 对齐。</p>
</li>
<li>
<p><strong>bottom-up</strong>：<code>in_channels</code> 用 <code>self.out_channels[...]</code> 做拼接；<code>embed_channels/num_heads</code> 用 <code>idx</code> 对齐；输出对齐 <code>idx+1</code>。</p>
</li>
</ul>
<hr>
<h2 id="def-forward"><a class="header-anchor" href="#def-forward"></a>def forward</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">List</span>[Tensor], txt_feats: Tensor = <span class="literal">None</span></span>) -&gt; <span class="built_in">tuple</span>:</span><br></pre></td></tr></table></figure>
<p>这一段就是把 backbone 的多尺度图像特征 <code>img_feats</code>，结合可选的文本特征 <code>txt_feats</code>，走一遍 <strong>reduce → top-down → bottom-up → out_layers</strong>，最终输出多尺度 neck 特征。</p>
<hr>
<h3 id="1-函数头与注释"><a class="header-anchor" href="#1-函数头与注释"></a>1) 函数头与注释</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">List</span>[Tensor], txt_feats: Tensor = <span class="literal">None</span></span>) -&gt; <span class="built_in">tuple</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward function.</span></span><br><span class="line"><span class="string">    including multi-level image features, text features: BxLxD</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>img_feats</code>: backbone 输出的多尺度特征列表，例如 <code>[P3, P4, P5]</code>，每个是 <code>Tensor</code>。</p>
</li>
<li>
<p><code>txt_feats</code>: 文本特征（可选）。注释写了 <code>BxLxD</code>：</p>
<ul>
<li>
<p><code>B</code>: batch size</p>
</li>
<li>
<p><code>L</code>: token 数</p>
</li>
<li>
<p><code>D</code>: token embedding 维度（也就是你在 <code>guide_channels</code> 里声明的维度，或兼容的维度）</p>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="2-基本一致性检查"><a class="header-anchor" href="#2-基本一致性检查"></a>2) 基本一致性检查</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(img_feats) == <span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>要求输入的特征层数，必须和 neck 配置的 <code>in_channels</code> 层数一致。</p>
</li>
<li>
<p>比如你配置 neck 接 3 个尺度，那 <code>img_feats</code> 也必须是长度 3 的 list。</p>
</li>
</ul>
<hr>
<h3 id="3-Reduce-阶段：先把每个尺度通道“对齐-压缩”"><a class="header-anchor" href="#3-Reduce-阶段：先把每个尺度通道“对齐-压缩”"></a>3) Reduce 阶段：先把每个尺度通道“对齐/压缩”</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reduce layers</span></span><br><span class="line">reduce_outs = [] <span class="comment"># 用于存储每一层的输出</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)):</span><br><span class="line">    reduce_outs.append(<span class="variable language_">self</span>.reduce_layers[idx](img_feats[idx]))</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>结果 <code>reduce_outs</code> 仍然是一个多尺度 list，长度不变，但每层通道通常被“统一/对齐”了。</p>
</li>
<li>
<p>这一阶段不涉及文本特征。</p>
</li>
</ul>
<blockquote>
<p><code>range(len(self.in_channels))</code>：在循环中迭代 <code>in_channels</code> 的长度，即 <strong>遍历每一层的输入通道数</strong>。</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<ul>
<li>假设 <code>self.in_channels = [256, 512, 1024]</code>，那么 <code>idx</code> 会从 0 到 2（共 3 次）。</li>
</ul>
</blockquote>
<blockquote></blockquote>
<blockquote>
<hr>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p><code>img_feats[idx]</code>：这是传递到模型中的输入特征图列表（<code>img_feats</code>）。每一项 <code>img_feats[idx]</code> 是一个张量，表示某一层的特征图，尺寸为 <code>(batch_size, channels, height, width)</code>。</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<hr>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p><code>self.reduce_layers[idx](img_feats[idx])</code>：<strong>对每一层特征图应用 reduce layer</strong>，进行降维（通常是减小通道数）。此操作通常是一个卷积层，<strong>将 <code>img_feats[idx]</code> 的通道数减小</strong>，并且保留特征图的空间分辨率（<code>height</code> 和 <code>width</code> 不变）。</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<hr>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p><strong>例子</strong></p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;<span class="variable language_">self</span>.in_channels = [<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#self.reduce_layers 包含了 3 个不同的 卷积层，分别对应于每一层输入通道数</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="variable language_">self</span>.reduce_layers = [conv1, conv2, conv3]</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#conv1 可能是一个 Conv2d 层，接收 256 通道的输入并将输出通道数减小（例如降到 128）。同理，conv2 会将 512 通道的特征图减小通道数，conv3 将 1024 通道的特征图减小。</span></span><br><span class="line"></span><br><span class="line">&gt;img_feats = [feat1, feat2, feat3]</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#feat1 的形状是 (batch_size, 256, height, width)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#feat2 的形状是 (batch_size, 512, height // 2, width // 2)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#feat3 的形状是 (batch_size, 1024, height // 4, width // 4)</span></span><br><span class="line"></span><br><span class="line">&gt;reduce_outs.append(conv1(feat1))  <span class="comment"># 输出形状: (batch_size, 128, height, width)</span></span><br><span class="line"></span><br><span class="line">&gt;reduce_outs.append(conv2(feat2))  <span class="comment"># 输出形状: (batch_size, 256, height//2, width//2)</span></span><br><span class="line"></span><br><span class="line">&gt;reduce_outs.append(conv3(feat3))  <span class="comment"># 输出形状: (batch_size, 512, height//4, width//4)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote></blockquote>
<blockquote></blockquote>
<hr>
<h3 id="4-Top-down-路径：高层语义向低层传播（上采样-concat-融合块）"><a class="header-anchor" href="#4-Top-down-路径：高层语义向低层传播（上采样-concat-融合块）"></a>4) Top-down 路径：高层语义向低层传播（上采样 + concat + 融合块）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># top-down path</span></span><br><span class="line">inner_outs = [reduce_outs[-<span class="number">1</span>]]</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">    feat_high = inner_outs[<span class="number">0</span>]</span><br><span class="line">    feat_low = reduce_outs[idx - <span class="number">1</span>]</span><br><span class="line">    upsample_feat = <span class="variable language_">self</span>.upsample_layers[<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span> - idx](feat_high)</span><br></pre></td></tr></table></figure>
<p>逐行解释：</p>
<ul>
<li>
<p><code>inner_outs = [reduce_outs[-1]]</code></p>
<ul>
<li>从<strong>最深层/分辨率最低/语义最强</strong>的那层开始（list 最后一个）。</li>
</ul>
</li>
<li>
<p><code>for idx in range(len(self.in_channels) - 1, 0, -1):</code></p>
</li>
<li>
<p>若<code>len(self.in_channels)=3</code>，则<code>idx=2,1</code></p>
</li>
<li>
<p><code>feat_high = inner_outs[0]</code></p>
</li>
<li>
<p>当前已经得到的“更高语义”的特征（一开始就是最深层）。</p>
</li>
<li>
<p><code>feat_low = reduce_outs[idx - 1]</code></p>
<ul>
<li>当前要融合的“更高分辨率”的那一层。</li>
</ul>
</li>
<li>
<p><code>upsample_feat = self.upsample_layers[...] (feat_high)</code></p>
<ul>
<li>把高层特征上采样到与 <code>feat_low</code> 相同的空间尺寸，准备 concat。</li>
</ul>
</li>
</ul>
<p>接着是 concat 的顺序控制：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.upsample_feats_cat_first:</span><br><span class="line">    top_down_layer_inputs = torch.cat([upsample_feat, feat_low], <span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    top_down_layer_inputs = torch.cat([feat_low, upsample_feat], <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>torch.cat(..., 1)</code> 表示在 <strong>channel 维度</strong>拼接。</p>
</li>
<li>
<p><code>self.upsample_feats_cat_first</code> 决定拼接顺序：</p>
<ul>
<li>
<p><code>True</code>：<code>[上采样高层, 低层]</code></p>
</li>
<li>
<p><code>False</code>：<code>[低层, 上采样高层]</code></p>
</li>
</ul>
</li>
<li>
<p>为什么要有这个开关？有些实现/权重约定里，concat 顺序会影响后续卷积层“看到的通道排列”，为了兼容不同版本/预训练权重就会保留这个选项。</p>
</li>
</ul>
<p>然后进入融合块（这里就是 YOLO-World 的关键差异：把 <code>txt_feats</code> 传进去）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inner_out = <span class="variable language_">self</span>.top_down_layers[<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span> - idx](</span><br><span class="line">    top_down_layer_inputs, txt_feats)</span><br><span class="line">inner_outs.insert(<span class="number">0</span>, inner_out)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.top_down_layers[...]</code> 是在 <code>build_top_down_layer</code> 里构建出来的模块。</p>
</li>
<li>
<p>它的 forward 形式是 <code>(x, txt_feats)</code>，说明这个 block <strong>内部会用文本特征引导/交互</strong>（比如注意力、相似度调制、门控等——具体细节取决于你 <code>block_cfg[&quot;type&quot;]</code> 的实现）。</p>
</li>
<li>
<p><code>inner_outs.insert(0, inner_out)</code>：</p>
<ul>
<li>把新得到的更低层结果插到最前面，保证 <code>inner_outs</code> 始终从“高分辨率→低分辨率”顺序排列。</li>
</ul>
</li>
</ul>
<blockquote>
<p>走完 top-down 后，<code>inner_outs</code> 就是一套已经融合过的多尺度特征（但还没走 PAN 的 bottom-up 回传）。</p>
</blockquote>
<hr>
<blockquote>
<p><span style="color:#FF0000"><strong>全流程例子</strong></span></p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p><strong>假设</strong></p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<ul>
<li><code>reduce_outs = [feat1, feat2, feat3]</code>，其中：</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><code>feat1</code> 是最浅层的特征图，假设它的形状为 <code>(batch_size, 256, 128, 128)</code>。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><code>feat2</code> 是中间层的特征图，假设它的形状为 <code>(batch_size, 512, 64, 64)</code>。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><code>feat3</code> 是最深层的特征图，假设它的形状为 <code>(batch_size, 1024, 32, 32)</code>。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><code>self.in_channels = [256, 512, 1024]</code>，表示每一层输入特征图的通道数。</li>
</ul>
</blockquote>
<blockquote></blockquote>
<blockquote>
<p>假设 <code>self.upsample_layers</code> 是一个包含上采样层的列表，其中每一项对应一个上采样操作，假设有三个上采样层，每个上采样层负责将特征图的空间尺寸上采样到较低层特征图的分辨率。</p>
</blockquote>
<blockquote></blockquote>
<blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;inner_outs = [reduce_outs[-<span class="number">1</span>]] <span class="comment">#reduce_outs[-1] 取的是最深层的特征图，即 feat3</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#inner_outs = [feat3]，记为inner_outs =[inner_out3]</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#len(self.in_channels) = 3 --&gt;for idx in range(2, 0, -1): --&gt;idx 的值依次为 2 和 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#---------------第一次循环 (idx = 2)------------------------</span></span><br><span class="line"></span><br><span class="line">&gt;feat_high = inner_outs[<span class="number">0</span>] <span class="comment">#inner_outs[0] 是 feat3</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#feat_high = feat3  shape: (batch_size, 1024, 32, 32)</span></span><br><span class="line"></span><br><span class="line">&gt;feat_low = reduce_outs[idx - <span class="number">1</span>]  <span class="comment"># =reduce_outs[1] ; 即 feat2，shape: (batch_size, 512, 64, 64)</span></span><br><span class="line"></span><br><span class="line">&gt;upsample_feat = <span class="variable language_">self</span>.upsample_layers[<span class="number">0</span>](feat_high)  <span class="comment"># shape: (batch_size, 1024, 64, 64)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#假设 self.upsample_feats_cat_first = True</span></span><br><span class="line"></span><br><span class="line">&gt;top_down_layer_inputs = torch.cat([upsample_feat, feat_low], <span class="number">1</span>)  <span class="comment"># shape: (batch_size, 1024+512, 64, 64)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#假设 top_down_layers[0] 是一个卷积层</span></span><br><span class="line"></span><br><span class="line">&gt;inner_out = <span class="variable language_">self</span>.top_down_layers[<span class="number">0</span>](top_down_layer_inputs, txt_feats)  <span class="comment"># shape: (batch_size, out_channels, 64, 64)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#更新 inner_outs:inner_outs 列表中的第一个位置（inner_outs[0]）插入当前的输出 inner_out</span></span><br><span class="line"></span><br><span class="line">&gt;inner_outs.insert(<span class="number">0</span>, inner_out)  <span class="comment"># 更新 inner_outs = [inner_out, inner_out3] = [inner_out2, inner_out3]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#---------------第二次循环 (idx = 1)------------------------</span></span><br><span class="line"></span><br><span class="line">&gt;feat_high = inner_outs[<span class="number">0</span>] <span class="comment">#现在 inner_outs[0] 是刚刚计算的 inner_out，它的形状是 (batch_size, out_channels, 64, 64)，假设 out_channels = 256</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#feat_high = inner_out  shape: (batch_size, 256, 64, 64)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;feat_low = reduce_outs[idx - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">&gt;feat_low = reduce_outs[<span class="number">0</span>]  <span class="comment"># 即 feat1，shape: (batch_size, 256, 128, 128)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#假设 self.upsample_layers[1] 会将其上采样到 (batch_size, 256, 128, 128)</span></span><br><span class="line"></span><br><span class="line">&gt;upsample_feat = <span class="variable language_">self</span>.upsample_layers[<span class="number">1</span>](feat_high)  <span class="comment"># shape: (batch_size, 256, 128, 128)</span></span><br><span class="line"></span><br><span class="line">&gt;top_down_layer_inputs = torch.cat([upsample_feat, feat_low], <span class="number">1</span>)  <span class="comment"># shape: (batch_size, 256+256, 128, 128)</span></span><br><span class="line"></span><br><span class="line">&gt;inner_out = <span class="variable language_">self</span>.top_down_layers[<span class="number">1</span>](top_down_layer_inputs, txt_feats)  <span class="comment"># shape: (batch_size, out_channels, 128, 128)</span></span><br><span class="line"></span><br><span class="line">&gt;inner_outs.insert(<span class="number">0</span>, inner_out)  <span class="comment"># 更新 inner_outs = [inner_out1, inner_out2, inner_out3]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote></blockquote>
<blockquote></blockquote>
<h3 id="5-Bottom-up-路径：低层信息向高层再聚合（下采样-concat-融合块）"><a class="header-anchor" href="#5-Bottom-up-路径：低层信息向高层再聚合（下采样-concat-融合块）"></a>5) Bottom-up 路径：低层信息向高层再聚合（下采样 + concat + 融合块）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bottom-up path</span></span><br><span class="line">outs = [inner_outs[<span class="number">0</span>]]</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span>):</span><br><span class="line">    feat_low = outs[-<span class="number">1</span>]</span><br><span class="line">    feat_high = inner_outs[idx + <span class="number">1</span>]</span><br><span class="line">    downsample_feat = <span class="variable language_">self</span>.downsample_layers[idx](feat_low)</span><br><span class="line">    out = <span class="variable language_">self</span>.bottom_up_layers[idx](torch.cat([downsample_feat, feat_high], <span class="number">1</span>), txt_feats)</span><br><span class="line">    outs.append(out)</span><br></pre></td></tr></table></figure>
<p>逐行解释：</p>
<ul>
<li>
<p><code>outs = [inner_outs[0]]</code></p>
<ul>
<li>假设 <code>inner_outs = [inner_out1, inner_out2, inner_out3]</code>，那么 <code>inner_outs[0]</code> 就是我们最开始的高层特征图 <code>inner_out1</code>（<strong>最高分辨率层</strong>）。</li>
</ul>
</li>
<li>
<p><code>for idx in range(len(self.in_channels) - 1):</code></p>
<ul>
<li>若len(self.in_channels) = 3，<code>idx</code> 为 0 和 1</li>
</ul>
</li>
<li>
<p><code>feat_low = outs[-1]</code></p>
</li>
<li>
<p>已知<code>outs = [inner_outs[0]]=[inner_out1]</code>--&gt;第一次迭代时<code>feat_low = outs[-1]=inner_out1</code>（<strong>最高分辨率层</strong>）。</p>
</li>
<li>
<p><code>feat_high = inner_outs[idx + 1]</code></p>
<ul>
<li><code>idx + 1</code> 确保我们获取的<code>feat_low </code><strong>更高层的特征图</strong>(更高指的是：卷积后的，通道数更多，分辨率更小)</li>
</ul>
</li>
<li>
<p><code>downsample_feat = self.downsample_layers[idx](feat_low)</code></p>
<ul>
<li>
<p>把高分辨率特征下采样到与 <code>feat_high</code> 同尺寸。</p>
</li>
<li>
<p><code>self.downsample_layers[idx]</code> 是一个下采样层，它将 <code>feat_low</code>（当前底层特征图）进行下采样（例如通过池化或卷积实现下采样），减少其空间分辨率。</p>
</li>
</ul>
</li>
<li>
<p><code>torch.cat([downsample_feat, feat_high], 1)</code></p>
<ul>
<li>按 channel 拼接（这里没有做顺序开关，固定是 <code>[downsample, higher_level]</code>）。</li>
</ul>
</li>
<li>
<p><code>self.bottom_up_layers[idx](..., txt_feats)</code></p>
<ul>
<li>bottom-up 融合块同样接收 <code>txt_feats</code>，继续让文本引导参与特征聚合。</li>
</ul>
</li>
<li>
<p><code>outs.append(out)</code></p>
<ul>
<li>
<p>将当前层的输出 <code>out</code> 插入到 <code>outs</code> 列表中，供下一次循环使用。</p>
</li>
<li>
<p><code>outs = [out1,out2,out3]</code>（特征图分辨率从大到小）</p>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="6-Out-layers：最后再做一层输出整形（通常是-1x1-3x3-conv）"><a class="header-anchor" href="#6-Out-layers：最后再做一层输出整形（通常是-1x1-3x3-conv）"></a>6) Out layers：最后再做一层输出整形（通常是 1x1/3x3 conv）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># out_layers</span></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)):</span><br><span class="line">    results.append(<span class="variable language_">self</span>.out_layers[idx](outs[idx]))</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">tuple</span>(results)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.out_layers[idx]</code>：通常用于把 <code>outs[idx]</code> 的通道/形式变成 head 期望的输入形式（例如再做一次卷积整形/对齐）。</p>
</li>
<li>
<p>最终返回 <code>tuple(results)</code>：一个多尺度输出元组（给检测头/分割头继续用）。</p>
</li>
</ul>
<hr>
<h1 id="class-YOLOWorldDualPAFPN-YOLOWorldPAFPN"><a class="header-anchor" href="#class-YOLOWorldDualPAFPN-YOLOWorldPAFPN"></a>class YOLOWorldDualPAFPN(YOLOWorldPAFPN)</h1>
<h2 id="def-init-2"><a class="header-anchor" href="#def-init-2"></a>def <strong>init</strong></h2>
<p>这份实现里 Dual 的核心新增点是：在继承 <code>YOLOWorldPAFPN</code> 原本“图像-文本引导的 PAFPN”基础上，又额外加了一个 <code>text_enhancer</code>，用多尺度图像特征去<strong>增强/更新文本特征</strong>，从而形成更“image-aware”的 text embedding。</p>
<h3 id="1-函数签名：把-Dual-版本需要的超参都收进来"><a class="header-anchor" href="#1-函数签名：把-Dual-版本需要的超参都收进来"></a>1) 函数签名：把 Dual 版本需要的超参都收进来</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOWorldDualPAFPN</span>(<span class="title class_ inherited__">YOLOWorldPAFPN</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Path Aggregation Network used in YOLO World v8.&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p><strong>解析</strong>：该类继承自 <code>YOLOWorldPAFPN</code>。这意味着它继承了构建 Top-down 和 Bottom-up 层的基本能力，但会通过额外的组件来增强交互逻辑。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             in_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             out_channels: <span class="type">Union</span>[<span class="type">List</span>[<span class="built_in">int</span>], <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             guide_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             embed_channels: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             num_heads: <span class="type">List</span>[<span class="built_in">int</span>],</span></span><br><span class="line"><span class="params">             deepen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             widen_factor: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">             num_csp_blocks: <span class="built_in">int</span> = <span class="number">3</span>,</span></span><br><span class="line"><span class="params">             freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             text_enhancder: ConfigType = <span class="built_in">dict</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="params">                 <span class="built_in">type</span>=<span class="string">&#x27;ImagePoolingAttentionModule&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                 embed_channels=<span class="number">256</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                 num_heads=<span class="number">8</span>,</span></span></span><br><span class="line"><span class="params"><span class="params">                 pool_size=<span class="number">3</span></span>),</span></span><br><span class="line"><span class="params">             block_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;CSPLayerWithTwoConv&#x27;</span></span>),</span></span><br><span class="line"><span class="params">             norm_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;BN&#x27;</span>, momentum=<span class="number">0.03</span>, eps=<span class="number">0.001</span></span>),</span></span><br><span class="line"><span class="params">             act_cfg: ConfigType = <span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;SiLU&#x27;</span>, inplace=<span class="literal">True</span></span>),</span></span><br><span class="line"><span class="params">             init_cfg: OptMultiConfig = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<p>逐个参数讲清楚：</p>
<ul>
<li>
<p><code>in_channels: List[int]</code></p>
<p>backbone 输出给 neck 的多尺度通道数列表，例如 <code>[C3, C4, C5]</code> 的通道。</p>
</li>
<li>
<p><code>out_channels: Union[List[int], int]</code></p>
<p>neck 期望输出的通道配置。允许你传一个 <code>int</code>（内部可能会 broadcast 成 list），或者直接传 list（如 <code>[256, 512, 1024]</code> 之类）。<strong>注意：这份 Dual 代码后面把它当 list 用</strong>（会 <code>for x in out_channels</code>），所以通常你的配置里应该最终是 list（或父类会把 int 转 list）。</p>
</li>
<li>
<p><code>guide_channels: int</code></p>
<p>文本特征 <code>txt_feats</code> 的通道维（D）。也就是你前面在 <code>top_down_layers/bottom_up_layers</code> 里传进去的 <code>txt_feats(B×L×D)</code> 的 <code>D</code>。</p>
</li>
<li>
<p><code>embed_channels: List[int]</code>, <code>num_heads: List[int]</code></p>
<p>给每个尺度用的 attention/embedding 配置（和你前面在 <code>build_top_down_layer / build_bottom_up_layer</code> 里看到的一样，会按 idx 取不同值）。</p>
</li>
<li>
<p><code>deepen_factor / widen_factor / num_csp_blocks</code></p>
<p>YOLO 系列常见的宽深缩放因子（控制 block 堆叠数、通道宽度等）。</p>
</li>
<li>
<p><code>freeze_all: bool</code></p>
<p>是否冻结该 neck 的参数（由父类实现具体冻结逻辑）。</p>
</li>
<li>
<p><code>text_enhancder: ConfigType = dict(...)</code>  ← Dual 版本新增的重点</p>
<p>这是一个 <strong>“文本增强模块”的配置字典</strong>，默认类型是 <code>ImagePoolingAttentionModule</code>，并带默认超参：</p>
<ul>
<li>
<p><code>embed_channels=256</code></p>
</li>
<li>
<p><code>num_heads=8</code></p>
</li>
<li>
<p><code>pool_size=3</code>（很像 paper 里 I-Pooling Attention 的 3×3 pooling 设计）</p>
</li>
</ul>
</li>
<li>
<p><code>block_cfg / norm_cfg / act_cfg / init_cfg</code></p>
<p>这些是 neck 内部 CSP 融合块、BN、激活函数、初始化配置。</p>
</li>
</ul>
<hr>
<h3 id="2-super-init-：先把“基础-YOLOWorldPAFPN”完整搭出来"><a class="header-anchor" href="#2-super-init-：先把“基础-YOLOWorldPAFPN”完整搭出来"></a>2) <code>super().__init__(...)</code>：先把“基础 YOLOWorldPAFPN”完整搭出来</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__(in_channels=in_channels,</span><br><span class="line">                 out_channels=out_channels,</span><br><span class="line">                 guide_channels=guide_channels,</span><br><span class="line">                 embed_channels=embed_channels,</span><br><span class="line">                 num_heads=num_heads,</span><br><span class="line">                 deepen_factor=deepen_factor,</span><br><span class="line">                 widen_factor=widen_factor,</span><br><span class="line">                 num_csp_blocks=num_csp_blocks,</span><br><span class="line">                 freeze_all=freeze_all,</span><br><span class="line">                 block_cfg=block_cfg,</span><br><span class="line">                 norm_cfg=norm_cfg,</span><br><span class="line">                 act_cfg=act_cfg,</span><br><span class="line">                 init_cfg=init_cfg)</span><br></pre></td></tr></table></figure>
<p>这一步做的是：<strong>完全复用 YOLOWorldPAFPN 的那套结构</strong>，也就是你刚刚分析过的 forward 里会用到的：</p>
<ul>
<li>
<p><code>reduce_layers</code></p>
</li>
<li>
<p><code>upsample_layers</code> + <code>top_down_layers(…, txt_feats)</code></p>
</li>
<li>
<p><code>downsample_layers</code> + <code>bottom_up_layers(…, txt_feats)</code></p>
</li>
<li>
<p><code>out_layers</code></p>
</li>
</ul>
<p>并且把：</p>
<ul>
<li>
<p>文本引导维度（<code>guide_channels</code>）</p>
</li>
<li>
<p>多尺度 embedding/head/blocks 的配置（<code>embed_channels/num_heads/num_csp_blocks</code>）</p>
</li>
<li>
<p>宽深缩放（<code>widen_factor/deepen_factor</code>）</p>
</li>
<li>
<p>归一化/激活配置（<code>norm_cfg/act_cfg</code>）</p>
<p>都交给父类去初始化好。</p>
</li>
</ul>
<blockquote>
<p>换句话说：Dual 版本 <strong>不是替换 PAFPN 主干</strong>，而是在“已有的图像-文本融合 PAFPN”基础上<strong>额外加一条“图像→文本”的增强支路</strong>。</p>
</blockquote>
<hr>
<h3 id="3-text-enhancder-update-：把运行时必要的维度信息补进配置"><a class="header-anchor" href="#3-text-enhancder-update-：把运行时必要的维度信息补进配置"></a>3) <code>text_enhancder.update(...)</code>：把运行时必要的维度信息补进配置</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">text_enhancder.update(</span><br><span class="line">    <span class="built_in">dict</span>(</span><br><span class="line">        image_channels=[<span class="built_in">int</span>(x * widen_factor) <span class="keyword">for</span> x <span class="keyword">in</span> out_channels],</span><br><span class="line">        text_channels=guide_channels,</span><br><span class="line">        num_feats=<span class="built_in">len</span>(out_channels),</span><br><span class="line">    ))</span><br></pre></td></tr></table></figure>
<p>这几行非常关键：默认的 <code>text_enhancder</code> 只写了模块类型和一些内部超参，但它还缺少“它到底要吃哪些尺度的图像特征、图像通道是多少、文本通道是多少”等信息，所以这里补齐：</p>
<ul>
<li>
<h4 id="update-方法："><a class="header-anchor" href="#update-方法："></a><code>update()</code> 方法：</h4>
<ul>
<li><strong><code>text_enhancer</code></strong> 是一个配置字典（<code>ConfigType</code>），用于存储文本增强模块的配置信息。<code>update()</code> 方法会将传入的字典更新到 <code>text_enhancer</code> 中。</li>
</ul>
</li>
</ul>
<ul>
<li>
<p><code>image_channels=[int(x * widen_factor) for x in out_channels]</code></p>
<p>生成一个 list，表示每个尺度图像特征的通道数。</p>
<ul>
<li>
<p>这一行表示：对于每个输出通道数（<code>out_channels</code>），它会乘以 <code>widen_factor</code> 来调整通道数的大小。这个操作通常用于根据需要缩放网络的宽度。</p>
</li>
<li>
<p>例如，假设 <code>out_channels = [256, 512, 1024]</code>，<code>widen_factor = 1.5</code>，那么 <code>image_channels</code> 将会变成 <code>[384, 768, 1536]</code>。</p>
</li>
</ul>
<ul>
<li>注意它用的是 <code>out_channels</code> 而不是 <code>in_channels</code>：说明 <code>text_enhancer</code> 预期吃的是 <strong>neck 过程中对齐后的多尺度特征通道</strong>（与 neck 输出尺度一致的通道口径）。</li>
</ul>
</li>
</ul>
<p>​</p>
<ul>
<li>
<p><code>text_channels=guide_channels</code></p>
<p><code>guide_channels</code> 是 <strong>文本特征的通道数</strong>。它决定了文本特征在后续模型中的维度。假设 <code>guide_channels = 128</code>，那么文本特征的通道数就是 <code>128</code>。</p>
</li>
<li>
<p><code>num_feats=len(out_channels)</code></p>
<p>这一行指定了<strong>特征的数量</strong>，即输出特征图的层数。假设 <code>out_channels = [256, 512, 1024]</code>，那么 <code>num_feats = 3</code>，表示有 3 个输出特征层。</p>
</li>
</ul>
<blockquote>
<p>这一步本质上是在把 “结构超参（type/embed_heads/pool_size）” 和 “形状信息（image_channels/text_channels/num_feats）” 合并成一个完整的可 build 配置。</p>
</blockquote>
<hr>
<h3 id="4-print-text-enhancder-：调试输出（训练-构建时会打印）"><a class="header-anchor" href="#4-print-text-enhancder-：调试输出（训练-构建时会打印）"></a>4) <code>print(text_enhancder)</code>：调试输出（训练/构建时会打印）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(text_enhancder)</span><br></pre></td></tr></table></figure>
<p>这行没有功能性影响，纯粹是作者用来确认最终配置字典长什么样（你跑起来会在日志里看到）。</p>
<hr>
<h3 id="5-self-text-enhancer-MODELS-build-text-enhancder-：用注册表把模块实例化出来"><a class="header-anchor" href="#5-self-text-enhancer-MODELS-build-text-enhancder-：用注册表把模块实例化出来"></a>5) <code>self.text_enhancer = MODELS.build(text_enhancder)</code>：用注册表把模块实例化出来</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.text_enhancer = MODELS.build(text_enhancder)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>MODELS.build(...)</code> 是 MMEngine/OpenMMLab 的注册表构建方式：根据 <code>text_enhancder['type']</code> 找到对应类（这里默认 <code>ImagePoolingAttentionModule</code>），并把刚刚 update 的参数一起传进去构造。</p>
</li>
<li>
<p>最终得到 <code>self.text_enhancer</code>：Dual 版本新增的模块实例。</p>
</li>
</ul>
<blockquote>
<p>你后面看 <code>YOLOWorldDualPAFPN.forward</code> 时，大概率会发现：它会先用这个 <code>text_enhancer</code> 把 <code>txt_feats</code> 做一次“图像条件化”，再送进 <code>top_down_layers/bottom_up_layers</code> 去做“文本引导图像”的融合；从而构成一种更“对称”的双向交互（I→T 再 T→I）。</p>
</blockquote>
<hr>
<h2 id="def-forward-2"><a class="header-anchor" href="#def-forward-2"></a>def forward</h2>
<p>相对 <code>YOLOWorldPAFPN</code>，<strong>唯一关键新增点</strong>是在 top-down 完成后插入了一句 <code>txt_feats = self.text_enhancer(txt_feats, inner_outs)</code>：用多尺度图像特征去“增强/更新”文本特征，然后再进入 bottom-up）。</p>
<h3 id="函数入口与基本检查"><a class="header-anchor" href="#函数入口与基本检查"></a>函数入口与基本检查</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">List</span>[Tensor], txt_feats: Tensor</span>) -&gt; <span class="built_in">tuple</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward function.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(img_feats) == <span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>img_feats</code>：backbone 多尺度图像特征列表（例如 3 个尺度）。</p>
</li>
<li>
<p><code>txt_feats</code>：文本特征（这里 Dual 版本不设默认 <code>None</code>，调用方应保证传入）。</p>
</li>
<li>
<p><code>assert</code>：确保尺度数对齐 neck 的 <code>in_channels</code> 配置。</p>
</li>
</ul>
<hr>
<h3 id="通道缩减（Reduce-Layers）"><a class="header-anchor" href="#通道缩减（Reduce-Layers）"></a>通道缩减（Reduce Layers）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reduce layers</span></span><br><span class="line">reduce_outs = []</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)):</span><br><span class="line">    reduce_outs.append(<span class="variable language_">self</span>.reduce_layers[idx](img_feats[idx]))</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.reduce_layers[idx]</code> 通常是 1×1 conv（或类似），把每个尺度的 <code>img_feats[idx]</code> 变成 neck 内部期望的通道数。</p>
</li>
<li>
<p>输出 <code>reduce_outs</code>：依旧是多尺度 list，但通道已统一到 neck 设定。</p>
</li>
</ul>
<hr>
<h3 id="自顶向下路径（Top-down-Path）——-文本引导图像"><a class="header-anchor" href="#自顶向下路径（Top-down-Path）——-文本引导图像"></a>自顶向下路径（Top-down Path）—— 文本引导图像</h3>
<p><span style="color:#FF0000">这是 <strong>Text-to-Image</strong> 的第一次交互。</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># top-down path</span></span><br><span class="line">inner_outs = [reduce_outs[-<span class="number">1</span>]]</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">    feat_high = inner_outs[<span class="number">0</span>]</span><br><span class="line">    feat_low = reduce_outs[idx - <span class="number">1</span>]</span><br><span class="line">    upsample_feat = <span class="variable language_">self</span>.upsample_layers[<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span> - idx](feat_high)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>inner_outs</code> 先从最深层（最低分辨率、最高语义）开始：<code>reduce_outs[-1]</code>。</p>
</li>
<li>
<p>循环从高层走向低层（例如 idx=2→1），每次：</p>
<ul>
<li>
<p><code>feat_high</code>：当前高语义特征（会被上采样）</p>
</li>
<li>
<p><code>feat_low</code>：对应的更高分辨率特征（横向连接）</p>
</li>
<li>
<p><code>upsample_feat</code>：把 <code>feat_high</code> 上采样到与 <code>feat_low</code> 同空间尺寸</p>
</li>
</ul>
</li>
</ul>
<p>接下来决定 concat 的通道拼接顺序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.upsample_feats_cat_first:</span><br><span class="line">    top_down_layer_inputs = torch.cat([upsample_feat, feat_low], <span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    top_down_layer_inputs = torch.cat([feat_low, upsample_feat], <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>torch.cat(..., 1)</code>：沿 channel 维拼接。</p>
</li>
<li>
<p><code>upsample_feats_cat_first</code> 是一个兼容性/权重对齐用的开关：控制拼接时两路特征谁在前。</p>
</li>
</ul>
<p>然后过 top-down 融合块（注意这里把 <code>txt_feats</code> 传进去了）<span style="color:#FF0000">【用文本增强图像特征】</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inner_out = <span class="variable language_">self</span>.top_down_layers[<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span> - idx](</span><br><span class="line">    top_down_layer_inputs, txt_feats)</span><br><span class="line">inner_outs.insert(<span class="number">0</span>, inner_out)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.top_down_layers[...]</code>  文本引导融合：将拼接特征送入 Top-down CSP 块 ；<code>txt_feats</code> 在这里作为“引导信号”传入，控制卷积块关注哪些视觉区域</p>
</li>
<li>
<p><code>insert(0, ...)</code>：把新得到的更高分辨率输出插到最前面，保证 <code>inner_outs</code> 顺序从高分辨率到低分辨率排列。</p>
</li>
</ul>
<blockquote>
<p>走完这段循环后，<code>inner_outs</code> 就是一套完成 top-down 融合后的多尺度特征。</p>
</blockquote>
<hr>
<h3 id="Dual-的核心新增-span-style-color-FF0000-图像引导文本-span"><a class="header-anchor" href="#Dual-的核心新增-span-style-color-FF0000-图像引导文本-span"></a>Dual 的核心新增--<span style="color:#FF0000">图像引导文本</span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">txt_feats = <span class="variable language_">self</span>.text_enhancer(txt_feats, inner_outs)</span><br></pre></td></tr></table></figure>
<p>这句是 <strong>YOLOWorldDualPAFPN 相对 YOLOWorldPAFPN 的关键差异</strong>：</p>
<ul>
<li>
<p><code>self.text_enhancer</code> 在 <code>__init__</code> 里通过 <code>MODELS.build(text_enhancder)</code> 构建，默认 <code>type='ImagePoolingAttentionModule'</code>，并带 <code>pool_size=3</code> 等超参。</p>
</li>
<li>
<p>调用形态：<code>text_enhancer(txt_feats, inner_outs)</code></p>
<ul>
<li>
<p><code>txt_feats</code>：原始文本 token embedding（B×L×D）</p>
</li>
<li>
<p><code>inner_outs</code>：top-down 得到的多尺度图像特征 list</p>
</li>
</ul>
</li>
<li>
<p>输出：更新后的 <code>txt_feats</code>（仍然是 B×L×D 这种“文本 token 序列”形状，但被注入了图像条件信息，变成更 image-aware 的文本特征）</p>
</li>
</ul>
<p>直观理解：</p>
<p><strong>先做一次“文本引导图像”的 top-down（T→I），再做一次“图像反哺文本”的增强（I→T），然后再用更新后的文本继续引导 bottom-up（再 T→I）。</strong></p>
<hr>
<h3 id="自底向上路径（Bottom-up-Path）——-增强文本再次引导图像"><a class="header-anchor" href="#自底向上路径（Bottom-up-Path）——-增强文本再次引导图像"></a>自底向上路径（Bottom-up Path）—— 增强文本再次引导图像</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bottom-up path</span></span><br><span class="line">outs = [inner_outs[<span class="number">0</span>]]</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels) - <span class="number">1</span>):</span><br><span class="line">    feat_low = outs[-<span class="number">1</span>]</span><br><span class="line">    feat_high = inner_outs[idx + <span class="number">1</span>]</span><br><span class="line">    downsample_feat = <span class="variable language_">self</span>.downsample_layers[idx](feat_low)</span><br><span class="line">    out = <span class="variable language_">self</span>.bottom_up_layers[idx](torch.cat(</span><br><span class="line">        [downsample_feat, feat_high], <span class="number">1</span>), txt_feats)</span><br><span class="line">    outs.append(out)</span><br></pre></td></tr></table></figure>
<p>逐行要点：</p>
<ul>
<li>
<p><code>outs</code> 从最高分辨率那层开始（<code>inner_outs[0]</code>）。</p>
</li>
<li>
<p>每次循环：</p>
<ul>
<li>
<p><code>feat_low</code>：当前高分辨率输出</p>
</li>
<li>
<p><code>downsample_feat</code>：把 <code>feat_low</code> 下采样到下一层分辨率</p>
</li>
<li>
<p><code>feat_high</code>：top-down 里对应的下一层特征（作为 concat 的另一支）</p>
</li>
<li>
<p>拼接后喂给 <code>bottom_up_layers[idx](..., txt_feats)</code></p>
<p><span style="color:#FF0000">$ \bigstar \bigstar \bigstar$</span>此时的 <code>txt_feats</code> 已经是 <strong>被 <code>text_enhancer</code> 更新过的版本</strong>，所以 bottom-up 的融合是“更强的文本引导”。</p>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Out-layers：输出整形并返回"><a class="header-anchor" href="#Out-layers：输出整形并返回"></a>Out layers：输出整形并返回</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># out_layers</span></span><br><span class="line">results = []</span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.in_channels)):</span><br><span class="line">    results.append(<span class="variable language_">self</span>.out_layers[idx](outs[idx]))</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">tuple</span>(results)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.out_layers[idx]</code>：把每个尺度的 <code>outs[idx]</code> 做最后一次通道/形式整形，使其符合 detection head 的输入口径。</p>
</li>
<li>
<p>返回 <code>tuple(results)</code>：多尺度 neck 输出。</p>
</li>
</ul>
<hr>
<p>如果你要继续“更落地”一点，我建议下一步把 <code>ImagePoolingAttentionModule</code>（也就是默认的 <code>text_enhancer</code>）那段实现源码贴出来/指出它在你工程里的文件位置，我就能把 <strong>它到底如何把 <code>inner_outs</code> 池化成 token，再对 <code>txt_feats</code> 做 attention 更新</strong>逐行拆开讲。</p>
<h1 id="总结1"><a class="header-anchor" href="#总结1"></a>总结1</h1>
<p>在深入学习 <strong>Head</strong>（检测头）之前，对 <code>yolo_world_pafpn.py</code> 进行全面总结是非常必要的。这个文件实现了 YOLO-World 论文中最核心的结构创新：<strong>RepVL-PAN</strong> (Re-parameterizable Vision-Language Path Aggregation Network)。</p>
<p>以下是从功能、代码结构、项目地位以及论文对应关系四个维度的深度总结。</p>
<hr>
<h3 id="1-核心任务：RepVL-PAN-的实现"><a class="header-anchor" href="#1-核心任务：RepVL-PAN-的实现"></a>1. 核心任务：RepVL-PAN 的实现</h3>
<p>该文件的唯一目标是打破视觉和语言的界限。传统的 YOLO Neck（如 PAFPN）只负责图像特征的尺度融合，而这里的 <strong>RepVL-PAN</strong> 将 <strong>Text Embedding</strong> 注入到特征融合的过程中，使得输出的特征图不再是纯粹的视觉像素聚合，而是包含了语义信息的“多模态特征”。</p>
<h3 id="2-类关系与区别：从单向到双向"><a class="header-anchor" href="#2-类关系与区别：从单向到双向"></a>2. 类关系与区别：从单向到双向</h3>
<p>文件定义了两个主要的类，它们构成了从基础到完全体的演进：</p>
<p>| 特性         | <code>YOLOWorldPAFPN</code> (基础版)                    | <code>YOLOWorldDualPAFPN</code> (完全体)              |</p>
<p>| ------------ | -------------------------------------------- | ------------------------------------------ |</p>
<p>| <strong>继承关系</strong> | 继承自 <code>YOLOv8PAFPN</code>                         | 继承自 <code>YOLOWorldPAFPN</code>                    |</p>
<p>| <strong>交互逻辑</strong> | <strong>单向引导</strong>：Text → Image                   | <strong>双向引导</strong>：Text ↔ Image                 |</p>
<p>| <strong>核心组件</strong> | 带有 <code>guide_channels</code> 的 CSP 模块            | CSP 模块 + <code>text_enhancer</code> (文本增强器)    |</p>
<p>| <strong>论文对应</strong> | RepVL-PAN 的基本结构                         | 完整的 RepVL-PAN，包含图像池化注意力       |</p>
<p>| <strong>数据流</strong>   | 文本特征在 Top-down/Bottom-up 中作为辅助输入 | 在 Top-down 后利用图像特征动态更新文本特征 |</p>
<hr>
<h3 id="3-模块间的前后联系（枢纽地位）"><a class="header-anchor" href="#3-模块间的前后联系（枢纽地位）"></a>3. 模块间的前后联系（枢纽地位）</h3>
<p>在 YOLO-World 的整个工作流中，PAFPN 起到了承上启下的枢纽作用：</p>
<ul>
<li>
<p><strong>上游 (Input)</strong>：</p>
</li>
<li>
<p>从 <strong>Backbone</strong> 接收 3 个尺度的原始图像特征图（P3, P4, P5）。</p>
</li>
<li>
<p>从 <strong>Text Encoder</strong> 接收处理好的文本 Embedding (<code>txt_feats</code>)。</p>
</li>
<li>
<p><strong>中游 (Processing)</strong>：</p>
</li>
<li>
<p>在 <code>forward</code> 过程中，通过卷积和注意力机制，将文本语义“点对点”地融合进图像特征图中。</p>
</li>
<li>
<p><strong>下游 (Output)</strong>：</p>
</li>
<li>
<p>输出融合后的 3 尺度特征图给 <strong>Head</strong>。此时的特征图已经能够区分“哪个区域更像文本描述的物体”了。</p>
</li>
</ul>
<hr>
<h3 id="4-论文中的算法对应"><a class="header-anchor" href="#4-论文中的算法对应"></a>4. 论文中的算法对应</h3>
<p>如果你对着 YOLO-World 的论文看，你会发现这个文件精确实现了以下概念：</p>
<ul>
<li>
<p><strong>Text-guided CSPLayers</strong>：对应 <code>build_top_down_layer</code> 和 <code>build_bottom_up_layer</code> 中通过 <code>block_cfg</code> 实例化的模块。这些模块内部实现了视觉特征与文本特征的线性交互。</p>
</li>
<li>
<p><strong>Image-Pooling Attention</strong>：对应 <code>YOLOWorldDualPAFPN</code> 中的 <code>self.text_enhancer</code>。论文指出，由于文本 Embedding 通常是离线生成的，缺乏对当前图片的感知，因此需要利用图像特征通过 Max-Pooling 和 Attention 来增强文本的判别力。</p>
</li>
<li>
<p><strong>Re-parameterization (重参数化)</strong>：虽然代码中体现的是动态计算，但其设计允许在推理时将文本特征与卷积层权重合并。这解释了为什么 <code>YOLOWorldDetector</code> 中有一个 <code>reparameterize</code> 方法。</p>
</li>
</ul>
<hr>
<h3 id="5-总结：你应该掌握的三个关键点"><a class="header-anchor" href="#5-总结：你应该掌握的三个关键点"></a>5. 总结：你应该掌握的三个关键点</h3>
<ol>
<li>
<p><strong>为什么需要这个文件？</strong> 因为要让模型在检测之前就“读懂”我们要找的是什么。</p>
</li>
<li>
<p><strong><code>Dual</code> 强在哪？</strong> 它不仅用文本找图像，还用图像中发现的线索去修正文本的理解（通过 <code>text_enhancer</code>）。</p>
</li>
<li>
<p><strong>代码的巧妙之处：</strong> 它通过继承和配置驱动 (<code>block_cfg</code>)，仅用少量的改动就将成熟的 YOLOv8 结构升级为了开放词汇检测器。</p>
</li>
</ol>
<h1 id="总结2"><a class="header-anchor" href="#总结2"></a>总结2</h1>
<p>下面给你一份对 <strong><code>yolo_world/models/necks/yolo_world_pafpn.py</code></strong> 的“全景式掌握”总结：它实现了什么、两个 class 的联系与区别、在整个项目中的前后关系、以及和论文（RepVL-PAN / I-Pooling Attention / T→I &amp; I→T）之间的对应。</p>
<hr>
<h2 id="1-这份文件整体在实现什么"><a class="header-anchor" href="#1-这份文件整体在实现什么"></a>1) 这份文件整体在实现什么</h2>
<p><strong>一句话：<strong>它实现 YOLO-World 的 “视觉-语言 PAFPN/RepVL-PAN” neck，把 backbone 的多尺度图像特征（<code>img_feats</code>）做 <strong>Reduce → Top-down → Bottom-up → Out</strong> 的 PAN-FPN 聚合，并且在聚合过程中</strong>用文本特征 <code>txt_feats</code> 引导/调制特征融合</strong>；Dual 版本额外加入 <strong>图像→文本（I→T）增强</strong>，形成更“对称”的双向交互。</p>
<p>它解决的核心问题是：<strong>在 YOLOv8 风格的轻量 PAN-FPN 中插入跨模态交互，使得多尺度图像特征携带文本语义，从而支持 open-vocabulary detection/segmentation。</strong></p>
<hr>
<h2 id="2-文件里的两个-class：联系与区别"><a class="header-anchor" href="#2-文件里的两个-class：联系与区别"></a>2) 文件里的两个 class：联系与区别</h2>
<h3 id="A-YOLOWorldPAFPN（基础版本）"><a class="header-anchor" href="#A-YOLOWorldPAFPN（基础版本）"></a>A. <code>YOLOWorldPAFPN</code>（基础版本）</h3>
<p><strong>定位：</strong>“文本引导的 YOLOv8-PAN 颈部网络”。</p>
<p><strong>关键点：</strong></p>
<ul>
<li>
<p>继承自 <code>YOLOv8PAFPN</code>（或其思想），但它构造的 <code>top_down_layers / bottom_up_layers</code> 的 block <strong>支持 <code>(x, txt_feats)</code> 输入</strong>，即融合块内部可以做文本调制/注意力。</p>
</li>
<li>
<p><code>forward(img_feats, txt_feats=None)</code>：允许推理时传/不传文本（有些模式可能会走离线 vocab / re-parameterization）。</p>
</li>
</ul>
<p><strong>它的交互方向主要是：T→I（文本引导图像特征融合）</strong>：</p>
<ul>
<li>
<p>Top-down：<code>top_down_layers(..., txt_feats)</code></p>
</li>
<li>
<p>Bottom-up：<code>bottom_up_layers(..., txt_feats)</code></p>
</li>
</ul>
<h3 id="B-YOLOWorldDualPAFPN（Dual-版本）"><a class="header-anchor" href="#B-YOLOWorldDualPAFPN（Dual-版本）"></a>B. <code>YOLOWorldDualPAFPN</code>（Dual 版本）</h3>
<p>**定位：**在 <code>YOLOWorldPAFPN</code> 基础上额外引入一个 <code>text_enhancer</code>（默认 <code>ImagePoolingAttentionModule</code>），实现 <strong>I→T（图像增强文本）</strong>。</p>
<p><strong>差异点：</strong></p>
<ul>
<li>
<p><code>__init__</code> 里构建 <code>self.text_enhancer = MODELS.build(text_enhancder)</code>，并把 <code>image_channels / text_channels / num_feats</code> 等形状信息补齐。</p>
</li>
<li>
<p><code>forward</code> 中的关键新增一行：</p>
<p><strong>在 top-down 得到 <code>inner_outs</code> 后，先做：<code>txt_feats = self.text_enhancer(txt_feats, inner_outs)</code></strong></p>
<p>让文本 embedding 变得 <em>image-aware</em>，再进入 bottom-up。</p>
</li>
</ul>
<p><strong>它的交互变成：T→I（top-down）→ I→T（text_enhancer）→ T→I（bottom-up）</strong>。</p>
<p>这比基础版更接近论文图示里的“双向融合”味道。</p>
<hr>
<h2 id="3-YOLOWorldPAFPN-forward-的信息流：你需要在脑中固定的“骨架”"><a class="header-anchor" href="#3-YOLOWorldPAFPN-forward-的信息流：你需要在脑中固定的“骨架”"></a>3) <code>YOLOWorldPAFPN.forward</code> 的信息流：你需要在脑中固定的“骨架”</h2>
<p>无论基础版还是 Dual 版，图像特征主干流程不变：</p>
<ol>
<li>
<p><strong>Reduce</strong>：<code>reduce_layers[idx](img_feats[idx])</code></p>
<p>把 backbone 多尺度输出通道对齐到 neck 期望维度。</p>
</li>
<li>
<p><strong>Top-down</strong>（FPN 部分）：</p>
<p>高层特征上采样 → 与低层特征 concat → <code>top_down_layers(..., txt_feats)</code> 融合</p>
<p>产物：<code>inner_outs</code>（完成 top-down 的多尺度特征）</p>
</li>
<li>
<p><strong>Bottom-up</strong>（PAN 部分）：</p>
<p>高分辨率特征下采样 → 与更低分辨率特征 concat → <code>bottom_up_layers(..., txt_feats)</code> 融合</p>
<p>产物：<code>outs</code></p>
</li>
<li>
<p><strong>Out layers</strong>：<code>out_layers[idx](outs[idx])</code></p>
<p>输出整形给 head 使用（检测头/分割头）。</p>
</li>
</ol>
<p><strong>Dual 版只是在 2) 和 3) 之间插入了一步 I→T：更新 txt_feats。</strong></p>
<hr>
<h2 id="4-这个文件在项目里处在什么位置：前后模块关系"><a class="header-anchor" href="#4-这个文件在项目里处在什么位置：前后模块关系"></a>4) 这个文件在项目里处在什么位置：前后模块关系</h2>
<p>把 YOLO-World 按“数据流”串起来，你会更稳：</p>
<h3 id="前：Data-→-Backbone"><a class="header-anchor" href="#前：Data-→-Backbone"></a>前：Data → Backbone</h3>
<ul>
<li>
<p>数据经过 data_preprocessor（你贴的 <code>YOLOWDetDataPreprocessor</code>）做归一化/增强，并把 <code>data_samples</code> 组织成模型需要的字典格式（含 <code>texts</code> 等字段）。</p>
</li>
<li>
<p>Backbone（在你的工程里是 YOLOv8/Darknet 类或多模态 backbone）输出 <code>img_feats = [C3, C4, C5]</code> 这种多尺度特征。</p>
</li>
</ul>
<h3 id="中：Neck（就是本文件）"><a class="header-anchor" href="#中：Neck（就是本文件）"></a>中：Neck（就是本文件）</h3>
<ul>
<li>本文件的 PAFPN 把 <code>img_feats</code> 聚合成更强的多尺度 <code>neck_feats</code>（同时注入/融合了文本条件）。</li>
</ul>
<h3 id="后：Head（检测-分割）"><a class="header-anchor" href="#后：Head（检测-分割）"></a>后：Head（检测/分割）</h3>
<ul>
<li>
<p>Head 会拿 <code>neck_feats</code> 做：</p>
<ul>
<li>
<p>bbox regression</p>
</li>
<li>
<p>object embedding / similarity（与文本 embedding 做 region-text matching / contrastive）</p>
</li>
</ul>
</li>
<li>
<p>如果你在做 segmentation，后面还会连 segmentation head（你工程里有 <code>yolo_world_seg_head.py</code>）。</p>
</li>
</ul>
<h3 id="训练时的-Assign-Loss"><a class="header-anchor" href="#训练时的-Assign-Loss"></a>训练时的 Assign / Loss</h3>
<ul>
<li>分配策略（你贴的 <code>YOLOWorldSegAssigner</code>）属于 task-aligned assigner 的变体，用于训练阶段把预测和 GT 匹配，并生成 <code>assigned_scores/labels/...</code>。它并不改 neck，但决定了“哪些预测被当作正样本”，进而影响 region-text loss 的学习信号。</li>
</ul>
<hr>
<h2 id="5-这份文件和论文各部分的对应关系"><a class="header-anchor" href="#5-这份文件和论文各部分的对应关系"></a>5) 这份文件和论文各部分的对应关系</h2>
<p>论文的核心在 RepVL-PAN：<strong>T-CSPLayer（文本引导注入到图像） + I-Pooling Attention（图像增强文本） + 可 re-parameterize</strong>。</p>
<h3 id="对应-1：T-CSPLayer-T→I-注入"><a class="header-anchor" href="#对应-1：T-CSPLayer-T→I-注入"></a>对应 1：T-CSPLayer / T→I 注入</h3>
<ul>
<li>
<p>在这份 <code>yolo_world_pafpn.py</code> 里，体现为：</p>
<ul>
<li>
<p><code>top_down_layers(..., txt_feats)</code></p>
</li>
<li>
<p><code>bottom_up_layers(..., txt_feats)</code></p>
</li>
</ul>
</li>
<li>
<p>具体 “怎么注入” 不在这个文件里展开（它把 <code>txt_feats</code> 作为参数传给 block），而是在你配置的 <code>block_cfg[&quot;type&quot;]</code> 对应的模块实现里（例如某种 text-guided CSP/attention block）。</p>
</li>
</ul>
<h3 id="对应-2：I-Pooling-Attention-I→T-更新（Dual-版）"><a class="header-anchor" href="#对应-2：I-Pooling-Attention-I→T-更新（Dual-版）"></a>对应 2：I-Pooling Attention / I→T 更新（Dual 版）</h3>
<ul>
<li>
<p><code>YOLOWorldDualPAFPN</code> 的 <code>text_enhancer</code> 默认就是 <code>ImagePoolingAttentionModule</code>：</p>
<ul>
<li>
<p>多尺度特征池化为固定数量的 patch tokens（<code>pool_size=3</code> → 每尺度 9 tokens，3 尺度共 27 tokens）</p>
</li>
<li>
<p>用 cross-attention：<code>Q=文本，K/V=图像 tokens</code> 更新文本</p>
</li>
</ul>
</li>
<li>
<p>这就对应论文图 4 的 I-Pooling Attention 思路。</p>
</li>
</ul>
<h3 id="对应-3：RepVL-PAN-的“结构外观”"><a class="header-anchor" href="#对应-3：RepVL-PAN-的“结构外观”"></a>对应 3：RepVL-PAN 的“结构外观”</h3>
<ul>
<li>
<p>论文图 4 展示的是在 PAN 结构的多个位置插入 T-CSPLayer 和 I-Pooling Attention。</p>
</li>
<li>
<p>这份代码在“结构层面”对应的就是：</p>
<ul>
<li>
<p>PAN 的 top-down/bottom-up 骨架（YOLOv8 风格）</p>
</li>
<li>
<p>在融合块里做跨模态（T→I）</p>
</li>
<li>
<p>Dual 版额外在 top-down 结束后显式做 I→T（text_enhancer）</p>
</li>
</ul>
</li>
</ul>
<h3 id="对应-4：re-parameterization（部署时离线-vocab）"><a class="header-anchor" href="#对应-4：re-parameterization（部署时离线-vocab）"></a>对应 4：re-parameterization（部署时离线 vocab）</h3>
<ul>
<li>
<p>论文强调 inference 时可以把 text encoder 移除，预编码 prompts，做离线 vocab。</p>
</li>
<li>
<p>这份文件本身不实现“把文本 embedding 写进卷积权重”的 reparam 细节，但它的接口设计（<code>txt_feats</code> 作为外部输入）天然支持：</p>
<ul>
<li>
<p>在线 vocab：每次 forward 传入当前 prompts 的 embedding</p>
</li>
<li>
<p>离线 vocab：预先算好 embedding，推理时直接喂给 <code>txt_feats</code></p>
</li>
</ul>
</li>
<li>
<p>真正的“权重重参数化”通常在具体 block（T-CSPLayer）实现或部署脚本里完成。</p>
</li>
</ul>
<hr>
<h2 id="6-你掌握这份文件需要抓住的“关键抽象”"><a class="header-anchor" href="#6-你掌握这份文件需要抓住的“关键抽象”"></a>6) 你掌握这份文件需要抓住的“关键抽象”</h2>
<ol>
<li>
<p><strong>它是 neck，不负责产生文本 embedding</strong>：<code>txt_feats</code> 来自外部（text encoder / offline vocab）。</p>
</li>
<li>
<p><strong>它只管多尺度特征聚合</strong>：reduce/top-down/bottom-up/out 是固定骨架。</p>
</li>
<li>
<p><strong>跨模态发生在哪里</strong>：</p>
<ul>
<li>
<p>基础版：发生在 <code>top_down_layers</code> / <code>bottom_up_layers</code> 的 block 内部（T→I）。</p>
</li>
<li>
<p>Dual 版：额外显式做一次 I→T（<code>text_enhancer</code>）。</p>
</li>
</ul>
</li>
<li>
<p><strong>它不直接决定分类/匹配 loss</strong>：loss/assign 在 head/assigner；neck 只提供“更语义化、带文本条件”的特征。</p>
</li>
</ol>
<hr>
<h2 id="7-建议你下一步怎么“彻底吃透”它（不学新知识，只是把链路闭环）"><a class="header-anchor" href="#7-建议你下一步怎么“彻底吃透”它（不学新知识，只是把链路闭环）"></a>7) 建议你下一步怎么“彻底吃透”它（不学新知识，只是把链路闭环）</h2>
<p>如果你想把这份文件真正做到“闭眼能复述”，下一步最关键的是确认两件事：</p>
<ol>
<li>
<p><code>block_cfg[&quot;type&quot;]</code> 具体是什么类？（在哪个文件实现）</p>
<ul>
<li>因为它决定了 <code>top_down_layers/bottom_up_layers</code> 如何使用 <code>txt_feats</code>（是门控？是注意力？是 max-sigmoid？）</li>
</ul>
</li>
<li>
<p>Dual 版的 <code>ImagePoolingAttentionModule</code> 的输入输出 shape 在你的训练配置下是否完全一致（尤其是 <code>image_channels</code> 是否与 <code>inner_outs</code> 的 C 对齐）。</p>
</li>
</ol>
<p>你把 <strong><code>block_cfg</code> 对应模块的源码文件名/类名</strong>贴一下，我就能把“txt_feats 在 block 内部到底怎么注入（逐行 + shape 推导）”也补齐，这样你对整个 RepVL-PAN 的代码闭环就完成了。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blog/tags/Yolo-World/">Yolo-World</a></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py"><img class="cover" src="/blog/image/q4SynOBjcxn5gA6.jpeg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">代码解读：yolo_world-models-detectors-yolo_world.py</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  yolo_world yolo_world/models/detectors/yolo_world.py 这份分析将结合 YOLO-World 论文（Cheng et al., 2024）的核心概念，逐行解读 yolo_world/models/detectors/yolo_world.py 代码。 这份代码实现了论文中提出的 YOLO-World...</div></div></div></a><a class="pagination-related" href="/blog/2025/12/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yoloe/%E3%80%90YOLOE%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【YOLOE】论文阅读"><img class="cover" src="/blog/image/cover/5.jpeg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">【YOLOE】论文阅读</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yoloe  </div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py"><img class="cover" src="/blog/image/q4SynOBjcxn5gA6.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">代码解读：yolo_world-models-detectors-yolo_world.py</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  yolo_world yolo_world/models/detectors/yolo_world.py 这份分析将结合 YOLO-World 论文（Cheng et al., 2024）的核心概念，逐行解读 yolo_world/models/detectors/yolo_world.py 代码。 这份代码实现了论文中提出的 YOLO-World...</div></div></div></a><a class="pagination-related" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"><img class="cover" src="/blog/image/A1-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-24</div><div class="info-item-2">论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  1 Introduction 1. 这节在回答什么问题？  现实动机：传统检测器（例如在 COCO 上训练的模型）只能识别固定词表中的类别（COCO 只有80类）。一旦训练好的类别被定死，模型就无法识别不在词表里的目标，这在开放场景里很受限。作者先明确了这个“固定词表的天花板”问题。 需求与挑战：我们需要的是开放词汇检测（Open-Vocabulary...</div></div></div></a><a class="pagination-related" href="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/" title="代码解读：yolo_world-models-dense_heads-yolo_world_head.py"><img class="cover" src="/blog/image/A1-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-01</div><div class="info-item-2">代码解读：yolo_world-models-dense_heads-yolo_world_head.py</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  class ContrastiveHead(BaseModule) 总结 ContrastiveHead的作用  把每个位置的图像特征向量 x[:, :, h, w] 与每个文本类别向量 w[:, k, :] 做点积相似度，得到该位置对每个类别的 logit。 在论文语言里，这就是 region-text matching / text contrastive...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">lian</div><div class="author-info-description">读研，尝试新技术与记录生活。</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qieliqiean"><i class="fab fa-github"></i><span>访问 GitHub</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qieliqiean" target="_blank" title="GitHub"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2895014608@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎交流：2895014608@qq.com</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#class-YOLOWorldPAFPN-YOLOv8PAFPN"><span class="toc-text">class YOLOWorldPAFPN(YOLOv8PAFPN)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init"><span class="toc-text">def init</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-build-top-down-layer"><span class="toc-text">def build_top_down_layer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%8E%9F%E6%96%87"><span class="toc-text">代码原文</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%BD%E6%95%B0%E5%A4%B4"><span class="toc-text">1) 函数头</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B7%B1%E6%8B%B7%E8%B4%9D-block-%E9%85%8D%E7%BD%AE%EF%BC%8C%E9%81%BF%E5%85%8D%E6%B1%A1%E6%9F%93%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE"><span class="toc-text">2) 深拷贝 block 配置，避免污染全局配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%94%A8-update-%E6%8A%8A%E2%80%9C%E8%BF%99%E4%B8%80%E5%B1%82%E2%80%9D%E9%9C%80%E8%A6%81%E7%9A%84%E5%85%B3%E9%94%AE%E8%B6%85%E5%8F%82%E6%95%B0%E8%A1%A5%E9%BD%90"><span class="toc-text">3) 用 update() 把“这一层”需要的关键超参数补齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E8%AE%A1%E7%AE%97-in-channels%EF%BC%9A%E6%9D%A5%E8%87%AA-concat-%E7%9A%84%E9%80%9A%E9%81%93%E6%95%B0"><span class="toc-text">3.1 计算 in_channels：来自 concat 的通道数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E8%AE%A1%E7%AE%97-out-channels%EF%BC%9A%E8%BE%93%E5%87%BA%E5%88%B0-idx-1-%E5%B0%BA%E5%BA%A6%E7%9A%84%E9%80%9A%E9%81%93"><span class="toc-text">3.2 计算 out_channels：输出到 idx-1 尺度的通道</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-YOLO-World-%E7%89%B9%E6%9C%89%EF%BC%9Aguide-channels%EF%BC%88%E6%96%87%E6%9C%AC-%E5%BC%95%E5%AF%BC%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6%EF%BC%89"><span class="toc-text">3.3 YOLO-World 特有：guide_channels（文本&#x2F;引导特征维度）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-embedding-%E7%BB%B4%E5%BA%A6%EF%BC%9A%E6%AF%8F%E4%B8%AA%E5%B0%BA%E5%BA%A6%E4%B8%80%E4%B8%AA"><span class="toc-text">3.4 embedding 维度：每个尺度一个</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-%E5%A4%9A%E5%A4%B4%E6%95%B0%EF%BC%9A%E6%AF%8F%E4%B8%AA%E5%B0%BA%E5%BA%A6%E4%B8%80%E4%B8%AA"><span class="toc-text">3.5 多头数：每个尺度一个</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-CSP-%E5%86%85%E9%83%A8%E5%A0%86%E5%8F%A0%E6%AC%A1%E6%95%B0%EF%BC%9A%E5%8F%97-deepen-factor-%E5%BD%B1%E5%93%8D"><span class="toc-text">3.6 CSP 内部堆叠次数：受 deepen_factor 影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7-add-identity-False%EF%BC%9A%E5%85%B3%E9%97%AD%E6%AE%8B%E5%B7%AE%E6%8D%B7%E5%BE%84"><span class="toc-text">3.7 add_identity&#x3D;False：关闭残差捷径</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-8-norm-act%EF%BC%9A%E6%8A%8A%E8%A7%84%E8%8C%83%E5%8C%96%E5%92%8C%E6%BF%80%E6%B4%BB%E9%85%8D%E7%BD%AE%E4%BC%A0%E8%BF%9B%E5%8E%BB"><span class="toc-text">3.8 norm&#x2F;act：把规范化和激活配置传进去</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%94%B1%E6%B3%A8%E5%86%8C%E8%A1%A8%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9D%97%E5%AE%9E%E4%BE%8B"><span class="toc-text">4) 由注册表构建模块实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-build-bottom-up-layer"><span class="toc-text">def build_bottom_up_layer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%8E%9F%E6%96%87-2"><span class="toc-text">代码原文</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%BD%E6%95%B0%E5%A4%B4-2"><span class="toc-text">1) 函数头</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B7%B1%E6%8B%B7%E8%B4%9D-block-%E6%A8%A1%E6%9D%BF%E9%85%8D%E7%BD%AE"><span class="toc-text">2) 深拷贝 block 模板配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%85%B3%E9%94%AE%EF%BC%9A%E7%BB%99%E8%BF%99%E4%B8%80%E5%B1%82%E8%A1%A5%E9%BD%90%E6%9E%84%E5%BB%BA%E5%8F%82%E6%95%B0"><span class="toc-text">3) 关键：给这一层补齐构建参数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-bottom-up-%E7%9A%84-in-channels%EF%BC%9A%E6%9D%A5%E8%87%AA-concat%EF%BC%88%E4%B8%A4%E4%B8%AA%E9%83%BD%E6%98%AF-out-channels%EF%BC%89"><span class="toc-text">3.1 bottom-up 的 in_channels：来自 concat（两个都是 out_channels）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-out-channels%EF%BC%9A%E5%AF%B9%E9%BD%90%E5%88%B0%E6%9B%B4%E4%BD%8E%E5%88%86%E8%BE%A8%E7%8E%87%E9%82%A3%E5%B1%82%EF%BC%88idx-1%EF%BC%89"><span class="toc-text">3.2 out_channels：对齐到更低分辨率那层（idx+1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-YOLO-World-%E7%89%B9%E6%9C%89%EF%BC%9A%E6%96%87%E6%9C%AC%E5%BC%95%E5%AF%BC%E7%BB%B4%E5%BA%A6"><span class="toc-text">3.3 YOLO-World 特有：文本引导维度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-embed-channels%EF%BC%9A%E6%B3%A8%E6%84%8F%E8%BF%99%E9%87%8C%E7%94%A8%E7%9A%84%E6%98%AF-embed-channels-idx"><span class="toc-text">3.4 embed_channels：注意这里用的是 embed_channels[idx]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-num-heads%EF%BC%9A%E5%90%8C%E6%A0%B7%E6%8C%89-idx-%E5%8F%96"><span class="toc-text">3.5 num_heads：同样按 idx 取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-6-num-blocks%EF%BC%9ACSP-%E5%A0%86%E5%8F%A0%E6%95%B0%E6%8C%89-deepen-factor-%E7%BC%A9%E6%94%BE"><span class="toc-text">3.6 num_blocks：CSP 堆叠数按 deepen_factor 缩放</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-7-add-identity-False"><span class="toc-text">3.7 add_identity&#x3D;False</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-8-%E8%A7%84%E8%8C%83%E5%8C%96%E4%B8%8E%E6%BF%80%E6%B4%BB%E9%85%8D%E7%BD%AE"><span class="toc-text">3.8 规范化与激活配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%94%A8%E6%B3%A8%E5%86%8C%E8%A1%A8%E7%9C%9F%E6%AD%A3%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9D%97"><span class="toc-text">4) 用注册表真正实例化模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bottom-up-vs-top-down-%E7%9A%84%E6%A0%B8%E5%BF%83%E5%B7%AE%E5%BC%82"><span class="toc-text">bottom-up vs top-down 的核心差异</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%BD%E6%95%B0%E5%A4%B4%E4%B8%8E%E6%B3%A8%E9%87%8A"><span class="toc-text">1) 函数头与注释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9F%BA%E6%9C%AC%E4%B8%80%E8%87%B4%E6%80%A7%E6%A3%80%E6%9F%A5"><span class="toc-text">2) 基本一致性检查</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Reduce-%E9%98%B6%E6%AE%B5%EF%BC%9A%E5%85%88%E6%8A%8A%E6%AF%8F%E4%B8%AA%E5%B0%BA%E5%BA%A6%E9%80%9A%E9%81%93%E2%80%9C%E5%AF%B9%E9%BD%90-%E5%8E%8B%E7%BC%A9%E2%80%9D"><span class="toc-text">3) Reduce 阶段：先把每个尺度通道“对齐&#x2F;压缩”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Top-down-%E8%B7%AF%E5%BE%84%EF%BC%9A%E9%AB%98%E5%B1%82%E8%AF%AD%E4%B9%89%E5%90%91%E4%BD%8E%E5%B1%82%E4%BC%A0%E6%92%AD%EF%BC%88%E4%B8%8A%E9%87%87%E6%A0%B7-concat-%E8%9E%8D%E5%90%88%E5%9D%97%EF%BC%89"><span class="toc-text">4) Top-down 路径：高层语义向低层传播（上采样 + concat + 融合块）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-Bottom-up-%E8%B7%AF%E5%BE%84%EF%BC%9A%E4%BD%8E%E5%B1%82%E4%BF%A1%E6%81%AF%E5%90%91%E9%AB%98%E5%B1%82%E5%86%8D%E8%81%9A%E5%90%88%EF%BC%88%E4%B8%8B%E9%87%87%E6%A0%B7-concat-%E8%9E%8D%E5%90%88%E5%9D%97%EF%BC%89"><span class="toc-text">5) Bottom-up 路径：低层信息向高层再聚合（下采样 + concat + 融合块）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-Out-layers%EF%BC%9A%E6%9C%80%E5%90%8E%E5%86%8D%E5%81%9A%E4%B8%80%E5%B1%82%E8%BE%93%E5%87%BA%E6%95%B4%E5%BD%A2%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF-1x1-3x3-conv%EF%BC%89"><span class="toc-text">6) Out layers：最后再做一层输出整形（通常是 1x1&#x2F;3x3 conv）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-YOLOWorldDualPAFPN-YOLOWorldPAFPN"><span class="toc-text">class YOLOWorldDualPAFPN(YOLOWorldPAFPN)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-2"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D%EF%BC%9A%E6%8A%8A-Dual-%E7%89%88%E6%9C%AC%E9%9C%80%E8%A6%81%E7%9A%84%E8%B6%85%E5%8F%82%E9%83%BD%E6%94%B6%E8%BF%9B%E6%9D%A5"><span class="toc-text">1) 函数签名：把 Dual 版本需要的超参都收进来</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-super-init-%EF%BC%9A%E5%85%88%E6%8A%8A%E2%80%9C%E5%9F%BA%E7%A1%80-YOLOWorldPAFPN%E2%80%9D%E5%AE%8C%E6%95%B4%E6%90%AD%E5%87%BA%E6%9D%A5"><span class="toc-text">2) super().__init__(...)：先把“基础 YOLOWorldPAFPN”完整搭出来</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-text-enhancder-update-%EF%BC%9A%E6%8A%8A%E8%BF%90%E8%A1%8C%E6%97%B6%E5%BF%85%E8%A6%81%E7%9A%84%E7%BB%B4%E5%BA%A6%E4%BF%A1%E6%81%AF%E8%A1%A5%E8%BF%9B%E9%85%8D%E7%BD%AE"><span class="toc-text">3) text_enhancder.update(...)：把运行时必要的维度信息补进配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#update-%E6%96%B9%E6%B3%95%EF%BC%9A"><span class="toc-text">update() 方法：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-print-text-enhancder-%EF%BC%9A%E8%B0%83%E8%AF%95%E8%BE%93%E5%87%BA%EF%BC%88%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E6%97%B6%E4%BC%9A%E6%89%93%E5%8D%B0%EF%BC%89"><span class="toc-text">4) print(text_enhancder)：调试输出（训练&#x2F;构建时会打印）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-self-text-enhancer-MODELS-build-text-enhancder-%EF%BC%9A%E7%94%A8%E6%B3%A8%E5%86%8C%E8%A1%A8%E6%8A%8A%E6%A8%A1%E5%9D%97%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%87%BA%E6%9D%A5"><span class="toc-text">5) self.text_enhancer &#x3D; MODELS.build(text_enhancder)：用注册表把模块实例化出来</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-2"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%85%A5%E5%8F%A3%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%A3%80%E6%9F%A5"><span class="toc-text">函数入口与基本检查</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E9%81%93%E7%BC%A9%E5%87%8F%EF%BC%88Reduce-Layers%EF%BC%89"><span class="toc-text">通道缩减（Reduce Layers）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E8%B7%AF%E5%BE%84%EF%BC%88Top-down-Path%EF%BC%89%E2%80%94%E2%80%94-%E6%96%87%E6%9C%AC%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F"><span class="toc-text">自顶向下路径（Top-down Path）—— 文本引导图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dual-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%96%B0%E5%A2%9E-span-style-color-FF0000-%E5%9B%BE%E5%83%8F%E5%BC%95%E5%AF%BC%E6%96%87%E6%9C%AC-span"><span class="toc-text">Dual 的核心新增--图像引导文本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E8%B7%AF%E5%BE%84%EF%BC%88Bottom-up-Path%EF%BC%89%E2%80%94%E2%80%94-%E5%A2%9E%E5%BC%BA%E6%96%87%E6%9C%AC%E5%86%8D%E6%AC%A1%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F"><span class="toc-text">自底向上路径（Bottom-up Path）—— 增强文本再次引导图像</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Out-layers%EF%BC%9A%E8%BE%93%E5%87%BA%E6%95%B4%E5%BD%A2%E5%B9%B6%E8%BF%94%E5%9B%9E"><span class="toc-text">Out layers：输出整形并返回</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%931"><span class="toc-text">总结1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E4%BB%BB%E5%8A%A1%EF%BC%9ARepVL-PAN-%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">1. 核心任务：RepVL-PAN 的实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%B1%BB%E5%85%B3%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB%EF%BC%9A%E4%BB%8E%E5%8D%95%E5%90%91%E5%88%B0%E5%8F%8C%E5%90%91"><span class="toc-text">2. 类关系与区别：从单向到双向</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A8%A1%E5%9D%97%E9%97%B4%E7%9A%84%E5%89%8D%E5%90%8E%E8%81%94%E7%B3%BB%EF%BC%88%E6%9E%A2%E7%BA%BD%E5%9C%B0%E4%BD%8D%EF%BC%89"><span class="toc-text">3. 模块间的前后联系（枢纽地位）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E7%AE%97%E6%B3%95%E5%AF%B9%E5%BA%94"><span class="toc-text">4. 论文中的算法对应</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%80%BB%E7%BB%93%EF%BC%9A%E4%BD%A0%E5%BA%94%E8%AF%A5%E6%8E%8C%E6%8F%A1%E7%9A%84%E4%B8%89%E4%B8%AA%E5%85%B3%E9%94%AE%E7%82%B9"><span class="toc-text">5. 总结：你应该掌握的三个关键点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%932"><span class="toc-text">总结2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E8%BF%99%E4%BB%BD%E6%96%87%E4%BB%B6%E6%95%B4%E4%BD%93%E5%9C%A8%E5%AE%9E%E7%8E%B0%E4%BB%80%E4%B9%88"><span class="toc-text">1) 这份文件整体在实现什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%96%87%E4%BB%B6%E9%87%8C%E7%9A%84%E4%B8%A4%E4%B8%AA-class%EF%BC%9A%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB"><span class="toc-text">2) 文件里的两个 class：联系与区别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-YOLOWorldPAFPN%EF%BC%88%E5%9F%BA%E7%A1%80%E7%89%88%E6%9C%AC%EF%BC%89"><span class="toc-text">A. YOLOWorldPAFPN（基础版本）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#B-YOLOWorldDualPAFPN%EF%BC%88Dual-%E7%89%88%E6%9C%AC%EF%BC%89"><span class="toc-text">B. YOLOWorldDualPAFPN（Dual 版本）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-YOLOWorldPAFPN-forward-%E7%9A%84%E4%BF%A1%E6%81%AF%E6%B5%81%EF%BC%9A%E4%BD%A0%E9%9C%80%E8%A6%81%E5%9C%A8%E8%84%91%E4%B8%AD%E5%9B%BA%E5%AE%9A%E7%9A%84%E2%80%9C%E9%AA%A8%E6%9E%B6%E2%80%9D"><span class="toc-text">3) YOLOWorldPAFPN.forward 的信息流：你需要在脑中固定的“骨架”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%BF%99%E4%B8%AA%E6%96%87%E4%BB%B6%E5%9C%A8%E9%A1%B9%E7%9B%AE%E9%87%8C%E5%A4%84%E5%9C%A8%E4%BB%80%E4%B9%88%E4%BD%8D%E7%BD%AE%EF%BC%9A%E5%89%8D%E5%90%8E%E6%A8%A1%E5%9D%97%E5%85%B3%E7%B3%BB"><span class="toc-text">4) 这个文件在项目里处在什么位置：前后模块关系</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%EF%BC%9AData-%E2%86%92-Backbone"><span class="toc-text">前：Data → Backbone</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%AD%EF%BC%9ANeck%EF%BC%88%E5%B0%B1%E6%98%AF%E6%9C%AC%E6%96%87%E4%BB%B6%EF%BC%89"><span class="toc-text">中：Neck（就是本文件）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%EF%BC%9AHead%EF%BC%88%E6%A3%80%E6%B5%8B-%E5%88%86%E5%89%B2%EF%BC%89"><span class="toc-text">后：Head（检测&#x2F;分割）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%97%B6%E7%9A%84-Assign-Loss"><span class="toc-text">训练时的 Assign &#x2F; Loss</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E8%BF%99%E4%BB%BD%E6%96%87%E4%BB%B6%E5%92%8C%E8%AE%BA%E6%96%87%E5%90%84%E9%83%A8%E5%88%86%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"><span class="toc-text">5) 这份文件和论文各部分的对应关系</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94-1%EF%BC%9AT-CSPLayer-T%E2%86%92I-%E6%B3%A8%E5%85%A5"><span class="toc-text">对应 1：T-CSPLayer &#x2F; T→I 注入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94-2%EF%BC%9AI-Pooling-Attention-I%E2%86%92T-%E6%9B%B4%E6%96%B0%EF%BC%88Dual-%E7%89%88%EF%BC%89"><span class="toc-text">对应 2：I-Pooling Attention &#x2F; I→T 更新（Dual 版）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94-3%EF%BC%9ARepVL-PAN-%E7%9A%84%E2%80%9C%E7%BB%93%E6%9E%84%E5%A4%96%E8%A7%82%E2%80%9D"><span class="toc-text">对应 3：RepVL-PAN 的“结构外观”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%BA%94-4%EF%BC%9Are-parameterization%EF%BC%88%E9%83%A8%E7%BD%B2%E6%97%B6%E7%A6%BB%E7%BA%BF-vocab%EF%BC%89"><span class="toc-text">对应 4：re-parameterization（部署时离线 vocab）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E4%BD%A0%E6%8E%8C%E6%8F%A1%E8%BF%99%E4%BB%BD%E6%96%87%E4%BB%B6%E9%9C%80%E8%A6%81%E6%8A%93%E4%BD%8F%E7%9A%84%E2%80%9C%E5%85%B3%E9%94%AE%E6%8A%BD%E8%B1%A1%E2%80%9D"><span class="toc-text">6) 你掌握这份文件需要抓住的“关键抽象”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%BB%BA%E8%AE%AE%E4%BD%A0%E4%B8%8B%E4%B8%80%E6%AD%A5%E6%80%8E%E4%B9%88%E2%80%9C%E5%BD%BB%E5%BA%95%E5%90%83%E9%80%8F%E2%80%9D%E5%AE%83%EF%BC%88%E4%B8%8D%E5%AD%A6%E6%96%B0%E7%9F%A5%E8%AF%86%EF%BC%8C%E5%8F%AA%E6%98%AF%E6%8A%8A%E9%93%BE%E8%B7%AF%E9%97%AD%E7%8E%AF%EF%BC%89"><span class="toc-text">7) 建议你下一步怎么“彻底吃透”它（不学新知识，只是把链路闭环）</span></a></li></ol></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py"><img src="/blog/image/q4SynOBjcxn5gA6.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-detectors-yolo_world.py"></a><div class="content"><a class="title" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py">代码解读：yolo_world-models-detectors-yolo_world.py</a><time datetime="2025-12-18T02:04:06.000Z" title="发表于 2025-12-18 10:04:06">2025-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/" title="代码解读：yolo_world-models-necks-yolo_world_pafpn.py"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-necks-yolo_world_pafpn.py"></a><div class="content"><a class="title" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/" title="代码解读：yolo_world-models-necks-yolo_world_pafpn.py">代码解读：yolo_world-models-necks-yolo_world_pafpn.py</a><time datetime="2025-12-18T02:04:06.000Z" title="发表于 2025-12-18 10:04:06">2025-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/" title="代码解读：yolo_world-models-dense_heads-yolo_world_head.py"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-dense_heads-yolo_world_head.py"></a><div class="content"><a class="title" href="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/" title="代码解读：yolo_world-models-dense_heads-yolo_world_head.py">代码解读：yolo_world-models-dense_heads-yolo_world_head.py</a><time datetime="2025-12-01T03:04:06.000Z" title="发表于 2025-12-01 11:04:06">2025-12-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"></a><div class="content"><a class="title" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection">论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection</a><time datetime="2025-10-24T07:19:06.000Z" title="发表于 2025-10-24 15:19:06">2025-10-24</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/easter-egg/" title="彩蛋"><img src="/blog/image/cover/IMG_20260217_201822.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="彩蛋"/></a><div class="content"><a class="title" href="/blog/easter-egg/" title="彩蛋">彩蛋</a><time datetime="2026-02-18T05:09:03.000Z" title="发表于 2026-02-18 13:09:03">2026-02-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/21/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/WeDetect/%E3%80%90WeDetect%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【WeDetect】论文阅读"><img src="/blog/image/cover/9.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="【WeDetect】论文阅读"/></a><div class="content"><a class="title" href="/blog/2026/01/21/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/WeDetect/%E3%80%90WeDetect%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【WeDetect】论文阅读">【WeDetect】论文阅读</a><time datetime="2026-01-21T01:41:58.000Z" title="发表于 2026-01-21 09:41:58">2026-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/20/AI%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="AI使用手册"><img src="/blog/image/cover/13.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="AI使用手册"/></a><div class="content"><a class="title" href="/blog/2026/01/20/AI%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="AI使用手册">AI使用手册</a><time datetime="2026-01-20T01:21:48.000Z" title="发表于 2026-01-20 09:21:48">2026-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/19/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/OV-DQUO/%E3%80%90OV-DQUO%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【OV-DQUO】论文阅读"><img src="/blog/image/cover/2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="【OV-DQUO】论文阅读"/></a><div class="content"><a class="title" href="/blog/2026/01/19/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/OV-DQUO/%E3%80%90OV-DQUO%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【OV-DQUO】论文阅读">【OV-DQUO】论文阅读</a><time datetime="2026-01-19T07:59:50.000Z" title="发表于 2026-01-19 15:59:50">2026-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/14/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/YOLO-UniOW/%E3%80%90YOLO-UniOW%E3%80%91%E6%8C%87%E6%A0%87%E8%A7%A3%E9%87%8A/" title="YOLO-UniOW-指标解释"><img src="/blog/image/cover/6.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="YOLO-UniOW-指标解释"/></a><div class="content"><a class="title" href="/blog/2026/01/14/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/YOLO-UniOW/%E3%80%90YOLO-UniOW%E3%80%91%E6%8C%87%E6%A0%87%E8%A7%A3%E9%87%8A/" title="YOLO-UniOW-指标解释">YOLO-UniOW-指标解释</a><time datetime="2026-01-14T01:44:34.000Z" title="发表于 2026-01-14 09:44:34">2026-01-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 - 2026 By lian</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">岁岁平，岁岁安，岁岁平安</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><script src="/blog/true"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark_dimmed' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qieliqiean/blog',
      'data-repo-id': 'R_kgDONvpdYw',
      'data-category-id': 'DIC_kwDONvpdY84C1DqB',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script defer src="/blog/js/site.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>