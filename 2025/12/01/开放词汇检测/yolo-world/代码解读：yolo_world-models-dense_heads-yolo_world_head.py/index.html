<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>代码解读：yolo_world-models-dense_heads-yolo_world_head.py | 且离且安的碎碎念</title><meta name="author" content="lian"><meta name="copyright" content="lian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#fdfcf8"><meta name="description" content="系列文章   &#x2F;   开放词汇检测 &#x2F; yolo-world  class ContrastiveHead(BaseModule) 总结 ContrastiveHead的作用  把每个位置的图像特征向量 x[:, :, h, w] 与每个文本类别向量 w[:, k, :] 做点积相似度，得到该位置对每个类别的 logit。 在论文语言里，这就是 region-text matching &#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="代码解读：yolo_world-models-dense_heads-yolo_world_head.py">
<meta property="og:url" content="https://qieliqiean.github.io/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/index.html">
<meta property="og:site_name" content="且离且安的碎碎念">
<meta property="og:description" content="系列文章   &#x2F;   开放词汇检测 &#x2F; yolo-world  class ContrastiveHead(BaseModule) 总结 ContrastiveHead的作用  把每个位置的图像特征向量 x[:, :, h, w] 与每个文本类别向量 w[:, k, :] 做点积相似度，得到该位置对每个类别的 logit。 在论文语言里，这就是 region-text matching &#x2F;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qieliqiean.github.io/blog/image/A1-2.jpg">
<meta property="article:published_time" content="2025-12-01T03:04:06.000Z">
<meta property="article:modified_time" content="2026-02-18T11:59:46.445Z">
<meta property="article:author" content="lian">
<meta property="article:tag" content="Yolo-World">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qieliqiean.github.io/blog/image/A1-2.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "代码解读：yolo_world-models-dense_heads-yolo_world_head.py",
  "url": "https://qieliqiean.github.io/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/",
  "image": "https://qieliqiean.github.io/blog/image/A1-2.jpg",
  "datePublished": "2025-12-01T03:04:06.000Z",
  "dateModified": "2026-02-18T11:59:46.445Z",
  "author": [
    {
      "@type": "Person",
      "name": "lian",
      "url": "https://qieliqiean.github.io/blog/"
    }
  ]
}</script><link rel="shortcut icon" href="/blog/image/1.jpg"><link rel="canonical" href="https://qieliqiean.github.io/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="stylesheet" href="/blog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0f172a')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fdfcf8')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')
          
          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6b5d1303d19816191830cd73eccfdb1e";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/blog/',
  algolia: undefined,
  localSearch: {"path":"/blog/search.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '代码解读：yolo_world-models-dense_heads-yolo_world_head.py',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=LXGW+WenKai:wght@400;700&family=Noto+Serif+SC:wght@400;600;700&display=swap" rel="stylesheet"><link rel="stylesheet" href="/blog/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/easter-egg/"><i class="fa-fw fas fa-egg"></i><span> 彩蛋</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(/image/A1-2.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/blog/"><span class="site-name">且离且安的碎碎念</span></a><a class="nav-page-title" href="/blog/"><span class="site-name">代码解读：yolo_world-models-dense_heads-yolo_world_head.py</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/blog/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/blog/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/blog/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/blog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/blog/easter-egg/"><i class="fa-fw fas fa-egg"></i><span> 彩蛋</span></a></div><div class="menus_item"><a class="site-page" href="/blog/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">代码解读：yolo_world-models-dense_heads-yolo_world_head.py</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-01T03:04:06.000Z" title="发表于 2025-12-01 11:04:06">2025-12-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-18T11:59:46.445Z" title="更新于 2026-02-18 19:59:46">2026-02-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/blog/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">45.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>189分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><nav class="series-breadcrumb" aria-label="系列导航">
  <a href="/blog/series/">系列文章</a>
  <span class="series-breadcrumb__sep">/</span>
  <a href="/blog/series/5byA5pS-6K-N5rGH5qOA5rWLIC8geW9sby13b3JsZA/">开放词汇检测 / yolo-world</a>
</nav>
<h1 id="class-ContrastiveHead-BaseModule"><a class="header-anchor" href="#class-ContrastiveHead-BaseModule"></a>class ContrastiveHead(BaseModule)</h1>
<h2 id="总结"><a class="header-anchor" href="#总结"></a>总结</h2>
<h3 id="ContrastiveHead的作用"><a class="header-anchor" href="#ContrastiveHead的作用"></a>ContrastiveHead的作用</h3>
<blockquote>
<p><strong>把每个位置的图像特征向量 <code>x[:, :, h, w]</code> 与每个文本类别向量 <code>w[:, k, :]</code> 做点积相似度，得到该位置对每个类别的 logit。</strong></p>
<p>在论文语言里，这就是 region-text matching / text contrastive head。</p>
</blockquote>
<h3 id="ContrastiveHead-forward-x-w-的输入输出与形状"><a class="header-anchor" href="#ContrastiveHead-forward-x-w-的输入输出与形状"></a>ContrastiveHead.forward(x, w) 的输入输出与形状</h3>
<h4 id="输入"><a class="header-anchor" href="#输入"></a>输入</h4>
<ul>
<li>
<p><code>x: Tensor</code>：来自检测头分类分支的 <strong>图像 embedding 特征图</strong></p>
<p><span style="color:#FF0000">(来自 Neck 网络（RepVL-PAN）输出的图像特征图)</span>
形状：<code>[B, C, H, W]</code></p>
<ul>
<li><code>B</code>：batch size</li>
<li><code>C</code>：<code>embed_dims</code>（不是 num_classes！）</li>
<li><code>H, W</code>：当前特征层分辨率（例如 P3/P4/P5 对应不同尺度）</li>
</ul>
<hr>
</li>
<li>
<p><code>w: Tensor</code>：文本 encoder（CLIP text encoder 等）输出的 <strong>文本 embedding</strong>（一批“在线词表/离线词表”）</p>
<p><span style="color:#FF0000">(来自文本编码器（如 CLIP）提取的类别单词的向量)</span></p>
<p>形状：<code>[B, K, C]</code>（代码里 einsum 分支假设是 <code>bkc</code>）</p>
<ul>
<li><code>K</code>：这一批样本里参与匹配的文本 token/类别数（训练时通常是 online vocabulary，推理时可用 offline vocabulary）</li>
</ul>
</li>
</ul>
<hr>
<h4 id="关于embed-dims"><a class="header-anchor" href="#关于embed-dims"></a>关于embed_dims</h4>
<blockquote>
<p><code>x:[B, C, H, W]</code>与<code>w:[B, K, C]</code>中的<code>c</code>都是<code>embed_dims</code></p>
<ul>
<li>图像 embedding：<code>[B, embed_dims, H, W]</code></li>
<li>文本 embedding：<code>[B, K, embed_dims]</code></li>
</ul>
<p>它做的事只有一句话：</p>
<blockquote>
<p>在 <code>embed_dims</code> 维空间里，比较“这块图像”和“这段文字”像不像。</p>
</blockquote>
<p>所以：</p>
<ul>
<li><code>embed_dims</code> 必须 <strong>同时适配图像和文本</strong></li>
<li>这也是为什么文本 embedding 通常来自 CLIP 或同构投影层</li>
</ul>
<hr>
<p>❌ 误解 1：embed_dims ≈ num_classes</p>
<p>❌ 误解 2：embed_dims = backbone 输出通道数</p>
</blockquote>
<h4 id="输出"><a class="header-anchor" href="#输出"></a>输出</h4>
<ul>
<li><code>cls_logit: Tensor</code>：得到一张“响应图”，图上的每个点都代表了：<em>这个像素点属于某个词（如“猫”）的概率有多大</em>。</li>
<li>形状：<code>[B, K, H, W]</code>（代码里就是 <code>bkhw</code>）</li>
</ul>
<blockquote>
<p>这就是你后面在 loss 里看到的 <code>cls_scores</code>（每个 level 一个 <code>[B,K,H,W]</code>），只是变量名会变来变去让人烦躁。<span id="my-anchor2"></span></p>
</blockquote>
<h3 id="ContrastiveHead-在整个-head-里的“前后连接关系”"><a class="header-anchor" href="#ContrastiveHead-在整个-head-里的“前后连接关系”"></a>ContrastiveHead 在整个 head 里的“前后连接关系”</h3>
<p>它在<span style="color:#FF0000"> YOLOWorldHeadModule</span> 里被当成 <code>cls_contrasts[i]</code></p>
<p>YOLOWorldHeadModule 初始化时会为每个尺度建三套东西：</p>
<ul>
<li><code>self.cls_preds[i]</code>：把 <code>img_feat</code> → <code>cls_embed</code>（通道变成 embed_dims）</li>
<li><code>self.reg_preds[i]</code>：回归分支</li>
<li><code>self.cls_contrasts[i]</code>：就是 <code>ContrastiveHead</code> 或 <code>BNContrastiveHead</code>（负责 <code>cls_embed + txt_feat → cls_logit</code>）</li>
</ul>
<p>在 forward_single 里看到的链路就是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img_feat -&gt; cls_pred -&gt; cls_embed -&gt; cls_contrast(ContrastiveHead) + txt_feat -&gt; cls_logit</span><br></pre></td></tr></table></figure>
<h3 id="和-BNContrastiveHead-RepBNContrastiveHead-的关系"><a class="header-anchor" href="#和-BNContrastiveHead-RepBNContrastiveHead-的关系"></a>和 BNContrastiveHead / RepBNContrastiveHead 的关系</h3>
<ul>
<li><strong>BNContrastiveHead</strong>：
只把 <code>ContrastiveHead</code> 里的 <code>x</code> 侧 L2 normalize 换成 BN：<code>x = self.norm(x)</code>；<code>w</code> 仍然 L2 normalize；输出仍是 <code>[B,K,H,W]</code>。</li>
<li><strong>RepBNContrastiveHead</strong>：
不吃文本 <code>w</code>，只做 <code>BN + 1×1 Conv</code>，输出 <code>[B, num_guide_embeds, H, W]</code>，更像“把某种匹配固化/重参数化”的路线。
它会在 <code>RepYOLOWorldHeadModule</code> 里替换掉 <code>cls_contrasts</code>，使得 <code>cls_logit = cls_contrast(cls_embed)</code>（不再需要 txt_feat）。</li>
</ul>
<h2 id="def-init"><a class="header-anchor" href="#def-init"></a>def <strong>init</strong></h2>
<hr>
<h3 id="1-ContrastiveHead-类定义与初始化"><a class="header-anchor" href="#1-ContrastiveHead-类定义与初始化"></a>1) <code>ContrastiveHead</code> 类定义与初始化</h3>
<p><code>ContrastiveHead</code> 的作用就是把 <strong>图像特征图上的每个位置（region / pixel）</strong> 和 <strong>文本类别向量（prompts）</strong> 做相似度匹配，输出一个“分类 logit 特征图”：</p>
<ul>
<li>
<p>输入：</p>
<ul>
<li><code>x</code>: 图像侧 embedding feature map，形状通常是 <strong><code>[B, C, H, W]</code></strong></li>
<li><code>w</code>: 文本侧 embedding（每张图的类别词向量），形状通常是 <strong><code>[B, K, C]</code></strong></li>
</ul>
</li>
<li>
<p>输出：</p>
<ul>
<li><code>cls_logit</code>: 每个位置对每个文本类别的 logit，形状 <strong><code>[B, K, H, W]</code></strong></li>
</ul>
</li>
</ul>
<p>你可以把它理解成：YOLOv8 把分类头最后一层输出 “num_classes 个通道”，YOLO-World 则把分类这件事改成 <strong>“region embedding vs text embedding 的对比匹配”</strong>。</p>
<hr>
<h3 id="2-逐行解析"><a class="header-anchor" href="#2-逐行解析"></a>2) 逐行解析</h3>
<p>源码片段如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ContrastiveHead</span>(<span class="title class_ inherited__">BaseModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 init_cfg: OptConfigType = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_einsum: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(init_cfg=init_cfg)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros([]))</span><br><span class="line">        <span class="variable language_">self</span>.logit_scale = nn.Parameter(torch.ones([]) * np.log(<span class="number">1</span> / <span class="number">0.07</span>))</span><br><span class="line">        <span class="variable language_">self</span>.use_einsum = use_einsum</span><br></pre></td></tr></table></figure>
<p><strong><code>@MODELS.register_module()</code></strong></p>
<ul>
<li><strong>基础概念：</strong> 这是 Python 中的一个“装饰器”。</li>
<li><strong>通俗解释：</strong> 想象你有一个大型的乐高仓库（MMDetection 框架）。这个装饰器就像是在乐高零件上贴个标签，告诉仓库：“嘿，我这儿有个叫 <code>ContrastiveHead</code> 的新零件，以后在配置文件里写这个名字，你就能找到我并把我组装起来。”</li>
</ul>
<hr>
<p><strong><code>class ContrastiveHead(BaseModule):</code></strong></p>
<ul>
<li><strong>基础概念：</strong> 这是类的继承。<code>BaseModule</code> 是 MMEngine 提供的一个基础类，它帮我们处理了很多模型初始化和保存的琐碎工作。</li>
<li><strong>通俗解释：</strong> 我们在 <code>BaseModule</code> 的基础上，穿上了一层专门处理“对比（Contrastive）”任务的马甲。</li>
</ul>
<hr>
<p><code>def __init__(..., embed_dims: int, init_cfg..., use_einsum: bool=True)</code></p>
<ul>
<li><code>embed_dims</code>：图文共同的 embedding 维度（比如 512）。
<strong>注意</strong>：这里并没有显式存 <code>self.embed_dims</code>，因为这个 head 本身不需要用它建层（它只做 normalize + 相似度），真正的 channel 对齐是在上游 <code>cls_pred</code> 那个 <code>Conv2d(..., out_channels=self.embed_dims, ...)</code> 做的。</li>
<li><code>init_cfg</code>：mmengine 的初始化配置（可选）。</li>
<li><code>use_einsum</code>：是否用 <code>torch.einsum</code> 实现匹配（更简洁；某些部署/导出场景可能会关掉走 matmul 分支）。</li>
</ul>
<hr>
<p><code>super().__init__(init_cfg=init_cfg)</code></p>
<ul>
<li>调用 <code>BaseModule</code> 的构造函数，让 mmengine 能管理初始化、权重加载等机制。</li>
</ul>
<hr>
<p><code>self.bias = nn.Parameter(torch.zeros([]))</code></p>
<ul>
<li><strong><code>torch.zeros([])</code></strong>：这会创建一个全为零的张量，<code>[]</code>表示这个张量没有任何维度，也就是一个标量（scalar）。简单来说，它就是一个值为零的数。</li>
<li><strong><code>nn.Parameter()</code></strong>：<code>nn.Parameter</code>是PyTorch中的一个类，它是<code>Tensor</code>的子类。将张量封装成<code>nn.Parameter</code>后，PyTorch会将它视为模型的可学习参数（trainable parameter）。这样，<code>self.bias</code>就会成为该模型的参数之一，在训练过程中会自动计算梯度。</li>
<li>最终会加到所有类别、所有空间位置的 logit 上：
    <span id="mjx-3bc9fb7">
      <style>
      #mjx-3bc9fb7{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="16.887ex" height="2.4ex" role="img" focusable="false" viewBox="0 -811 7464.1 1061" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(746.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1802.6,0)"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(2664.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(3165,0)"><path data-c="27E8" d="M333 -232Q332 -239 327 -244T313 -250Q303 -250 296 -240Q293 -233 202 6T110 250T201 494T296 740Q299 745 306 749L309 750Q312 750 313 750Q331 750 333 732Q333 727 243 489Q152 252 152 250T243 11Q333 -227 333 -232Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3554,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4126,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4570.7,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(441.3,17) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5286.7,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740Q95 733 186 494T278 250T187 6T92 -240Q85 -250 75 -250Q67 -250 62 -245T55 -232Q55 -227 145 11Q236 248 236 250T145 489Q55 727 55 732Z"></path></g><g data-mml-node="mo" transform="translate(5897.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(6898.1,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>s</mi><mo>=</mo><mi>α</mi><mo>⋅</mo><mo fence="false" stretchy="false">⟨</mo><mrow data-mjx-texclass="ORD"><mover><mi>x</mi><mo stretchy="false">^</mo></mover></mrow><mo>,</mo><mrow data-mjx-texclass="ORD"><mover><mi>w</mi><mo stretchy="false">^</mo></mover></mrow><mo fence="false" stretchy="false">⟩</mo><mo>+</mo><mi>β</mi></math></mjx-assistive-mml></mjx-container>
    </span>
  这里的 (
    <span id="mjx-8f49d71">
      <style>
      #mjx-8f49d71{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="1.281ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 566 899" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>β</mi></math></mjx-assistive-mml></mjx-container>
    </span>
  ) 就是这个 <code>bias</code>。</li>
</ul>
<p>为什么 bias 用标量？</p>
<ul>
<li>因为这里的 logit 本质是“相似度”，整体平移一下就够了；不像普通分类头那样每类一套 bias。它也更贴近 CLIP 的 logit_bias / temperature 思路。</li>
</ul>
<hr>
<p><code>self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))</code></p>
<ul>
<li>
<p>这也是一个 <strong>标量参数</strong>，但它存的是 <strong>log(scale)</strong>。</p>
</li>
<li>
<p>初始化为 <code>log(1/0.07)</code>，你可以把它理解为复用了 CLIP 常用的温度 <code>0.07</code>：</p>
<ul>
<li>scale ≈ 1 / 0.07 ≈ 14.2857</li>
<li>代码里后面会用 <code>self.logit_scale.exp()</code> 得到正的 scale（避免 scale 变负、训练更稳定）。</li>
</ul>
</li>
</ul>
<p>它的作用是什么？</p>
<ul>
<li>
<p>对比学习/相似度分类里，logit 的幅度非常关键：</p>
<ul>
<li>scale 太小：softmax 太“平”，梯度弱，学不动</li>
<li>scale 太大：softmax 太“尖”，容易早早饱和/不稳定</li>
</ul>
</li>
<li>
<p>让模型自己学一个 <code>logit_scale</code>（而不是固定温度）通常更稳。</p>
</li>
</ul>
<hr>
<p><code>self.use_einsum = use_einsum</code></p>
<ul>
<li>
<p><strong>基础概念：</strong> 这是一个布尔开关（True 或 False）。</p>
<p><strong>通俗解释：</strong> 决定等会儿用哪种“数学算法”来算相似度。<code>einsum</code> 是一种非常强大、简洁的矩阵计算方式，我们稍后在 <code>forward</code> 函数里会看到它。</p>
</li>
</ul>
<h2 id="def-forward"><a class="header-anchor" href="#def-forward"></a>def forward</h2>
<p>对于 <code>ContrastiveHead</code> 来说，它的输入有两个：<strong>图像特征</strong>和<strong>文本特征</strong>，输出是它们之间的<strong>匹配分数</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, w: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward function of contrastive learning.&quot;&quot;&quot;</span></span><br><span class="line">    x = F.normalize(x, dim=<span class="number">1</span>, p=<span class="number">2</span>)</span><br><span class="line">    w = F.normalize(w, dim=-<span class="number">1</span>, p=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.use_einsum:</span><br><span class="line">        x = torch.einsum(<span class="string">&#x27;bchw,bkc-&gt;bkhw&#x27;</span>, x, w)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        batch, channel, height, width = x.shape</span><br><span class="line">        _, k, _ = w.shape</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)  <span class="comment"># bchw-&gt;bhwc</span></span><br><span class="line">        x = x.reshape(batch, -<span class="number">1</span>, channel)  <span class="comment"># bhwc-&gt;b(hw)c</span></span><br><span class="line">        w = w.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># bkc-&gt;bck</span></span><br><span class="line">        x = torch.matmul(x, w)</span><br><span class="line">        x = x.reshape(batch, height, width, k)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    x = x * <span class="variable language_">self</span>.logit_scale.exp() + <span class="variable language_">self</span>.bias</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="输入-2"><a class="header-anchor" href="#输入-2"></a>输入</h3>
<ul>
<li><code>x</code>: 图像特征（region embedding map），常见形状 <code>[Batch, Channel, Height, Width]</code>（批次, 通道, 高, 宽）。</li>
<li><code>w</code>: 文本特征（类别/prompt embedding），常见形状 <strong><code>[B, K, C]</code></strong>
<ul>
<li><code>K</code> = 文本类别数/提示词数（open-vocab 下可变）</li>
<li><code>C</code> 必须和 <code>x</code> 的通道维一致（都是 embedding 维度）</li>
</ul>
</li>
</ul>
<h3 id="输出-2"><a class="header-anchor" href="#输出-2"></a>输出</h3>
<p>最终输出要变成：<strong><code>[B, K, H, W]</code></strong>（每个空间位置对每个文本类别的相似度 logit）。</p>
<hr>
<h3 id="操作：通道归一化"><a class="header-anchor" href="#操作：通道归一化"></a>操作：通道归一化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = F.normalize(x, dim=<span class="number">1</span>, p=<span class="number">2</span>)</span><br><span class="line">w = F.normalize(w, dim=-<span class="number">1</span>, p=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><code>x = F.normalize(x, dim=1, p=2)</code></p>
<ul>
<li>对 <strong>channel 维 <code>C</code></strong> 做 L2 归一化（<code>dim=1</code> 对应 <code>[B, C, H, W]</code> 的 C）。</li>
<li>归一化后，每个位置 <code>(h,w)</code> 的向量 <code>x[:, :, h, w]</code> 变成单位向量。</li>
<li>目的：把后面的点积变成<strong>余弦相似度</strong>（cosine similarity）的形式，稳定训练、避免特征幅度主导相似度。</li>
</ul>
<hr>
<p><code>w = F.normalize(w, dim=-1, p=2)</code></p>
<ul>
<li>对文本向量的最后一维 <code>C</code> 做 L2 归一化（<code>dim=-1</code> 对应 <code>[B, K, C]</code> 的 C）。</li>
<li>同理，把每个类别向量 <code>w[:, k, :]</code> 变成单位向量。</li>
</ul>
<blockquote>
<p>到这里：后续的点积 ≈ cosine similarity（但还会乘温度/scale）</p>
</blockquote>
<h3 id="操作：相似度计算（两种等价实现）"><a class="header-anchor" href="#操作：相似度计算（两种等价实现）"></a>操作：相似度计算（两种等价实现）</h3>
<h4 id="方法1"><a class="header-anchor" href="#方法1"></a>方法1</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.use_einsum:</span><br><span class="line">    x = torch.einsum(<span class="string">&#x27;bchw,bkc-&gt;bkhw&#x27;</span>, x, w)</span><br></pre></td></tr></table></figure>
<p>把图像每个位置的 embedding 和每个文本类别 embedding 做点积。</p>
<hr>
<p><strong><code>torch.einsum('bchw,bkc-&gt;bkhw', x, w)</code></strong>：</p>
<ul>
<li>
<p><code>x</code> 和 <code>w</code> 是输入的两个张量，<code>einsum</code> 用来进行它们的乘法运算和维度变换。</p>
</li>
<li>
<p><code>'bchw,bkc-&gt;bkhw'</code> 是一个字符串表示的爱因斯坦求和约定，描述了张量的维度如何进行乘法和变换。具体解释如下：</p>
<ul>
<li><code>'bchw'</code>：表示张量 <code>x</code> 的维度为 <code>(batch_size, channel, height, width)</code>。</li>
<li><code>'bkc'</code>：表示张量 <code>w</code> 的维度为 <code>(batch_size, k, channel)</code>。</li>
<li><code>'bkhw'</code>：表示输出张量的维度为 <code>(batch_size, k, height, width)</code>，这是目标维度。</li>
</ul>
</li>
<li>
<p><code>b</code>: Batch（批次）对齐。</p>
</li>
<li>
<p><code>c</code>: Channel（通道）进行相乘并求和（点积）（因为图片是 <code>bchw</code>，文字是 <code>bkc</code>，它们在 <code>c</code> 这个维度重合了）。</p>
</li>
<li>
<p><code>h, w</code>: 图像的高宽保留。</p>
</li>
<li>
<p><code>k</code>: 文本的类别维度保留。</p>
</li>
<li>
<p>输出 <code>x</code> 形状变成：<strong><code>[B, K, H, W]</code></strong></p>
</li>
</ul>
<p>直观理解：对每个 batch 的每个空间位置 <code>(h,w)</code>，和每个类别 <code>k</code> 做 <code>dot(x_vec, w_vec)</code>。</p>
<blockquote>
<h5 id="示例"><a class="header-anchor" href="#示例"></a><strong>示例</strong></h5>
<p>⚠️ <strong>einsum 的隐式规则</strong>：</p>
<blockquote>
<p><strong>凡是只出现在输入、不出现在输出的维度 → 被“求和消掉”</strong></p>
</blockquote>
<p>这里：</p>
<ul>
<li><code>c</code> 在输入里出现</li>
<li><code>c</code> 在输出里 <strong>没有</strong></li>
</ul>
<p>👉 所以：<strong>沿着 <code>c</code> 维做求和（点积）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;B = <span class="number">1</span></span><br><span class="line">&gt;C = <span class="number">2</span></span><br><span class="line">&gt;H = <span class="number">1</span></span><br><span class="line">&gt;W = <span class="number">1</span></span><br><span class="line">&gt;K = <span class="number">3</span></span><br><span class="line">&gt;<span class="comment">#----------图像特征x:bchw-----------</span></span><br><span class="line">&gt;x.shape = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">&gt;x[<span class="number">0</span>, :, <span class="number">0</span>, <span class="number">0</span>] = [<span class="number">1.0</span>, <span class="number">2.0</span>] <span class="comment">#表示：这个像素点的 embedding 是 [1, 2]</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment">#----------文本特征w:bkc-----------</span></span><br><span class="line">&gt;w.shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">&gt;w[<span class="number">0</span>] =</span><br><span class="line">&gt;[</span><br><span class="line"> [<span class="number">1.0</span>, <span class="number">0.0</span>],   <span class="comment"># 类别 0</span></span><br><span class="line"> [<span class="number">0.0</span>, <span class="number">1.0</span>],   <span class="comment"># 类别 1</span></span><br><span class="line"> [<span class="number">1.0</span>, <span class="number">1.0</span>],   <span class="comment"># 类别 2</span></span><br><span class="line">&gt;]</span><br><span class="line">&gt;<span class="comment">#---------开始手算-----------</span></span><br><span class="line">&gt;out = torch.einsum(<span class="string">&#x27;bchw,bkc-&gt;bkhw&#x27;</span>, x, w)</span><br><span class="line">&gt;out.shape = (<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">&gt;<span class="comment">#====类别 0==</span></span><br><span class="line">&gt;[<span class="number">1</span>, <span class="number">2</span>] · [<span class="number">1</span>, <span class="number">0</span>] = <span class="number">1</span>*<span class="number">1</span> + <span class="number">2</span>*<span class="number">0</span> = <span class="number">1</span></span><br><span class="line">&gt;<span class="comment">#====类别 1==</span></span><br><span class="line">&gt;[<span class="number">1</span>, <span class="number">2</span>] · [<span class="number">0</span>, <span class="number">1</span>] = <span class="number">1</span>*<span class="number">0</span> + <span class="number">2</span>*<span class="number">1</span> = <span class="number">2</span></span><br><span class="line">&gt;<span class="comment">#====类别 2==</span></span><br><span class="line">&gt;[<span class="number">1</span>, <span class="number">2</span>] · [<span class="number">1</span>, <span class="number">1</span>] = <span class="number">1</span>*<span class="number">1</span> + <span class="number">2</span>*<span class="number">1</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">&gt;out[<span class="number">0</span>, :, <span class="number">0</span>, <span class="number">0</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="可运行的伪代码"><a class="header-anchor" href="#可运行的伪代码"></a>可运行的伪代码</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="keyword">import</span> torch</span><br><span class="line">&gt;<span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment"># ===== 1. 构造一个极小的输入 =====</span></span><br><span class="line">&gt;<span class="comment"># B=1, C=2, H=1, W=1</span></span><br><span class="line">&gt;x = torch.tensor([[[[<span class="number">1.0</span>]],   <span class="comment"># channel 0</span></span><br><span class="line">                  [[<span class="number">2.0</span>]]]]) <span class="comment"># channel 1</span></span><br><span class="line">&gt;<span class="comment"># x.shape = (1, 2, 1, 1)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment"># B=1, K=3, C=2</span></span><br><span class="line">&gt;w = torch.tensor([[</span><br><span class="line">   [<span class="number">1.0</span>, <span class="number">0.0</span>],   <span class="comment"># 类别 0</span></span><br><span class="line">   [<span class="number">0.0</span>, <span class="number">1.0</span>],   <span class="comment"># 类别 1</span></span><br><span class="line">   [<span class="number">1.0</span>, <span class="number">1.0</span>],   <span class="comment"># 类别 2</span></span><br><span class="line">&gt;]])</span><br><span class="line">&gt;<span class="comment"># w.shape = (1, 3, 2)</span></span><br><span class="line"></span><br><span class="line">&gt;<span class="comment"># ===== 2. 模拟 ContrastiveHead 中的 normalize =====</span></span><br><span class="line">&gt;x = F.normalize(x, dim=<span class="number">1</span>)</span><br><span class="line">&gt;w = F.normalize(w, dim=-<span class="number">1</span>)</span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;x:&quot;</span>, x)</span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;x的c维:&quot;</span>,x[<span class="number">0</span>, :, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;w:&quot;</span>, w)</span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;w的c维:&quot;</span>,w[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">&gt;<span class="comment"># ===== 3. einsum：核心一行 =====</span></span><br><span class="line">&gt;out = torch.einsum(<span class="string">&#x27;bchw,bkc-&gt;bkhw&#x27;</span>, x, w)</span><br><span class="line"></span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;输出形状:&quot;</span>, out.shape)</span><br><span class="line">&gt;<span class="built_in">print</span>(<span class="string">&quot;输出内容:\n&quot;</span>, out)</span><br><span class="line">&gt;<span class="built_in">print</span>(out[<span class="number">0</span>, :, <span class="number">0</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&gt;x: tensor([[[[0.4472]],</span><br><span class="line"></span><br><span class="line">        [[0.8944]]]])</span><br><span class="line">&gt;x的c维: tensor([0.4472, 0.8944])</span><br><span class="line">&gt;w: tensor([[[1.0000, 0.0000],</span><br><span class="line">        [0.0000, 1.0000],</span><br><span class="line">        [0.7071, 0.7071]]])</span><br><span class="line">&gt;w的c维: tensor([[1.0000, 0.0000],</span><br><span class="line">       [0.0000, 1.0000],</span><br><span class="line">       [0.7071, 0.7071]])</span><br><span class="line">&gt;输出形状: torch.Size([1, 3, 1, 1])</span><br><span class="line">&gt;输出内容:</span><br><span class="line">tensor([[[[0.4472]],</span><br><span class="line"></span><br><span class="line">        [[0.8944]],</span><br><span class="line"></span><br><span class="line">        [[0.9487]]]])</span><br><span class="line">&gt;tensor([0.4472, 0.8944, 0.9487])</span><br><span class="line"></span><br><span class="line">&gt;进程已结束，退出代码为 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<h4 id="方法2"><a class="header-anchor" href="#方法2"></a>方法2</h4>
<p><code>else:</code> 分支：不用 einsum 时，手动 reshape + matmul</p>
<p>这是为了兼容那些不支持 <code>einsum</code> 的推理框架。它通过一系列的 <code>permute</code>（交换维度）和 <code>reshape</code>（改变形状），把图像和文本变成标准的矩阵，然后用普通的矩阵乘法 <code>torch.matmul</code> 来计算相似度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">batch, channel, height, width = x.shape <span class="comment">#拿到 B,C,H,W</span></span><br><span class="line">_, k, _ = w.shape <span class="comment">#拿到 K（类别数）</span></span><br><span class="line">x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)  <span class="comment"># 把 x从 [B, C, H, W] 变成 [B, H, W, C]</span></span><br><span class="line">x = x.reshape(batch, -<span class="number">1</span>, channel)  </span><br><span class="line"><span class="comment"># bhwc-&gt;b(hw)c |把空间 (H,W) 拉平：HW = H*W</span></span><br><span class="line"></span><br><span class="line">w = w.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># bkc-&gt;bck</span></span><br><span class="line">x = torch.matmul(x, w) <span class="comment">#[B, HW, C] @ [B, C, K] -&gt; [B, HW, K]</span></span><br><span class="line">x = x.reshape(batch, height, width, k) <span class="comment">#[B, HW, K] -&gt; [B, H, W, K]</span></span><br><span class="line">x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>) <span class="comment">#[B, H, W, K] -&gt; [B, K, H, W]</span></span><br><span class="line"><span class="comment">#回到和 einsum 分支一致的输出形状</span></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="操作：温度缩放-bias"><a class="header-anchor" href="#操作：温度缩放-bias"></a>操作：温度缩放 + bias</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = x * <span class="variable language_">self</span>.logit_scale.exp() + <span class="variable language_">self</span>.bias</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>self.logit_scale</code> 存的是 log(scale)，这里 <code>exp()</code> 得到 <strong>正的 scale</strong>（可学习温度的倒数）</p>
</li>
<li>
<p><code>self.bias</code> 是一个标量 bias（全局平移 logit）</p>
</li>
<li>
<p>这行代码先对 <code>x</code> 进行 <strong>缩放</strong>（乘以指数化后的 <code>logit_scale</code>），然后再加上一个 <strong>偏置项 <code>bias</code></strong>，调整最终的输出。</p>

    <span id="mjx-8732501">
      <style>
      #mjx-8732501{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="36.817ex" height="2.4ex" role="img" focusable="false" viewBox="0 -811 16273.1 1061" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1278,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1556,0)"></path></g><g data-mml-node="mo" transform="translate(2222.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3278.6,0)"><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path data-c="78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z" transform="translate(444,0)"></path><path data-c="70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z" transform="translate(972,0)"></path></g><g data-mml-node="mo" transform="translate(4806.6,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(4806.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mtext" transform="translate(5195.6,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(1278,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1556,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(1945,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(2445,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(2839,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(3283,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(3783,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(4061,0)"></path></g><g data-mml-node="mo" transform="translate(9700.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10311.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mo" transform="translate(10812,0)"><path data-c="27E8" d="M333 -232Q332 -239 327 -244T313 -250Q303 -250 296 -240Q293 -233 202 6T110 250T201 494T296 740Q299 745 306 749L309 750Q312 750 313 750Q331 750 333 732Q333 727 243 489Q152 252 152 250T243 11Q333 -227 333 -232Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(11201,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(313.8,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11773,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(12217.7,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(441.3,17) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12933.7,0)"><path data-c="27E9" d="M55 732Q56 739 61 744T75 750Q85 750 92 740Q95 733 186 494T278 250T187 6T92 -240Q85 -250 75 -250Q67 -250 62 -245T55 -232Q55 -227 145 11Q236 248 236 250T145 489Q55 727 55 732Z"></path></g><g data-mml-node="mo" transform="translate(13544.9,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mtext" transform="translate(14545.1,0)"><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(556,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(834,0)"></path><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z" transform="translate(1334,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>logit</mtext><mo>=</mo><mi>exp</mi><mo data-mjx-texclass="NONE">⁡</mo><mo stretchy="false">(</mo><mtext>logit_scale</mtext><mo stretchy="false">)</mo><mo>⋅</mo><mo fence="false" stretchy="false">⟨</mo><mrow data-mjx-texclass="ORD"><mover><mi>x</mi><mo stretchy="false">^</mo></mover></mrow><mo>,</mo><mrow data-mjx-texclass="ORD"><mover><mi>w</mi><mo stretchy="false">^</mo></mover></mrow><mo fence="false" stretchy="false">⟩</mo><mo>+</mo><mtext>bias</mtext></math></mjx-assistive-mml></mjx-container>
    </span>
  <p>这一步对训练很关键：scale 控制 softmax 的“尖锐程度”，决定梯度强弱和稳定性。</p>
</li>
<li>
<p>输出形状固定是 <strong><code>[B, K, H, W]</code></strong>，后续会进入 YOLO 的分类损失/匹配流程（在更上层 head 里做 assign、loss 等）。</p>
</li>
</ul>
<hr>
<h1 id="class-BNContrastiveHead-BaseModule"><a class="header-anchor" href="#class-BNContrastiveHead-BaseModule"></a>class BNContrastiveHead(BaseModule)</h1>
<h2 id="总结-2"><a class="header-anchor" href="#总结-2"></a>总结</h2>
<p><strong>BNContrastiveHead = ContrastiveHead + 用 BatchNorm 替代图像特征的 L2 normalize。</strong></p>
<p>换句话说：</p>
<blockquote>
<p>不再把每个像素 embedding 强行压到单位球面，而是让 BN 在 batch 维度上“驯化分布”。</p>
</blockquote>
<p>这不是小改动，这是<strong>优化目标层面的改动</strong>。</p>
<h2 id="def-init-2"><a class="header-anchor" href="#def-init-2"></a>def <strong>init</strong></h2>
<p>先把这一段构造函数贴出来方便对照（与你文件一致）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BNContrastiveHead</span>(<span class="title class_ inherited__">BaseModule</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Batch Norm Contrastive Head for YOLO-World</span></span><br><span class="line"><span class="string">    using batch norm instead of l2-normalization</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dims (int): embed dim of text and image features</span></span><br><span class="line"><span class="string">        norm_cfg (dict): normalization params</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 norm_cfg: ConfigDict,</span></span><br><span class="line"><span class="params">                 init_cfg: OptConfigType = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_einsum: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(init_cfg=init_cfg)</span><br><span class="line">        <span class="variable language_">self</span>.norm = build_norm_layer(norm_cfg, embed_dims)[<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros([]))</span><br><span class="line">        <span class="comment"># use -1.0 is more stable</span></span><br><span class="line">        <span class="variable language_">self</span>.logit_scale = nn.Parameter(-<span class="number">1.0</span> * torch.ones([]))</span><br><span class="line">        <span class="variable language_">self</span>.use_einsum = use_einsum</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>@MODELS.register_module()</code></strong> 和 **<code>class BNContrastiveHead(BaseModule):</code>**这两行和之前完全一样。它们的作用是将这个新零件注册到框架中，并继承基础模块的功能。</li>
</ul>
<ul>
<li><code>embed_dims: int</code>：图像/文本对齐用的 embedding 维度 <code>C</code>（后续 BN 的通道数也就是它）。</li>
<li><code>norm_cfg: ConfigDict</code>：在 Python 中，<code>ConfigDict</code> 就像是一个高级的字典（Dictionary），里面装着“配方”。 既然我们要用 Batch Norm（批归一化），我们就得告诉程序具体用哪种归一化（是普通的 BN，还是层归一化 LN？学习率是多少？）。这些细节都装在 <code>norm_cfg</code> 这个配方本里。</li>
<li><code>init_cfg</code>：mmengine 的初始化配置。</li>
<li><code>use_einsum</code>：forward 时相似度计算是否用 <code>einsum</code>（和 <code>ContrastiveHead</code> 一样的开关）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#调用 BaseModule 的构造，接入 mmengine 的初始化/权重管理体系。</span></span><br><span class="line"><span class="built_in">super</span>().__init__(init_cfg=init_cfg)</span><br><span class="line"></span><br><span class="line"><span class="variable language_">self</span>.norm = build_norm_layer(norm_cfg, embed_dims)[<span class="number">1</span>]</span><br><span class="line"><span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros([]))</span><br><span class="line"><span class="comment"># use -1.0 is more stable</span></span><br><span class="line"><span class="variable language_">self</span>.logit_scale = nn.Parameter(-<span class="number">1.0</span> * torch.ones([]))</span><br><span class="line"><span class="variable language_">self</span>.use_einsum = use_einsum</span><br></pre></td></tr></table></figure>
<p><code>self.norm = build_norm_layer(norm_cfg, embed_dims)[1]</code></p>
<blockquote>
<p><strong>基础概念：</strong> <code>build_norm_layer</code> 是 MM 系列框架提供的一个“工厂函数”。</p>
<p><strong>通俗解释：</strong> 我们把配方（<code>norm_cfg</code>）和要求的维度（<code>embed_dims</code>）交给这个工厂。它会根据要求生产出一个具体的 PyTorch 层（Layer）。</p>
</blockquote>
<ul>
<li><code>build_norm_layer(norm_cfg, embed_dims)</code> 会返回 <code>(layer_name, layer_module)</code> 这样的二元组。</li>
<li>这里取 <code>[1]</code>，拿到真正的 <strong>归一化层模块</strong>（通常是 BatchNorm2d 或 SyncBN 之类），并保存为 <code>self.norm</code>。</li>
<li>这一步的关键意义：<strong>BNContrastiveHead 用 BN 来替代 <code>ContrastiveHead</code> 里的 L2 normalize（对图像特征 <code>x</code>）</strong>。</li>
</ul>
<blockquote>
<p>对比一下：</p>
<ul>
<li><code>ContrastiveHead</code>: <code>x = F.normalize(x, dim=1)</code>（显式 L2）</li>
<li><code>BNContrastiveHead</code>: <code>x = self.norm(x)</code>（用 BN 让特征“标准化”，再去做相似度）</li>
</ul>
</blockquote>
<p><code>self.bias = nn.Parameter(torch.zeros([]))</code></p>
<ul>
<li>一个标量 bias</li>
<li>最终会对所有位置、所有类别的相似度 logits 做整体平移：<code>logits = ... + bias</code>。(同上面一致)</li>
</ul>
<p><code>self.logit_scale = nn.Parameter(-1.0 * torch.ones([]))</code></p>
<ul>
<li>同样是一个标量参数，但这里的初始化不再是 <code>log(1/0.07)</code>，而是 <strong>-1.0</strong>（注释写了“更稳定”）。</li>
<li>forward 里依旧会用 <code>self.logit_scale.exp()</code>，所以初始 scale = <code>exp(-1) ≈ 0.3679</code>，一开始 logits 会更“温和”。</li>
</ul>
<p>直觉上：BN 可能让特征分布的幅度/方差更活跃，若一开始 scale 太大容易导致 logits 过尖、训练不稳，所以用 -1 起步更保守。</p>
<p><code>self.use_einsum = use_einsum</code></p>
<p>保存开关，决定 forward 用 <code>einsum('bchw,bkc-&gt;bkhw')</code> 还是等价实现。</p>
<hr>
<h2 id="def-forward-2"><a class="header-anchor" href="#def-forward-2"></a>def forward</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor, w: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward function of contrastive learning.&quot;&quot;&quot;</span></span><br><span class="line">    x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">    w = F.normalize(w, dim=-<span class="number">1</span>, p=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.use_einsum:</span><br><span class="line">        x = torch.einsum(<span class="string">&#x27;bchw,bkc-&gt;bkhw&#x27;</span>, x, w)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        batch, channel, height, width = x.shape</span><br><span class="line">        _, k, _ = w.shape</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)  <span class="comment"># bchw-&gt;bhwc</span></span><br><span class="line">        x = x.reshape(batch, -<span class="number">1</span>, channel)  <span class="comment"># bhwc-&gt;b(hw)c</span></span><br><span class="line">        w = w.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># bkc-&gt;bck</span></span><br><span class="line">        x = torch.matmul(x, w)</span><br><span class="line">        x = x.reshape(batch, height, width, k)</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    x = x * <span class="variable language_">self</span>.logit_scale.exp() + <span class="variable language_">self</span>.bias</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ul>
<li><code>x</code>: 图像侧特征图，<strong><code>[B, C, H, W]</code></strong></li>
<li><code>w</code>: 文本侧类别向量，<strong><code>[B, K, C]</code></strong></li>
<li>输出：每个空间位置对每个类别的 logit，<strong><code>[B, K, H, W]</code></strong></li>
</ul>
<hr>
<h3 id="操作：F-normalize-与self-norm"><a class="header-anchor" href="#操作：F-normalize-与self-norm"></a>操作：F.normalize()与self.norm()</h3>
<p><code>x = self.norm(x)</code></p>
<ul>
<li>
<p>这里是 BNContrastiveHead 和 ContrastiveHead 最大的差别：</p>
<ul>
<li>ContrastiveHead：<code>F.normalize(x, dim=1, p=2)</code>（对 <strong>channel 维 <code>C</code></strong> 做 L2 归一化（<code>dim=1</code> 对应 <code>[B, C, H, W]</code> 的 C）</li>
<li>BNContrastiveHead：<code>self.norm(x)</code>（对 <code>C</code> 通道做 BatchNorm/SyncBN）</li>
</ul>
</li>
</ul>
<p><code>self.norm</code> 是在 <code>__init__</code> 里用 <code>build_norm_layer(norm_cfg, embed_dims)[1]</code> 构出来的，所以它通常期望输入就是 <code>[B, C, H, W]</code>。</p>
<p>直观效果：</p>
<ul>
<li>这行代码让图像特征 <code>x</code> 通过 Batch Norm 层。它不是简单地把向量长度缩放到 1，而是根据训练数据的统计特性（均值和方差），动态地把特征调整到一个更适合比对的分布。这通常能让模型学到更丰富的表达。</li>
</ul>
<hr>
<p><code>w = F.normalize(w, dim=-1, p=2)</code></p>
<ul>
<li>文本 embedding 仍然做 L2 normalize（对最后一维 <code>C</code>）。</li>
<li>即使图像端用了 BN，文本端的特征（通常来自 CLIP 的 Text Encoder）还是习惯性地缩放到长度为 1 的单位圆上。这样可以保持文本表示的语义纯度</li>
</ul>
<blockquote>
<p>这里的组合可以理解为：
图像侧用 BN 让分布稳、文本侧用 L2 保持类别向量长度一致，避免“某些文本向量更长导致 logit 偏大”。</p>
</blockquote>
<hr>
<h3 id="操作：相似度计算（两种等价实现）-2"><a class="header-anchor" href="#操作：相似度计算（两种等价实现）-2"></a>操作：相似度计算（两种等价实现）</h3>
<p>这部分的计算逻辑（无论走 <code>einsum</code> 还是 <code>matmul</code>）与 <code>ContrastiveHead</code> <strong>完全一致</strong>。</p>
<p>它们的目标都是计算：<strong>[图像特征] 乘以 [文本特征] = [相似度分数矩阵]</strong>。</p>
<p>结果 <code>bkhw</code> 代表：在 <code>Batch</code> 中，第 <code>k</code> 个类别在图像 <code>(h, w)</code> 位置的匹配程度。</p>
<hr>
<h3 id="操作：温度缩放-bias-2"><a class="header-anchor" href="#操作：温度缩放-bias-2"></a>操作：温度缩放 + bias</h3>
<p><strong>代码解读：</strong> 同样进行分数的缩放（乘以 <code>logit_scale</code> 的指数）和偏移（加上 <code>bias</code>）。</p>
<p><strong>通俗讲解：</strong> 虽然计算方式一样，但因为前面用了 BN 处理图像特征，这里的 <code>logit_scale</code> 和 <code>bias</code> 会学习到完全不同的数值，以适应 BN 输出的数值范围。</p>
<hr>
<p>如果你想更“抓住差异点”，一句话总结 BNContrastiveHead 的 forward：
<strong>把图像侧的 L2 normalize 换成 BN（<code>x = self.norm(x)</code>），文本侧仍保持 L2 normalize，其余“图像-文本点积→scale→bias”的流程不变。</strong></p>
<h1 id="class-RepBNContrastiveHead-BaseModule"><a class="header-anchor" href="#class-RepBNContrastiveHead-BaseModule"></a>class RepBNContrastiveHead(BaseModule)</h1>
<h2 id="def-init-3"><a class="header-anchor" href="#def-init-3"></a>def <strong>init</strong></h2>
<p>好，我们开始逐行讲解 <code>class RepBNContrastiveHead(BaseModule)</code>。这段类本身很短，但它在 YOLO-World 里承担的是一种“可替代/可重参数化思路”：<strong>把“图文点积”那种在线匹配，改成直接用 1×1 conv 产出 guide/embedding（更像传统检测头的最后一层）</strong>。</p>
<blockquote>
<p>目的是<strong>在推理（测试）阶段让模型跑得飞快</strong></p>
</blockquote>
<p>先把类的源码贴出来对照：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RepBNContrastiveHead</span>(<span class="title class_ inherited__">BaseModule</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Batch Norm Contrastive Head for YOLO-World</span></span><br><span class="line"><span class="string">    using batch norm instead of l2-normalization</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dims (int): embed dim of text and image features</span></span><br><span class="line"><span class="string">        norm_cfg (dict): normalization params</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 num_guide_embeds: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 norm_cfg: ConfigDict,</span></span><br><span class="line"><span class="params">                 init_cfg: OptConfigType = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(init_cfg=init_cfg)</span><br><span class="line">        <span class="variable language_">self</span>.norm = build_norm_layer(norm_cfg, embed_dims)[<span class="number">1</span>]</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(embed_dims, num_guide_embeds, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward function of contrastive learning.&quot;&quot;&quot;</span></span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="类注释"><a class="header-anchor" href="#类注释"></a>类注释</h3>
<p>它写的是 “Batch Norm Contrastive Head… using batch norm instead of l2-normalization”，但你会发现它<strong>已经不做 text/image 的点积了</strong>；它更像一个“<strong>BN + 1×1 Conv 投影头</strong>”。</p>
<hr>
<h3 id="初始化参数"><a class="header-anchor" href="#初始化参数"></a>初始化参数</h3>
<ul>
<li><code>embed_dims: int</code>：输入特征 <code>x</code> 的通道数 <code>C</code>（embedding 维度）。</li>
<li><code>num_guide_embeds: int</code>(引导嵌入数量)：这对应于你想要检测的<strong>类别数量</strong>。比如你想检测“猫、狗、车”这 3 个词，那 <code>num_guide_embeds</code> 就是 3。<span id="my-anchor"></span></li>
<li><code>norm_cfg: ConfigDict</code>：归一化层配置（BN/SyncBN 等）。</li>
<li><code>init_cfg</code>：mmengine 初始化配置。</li>
</ul>
<h3 id="super-init-init-cfg-init-cfg"><a class="header-anchor" href="#super-init-init-cfg-init-cfg"></a><code>super().__init__(init_cfg=init_cfg)</code></h3>
<p>接入 <code>BaseModule</code>，用于统一初始化/权重加载机制。</p>
<p><code>self.norm = build_norm_layer(norm_cfg, embed_dims)[1]</code></p>
<ul>
<li>通过 mmcv 的 <code>build_norm_layer</code> 生成归一化层（返回 <code>(name, module)</code>），这里取 module。</li>
<li>该层作用于输入 <code>[B, embed_dims, H, W]</code>，对通道做 BN 风格标准化。</li>
</ul>
<hr>
<p><code>self.conv = nn.Conv2d(embed_dims, num_guide_embeds, kernel_size=1)</code></p>
<ul>
<li>
<p>一个 <strong>1×1 卷积</strong>，做通道投影：</p>
<ul>
<li>输入通道：<code>embed_dims</code></li>
<li>输出通道：<code>num_guide_embeds</code></li>
</ul>
</li>
<li>
<p>1×1 conv 的语义：对每个空间位置 <code>(h,w)</code> 做一个线性层，把 <code>C</code> 维向量映射到 <code>num_guide_embeds</code> 维。</p>
</li>
</ul>
<blockquote>
<p><strong>核心知识点：</strong> 这里不再是去计算两个变量的相似度，而是直接定义了一个 <strong>
    <span id="mjx-4b20a15">
      <style>
      #mjx-4b20a15{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 2222.4 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>×</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>
    </span>
   卷积层</strong>。</p>
<p><strong>为什么要用卷积？</strong> 在数学上，图像特征与文本向量的“点积（乘法）”操作，其实等价于一个 
    <span id="mjx-05cc1e2">
      <style>
      #mjx-05cc1e2{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.507ex" role="img" focusable="false" viewBox="0 -666 2222.4 666" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mo>×</mo><mn>1</mn></math></mjx-assistive-mml></mjx-container>
    </span>
   的卷积。</p>
<p><strong>重参数化黑科技：</strong> 在训练时，我们通过复杂的计算得到文本特征；但在推理时，我们可以把这些固定的文本特征直接**“塞进”**这个卷积层的权重（Weight）里。</p>
<p><strong>结果：</strong> 推理时，模型不需要再处理文本，只需要运行这行卷积代码，就像在运行普通的 YOLO 模型一样快。</p>
</blockquote>
<h3 id="def-forward-3"><a class="header-anchor" href="#def-forward-3"></a>def forward</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward function of contrastive learning.&quot;&quot;&quot;</span></span><br><span class="line">    x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><code>x = self.norm(x)</code></p>
<ul>
<li>输入 <code>x</code> 一般是 <code>[B, C, H, W]</code>。</li>
<li>先做 BN/SyncBN，让特征分布更稳定。</li>
</ul>
<p><code>x = self.conv(x)</code></p>
<ul>
<li>
<p>再用 1×1 conv 把通道从 <code>C</code> 投影到 <code>num_guide_embeds</code>：</p>
<ul>
<li><code>[B, C, H, W] -&gt; [B, num_guide_embeds, H, W]</code></li>
</ul>
</li>
</ul>
<p><code>return x</code></p>
<ul>
<li>返回的是一个新的 feature map（不是 <code>[B,K,H,W]</code> 的“类别相似度图”那种输出）。</li>
<li>它更像是“生成 guide embedding / guide logits”的中间或最终表示，供后面别的模块继续用。</li>
</ul>
<hr>
<h3 id="同ContrastiveHead-BNContrastiveHead的对比"><a class="header-anchor" href="#同ContrastiveHead-BNContrastiveHead的对比"></a>同ContrastiveHead / BNContrastiveHead的对比</h3>
<p>对比前两个 head：</p>
<ul>
<li><code>ContrastiveHead / BNContrastiveHead</code>：<strong>需要 text embedding <code>w</code></strong>，输出 <code>[B,K,H,W]</code> 的“图文匹配 logits”</li>
<li><code>RepBNContrastiveHead</code>：<strong>不吃文本 <code>w</code></strong>，只做 <code>BN + 1×1 Conv</code> 输出 <code>[B,num_guide_embeds,H,W]</code></li>
</ul>
<p>所以它更可能用于：</p>
<ul>
<li>“把某种可学习的 guide 表示提前算出来”</li>
<li>或者为了部署/加速，把部分对比计算“固化”为卷积形式（从结构上看，它具备这种潜力）</li>
</ul>
<hr>
<h1 id="class-YOLOWorldHeadModule-YOLOv8HeadModule"><a class="header-anchor" href="#class-YOLOWorldHeadModule-YOLOv8HeadModule"></a>class YOLOWorldHeadModule(YOLOv8HeadModule)</h1>
<h2 id="def-init-4"><a class="header-anchor" href="#def-init-4"></a>def <strong>init</strong></h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOWorldHeadModule</span>(<span class="title class_ inherited__">YOLOv8HeadModule</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Head Module for YOLO-World</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embed_dims (int): embed dim for text feautures and image features</span></span><br><span class="line"><span class="string">        use_bn_head (bool): use batch normalization head</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 *args,</span></span><br><span class="line"><span class="params">                 embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 use_bn_head: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 use_einsum: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 **kwargs</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.embed_dims = embed_dims</span><br><span class="line">        <span class="variable language_">self</span>.use_bn_head = use_bn_head</span><br><span class="line">        <span class="variable language_">self</span>.use_einsum = use_einsum</span><br><span class="line">        <span class="variable language_">self</span>.freeze_all = freeze_all</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br></pre></td></tr></table></figure>
<p><strong><code>class YOLOWorldHeadModule(YOLOv8HeadModule):</code></strong></p>
<ul>
<li><strong>基础概念：</strong> 类继承。</li>
<li><strong>通俗解释：</strong> YOLO-World 并不是从零开始写的，它是站在巨人（YOLOv8）的肩膀上。<code>YOLOv8HeadModule</code> 已经写好了怎么找框（回归），而我们只需要在这个基础上教它怎么认字（对比学习）。</li>
</ul>
<h3 id="初始化参数-2"><a class="header-anchor" href="#初始化参数-2"></a>初始化参数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             *args,</span></span><br><span class="line"><span class="params">             embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             use_bn_head: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             use_einsum: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">             freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             **kwargs</span>) -&gt; <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li><code>*args, **kwargs</code>：<strong>把绝大多数我们不关心的构造参数原封不动交给父类 <code>YOLOv8HeadModule</code></strong>。这通常包含：</li>
<li><code>num_classes</code>、<code>in_channels</code>、<code>featmap_strides</code>、<code>reg_max</code>、<code>norm_cfg</code>、<code>act_cfg</code> 等等（具体由 YOLOv8HeadModule 定义）。</li>
<li><code>embed_dims: int</code>：YOLO-World 的关键增量参数，表示图像特征与文本特征对齐时使用的 embedding 维度 <code>C</code>。</li>
<li><code>use_bn_head</code>：是否使用 <strong>BN 版本的对比头</strong>（也就是 <code>BNContrastiveHead</code>）来替代普通的 L2 normalize 版本（<code>ContrastiveHead</code>）。</li>
<li><code>use_einsum</code>：对比头内部算相似度时是否走 <code>einsum</code> 路径（对应你前面看的 <code>ContrastiveHead/BNContrastiveHead</code> 的 <code>use_einsum</code>）。</li>
<li><code>freeze_all</code>：一个“冻结开关”。它在后续层构建/训练逻辑里通常会用于控制头部参数是否需要 <code>requires_grad=False</code>（具体在哪里用，我们等会儿看 <code>_init_layers</code> / <code>train</code> / 其它函数时就能定位）。</li>
</ul>
<h3 id="属性赋值"><a class="header-anchor" href="#属性赋值"></a>属性赋值</h3>
<p><code>self.embed_dims = embed_dims</code></p>
<p>把 embedding 维度保存下来。<strong>后面 <code>_init_layers()</code> 会用它来构建分类分支输出的 embedding（以及 contrast head）</strong>。</p>
<p><code>self.use_bn_head = use_bn_head</code></p>
<p>保存开关。一般会在 <code>_init_layers()</code> 决定：</p>
<ul>
<li><code>use_bn_head=False</code> → 用 <code>ContrastiveHead</code></li>
<li><code>use_bn_head=True</code> → 用 <code>BNContrastiveHead</code>（图像侧用 BN 归一化）</li>
</ul>
<p><code>self.use_einsum = use_einsum</code></p>
<p>保存开关，后面构建对比头时会把这个开关传进去，让 forward 选择 <code>einsum</code> 或 reshape+matmul。</p>
<p><code>self.freeze_all = freeze_all</code></p>
<p>保存冻结开关。通常用于：</p>
<ul>
<li>训练时把 head 整体 <code>eval()</code> 或者把参数 <code>requires_grad=False</code></li>
<li>或者只冻结某些模块（具体要看后续代码怎么用它）</li>
</ul>
<p><code>super().__init__(*args, **kwargs)</code></p>
<p>最后调用父类 <code>YOLOv8HeadModule</code> 的初始化：</p>
<ul>
<li>父类会完成 YOLOv8 检测头的通用配置保存（<code>num_levels/in_channels/strides/reg_max...</code> 等）</li>
<li>并且通常会触发 <code>_init_layers()</code> 去真正建 <code>cls_preds/reg_preds/...</code> 这些子模块（你下一步要看的地方）</li>
</ul>
<hr>
<h2 id="def-init-weights"><a class="header-anchor" href="#def-init-weights"></a>def init_weights</h2>
<p>这段函数的核心目的：<strong>把分类分支（尤其是对比分类头里的 bias）初始化成一个“合理的先验”，让训练一开始不要到处乱报高置信度。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">self, prior_prob=<span class="number">0.01</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Initialize the weight and bias of PPYOLOE head.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">super</span>().init_weights()</span><br><span class="line">    <span class="keyword">for</span> cls_pred, cls_contrast, stride <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="variable language_">self</span>.cls_preds,</span><br><span class="line">                                              <span class="variable language_">self</span>.cls_contrasts,</span><br><span class="line">                                              <span class="variable language_">self</span>.featmap_strides):</span><br><span class="line">        cls_pred[-<span class="number">1</span>].bias.data[:] = <span class="number">0.0</span>  <span class="comment"># reset bias</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(cls_contrast, <span class="string">&#x27;bias&#x27;</span>):</span><br><span class="line">            nn.init.constant_(</span><br><span class="line">                cls_contrast.bias.data,</span><br><span class="line">                math.log(<span class="number">5</span> / <span class="variable language_">self</span>.num_classes / (<span class="number">640</span> /ride)**<span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p><code>def init_weights(self, prior_prob=0.01):</code></p>
<ul>
<li>定义初始化函数，带一个 <code>prior_prob</code> 参数（默认 0.01）。</li>
<li><strong><code>prior_prob</code> (先验概率)</strong>：这是一个非常微小的数。它的意思是：在模型刚开始看图片时，我们希望它保持谦虚，默认认为图片里“大概率没有物体”，这样可以防止模型在一开始就乱报置信度，导致训练不稳定。</li>
<li>注意：<strong>这个 <code>prior_prob</code> 在本函数体内并没有被使用</strong>（可能是沿用父类/其它 head 的接口习惯保留下来的）。</li>
</ul>
<hr>
<p><code>super().init_weights()</code></p>
<ul>
<li>调父类 <code>YOLOv8HeadModule</code> 的初始化逻辑。</li>
<li>父类一般会初始化回归分支、分类分支卷积的权重/偏置等（以及一些分布回归相关层）。</li>
</ul>
<hr>
<p><code>for cls_pred, cls_contrast, stride in zip(...)</code></p>
<p>这里把三组东西按“特征层级”对齐着遍历：</p>
<blockquote>
<p><strong>通俗解释</strong>：YOLO 会在不同的“层级”（Scale）检测物体。这个循环是说：我们要把每一个检测层级（<code>cls_pred</code>）、对应的对比头（<code>cls_contrast</code>）以及它的步长（<code>stride</code>）都拎出来，挨个进行特殊处理。</p>
</blockquote>
<ul>
<li><code>self.cls_preds</code>：每个 FPN level 的<strong>分类分支卷积序列</strong>（通常是 <code>nn.Sequential(...)</code>）</li>
<li><code>self.cls_contrasts</code>：每个 level 的<strong>对比分类头</strong>（<code>ContrastiveHead</code> / <code>BNContrastiveHead</code> / 或其它）</li>
<li><code>self.featmap_strides</code>：每个 level 的 stride（比如 8/16/32）</li>
</ul>
<hr>
<p><code>cls_pred[-1].bias.data[:] = 0.0  # reset bias</code></p>
<ul>
<li><code>cls_pred</code> 是一个 <code>nn.Sequential</code>，<code>cls_pred[-1]</code> 取最后一层（通常是最后那个 <code>Conv2d</code>）。</li>
</ul>
<blockquote>
<p><code>.bias</code></p>
<ul>
<li>每个神经网络层（如卷积层、全连接层）通常都有一个 <strong>偏置</strong>（bias）项，用来调整该层的输出。通过 <code>.bias</code> 属性可以访问这个偏置</li>
</ul>
<p><code>.data</code></p>
<ul>
<li><code>.data</code> 是一个属性，返回的是 <strong>张量的原始数据</strong>。它绕过了 PyTorch 的自动求导系统，用来直接访问或修改张量的数据。</li>
<li><strong>注意：</strong> <code>data</code> 属性不推荐在最新的 PyTorch 版本中使用，因为直接操作 <code>data</code> 可能会绕过计算图，导致梯度计算不正确。通常建议使用 <code>with torch.no_grad()</code> 来进行类似操作。</li>
</ul>
<p><code>[:] = 0.0</code></p>
<ul>
<li><code>[:]</code> 是一种切片操作，它表示选择张量中的所有元素。也就是说，<code>cls_pred[-1].bias.data[:]</code> 表示选择最后一层的 <strong>所有偏置值</strong>。</li>
<li><code>= 0.0</code> 将 <strong>所有偏置值</strong> 设置为 <code>0.0</code>。这就是重置偏置的操作。</li>
</ul>
</blockquote>
<ul>
<li>为什么要“reset”？因为 YOLO-World 这里分类不是直接用这个 conv 输出 <code>num_classes</code> logits，而是让它输出 <strong>embedding</strong>，再交给 <code>cls_contrast</code> 去和文本向量做相似度；所以这层的 bias 与传统“类别先验”意义不同，先清零更干净。</li>
</ul>
<hr>
<p><code>if hasattr(cls_contrast, 'bias'):</code></p>
<ul>
<li>
<p>只有当 <code>cls_contrast</code> 这个头<strong>真的有 <code>bias</code> 参数</strong>时才初始化它。</p>
</li>
<li>
<p>例如：</p>
<ul>
<li><code>ContrastiveHead</code> / <code>BNContrastiveHead</code>：有 <code>self.bias</code>（标量）✅</li>
<li>如果某些变体没有 bias（或接口不同），这里就会跳过。</li>
</ul>
</li>
</ul>
<p><code>nn.init.constant_(cls_contrast.bias.data, math.log(...))</code></p>
<p>这一句是关键：给对比头的 <strong>标量 bias</strong> 设置一个常数初值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">math.log(<span class="number">5</span> / <span class="variable language_">self</span>.num_classes / (<span class="number">640</span> / stride)**<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>把它拆开理解：</p>
<ul>
<li>
<p><code>640</code>：这里默认参考输入尺度 640（YOLO 系里非常常见的训练/推理尺寸基准）。</p>
</li>
<li>
<p><code>640 / stride</code>：对应这个 feature level 的特征图边长（近似），比如：</p>
<ul>
<li>stride=8 → 80</li>
<li>stride=16 → 40</li>
<li>stride=32 → 20</li>
</ul>
</li>
<li>
<p><code>(640 / stride)**2</code>：这个 level 上大约有多少个空间位置（cells）。（<code>**2</code>是平方运算）</p>
</li>
<li>
<p><code>self.num_classes</code>：类别数（open-vocab 时也可能代表训练时的 base 类别规模）。</p>
</li>
<li>
<p><code>5 / (num_classes * #cells)</code>：可以把它看成一个先验：<strong>每张图大概有 5 个正样本目标</strong>，均匀摊到“所有类别 × 所有位置”上，每个 logit 的先验正概率非常小。</p>
</li>
<li>
<p>再取 <code>log(...)</code>：把小概率映射到 logit 偏置的尺度上（让初始输出整体偏负，避免一开始满屏高分）。</p>
</li>
</ul>
<blockquote>
<p>小结：这一步是在给 <code>cls_contrast</code> 的输出做一个“负向先验”，让模型训练初期更稳、更不容易炸。</p>
</blockquote>
<h2 id="def-init-layers"><a class="header-anchor" href="#def-init-layers"></a>def _init_layers</h2>
<hr>
<h3 id="操作：创建三个分支容器"><a class="header-anchor" href="#操作：创建三个分支容器"></a>操作：创建三个分支容器</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_layers</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;initialize conv layers in YOLOv8 head.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Init decouple head</span></span><br><span class="line">        <span class="variable language_">self</span>.cls_preds = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.reg_preds = nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.cls_contrasts = nn.ModuleList()</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>基础概念：</strong> <code>nn.ModuleList()</code>。</p>
<p><strong>通俗讲解：</strong> 这是一个专门装 PyTorch 层的“智能列表”。你不能用 Python 原生的列表 <code>[]</code> 来装神经网络层，因为那样 PyTorch 就找不到这些层，没法更新参数了
<span style="color:#FF0000">【详细语法知识已整理】</span></p>
</blockquote>
<ul>
<li><code>cls_preds</code>：每个 FPN level 的<strong>分类 embedding 分支</strong>（注意：输出不是 <code>num_classes</code>，而是 <code>embed_dims</code>）。</li>
<li><code>reg_preds</code>：每个 level 的<strong>回归分支</strong>（输出 <code>4 * reg_max</code>，用于 DFL 分布回归）。</li>
<li><code>cls_contrasts</code>：每个 level 的<strong>对比头</strong>（<code>ContrastiveHead</code> 或 <code>BNContrastiveHead</code>），负责把 image embedding 和 text embedding 做相似度得到 <code>[B,K,H,W]</code> logits。</li>
</ul>
<hr>
<h3 id="操作：计算回归-分类分支的中间通道数"><a class="header-anchor" href="#操作：计算回归-分类分支的中间通道数"></a>操作：计算回归/分类分支的中间通道数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reg_out_channels = <span class="built_in">max</span>((<span class="number">16</span>, <span class="variable language_">self</span>.in_channels[<span class="number">0</span>] // <span class="number">4</span>, <span class="variable language_">self</span>.reg_max * <span class="number">4</span>))</span><br><span class="line">cls_out_channels = <span class="built_in">max</span>(<span class="variable language_">self</span>.in_channels[<span class="number">0</span>], <span class="variable language_">self</span>.num_classes)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>reg_out_channels</code>：回归塔的“隐藏通道数”，取三者最大值。</p>
<ul>
<li><code>16</code>：这是一个常数，表示回归任务（例如目标框的预测）输出通道的最小值。</li>
<li><code>self.in_channels[0] // 4</code>：<code>self.in_channels[0]</code> 表示输入的通道数（通常是上一层的输出通道数）。这里的 <code>// 4</code> 是对输入通道数进行除以4的操作，目的是将输入的通道数进行缩减。假设输入通道数是 256，那么除以4后的结果是 64。</li>
<li><code>self.reg_max * 4</code>：<code>self.reg_max</code> 是每个边用离散分布（DFL）表示的桶数；<code>self.reg_max * 4</code> 表示预测框的总数，乘以4是因为每个框通常需要四个数值（例如 <code>x, y, w, h</code>）。</li>
</ul>
<p><code>max(16, self.in_channels[0] // 4, self.reg_max * 4)</code> 会选择这三个值中的最大值作为 <code>reg_out_channels</code>。换句话说，<code>reg_out_channels</code> 的输出通道数将取决于以下因素：</p>
<ul>
<li>固定的最小值 16</li>
<li>输入通道数除以4后的值</li>
<li>回归任务最大桶数乘以4后的值</li>
</ul>
<p><strong>目的</strong>：计算回归任务所需的输出通道数。通常，回归任务的输出通道数与每个位置预测的框数（<code>reg_max</code>）和每个框的参数（如 <code>x, y, w, h</code>）相关。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><code>cls_out_channels</code>：分类塔的“隐藏通道数”。</p>
<ul>
<li><code>self.in_channels[0]</code>：表示输入的通道数，通常是上一层的输出通道数。</li>
<li><code>self.num_classes</code>：表示分类任务的类别数，通常是在检测任务中需要预测的目标类别数量（例如 80 类的 COCO 数据集）。</li>
</ul>
<p><code>max(self.in_channels[0], self.num_classes)</code> 会选择输入通道数和类别数中的较大值作为 <code>cls_out_channels</code>。这是因为分类任务的输出通道数至少应该等于类别数（每个类别一个输出通道），但如果输入通道数更大，则输出通道数应该与输入通道数一致。</p>
<p><strong>目的</strong>：计算分类任务所需的输出通道数。通常，分类任务的输出通道数与类别数直接相关，但如果输入通道数更大，则需要保持一致。</p>
</li>
</ul>
<hr>
<h3 id="操作：对每个特征层建一套-head（分类、回归、对比）"><a class="header-anchor" href="#操作：对每个特征层建一套-head（分类、回归、对比）"></a>操作：对每个特征层建一套 head（分类、回归、对比）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels):</span><br></pre></td></tr></table></figure>
<p><code>num_levels</code> 通常对应 P3/P4/P5 … 每层各自一套解耦头参数。</p>
<hr>
<h4 id="回归分支-reg-preds：两层-3×3-一层-1×1-输出分布"><a class="header-anchor" href="#回归分支-reg-preds：两层-3×3-一层-1×1-输出分布"></a>回归分支 reg_preds：两层 3×3 + 一层 1×1 输出分布</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.reg_preds.append(</span><br><span class="line">    nn.Sequential(</span><br><span class="line">        ConvModule(in_channels=<span class="variable language_">self</span>.in_channels[i],</span><br><span class="line">                   out_channels=reg_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg, act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        ConvModule(in_channels=reg_out_channels,</span><br><span class="line">                   out_channels=reg_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg, act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        nn.Conv2d(in_channels=reg_out_channels,</span><br><span class="line">                  out_channels=<span class="number">4</span> * <span class="variable language_">self</span>.reg_max,</span><br><span class="line">                  kernel_size=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>输入：该层特征 <code>self.in_channels[i]</code></p>
</li>
<li>
<p>两个 <code>ConvModule(3×3)</code>：典型 YOLO 解耦塔</p>
</li>
<li>
<p>最后 <code>1×1 conv</code> 输出通道 <code>4 * reg_max</code>：</p>
<ul>
<li>4 表示 l/t/r/b 或 xywh 四个边/参数</li>
<li><code>reg_max</code> 是每个边用离散分布（DFL）表示的桶数</li>
</ul>
</li>
</ul>
<hr>
<h4 id="分类-embedding-分支-cls-preds：两层-3×3-一层-1×1-输出-embed-dims"><a class="header-anchor" href="#分类-embedding-分支-cls-preds：两层-3×3-一层-1×1-输出-embed-dims"></a>分类 embedding 分支 cls_preds：两层 3×3 + 一层 1×1 输出 embed_dims</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.cls_preds.append(</span><br><span class="line">    nn.Sequential(</span><br><span class="line">        ConvModule(in_channels=<span class="variable language_">self</span>.in_channels[i],</span><br><span class="line">                   out_channels=cls_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg, act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        ConvModule(in_channels=cls_out_channels,</span><br><span class="line">                   out_channels=cls_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg, act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        nn.Conv2d(in_channels=cls_out_channels,</span><br><span class="line">                  out_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                  kernel_size=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<p>关键点：最后不是 <code>out_channels=num_classes</code>，而是 <strong><code>out_channels=self.embed_dims</code></strong>。
也就是说：分类塔输出的是“每个位置的图像 embedding”（形状 <code>[B, embed_dims, H, W]</code>），真正变成 <code>[B,K,H,W]</code> 的类别 logits，要交给下面的 <code>cls_contrasts</code> 去和文本向量算相似度。</p>
<hr>
<h4 id="对比头分支-BN版-or-L2版"><a class="header-anchor" href="#对比头分支-BN版-or-L2版"></a>对比头分支---BN版 or L2版</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.use_bn_head:</span><br><span class="line">    <span class="variable language_">self</span>.cls_contrasts.append(</span><br><span class="line">        BNContrastiveHead(<span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                          use_einsum=<span class="variable language_">self</span>.use_einsum))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="variable language_">self</span>.cls_contrasts.append(</span><br><span class="line">        ContrastiveHead(<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                        use_einsum=<span class="variable language_">self</span>.use_einsum))</span><br></pre></td></tr></table></figure>
<ul>
<li><code>use_bn_head=True</code>：图像侧用 BN 标准化（<code>x = self.norm(x)</code>）</li>
<li>否则：图像侧用 L2 normalize（<code>F.normalize(x, dim=1)</code>）</li>
<li><code>use_einsum</code> 会传进去决定相似度计算走 <code>einsum</code> 还是 reshape+matmul。</li>
</ul>
<hr>
<h3 id="操作：注册-DFL-用的投影向量-proj（buffer）"><a class="header-anchor" href="#操作：注册-DFL-用的投影向量-proj（buffer）"></a>操作：注册 DFL 用的投影向量 proj（buffer）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">proj = torch.arange(<span class="variable language_">self</span>.reg_max, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"><span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;proj&#x27;</span>, proj, persistent=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><strong><code>proj = torch.arange(self.reg_max, dtype=torch.float)</code></strong></p>
<ul>
<li>
<p><strong><code>torch.arange(self.reg_max)</code></strong>：</p>
<ul>
<li><code>torch.arange</code> 是 PyTorch 中的一个函数，用于生成一个从 0 到 <code>self.reg_max - 1</code> 的一维张量。<code>self.reg_max</code> 是一个整数，表示该张量的元素个数。</li>
<li>例如，如果 <code>self.reg_max</code> 是 10，那么 <code>torch.arange(self.reg_max)</code> 会返回一个包含 0 到 9 的张量：<code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</code>。</li>
<li><strong><code>dtype=torch.float</code></strong> 指定生成的张量的数据类型为 <code>float</code>（浮点数）。默认情况下，<code>torch.arange</code> 返回的是整型张量，而通过设置 <code>dtype=torch.float</code>，我们强制将其转换为浮点数张量。</li>
</ul>
<p>这行代码的作用是生成一个从 <code>0</code> 到 <code>self.reg_max - 1</code> 的浮点数张量。<code>self.reg_max</code> 的值通常表示回归任务中每个位置上需要预测的框数或离散的最大值数量。</p>
<hr>
</li>
</ul>
<p><strong><code>self.register_buffer('proj', proj, persistent=False)</code></strong></p>
<ul>
<li>
<p><strong><code>self.register_buffer(name, tensor, persistent=False)</code></strong>：</p>
<ul>
<li><code>register_buffer</code> 是 PyTorch <code>nn.Module</code> 中的一个方法，用来注册一个 <strong>常量张量</strong>，将它作为模型的一部分。这个张量不属于模型的参数，因此它不会在训练过程中进行更新（即不会计算梯度），但会被保存到模型的 <code>state_dict</code> 中。</li>
<li><code>name</code> 是注册该张量时的名称，这里是 <code>'proj'</code>，意味着该张量在模型中的名字是 <code>proj</code>。</li>
<li><code>tensor</code> 是要注册的张量，这里是 <code>proj</code>，即上面生成的从 <code>0</code> 到 <code>self.reg_max - 1</code> 的浮点数张量。</li>
<li><code>persistent=False</code> 表示该张量不会持久化到 <code>state_dict</code> 中（即不会被保存到模型的检查点文件中），如果设置为 <code>True</code>，则在保存模型时会将该张量包含在 <code>state_dict</code> 中。</li>
</ul>
<p>这行代码的作用是将 <code>proj</code> 张量注册为一个 <strong>常量缓冲区</strong>（buffer），它是模型的一部分，但是不会在训练过程中更新。</p>
</li>
</ul>
<blockquote>
<p>DFL 解码时常用 <code>softmax(prob) · proj</code> 把离散分布的期望还原成连续距离</p>
</blockquote>
<hr>
<h3 id="操作：冻结整个-head（可选）"><a class="header-anchor" href="#操作：冻结整个-head（可选）"></a>操作：冻结整个 head（可选）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.freeze_all:</span><br><span class="line">    <span class="variable language_">self</span>._freeze_all()</span><br></pre></td></tr></table></figure>
<p>如果你在配置里打开 <code>freeze_all</code>，这里会调用 <code>_freeze_all()</code> 把 head 的参数冻结/置为 eval 等（具体细节就在紧接着的 <code>_freeze_all</code> 函数里）。</p>
<hr>
<h2 id="def-freeze-all"><a class="header-anchor" href="#def-freeze-all"></a>def _freeze_all</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_freeze_all</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Freeze the model.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, _BatchNorm):</span><br><span class="line">            m.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> m.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>这段代码定义了一个名为<code>_freeze_all</code>的方法，其核心功能是<strong>冻结模型中所有参数的更新，并将批归一化层固定为评估模式</strong>，确保模型在训练过程中不发生参数变化。以下是详细解析：</p>
<h3 id="1-方法作用"><a class="header-anchor" href="#1-方法作用"></a>1. 方法作用</h3>
<p><code>_freeze_all</code>的主要目的是“冻结模型”，即让模型的所有参数在训练时不再被优化器更新，通常用于迁移学习、微调或固定部分网络权重的场景（例如仅训练新添加的层，而保持预训练主干网络参数不变）。</p>
<h3 id="2-代码逐句解析"><a class="header-anchor" href="#2-代码逐句解析"></a>2. 代码逐句解析</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.modules():</span><br></pre></td></tr></table></figure>
<ul>
<li><code>self.modules()</code>是PyTorch中<code>nn.Module</code>的内置方法，返回一个迭代器，可遍历当前模块（如<code>YOLOWorldHeadModule</code>）及其所有嵌套的子模块（如卷积层、批归一化层、<code>cls_preds</code>中的子模块等）。通过这个循环，能访问模型的所有组件。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(m, _BatchNorm):</span><br><span class="line">    m.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<ul>
<li><code>_BatchNorm</code>是PyTorch中所有批归一化层（如<code>nn.BatchNorm2d</code>、<code>nn.SyncBatchNorm</code>等）的基类。这里判断当前子模块是否为批归一化层。</li>
<li>若为批归一化层，则调用<code>m.eval()</code>将其设置为<strong>评估模式</strong>。在评估模式下，批归一化层会使用训练阶段计算的“移动均值”和“移动方差”，而不是当前批次的统计量，避免冻结后因批次数据变化导致归一化结果不稳定。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> m.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>m.parameters()</code>返回当前子模块<code>m</code>中所有可学习的参数（如卷积层的权重<code>weight</code>、偏置<code>bias</code>等）。</li>
<li><code>param.requires_grad = False</code>是核心操作：将参数的<code>requires_grad</code>属性设为<code>False</code>，表示该参数在反向传播时不需要计算梯度，优化器也不会更新它。通过遍历所有子模块的参数，实现了<strong>全模型参数冻结</strong>。</li>
</ul>
<h3 id="3-应用场景"><a class="header-anchor" href="#3-应用场景"></a>3. 应用场景</h3>
<p>在代码中，<code>_freeze_all</code>被调用的场景是：</p>
<ul>
<li>当<code>YOLOWorldHeadModule</code>或其派生类（如<code>RepYOLOWorldHeadModule</code>）初始化时，若<code>freeze_all=True</code>，则调用该方法冻结所有参数。</li>
<li>在<code>train</code>方法中，若<code>freeze_all=True</code>，会再次调用该方法，确保模型在训练模式下仍保持冻结状态（避免意外开启参数更新）。</li>
</ul>
<p>这种设计通常用于需要固定检测头参数，仅训练其他部分（如文本特征编码器）的场景，或在微调时保持预训练权重不变。</p>
<h3 id="总结-3"><a class="header-anchor" href="#总结-3"></a>总结</h3>
<p><code>_freeze_all</code>通过遍历模型所有子模块，将批归一化层设为评估模式，并冻结所有参数的梯度计算，实现了模型的完全冻结，确保其在训练过程中参数不被更新，适用于迁移学习或固定部分网络的需求。</p>
<h2 id="def-train"><a class="header-anchor" href="#def-train"></a>def train</h2>
<p>源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, mode=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="built_in">super</span>().train(mode)</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.freeze_all:</span><br><span class="line">        <span class="variable language_">self</span>._freeze_all()</span><br></pre></td></tr></table></figure>
<p><code>super().train(mode)</code></p>
<ul>
<li>这是 PyTorch/nn.Module 的标准接口：切换训练态/评估态。</li>
<li><code>mode=True</code> 时：模块进入训练模式（尤其会影响 BN/Dropout 等层）。</li>
<li><code>mode=False</code> 时：进入 eval 模式。</li>
</ul>
<p><code>if self.freeze_all: self._freeze_all()</code></p>
<ul>
<li>
<p>如果你在配置里把 <code>freeze_all=True</code>，这里会调用 <code>_freeze_all()</code>：</p>
<ul>
<li>通常会把该 head 的参数 <code>requires_grad=False</code></li>
<li>并且对含 BN 的模块做 <code>eval()</code> 以固定统计量（你前面 <code>_freeze_all</code> 已经讲过/马上也能对照）。</li>
</ul>
</li>
<li>
<p>这个设计的意思是：<strong>无论你外部怎么 <code>.train()</code>，只要 freeze_all 打开，就强制冻结 head。</strong></p>
</li>
</ul>
<hr>
<h2 id="def-forward-4"><a class="header-anchor" href="#def-forward-4"></a>def forward</h2>
<p>源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">Tuple</span>[Tensor], txt_feats: Tensor,</span></span><br><span class="line"><span class="params">            txt_masks: Tensor</span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward features from the upstream network.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(img_feats) == <span class="variable language_">self</span>.num_levels</span><br><span class="line">    txt_feats = [txt_feats <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels)]</span><br><span class="line">    txt_masks = [txt_masks <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels)]</span><br><span class="line">    <span class="keyword">return</span> multi_apply(<span class="variable language_">self</span>.forward_single, img_feats, txt_feats,</span><br><span class="line">                       txt_masks, <span class="variable language_">self</span>.cls_preds, <span class="variable language_">self</span>.reg_preds,</span><br><span class="line">                       <span class="variable language_">self</span>.cls_contrasts)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>img_feats: Tuple[Tensor]</code>：这是一个元组（Tuple），装着来自 Neck（比如 PAN）的 3 层特征图（P3, P4, P5），分别对应小、中、大物体。
每个 level 一般是 <code>[B, C_i, H_i, W_i]</code></li>
<li><code>txt_feats: Tensor</code>：文本特征（通常是 <code>[B, K, C_txt]</code>，并且会在内部对齐到 <code>embed_dims</code> 的需求）</li>
<li><code>txt_masks: Tensor</code>：文本 mask（可选语义：哪些 token/类别有效），后面逐层传入 <code>forward_single</code></li>
</ul>
<hr>
<p><code>assert len(img_feats) == self.num_levels</code></p>
<ul>
<li>保证上游给的特征层数正确（比如 3 层就必须对应 P3/P4/P5）。</li>
</ul>
<hr>
<p><code>txt_feats = [txt_feats for _ in range(self.num_levels)]</code></p>
<ul>
<li>把同一份 <code>txt_feats</code> <strong>复制成一个列表</strong>，长度等于 level 数。</li>
<li>目的：后面用 <code>multi_apply</code> 做“逐 level 并行式调用”时，每个 level 都能拿到一份 <code>txt_feats</code>（虽然内容相同）。</li>
<li><strong>通俗讲解</strong>：因为我们要处理 3 层图像特征（小、中、大），而文字特征只有一份。所以我们需要把文字特征“复制”三份，给每一层图像特征都分一份，好让它们“一对一”地去比对。</li>
</ul>
<hr>
<p><code>txt_masks = [txt_masks for _ in range(self.num_levels)]</code></p>
<ul>
<li>同理，把 mask 也复制成逐 level 的列表。</li>
</ul>
<p><code>return multi_apply(self.forward_single, ...)</code></p>
<p>这是这段 forward 的核心：它不会自己在这里算分类/回归，而是把每个 level 的计算委托给 <code>forward_single</code>，并把每层需要的模块也一并传进去：</p>
<p>传入的序列分别是：</p>
<ul>
<li><code>img_feats</code>：每层的图像特征</li>
<li><code>txt_feats</code>：每层同一份文本特征</li>
<li><code>txt_masks</code>：每层同一份 mask</li>
<li><code>self.cls_preds</code>：每层的分类 embedding 分支（nn.Sequential）</li>
<li><code>self.reg_preds</code>：每层的回归分支（nn.Sequential）</li>
<li><code>self.cls_contrasts</code>：每层的对比头（ContrastiveHead/BNContrastiveHead）</li>
</ul>
<p><code>multi_apply</code> 会做的事情可以理解为“zip 逐项喂给 forward_single，然后把每层的输出按类型收集成 list 返回”。</p>
<hr>
<h2 id="def-forward-single"><a class="header-anchor" href="#def-forward-single"></a>def forward_single</h2>
<blockquote>
<p>刚才在 <code>forward</code> 函数里，我们提到了那个分发任务的“工头” <code>multi_apply</code>。而 <code>forward_single</code> 就是每一个“工人”在自己的工作位上具体干的活儿。它负责处理<strong>某一个特定尺度</strong>（比如专门看小物体的那一层）的图像特征，并把它和文字特征进行比对。</p>
</blockquote>
<hr>
<h3 id="函数签名"><a class="header-anchor" href="#函数签名"></a>函数签名</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_single</span>(<span class="params">self, img_feat: Tensor, txt_feat: Tensor,</span></span><br><span class="line"><span class="params">                   txt_masks: Tensor, cls_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   reg_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   cls_contrast: nn.ModuleList</span>) -&gt; <span class="type">Tuple</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li><code>img_feat</code>: 单个尺度的图像特征，形状 <strong>[B, C_in, H, W]</strong></li>
<li><code>txt_feat</code>: 文本特征（类别/提示词向量），常见 <strong>[B, K, C_txt]</strong>（实际会与 <code>embed_dims</code> 对齐）</li>
<li><code>txt_masks</code>: 文本 mask（哪些类别有效），常见 <strong>[B, K]</strong> 或可 reshape 成该形状</li>
<li><code>cls_pred</code>: 该尺度的分类 embedding 分支（一个 <code>nn.Sequential</code>）</li>
<li><code>reg_pred</code>: 该尺度的回归分支（一个 <code>nn.Sequential</code>）</li>
<li><code>cls_contrast</code>: 该尺度的对比头（ContrastiveHead/BNContrastiveHead）</li>
</ul>
<blockquote>
<p><code>cls_pred</code>, <code>reg_pred</code>, <code>cls_contrast</code>: 分别是我们在 <code>_init_layers</code> 里准备好的分类分支、回归分支和对比头。</p>
</blockquote>
<hr>
<h3 id="操作：取-batch-与空间尺寸"><a class="header-anchor" href="#操作：取-batch-与空间尺寸"></a>操作：取 batch 与空间尺寸</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b, _, h, w = img_feat.shape</span><br></pre></td></tr></table></figure>
<ul>
<li><code>b=B</code>，<code>h=H</code>，<code>w=W</code></li>
<li><code>_</code> 是通道数，这里用不到通道的具体值。</li>
</ul>
<hr>
<h3 id="输出1-分类分支-embed-dims"><a class="header-anchor" href="#输出1-分类分支-embed-dims"></a>输出1:分类分支 --embed_dims</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cls_embed = cls_pred(img_feat)</span><br></pre></td></tr></table></figure>
<p><a name="my-point"></a></p>
<ul>
<li><code>cls_pred</code> 输出 <strong>embedding</strong></li>
<li>形状通常变为：<strong>[B, embed_dims, H, W]</strong></li>
<li><span style="color:#FF0000">【在<code>def _init_layers</code>定义】</span></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.cls_preds.append(</span><br><span class="line">    nn.Sequential(</span><br><span class="line">        ConvModule(in_channels=<span class="variable language_">self</span>.in_channels[i],</span><br><span class="line">                   out_channels=cls_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>,</span><br><span class="line">                   stride=<span class="number">1</span>,</span><br><span class="line">                   padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                   act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        ConvModule(in_channels=cls_out_channels,</span><br><span class="line">                   out_channels=cls_out_channels,</span><br><span class="line">                   kernel_size=<span class="number">3</span>,</span><br><span class="line">                   stride=<span class="number">1</span>,</span><br><span class="line">                   padding=<span class="number">1</span>,</span><br><span class="line">                   norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                   act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">        nn.Conv2d(in_channels=cls_out_channels,</span><br><span class="line">                  out_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                  kernel_size=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<ul>
<li>最后一层 nn.Conv2d的 out_channels 是 <code>self.embed_dims</code></li>
</ul>
<blockquote>
<p><strong>通俗讲解：</strong> 图像经过分类分支的卷积加工，产生了一串“物体描述向量” <code>cls_embed</code>。</p>
</blockquote>
<hr>
<h3 id="输出2：对比头-类别-logit"><a class="header-anchor" href="#输出2：对比头-类别-logit"></a>输出2：对比头--类别 logit</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cls_logit = cls_contrast(cls_embed, txt_feat)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>cls_contrast</code> 会做 normalize/BN，然后计算相似度：</p>
<ul>
<li>输入：<code>cls_embed</code> = [B, C, H, W]</li>
<li>输入：<code>txt_feat</code> = [B, K, C]</li>
<li>输出：<code>cls_logit</code> = <strong>[B, K, H, W]</strong></li>
</ul>
</li>
<li>
<p>这一步就是“open-vocab 分类”：类别数 <code>K</code> 由文本提示词决定，可变。</p>
</li>
</ul>
<blockquote>
<p><span style="color:#FF0000">【在<code>def _init_layers</code>定义】</span>,调用之前学过的 <code>ContrastiveHead</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.use_bn_head:</span><br><span class="line">    <span class="variable language_">self</span>.cls_contrasts.append(</span><br><span class="line">        BNContrastiveHead(<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                          <span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                          use_einsum=<span class="variable language_">self</span>.use_einsum))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="variable language_">self</span>.cls_contrasts.append(</span><br><span class="line">        ContrastiveHead(<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                        use_einsum=<span class="variable language_">self</span>.use_einsum))</span><br></pre></td></tr></table></figure>
</blockquote>
<hr>
<h3 id="文本-mask-处理（把无效类别彻底压下去）"><a class="header-anchor" href="#文本-mask-处理（把无效类别彻底压下去）"></a>文本 mask 处理（把无效类别彻底压下去）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> txt_masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    txt_masks = txt_masks.view(b, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, h, w)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>假设原始 <code>txt_masks</code> 是 <strong>[B, K]</strong>：</p>
<ul>
<li><code>view(b, -1, 1, 1)</code> → <strong>[B, K, 1, 1]</strong></li>
<li><code>expand(-1, -1, h, w)</code> → <strong>[B, K, H, W]</strong></li>
</ul>
</li>
<li>
<p>目的：让 mask 的形状与 <code>cls_logit</code> 对齐，方便逐元素屏蔽。</p>
</li>
</ul>
<h4 id="训练时："><a class="header-anchor" href="#训练时："></a>训练时：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">    cls_logit = cls_logit * txt_masks</span><br><span class="line">    cls_logit[txt_masks == <span class="number">0</span>] = -<span class="number">10e6</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>已知前提：</p>
<ul>
<li><code>cls_logit.shape == [B, K, H, W]</code></li>
<li><code>txt_masks.shape == [B, K, H, W]</code></li>
<li><code>txt_masks ∈ &#123;0,1&#125;</code></li>
</ul>
</blockquote>
<ul>
<li><code>cls_logit * txt_masks</code>：先把无效类的 logit 乘成 0（粗屏蔽）</li>
</ul>
<blockquote>
<p>数值效果</p>
<ul>
<li><code>txt_masks == 1</code> → 保留原值</li>
<li><code>txt_masks == 0</code> → 直接变成 <code>0</code></li>
</ul>
</blockquote>
<ul>
<li><code>cls_logit[txt_masks == 0] = -10e6</code>：对于那些无效的单词（Mask 为 0 的位置），我们强行把它们的匹配分数设为一个极小的负数（负一千万）。
<ul>
<li>这样 softmax/sigmoid 后无效类别概率≈0</li>
<li>也避免无效类参与 loss/assign 造成干扰</li>
</ul>
</li>
</ul>
<h4 id="推理时："><a class="header-anchor" href="#推理时："></a>推理时：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    cls_logit[txt_masks == <span class="number">0</span>] = -<span class="number">10e6</span></span><br></pre></td></tr></table></figure>
<ul>
<li>推理不需要乘 mask（反正最后直接把无效类打到极低分即可）。</li>
</ul>
<hr>
<h3 id="输出3：回归分支-bbox-dist-preds（DFL）"><a class="header-anchor" href="#输出3：回归分支-bbox-dist-preds（DFL）"></a>输出3：回归分支-- bbox_dist_preds（DFL）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bbox_dist_preds = reg_pred(img_feat)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>reg_pred</code> 输出的是分布形式的回归：通道一般是 <strong><code>4 * reg_max</code></strong></li>
<li>形状：<strong><code>[B, 4*reg_max, H, W]</code></strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.reg_preds.append(</span><br><span class="line">     nn.Sequential(</span><br><span class="line">         ConvModule(in_channels=<span class="variable language_">self</span>.in_channels[i],</span><br><span class="line">                    out_channels=reg_out_channels,</span><br><span class="line">                    kernel_size=<span class="number">3</span>,</span><br><span class="line">                    stride=<span class="number">1</span>,</span><br><span class="line">                    padding=<span class="number">1</span>,</span><br><span class="line">                    norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                    act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">         ConvModule(in_channels=reg_out_channels,</span><br><span class="line">                    out_channels=reg_out_channels,</span><br><span class="line">                    kernel_size=<span class="number">3</span>,</span><br><span class="line">                    stride=<span class="number">1</span>,</span><br><span class="line">                    padding=<span class="number">1</span>,</span><br><span class="line">                    norm_cfg=<span class="variable language_">self</span>.norm_cfg,</span><br><span class="line">                    act_cfg=<span class="variable language_">self</span>.act_cfg),</span><br><span class="line">         nn.Conv2d(in_channels=reg_out_channels,</span><br><span class="line">                   out_channels=<span class="number">4</span> * <span class="variable language_">self</span>.reg_max,</span><br><span class="line">                   kernel_size=<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>
<hr>
<h3 id="输出4：回归分支数据处理-bbox-preds"><a class="header-anchor" href="#输出4：回归分支数据处理-bbox-preds"></a>输出4：回归分支数据处理--bbox_preds</h3>
<h4 id="假设1：使用-DFL（reg-max-1）"><a class="header-anchor" href="#假设1：使用-DFL（reg-max-1）"></a>假设1：使用 DFL（reg_max &gt; 1）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.reg_max &gt; <span class="number">1</span>:</span><br><span class="line">    bbox_dist_preds = bbox_dist_preds.reshape(</span><br><span class="line">        [-<span class="number">1</span>, <span class="number">4</span>, <span class="variable language_">self</span>.reg_max, h * w]).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>一步一步看：</p>
<ul>
<li>
<p>原：<code>bbox_dist_preds</code> =<code> [B, 4*reg_max, H, W]</code>(回归分支的输出)</p>
</li>
<li>
<p><code>reshape([-1, 4, R, h*w])</code></p>
<ul>
<li>这里 <code>-1</code> 实际会变成 <code>B</code>（因为总元素数要对得上）（batch size 自动推断）</li>
<li>得到 <code>[B, 4, reg_max, H*W]</code></li>
</ul>
</li>
<li>
<p><code>.permute(0, 3, 1, 2)</code> → <strong><code>[B, H*W, 4, reg_max]</code></strong></p>
</li>
</ul>
<p>这就把“每个位置、每个边（4个）、每个离散桶（R个）”的分布排列好了。</p>
<blockquote>
<p>原来：
<strong>“网络一口气吐出 4×reg_max 个通道”</strong></p>
<p>现在：
<strong>“我把它整理成：
每个像素 → 四条边 → 每条边一个 reg_max 维分布”</strong></p>
</blockquote>
<h5 id="操作：DFL还原连续距离"><a class="header-anchor" href="#操作：DFL还原连续距离"></a>操作：DFL还原连续距离</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bbox_preds = bbox_dist_preds.softmax(<span class="number">3</span>).matmul(</span><br><span class="line">    <span class="variable language_">self</span>.proj.view([-<span class="number">1</span>, <span class="number">1</span>])).squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>softmax(3)</code>：对最后一维 <code>reg_max</code> 做 softmax，得到概率分布</li>
</ul>
<blockquote>
<p><strong>但现在语义变成了</strong>：</p>
<p>对每个像素、每条边： **reg_max 个桶的概率分布 p(i)**且 <code>∑ p(i) = 1</code></p>
</blockquote>
<p><span style="color:#FF0000"><code>proj</code>在上面def _init_layers中定义了</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proj = torch.arange(<span class="variable language_">self</span>.reg_max, dtype=torch.<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.proj = [0,1,2,...,reg_max-1]</span><br><span class="line">self.proj.shape == [reg_max]</span><br><span class="line">self.proj.view([-1, 1]).shape = [reg_max,1]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.proj = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, ..., reg_max-<span class="number">1</span>] <span class="comment">#它是一个 “刻度尺 / 桶编号”。</span></span><br><span class="line"><span class="variable language_">self</span>.proj.view([-<span class="number">1</span>, <span class="number">1</span>]) → [reg_max, <span class="number">1</span>] <span class="comment">#这是为了配合 matmul 做矩阵乘法。</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>matmul 用法总结</strong></p>
<p>情况 A：1D @ 1D（向量点积）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;a.shape = [n]</span><br><span class="line">&gt;b.shape = [n]</span><br><span class="line">&gt;a.matmul(b) → 标量</span><br></pre></td></tr></table></figure>
<p>结果是：</p>

    <span id="mjx-51e66b2">
      <style>
      #mjx-51e66b2{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -2.697ex;" xmlns="http://www.w3.org/2000/svg" width="7.291ex" height="4.847ex" role="img" focusable="false" viewBox="0 -950 3222.6 2142.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path></g><g data-mml-node="mi" transform="translate(600,-1084.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(1610.7,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="msub" transform="translate(2466.6,0)"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(462,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><munder><mo data-mjx-texclass="OP">∑</mo><mi>i</mi></munder><msub><mi>a</mi><mi>i</mi></msub><msub><mi>b</mi><mi>i</mi></msub></math></mjx-assistive-mml></mjx-container>
    </span>
  <hr>
<p>情况 B：2D @ 2D（矩阵乘法）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;A.shape = [m, n]</span><br><span class="line">&gt;B.shape = [n, p]</span><br><span class="line">&gt;A.matmul(B) → [m, p]</span><br></pre></td></tr></table></figure>
<hr>
<p>情况 C：高维张量（最常见于深度学习）</p>
<p>当输入是 3D/4D/…，<code>matmul</code> 会把它当成：</p>
<blockquote>
<p><strong>最后两维做矩阵乘法，前面的维度当 batch 维</strong>（可广播）</p>
</blockquote>
<p>也就是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;(..., m, n) @ (..., n, p) = (..., m, p)</span><br></pre></td></tr></table></figure>
<hr>
<p>源代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;bbox_preds = bbox_dist_preds.softmax(<span class="number">3</span>).matmul(</span><br><span class="line">   <span class="variable language_">self</span>.proj.view([-<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">&gt;).squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;bbox_dist_preds.shape == [B, H*W, 4, reg_max]</span><br><span class="line">&gt;P = bbox_dist_preds.softmax(3)</span><br><span class="line">&gt;P.shape == [B, H*W, 4, reg_max]</span><br></pre></td></tr></table></figure>
<p>这里 <code>P[..., reg_max]</code> 是概率分布。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;proj = self.proj.view([-1,1])</span><br><span class="line">&gt;proj.shape == [reg_max, 1]</span><br></pre></td></tr></table></figure>
<p><code>P</code> 是 4D，<code>proj</code> 是 2D。</p>
<p><code>matmul</code> 的规则是：<strong>取最后两维做矩阵乘法</strong>。</p>
<ul>
<li><code>P</code> 的最后两维是：<code>[4, reg_max]</code></li>
<li><code>proj</code> 的最后两维是：<code>[reg_max, 1]</code></li>
</ul>
<p>所以对每个 <code>(B, HW)</code>，都会做：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;[4, reg_max] @ [reg_max, 1] → [4, 1]</span><br></pre></td></tr></table></figure>
<p>最终输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;[B, H*W, 4, 1]</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li><code>matmul</code>：相当于做期望
<code>E[d] = Σ p(d=i) * i</code></li>
<li><code>.squeeze(-1)</code>：去掉最后的 1 维</li>
</ul>
<p>此时 <code>bbox_preds</code> 形状:<code>[B, HW, 4]</code></p>
<p><strong>再变回特征图格式</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bbox_preds = bbox_preds.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, -<span class="number">1</span>, h, w)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>transpose(1,2)</code>：从 [B, HW, 4] → [B, 4, HW]</li>
<li><code>reshape(b, -1, h, w)</code>：→ <strong>[B, 4, H, W]</strong></li>
</ul>
<p>最终 <code>bbox_preds</code> 就是连续的四边距离/参数图了。</p>
<hr>
<h4 id="假设2：不使用-DFL（reg-max-1）"><a class="header-anchor" href="#假设2：不使用-DFL（reg-max-1）"></a>假设2：不使用 DFL（reg_max &lt;= 1）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    bbox_preds = bbox_dist_preds</span><br></pre></td></tr></table></figure>
<ul>
<li>直接把 reg head 的输出当作 bbox（例如传统 L1/L2 回归形式）。</li>
</ul>
<hr>
<h3 id="返回值：训练-vs-推理不一样"><a class="header-anchor" href="#返回值：训练-vs-推理不一样"></a>返回值：训练 vs 推理不一样</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds, bbox_dist_preds</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>训练时多返回一个 <code>bbox_dist_preds</code></strong>：</p>
<ul>
<li>因为训练的 loss（尤其是 DFL loss）需要用“分布形式”的预测</li>
</ul>
</li>
<li>
<p>推理只需要 <code>cls_logit</code> + 连续 <code>bbox_preds</code> 就够了。</p>
</li>
</ul>
<hr>
<h1 id="class-RepYOLOWorldHeadModule-YOLOWorldHeadModule"><a class="header-anchor" href="#class-RepYOLOWorldHeadModule-YOLOWorldHeadModule"></a>class RepYOLOWorldHeadModule(YOLOWorldHeadModule)</h1>
<h2 id="总结-4"><a class="header-anchor" href="#总结-4"></a>总结</h2>
<p><code>RepYOLOWorldHeadModule</code> 继承自 <code>YOLOWorldHeadModule</code>，但它把 <strong>“图像 embedding 与文本 embedding 做相似度”</strong> 这件事改成了 <strong>“图像 embedding → BN → 1×1 conv → num_guide 通道”</strong> 的形式（也就是不再需要 <code>txt_feats/txt_masks</code> 输入）。这点从它的 <code>forward</code> 签名就能一眼看穿：</p>
<ul>
<li>普通版 <code>YOLOWorldHeadModule.forward(img_feats, txt_feats, txt_masks)</code></li>
<li>Rep 版 <code>RepYOLOWorldHeadModule.forward(img_feats)</code></li>
</ul>
<p>所以可以把它当成：<strong>“把文本相关的动态计算，尽可能搬到离线/权重里去；在线只跑纯视觉 head”</strong> 的一个组件方向。论文里也明确说了 <em>offline vocabulary 可以 re-parameterize 到卷积/线性层权重里</em>（这里是整体思想层面的对齐）。</p>
<h2 id="def-init-5"><a class="header-anchor" href="#def-init-5"></a>def <strong>init</strong></h2>
<p>先把 <code>__init__</code> 这段源码原样列出来方便对照：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             *args,</span></span><br><span class="line"><span class="params">             embed_dims: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             num_guide: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">             freeze_all: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             **kwargs</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">super</span>().__init__(*args,</span><br><span class="line">                     embed_dims=embed_dims,</span><br><span class="line">                     use_bn_head=<span class="literal">True</span>,</span><br><span class="line">                     use_einsum=<span class="literal">False</span>,</span><br><span class="line">                     freeze_all=freeze_all,</span><br><span class="line">                     **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># using rep head</span></span><br><span class="line">    cls_contrasts = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels):</span><br><span class="line">        cls_contrasts.append(</span><br><span class="line">            RepBNContrastiveHead(embed_dims=embed_dims,</span><br><span class="line">                                 num_guide_embeds=num_guide,</span><br><span class="line">                                 norm_cfg=<span class="variable language_">self</span>.norm_cfg))</span><br><span class="line">    <span class="variable language_">self</span>.cls_contrasts = nn.ModuleList(cls_contrasts)</span><br></pre></td></tr></table></figure>
<h3 id="1-函数签名"><a class="header-anchor" href="#1-函数签名"></a>1) 函数签名</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">..., embed_dims: <span class="built_in">int</span>, num_guide: <span class="built_in">int</span>, freeze_all: <span class="built_in">bool</span>=<span class="literal">False</span>, **kwargs</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>embed_dims</code>：图像侧分类分支最终输出的 embedding 维度（通道数）。<a href="#my-point">分类分支</a></p>
</li>
<li>
<p><code>num_guide</code>：<strong>guide embedding 的数量/维度</strong>，后面会传给 <code>RepBNContrastiveHead(..., num_guide_embeds=num_guide)</code>，决定它 1×1 conv 的输出通道数。<a href="#my-anchor">引导嵌入数量</a></p>
</li>
<li>
<p><code>freeze_all</code>：是否冻结整个 head（沿用父类机制）。</p>
</li>
<li>
<p><code>*args/**kwargs</code>：其余 YOLOv8 head module 的通用参数继续透传给父类。</p>
</li>
</ul>
<h3 id="2-调父类构造，但“强制改了两个关键开关”"><a class="header-anchor" href="#2-调父类构造，但“强制改了两个关键开关”"></a>2) 调父类构造，但“强制改了两个关键开关”</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__(*args,</span><br><span class="line">                 embed_dims=embed_dims,</span><br><span class="line">                 use_bn_head=<span class="literal">True</span>,</span><br><span class="line">                 use_einsum=<span class="literal">False</span>,</span><br><span class="line">                 freeze_all=freeze_all,</span><br><span class="line">                 **kwargs)</span><br></pre></td></tr></table></figure>
<p>这里很关键：<code>RepYOLOWorldHeadModule</code> 不是“完全按你传的参数来”，它<strong>固定</strong>了两件事：</p>
<ul>
<li><code>use_bn_head=True</code>：父类 <code>_init_layers()</code> 里原本会在 <code>ContrastiveHead</code> 和 <code>BNContrastiveHead</code> 之间二选一；这里强制让父类先走 <strong>BN 版本</strong>路径（图像侧标准化用 BN）。</li>
<li><code>use_einsum=False</code>：父类的 contrast head（如果用到）在计算相似度时会选择 <code>einsum</code> 或 reshape+matmul；这里强制关掉 <code>einsum</code>（通常是为了导出/部署兼容性，matmul 路径更“常规”）。</li>
</ul>
<blockquote>
<p>但注意：<strong>这俩开关对最终“rep head”的 cls_contrasts 并不是决定性</strong>，因为下面它会把 <code>self.cls_contrasts</code> 整个替换掉（见第 4 步）。</p>
</blockquote>
<h3 id="3-“using-rep-head”：开始重建-cls-contrasts"><a class="header-anchor" href="#3-“using-rep-head”：开始重建-cls-contrasts"></a>3) “using rep head”：开始重建 cls_contrasts</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cls_contrasts = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels):</span><br><span class="line">    cls_contrasts.append(RepBNContrastiveHead(...))</span><br></pre></td></tr></table></figure>
<ul>
<li><code>self.num_levels</code> 是特征层级数（P3/P4/P5…），每一层都配一个 head。</li>
<li>这里不再使用父类 <code>_init_layers()</code> 里构建的 <code>ContrastiveHead/BNContrastiveHead</code>，而是为每个 level 放一个 <code>RepBNContrastiveHead</code>。</li>
</ul>
<h3 id="4-构建-RepBNContrastiveHead-的参数含义"><a class="header-anchor" href="#4-构建-RepBNContrastiveHead-的参数含义"></a>4) 构建 <code>RepBNContrastiveHead</code> 的参数含义</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RepBNContrastiveHead(embed_dims=embed_dims,</span><br><span class="line">                     num_guide_embeds=num_guide,</span><br><span class="line">                     norm_cfg=<span class="variable language_">self</span>.norm_cfg)</span><br></pre></td></tr></table></figure>
<p>回忆你前面刚学过的 <code>RepBNContrastiveHead</code>：它是 <strong>BN + 1×1 Conv</strong>，forward 只吃 <code>x</code>，输出 <code>[B, num_guide_embeds, H, W]</code>。因此：</p>
<ul>
<li><code>embed_dims=embed_dims</code>：输入通道数（跟 <code>cls_pred</code> 输出 embedding 通道一致）。</li>
<li><code>num_guide_embeds=num_guide</code>：输出通道数（guide 的维度/数量）。</li>
<li><code>norm_cfg=self.norm_cfg</code>：沿用 head module 的 norm 配置来建 BN。</li>
</ul>
<h3 id="5-最后一行：把新-head-注册成-ModuleList（并覆盖父类的）"><a class="header-anchor" href="#5-最后一行：把新-head-注册成-ModuleList（并覆盖父类的）"></a>5) 最后一行：把新 head 注册成 ModuleList（并覆盖父类的）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.cls_contrasts = nn.ModuleList(cls_contrasts)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>ModuleList</code> 确保这些子模块能被 PyTorch 正确注册（参数能被优化器看到、能 <code>.to(device)</code>、能保存加载等）。</li>
<li>更重要的是：它<strong>覆盖</strong>了父类在 <code>_init_layers()</code> 里创建的 <code>self.cls_contrasts</code>，从此分类这条支路不再走 “image-text dot 的 ContrastiveHead”，而走 “RepBNContrastiveHead 产生 guide embedding”。</li>
</ul>
<hr>
<h3 id="一句话抓重点"><a class="header-anchor" href="#一句话抓重点"></a>一句话抓重点</h3>
<p><code>RepYOLOWorldHeadModule.__init__</code> 做的事就是：
<strong>先按 YOLOWorldHeadModule 初始化好 cls_preds/reg_preds 等通用结构，然后把每个 level 的 <code>cls_contrasts</code> 替换成 <code>RepBNContrastiveHead(BN + 1×1 Conv)</code>，输出 <code>num_guide</code> 维的 guide 特征，而不是直接输出 <code>[B,K,H,W]</code> 的图文相似度 logits。</strong></p>
<h2 id="def-forward-single-2"><a class="header-anchor" href="#def-forward-single-2"></a>def forward_single</h2>
<hr>
<h3 id="先验知识：cls-pred-reg-pred-cls-contrast"><a class="header-anchor" href="#先验知识：cls-pred-reg-pred-cls-contrast"></a>先验知识：cls_pred / reg_pred / cls_contrast</h3>
<p>现在看的 <code>RepYOLOWorldHeadModule</code> <strong>继承自</strong> <code>YOLOWorldHeadModule</code>，而这些东西（<code>cls_preds / reg_preds / cls_contrasts</code>）<strong>是在父类的 <code>_init_layers()</code> 里创建并保存为成员变量的</strong>：</p>
<ul>
<li><code>self.cls_preds: nn.ModuleList</code>
<ul>
<li>长度 = <code>num_levels</code>（通常 3 个尺度：P3/P4/P5）</li>
<li>每个元素是一个 <code>nn.Sequential(...)</code>：两层 ConvModule + 1x1 conv</li>
<li><strong>作用</strong>：把当前尺度的特征图 <code>img_feat</code> 映射成 <strong>分类分支的“embedding 特征图”</strong>，通道数 = <code>embed_dims</code>（不是 num_classes！）</li>
</ul>
</li>
<li><code>self.reg_preds: nn.ModuleList</code>
<ul>
<li>同样每个尺度一个 <code>nn.Sequential(...)</code></li>
<li><strong>作用</strong>：输出 bbox 的分布/回归（<code>4 * reg_max</code> 通道）</li>
</ul>
</li>
<li><code>self.cls_contrasts: nn.ModuleList</code>
<ul>
<li>在 <code>YOLOWorldHeadModule</code> 里，它是 <code>ContrastiveHead</code> 或 <code>BNContrastiveHead</code>，负责把 image embedding 和 text embedding 做相似度得到 “cls_logit”。</li>
<li><strong>但在 <code>RepYOLOWorldHeadModule</code> 里，它被重写成 <code>RepBNContrastiveHead</code></strong>：只做 BN + 1x1 conv，把 embedding 直接变成“guide logits”（用于后续 RepVL-PAN 等 re-parameterize 场景）。</li>
</ul>
</li>
</ul>
<p>所以在 <code>forward_single(img_feat, cls_pred, reg_pred, cls_contrast)</code> 里看到的：</p>
<ul>
<li><code>cls_pred</code> 其实就是 <code>self.cls_preds[i]</code>（第 i 个尺度的分类 embedding 头）</li>
<li><code>reg_pred</code> 其实就是 <code>self.reg_preds[i]</code>（第 i 个尺度的回归头）</li>
<li><code>cls_contrast</code> 其实就是 <code>self.cls_contrasts[i]</code>（第 i 个尺度的“对比/引导”头）</li>
</ul>
<hr>
<h3 id="1）RepYOLOWorldHeadModule：它到底“Rep”在哪？"><a class="header-anchor" href="#1）RepYOLOWorldHeadModule：它到底“Rep”在哪？"></a>1）RepYOLOWorldHeadModule：它到底“Rep”在哪？</h3>
<p>先看它的 <code>__init__</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RepYOLOWorldHeadModule</span>(<span class="title class_ inherited__">YOLOWorldHeadModule</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">..., embed_dims, num_guide, freeze_all=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(..., embed_dims=embed_dims,</span><br><span class="line">                         use_bn_head=<span class="literal">True</span>, use_einsum=<span class="literal">False</span>,</span><br><span class="line">                         freeze_all=freeze_all, **kwargs)</span><br><span class="line"></span><br><span class="line">        cls_contrasts = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels):</span><br><span class="line">            cls_contrasts.append(</span><br><span class="line">                RepBNContrastiveHead(embed_dims=embed_dims,</span><br><span class="line">                                     num_guide_embeds=num_guide,</span><br><span class="line">                                     norm_cfg=<span class="variable language_">self</span>.norm_cfg))</span><br><span class="line">        <span class="variable language_">self</span>.cls_contrasts = nn.ModuleList(cls_contrasts)</span><br></pre></td></tr></table></figure>
<p>关键点：</p>
<ul>
<li>先用父类把 <code>cls_preds / reg_preds</code> 等基础结构建好（父类 <code>_init_layers()</code> 会被调用）。</li>
<li>然后 <strong>把父类创建的 <code>self.cls_contrasts</code> 整个替换掉</strong>，换成 <code>RepBNContrastiveHead</code>（BN + 1x1 conv 输出 <code>num_guide</code> 通道）。</li>
</ul>
<p>这就导致后面 <code>forward_single</code> 里：</p>
<ul>
<li>普通 YOLO-World：<code>cls_contrast(cls_embed, txt_feat)</code>（图文相似度）</li>
<li>Rep 版本：<code>cls_contrast(cls_embed)</code>（不再吃 txt_feat，直接输出 guide logits）</li>
</ul>
<hr>
<h3 id="2）逐行讲解：RepYOLOWorldHeadModule-forward-single"><a class="header-anchor" href="#2）逐行讲解：RepYOLOWorldHeadModule-forward-single"></a>2）逐行讲解：RepYOLOWorldHeadModule.forward_single</h3>
<p>函数签名：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_single</span>(<span class="params">self, img_feat: Tensor,</span></span><br><span class="line"><span class="params">                   cls_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   reg_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   cls_contrast: nn.ModuleList</span>) -&gt; <span class="type">Tuple</span>:</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>对比观察</strong>：在之前的父类 <code>forward_single</code> 里，我们需要输入 <code>txt_feat</code>（文本特征）和 <code>txt_masks</code>（掩码）。</p>
<p><strong>点评</strong>：但在这里，参数列表里<strong>完全没有</strong>这两个东西。</p>
<p><strong>为什么？</strong>：因为我们已经在初始化阶段，把文本特征的信息“转换”并“注入”到了 <code>cls_contrast</code>（即 <code>RepBNContrastiveHead</code>）的卷积权重里了。现在模型已经把“单词”背下来了，不再需要拿着书（文本特征）边看边找了。</p>
</blockquote>
<h4 id="操作：取-batch-与空间尺寸-2"><a class="header-anchor" href="#操作：取-batch-与空间尺寸-2"></a>操作：取 batch 与空间尺寸</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b, _, h, w = img_feat.shape</span><br></pre></td></tr></table></figure>
<ul>
<li><code>img_feat</code> 是某个尺度的一张特征图（来自 neck 输出的 P3/P4/P5）</li>
<li><code>b</code>：batch size</li>
<li><code>h,w</code>：该尺度特征图的空间尺寸</li>
<li><code>_</code>：通道数（这个尺度的 in_channels）</li>
</ul>
<h4 id="操作：分类分支做-embedding"><a class="header-anchor" href="#操作：分类分支做-embedding"></a>操作：分类分支做 embedding</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cls_embed = cls_pred(img_feat)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cls_pred</code> 是一个 <code>nn.Sequential</code>（两层 3x3 conv + 最后 1x1 conv）</li>
<li>输出 <code>cls_embed</code> 的 shape 通常是 <code>[b, embed_dims, h, w]</code></li>
<li>注意：这一步<strong>不是输出类别数</strong>，而是输出“用于对齐文本/引导的 embedding 特征图”</li>
</ul>
<h4 id="操作：Rep-对比头（实际上是“BN-1x1-conv”）"><a class="header-anchor" href="#操作：Rep-对比头（实际上是“BN-1x1-conv”）"></a>操作：Rep 对比头（实际上是“BN + 1x1 conv”）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cls_logit = cls_contrast(cls_embed)</span><br></pre></td></tr></table></figure>
<ul>
<li>在 Rep 版本里，<code>cls_contrast</code> 是 <code>RepBNContrastiveHead</code>：先 BN，再 1x1 conv 把 <code>embed_dims -&gt; num_guide</code>。</li>
<li>所以 <code>cls_logit</code> shape ≈ <code>[b, num_guide, h, w]</code></li>
<li>这也是你会疑惑的点：<strong>为什么这里不需要 txt_feat？</strong>
<ul>
<li>因为 Rep 版本的设计是把“离线词表 / 文本信息”通过 re-parameterize 的方式提前塞进网络其他位置（比如 RepVL-PAN 的 guide 权重），这里输出的是用于后续融合/引导的 logits（或 guide maps），而不是直接做图文相似度分类。</li>
</ul>
</li>
</ul>
<h4 id="操作：回归分支输出-bbox-分布"><a class="header-anchor" href="#操作：回归分支输出-bbox-分布"></a>操作：回归分支输出 bbox 分布</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bbox_dist_preds = reg_pred(img_feat)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>reg_pred</code> 也是一个 <code>nn.Sequential</code></li>
<li>输出 shape 通常是 <code>[b, 4*reg_max, h, w]</code></li>
<li>这里的 “dist” 表示 DFL（Distribution Focal Loss）那套：每个边（l/t/r/b）预测一个离散分布，而不是直接回归一个数。</li>
</ul>
<h4 id="操作：把分布转成实际-bbox-offset（如果-reg-max-1）"><a class="header-anchor" href="#操作：把分布转成实际-bbox-offset（如果-reg-max-1）"></a>操作：把分布转成实际 bbox offset（如果 reg_max &gt; 1）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.reg_max &gt; <span class="number">1</span>:</span><br><span class="line">    bbox_dist_preds = bbox_dist_preds.reshape(</span><br><span class="line">        [-<span class="number">1</span>, <span class="number">4</span>, <span class="variable language_">self</span>.reg_max, h * w]).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>先 reshape：把 <code>[b, 4*reg_max, h, w]</code> 变形成“每个位置、每条边、reg_max 个bin”的结构</li>
<li><code>permute(0, 3, 1, 2)</code> 后的 shape 大致是：
<ul>
<li><code>[b, h*w, 4, reg_max]</code></li>
<li>解释：对每个 grid 点（h*w 个），4 个边，每个边一个 reg_max 分布。</li>
</ul>
</li>
</ul>
<p>接着：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bbox_preds = bbox_dist_preds.softmax(<span class="number">3</span>).matmul(</span><br><span class="line">    <span class="variable language_">self</span>.proj.view([-<span class="number">1</span>, <span class="number">1</span>])).squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>softmax(3)</code>：在 reg_max 维度上做概率分布</li>
<li><code>self.proj</code> 是 <code>[0,1,2,...,reg_max-1]</code>（buffer）</li>
<li><code>matmul(proj)</code>：就是把离散分布做期望，得到连续距离（DFL 常见做法）</li>
</ul>
<p>然后：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bbox_preds = bbox_preds.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, -<span class="number">1</span>, h, w)</span><br></pre></td></tr></table></figure>
<ul>
<li>把 <code>[b, h*w, 4]</code> 之类的结构整理回 <code>[b, 4, h, w]</code>（其中 <code>-1</code> 就是 4）</li>
</ul>
<h4 id="操作：如果-reg-max-1，就直接用回归输出"><a class="header-anchor" href="#操作：如果-reg-max-1，就直接用回归输出"></a>操作：如果 reg_max == 1，就直接用回归输出</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    bbox_preds = bbox_dist_preds</span><br></pre></td></tr></table></figure>
<ul>
<li>这种情况相当于没有 DFL，直接预测 bbox offset。</li>
</ul>
<h4 id="操作：训练-推理返回值不同"><a class="header-anchor" href="#操作：训练-推理返回值不同"></a>操作：训练/推理返回值不同</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds, bbox_dist_preds</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds</span><br></pre></td></tr></table></figure>
<ul>
<li>训练时需要 <code>bbox_dist_preds</code> 来算 DFL loss</li>
<li>推理时通常只要最终 <code>bbox_preds</code>（以及分类 logits）就够了，所以省掉 dist preds。</li>
</ul>
<hr>
<h3 id="3）Rep版-forward-single-和普通版-forward-single-的区别"><a class="header-anchor" href="#3）Rep版-forward-single-和普通版-forward-single-的区别"></a>3）Rep版 forward_single 和普通版 forward_single 的区别</h3>
<p>对比一下父类 <code>YOLOWorldHeadModule.forward_single</code> 的核心差异：</p>
<ul>
<li>普通版：
<ul>
<li><code>cls_logit = cls_contrast(cls_embed, txt_feat)</code></li>
<li>还有 <code>txt_masks</code> 的 expand / mask 逻辑（把无效 prompt 位置置成 <code>-10e6</code>）</li>
</ul>
</li>
<li>Rep版：
<ul>
<li><code>cls_logit = cls_contrast(cls_embed)</code>（不需要 txt_feat）</li>
<li>也没有 txt_masks（因为它的 forward 也改成只吃 img_feats）</li>
</ul>
</li>
</ul>
<p><strong>一句话总结：</strong></p>
<blockquote>
<p>普通 YOLO-World head 在 head 内部完成“图文相似度分类”；RepYOLOWorldHeadModule 把这件事拆出/改写成“可重参数化的 guide 表达”，所以 forward_single 的输入输出天然会少掉 txt_feat / txt_masks。</p>
</blockquote>
<hr>
<h2 id="def-forward-5"><a class="header-anchor" href="#def-forward-5"></a>def forward</h2>
<hr>
<h3 id="1）RepYOLOWorldHeadModule-forward：这一段是“把每个尺度跑一遍-forward-single”"><a class="header-anchor" href="#1）RepYOLOWorldHeadModule-forward：这一段是“把每个尺度跑一遍-forward-single”"></a>1）RepYOLOWorldHeadModule.forward：这一段是“把每个尺度跑一遍 forward_single”</h3>
<p>代码在 <code>RepYOLOWorldHeadModule</code> 最后：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">Tuple</span>[Tensor]</span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>]:</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(img_feats) == <span class="variable language_">self</span>.num_levels</span><br><span class="line">    <span class="keyword">return</span> multi_apply(<span class="variable language_">self</span>.forward_single, img_feats, <span class="variable language_">self</span>.cls_preds,<span class="variable language_">self</span>.reg_preds, <span class="variable language_">self</span>.cls_contrasts)</span><br></pre></td></tr></table></figure>
<h4 id="1-1-img-feats-是什么？"><a class="header-anchor" href="#1-1-img-feats-是什么？"></a>1.1 <code>img_feats</code> 是什么？</h4>
<ul>
<li><code>img_feats</code> 是 neck 输出的多尺度特征，比如 3 个尺度：<code>(P3, P4, P5)</code></li>
<li>所以 <code>len(img_feats) == self.num_levels</code> 是一个防呆：保证尺度数一致</li>
</ul>
<h4 id="1-2-关键：multi-apply-到底干了啥？"><a class="header-anchor" href="#1-2-关键：multi-apply-到底干了啥？"></a>1.2 关键：<code>multi_apply(...)</code> 到底干了啥？</h4>
<p><code>multi_apply</code> 你可以把它理解为“<strong>for 循环 + 把每次返回值按列收集</strong>”。</p>
<p>它等价于伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_levels):</span><br><span class="line">    outs.append(forward_single(img_feats[i],</span><br><span class="line">                              cls_preds[i],</span><br><span class="line">                              reg_preds[i],</span><br><span class="line">                              cls_contrasts[i]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果 forward_single 返回 (a, b, c)</span></span><br><span class="line"><span class="comment"># 那么 multi_apply 会把它变成：</span></span><br><span class="line"><span class="comment"># ([a0, a1, a2], [b0, b1, b2], [c0, c1, c2])</span></span><br></pre></td></tr></table></figure>
<p>所以你这一行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multi_apply(<span class="variable language_">self</span>.forward_single, img_feats, <span class="variable language_">self</span>.cls_preds, <span class="variable language_">self</span>.reg_preds, <span class="variable language_">self</span>.cls_contrasts)</span><br></pre></td></tr></table></figure>
<p>实际就是逐尺度调用：</p>
<ul>
<li>第 0 层：<code>forward_single(img_feats[0], cls_preds[0], reg_preds[0], cls_contrasts[0])</code></li>
<li>第 1 层：<code>forward_single(img_feats[1], cls_preds[1], reg_preds[1], cls_contrasts[1])</code></li>
<li>第 2 层：<code>forward_single(img_feats[2], cls_preds[2], reg_preds[2], cls_contrasts[2])</code></li>
</ul>
<h4 id="1-3-Rep版-forward-single-每层输出是什么？"><a class="header-anchor" href="#1-3-Rep版-forward-single-每层输出是什么？"></a>1.3 Rep版 forward_single 每层输出是什么？</h4>
<p>你前面已经看过 <code>forward_single</code>：训练时返回 3 个，推理时返回 2 个。</p>
<ul>
<li><strong>训练态</strong>：每层返回<span id="my-anchor1"></span>
<code>(cls_logit_i, bbox_preds_i, bbox_dist_preds_i)</code></li>
<li><code>multi_apply</code> 汇总后整体返回：
<code>([cls_logit_0, cls_logit_1, cls_logit_2], [bbox_preds_0,...], [bbox_dist_preds_0,...])</code></li>
</ul>
<p>也就是说，最终 <code>outs</code> 是一个 <strong>“tuple of lists”</strong>：</p>
<ul>
<li><code>outs[0]</code>：list，长度=尺度数，每个元素是该尺度的 <code>cls_logit</code></li>
<li><code>outs[1]</code>：list，<code>bbox_preds</code></li>
<li><code>outs[2]</code>：list，<code>bbox_dist_preds</code>（只有训练需要）</li>
</ul>
<blockquote>
<p>这就是你读起来割裂的典型点：<strong>forward_single 返回的是“单尺度张量”，forward 返回的是“按尺度打包后的 list”</strong>。</p>
</blockquote>
<hr>
<h3 id="2）把-RepHeadModule-的输出，接到-YOLOWorldHead：这一层只是“转发”"><a class="header-anchor" href="#2）把-RepHeadModule-的输出，接到-YOLOWorldHead：这一层只是“转发”"></a>2）把 RepHeadModule 的输出，接到 YOLOWorldHead：这一层只是“转发”</h3>
<p><code>YOLOWorldHead.forward</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats, txt_feats, txt_masks</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.head_module(img_feats, txt_feats, txt_masks)</span><br></pre></td></tr></table></figure>
<p>但注意：<strong>这是 YOLOWorldHead（非 Rep）</strong> 的 forward，它默认 head_module 是 <code>YOLOWorldHeadModule</code>（吃 txt_feats / txt_masks）。</p>
<p>如果你在配置里把 head_module 换成 <code>RepYOLOWorldHeadModule</code>，那一般也会对应换一个“Rep版的 Head Wrapper”（或者调用路径不同），否则签名对不上。</p>
<p>你现在这个文件里呈现的是：</p>
<ul>
<li><code>YOLOWorldHeadModule.forward(img_feats, txt_feats, txt_masks)</code>：开放词表/文本参与</li>
<li><code>RepYOLOWorldHeadModule.forward(img_feats)</code>：不再吃文本</li>
</ul>
<p><strong>所以：Rep 模式下，文本特征通常在别的模块融合/重参数化阶段用掉了，而不是在 head 里做相似度。</strong></p>
<hr>
<h3 id="3）为什么-loss-by-feat-里把-cls-score-reshape-成-num-classes？这点很容易让人懵"><a class="header-anchor" href="#3）为什么-loss-by-feat-里把-cls-score-reshape-成-num-classes？这点很容易让人懵"></a>3）为什么 loss_by_feat 里把 cls_score reshape 成 num_classes？这点很容易让人懵</h3>
<p>你在 <code>YOLOWorldHead.loss_by_feat</code> 里会看到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds = [</span><br><span class="line">    cls_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>, <span class="variable language_">self</span>.num_classes)</span><br><span class="line">    <span class="keyword">for</span> cls_pred <span class="keyword">in</span> cls_scores</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>这意味着：传进来的 <code>cls_scores[i]</code> 的 channel <strong>必须能对应 <code>self.num_classes</code></strong>。</p>
<p>那 YOLO-World 是怎么做到的？</p>
<ul>
<li><strong>普通 YOLOWorldHeadModule</strong>：<code>cls_logit = ContrastiveHead(cls_embed, txt_feat)</code>
输出通道数 = <code>K</code>（文本 token / 类别 prompt 数）。实际训练里，常见做法是让 <strong>K 就等于 num_classes</strong>（比如训练时给定 80 类文本 embedding），这样 reshape 才合理。</li>
<li><strong>RepYOLOWorldHeadModule</strong>：<code>cls_logit = RepBNContrastiveHead(cls_embed)</code>
输出通道数 = <code>num_guide</code>。要让它能进同一个 loss，通常要求：
<ul>
<li><code>num_guide == num_classes</code>（或者后续还有映射把 guide logits 转成 class logits）</li>
</ul>
</li>
</ul>
<blockquote>
<p>所以如果你在 Rep 配置里看到 <code>num_guide</code>，你可以先把它当作“<strong>最终要对齐到 num_classes 的那一维通道数</strong>”。不然 loss 那里维度就会崩。</p>
</blockquote>
<hr>
<h4 id="4）把你关心的“整体流程逻辑”用一句话串起来"><a class="header-anchor" href="#4）把你关心的“整体流程逻辑”用一句话串起来"></a>4）把你关心的“整体流程逻辑”用一句话串起来</h4>
<p>以 Rep 模式为例（你当前关注的类）：</p>
<ol>
<li>backbone/neck 输出多尺度 <code>img_feats = (P3,P4,P5)</code></li>
<li><code>RepYOLOWorldHeadModule.forward</code> 用 <code>multi_apply</code> 遍历每个尺度
<ul>
<li><code>cls_pred</code>：把特征变成 <code>cls_embed</code>（embedding map）</li>
<li><code>cls_contrast(RepBN...)</code>：把 embedding map 变成 <code>cls_logit</code>（guide/class logits）</li>
<li><code>reg_pred</code>：输出 <code>bbox_dist_preds</code>，再用 DFL 期望得到 <code>bbox_preds</code></li>
</ul>
</li>
<li>forward 返回：按尺度组织好的 <code>([cls_logit_i], [bbox_preds_i], [bbox_dist_preds_i])</code></li>
<li>下游 <code>loss_by_feat</code> 把各尺度展平、拼接、解码、分配正负样本、算分类/回归/DFL 等 loss</li>
</ol>
<hr>
<h1 id="class-YOLOWorldHead-YOLOv8Head"><a class="header-anchor" href="#class-YOLOWorldHead-YOLOv8Head"></a>class YOLOWorldHead(YOLOv8Head)</h1>
<h2 id="def-init-6"><a class="header-anchor" href="#def-init-6"></a>def <strong>init</strong></h2>
<p>源码非常短（你截图附近就是完整内容）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@MODELS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">YOLOWorldHead</span>(<span class="title class_ inherited__">YOLOv8Head</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;YOLO-World Head</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, world_size=-<span class="number">1</span>, *args, **kwargs</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.world_size = world_size</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>基础概念</strong>：它继承自 <code>YOLOv8Head</code>。</p>
<p><strong>通俗解释</strong>：这意味着它继承了 YOLOv8 处理坐标、处理预测结果的所有标准流程。我们只需要在它的基础上，把“文字特征”这个新变量塞进去。</p>
</blockquote>
<h3 id="函数签名-2"><a class="header-anchor" href="#函数签名-2"></a>函数签名</h3>
<ul>
<li><code>world_size=-1</code>：用于 <strong>loss 缩放</strong> 的一个参数（后面 <code>loss_by_feat</code> 里会用它把 loss 乘上 <code>num_imgs * world_size</code>，用于分布式/多卡训练时做尺度对齐）。</li>
<li><code>*args, **kwargs</code>：全部转交给父类 <code>YOLOv8Head</code> 去初始化（里面会建 head_module、assigner、loss 函数、prior 等等——这些你后面读 <code>loss_by_feat</code> 会频繁遇到）。</li>
</ul>
<p><code>super().__init__(*args, **kwargs)</code></p>
<ul>
<li>
<p>这一步是 <strong>真正把 YOLOv8/YOLOWorld 的 head 基建搭起来</strong> 的地方：</p>
<ul>
<li>包括 <code>self.head_module</code>（在 YOLO-World 里通常是 <code>YOLOWorldHeadModule</code>，它内部才有你之前读过的 <code>cls_preds / reg_preds / cls_contrasts</code> 等 ModuleList）</li>
<li>包括损失、assigner、bbox coder、prior generator 等</li>
</ul>
</li>
<li>
<p>所以：<strong>YOLOWorldHead 更像“包装器/调度器”</strong>，核心卷积头在 <code>head_module</code>。</p>
</li>
</ul>
<p><code>self.world_size = world_size</code></p>
<ul>
<li>
<p>只是把参数存起来，供后续算 loss 的时候使用。</p>
</li>
<li>
<p>你在文件里会看到 <code>loss_by_feat</code> 里类似：</p>
<ul>
<li>如果 <code>world_size &lt; 0</code> 就用 <code>get_dist_info()</code> 之类推断真实 world size</li>
<li>否则用 <code>self.world_size</code></li>
<li>然后把 <code>loss_cls/loss_bbox/loss_dfl</code> 乘上 <code>num_imgs * world_size</code></li>
</ul>
</li>
<li>
<p>这就是它存在的意义：<strong>控制分布式时的 loss 缩放口径</strong>。</p>
</li>
</ul>
<h2 id="def-loss"><a class="header-anchor" href="#def-loss"></a>def loss</h2>
<p>源码（你文件里就是这段）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, img_feats: <span class="type">Tuple</span>[Tensor], txt_feats: Tensor,</span></span><br><span class="line"><span class="params">         txt_masks: Tensor, batch_data_samples: <span class="type">Union</span>[<span class="built_in">list</span>, <span class="built_in">dict</span>]</span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Perform forward propagation and loss calculation of the detection</span></span><br><span class="line"><span class="string">    head on the features of the upstream network.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    outs = <span class="variable language_">self</span>(img_feats, txt_feats, txt_masks)</span><br><span class="line">    <span class="comment"># Fast version</span></span><br><span class="line">    loss_inputs = outs + (batch_data_samples[<span class="string">&#x27;bboxes_labels&#x27;</span>],</span><br><span class="line">                          batch_data_samples[<span class="string">&#x27;img_metas&#x27;</span>])</span><br><span class="line">    losses = <span class="variable language_">self</span>.loss_by_feat(*loss_inputs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> losses</span><br></pre></td></tr></table></figure>
<h3 id="debug"><a class="header-anchor" href="#debug"></a>debug</h3>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226144600550.png" alt="image-20251226144600550.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226144748217.png" alt="image-20251226144748217.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226144815664.png" alt="image-20251226144815664.png"></p>
<blockquote>
<p><strong>输入参数</strong>：</p>
<ul>
<li><code>img_feats</code>: 图像特征。</li>
<li><code>txt_feats</code>, <code>txt_masks</code>: 文本特征及其掩码。</li>
<li><code>batch_data_samples</code>: 这一批次的“标准答案”（标注信息），包括物体在哪、是什么类别。</li>
</ul>
</blockquote>
<p><code>outs = self(img_feats, txt_feats, txt_masks)</code></p>
<ul>
<li>在 PyTorch 里，<code>self(...)</code> 会触发 <code>nn.Module.__call__</code>，最终调用本类的 <code>forward(...)</code>。</li>
<li>而你文件里下面就有：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats, txt_feats, txt_masks</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.head_module(img_feats, txt_feats, txt_masks)</span><br></pre></td></tr></table></figure>
<p>所以这一句等价于：</p>
<blockquote>
<p><code>outs = self.head_module(img_feats, txt_feats, txt_masks)</code></p>
</blockquote>
<p>也就是说：</p>
<ul>
<li><code>YOLOWorldHead</code> 自己不做卷积预测；</li>
<li>预测全由 <code>self.head_module</code> 做；</li>
<li><code>loss()</code> 只是“先 forward 拿输出，再喂给 loss_by_feat”。</li>
</ul>
<p><span style="color:#FF0000">那 <code>outs</code> 的结构到底是什么？</span></p>
<p>这取决于 head_module（默认是 <code>YOLOWorldHeadModule</code>）的训练态返回值：</p>
<ul>
<li>
<p><strong>训练模式</strong>下，<code>YOLOWorldHeadModule.forward(...)</code>（内部 <code>multi_apply(forward_single, ...)</code>）会返回三项：</p>
<ol>
<li><code>cls_scores</code>: List[Tensor]（按尺度，每个形状大致 <code>[B, num_classes, Hi, Wi]</code>）（这是其实还是<code>cls_logit</code>）<a href="#my-anchor1">跳转</a></li>
<li><code>bbox_preds</code>: List[Tensor]（按尺度，每个 <code>[B, 4, Hi, Wi]</code> 或相关形状）</li>
<li><code>bbox_dist_preds</code>: List[Tensor]（按尺度，每个 <code>[B, H*W, 4, reg_max]</code>，用于 DFL loss）</li>
</ol>
<blockquote>
<p><strong>备注</strong></p>
<p><strong>bbox_dist_preds 有两种常见形状：</strong></p>
<ul>
<li><strong>卷积头原始输出（reshape 前）</strong>：<code>[B, 4*reg_max, H, W]</code></li>
<li><strong>forward_single 内部为了 DFL/loss 方便（reshape + permute 后）</strong>：<code>[B, H*W, 4, reg_max]</code></li>
</ul>
</blockquote>
</li>
</ul>
<p>所以你可以把 <code>outs</code> 当成一个 tuple：</p>
<blockquote>
<p><code>outs = (cls_scores, bbox_preds, bbox_dist_preds)</code></p>
</blockquote>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226152455810.png" alt="image-20251226152455810.png"></p>
<p>这就是后面 <code>outs + (...)</code> 能“直接拼元组”的原因。</p>
<blockquote>
<p>你之前读 Rep 版本时，<code>forward</code> 签名不同（不吃 txt），那是另一条配置路径；这里讲的是 <code>YOLOWorldHead</code> 这条“吃文本”的标准 YOLO-World 训练流。</p>
</blockquote>
<hr>
<p><code>loss_inputs = outs + (...)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_inputs = outs + (batch_data_samples[<span class="string">&#x27;bboxes_labels&#x27;</span>],</span><br><span class="line">                      batch_data_samples[<span class="string">&#x27;img_metas&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>这句在做一件事：<strong>把“模型输出”和“监督信息”拼成 loss_by_feat 需要的参数列表</strong>。</p>
<ul>
<li>
<p><code>batch_data_samples['bboxes_labels']</code></p>
<ul>
<li>通常是把每张图的 GT bboxes 和 labels 打包后的结构（实现里一般会被组织成 list/tuple，后面 assigner 会用它匹配正负样本）</li>
</ul>
</li>
<li>
<p><code>batch_data_samples['img_metas']</code></p>
<ul>
<li>每张图的 meta（原图尺寸、pad 后尺寸、scale factor 等），用于 decode / 还原尺度等</li>
</ul>
</li>
</ul>
<p>所以 <code>loss_inputs</code> 最终是一个 5 元组（训练态）：</p>
<ol>
<li><code>cls_scores</code></li>
<li><code>bbox_preds</code></li>
<li><code>bbox_dist_preds</code></li>
<li><code>bboxes_labels</code></li>
<li><code>img_metas</code></li>
</ol>
<hr>
<p><code>losses = self.loss_by_feat(*loss_inputs)</code></p>
<p>这句是“真正开算”的入口，但它把复杂度藏到 <code>loss_by_feat</code> 里了：</p>
<ul>
<li>
<p>它会：</p>
<ul>
<li>把各尺度输出 flatten（<code>B, Hi*Wi, C</code>）</li>
<li>生成 priors / stride</li>
<li>decode bbox（把网络预测的 offset/dist 变成实际坐标）</li>
<li>调 assigner（TaskAlignedAssigner）分配正负样本</li>
<li>计算分类 loss、IoU/bbox loss、DFL loss</li>
<li>最后按 <code>num_imgs * world_size</code> 做缩放（你前面问 world_size 的用途就在这里）</li>
</ul>
</li>
</ul>
<p>你现在只要求讲到 <code>loss</code>，但我先帮你把“下一步会发生什么”串一下，避免你马上又割裂。</p>
<hr>
<p><code>return losses</code></p>
<ul>
<li><code>losses</code> 是一个 dict，比如：</li>
<li><code>&#123;'loss_cls': ..., 'loss_bbox': ..., 'loss_dfl': ...&#125;</code></li>
</ul>
<hr>
<h3 id="小结：-init-和-loss-在整个-Head-中的角色"><a class="header-anchor" href="#小结：-init-和-loss-在整个-Head-中的角色"></a>小结：<code>__init__</code> 和 <code>loss</code> 在整个 Head 中的角色</h3>
<ul>
<li>
<p><code>__init__</code>：几乎不做事，只是让父类把 head 搭好 + 存一个 <code>world_size</code> 给 loss 缩放用。</p>
</li>
<li>
<p><code>loss</code>：典型“调度函数”</p>
<ol>
<li>调 forward 拿预测 <code>outs</code></li>
<li>从 batch 里取监督信息（gt + meta）</li>
<li>统一丢给 <code>loss_by_feat</code> 算出 loss dict</li>
</ol>
</li>
</ul>
<hr>
<p>如果你同意，我们下一步就顺着你刚才这段的调用链：<strong>从 <code>YOLOWorldHead.loss_by_feat</code> 第一行开始逐行讲</strong>（那一段就是你读起来最容易迷糊、但也是最关键的“flatten→decode→assign→loss”全流程）。</p>
<h2 id="def-loss-by-feat"><a class="header-anchor" href="#def-loss-by-feat"></a>def loss_by_feat</h2>
<p>好，我们从 <strong><code>YOLOWorldHead.loss_by_feat</code></strong> 第一行开始，把它当成“训练时真正算 loss 的主流程”来逐段拆解。我会一直强调：<strong>每个变量从哪来、形状是什么、为什么要这么变、下一步谁会用它</strong>（专门解决你说的割裂感）。</p>
<hr>
<h3 id="梳理：loss-by-feat-的流程"><a class="header-anchor" href="#梳理：loss-by-feat-的流程"></a>梳理：loss_by_feat 的流程</h3>
<p><code>loss_by_feat</code> 做的事按顺序是：</p>
<ol>
<li><strong>准备 priors（网格点 + stride）</strong>：如果当前输入分辨率变了，就重新生成</li>
<li><strong>整理 GT</strong>：把每张图的 gt bboxes/labels pad 到统一形状</li>
<li><strong>整理预测</strong>：把各尺度输出 flatten 成 (B, N, C) / (B, N, 4) / (B, N, 4*reg_max)</li>
<li><strong>decode bbox</strong>：把网络输出的 bbox offset 变成真实坐标（xyxy）</li>
<li><strong>assign 正负样本</strong>：TaskAlignedAssigner 输出每个 prior 的匹配结果（assigned_scores、fg_mask 等）</li>
<li><strong>算分类 loss</strong>：对全体 prior 算 BCE，再按 text mask 做“类别维度加权”</li>
<li><strong>算回归/DFL loss</strong>：只在正样本上算 IoU loss 和 DFL loss</li>
<li><strong>按 world_size &amp; num_imgs 缩放</strong>：返回 dict(loss_cls/loss_bbox/loss_dfl)</li>
</ol>
<p>你现在读下面每一行，就能把它对应到这张地图上。</p>
<hr>
<h3 id="函数签名-3"><a class="header-anchor" href="#函数签名-3"></a>函数签名</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_by_feat</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    cls_scores: <span class="type">Sequence</span>[Tensor],</span></span><br><span class="line"><span class="params">    bbox_preds: <span class="type">Sequence</span>[Tensor],</span></span><br><span class="line"><span class="params">    bbox_dist_preds: <span class="type">Sequence</span>[Tensor],</span></span><br><span class="line"><span class="params">    batch_text_masks: Tensor,</span></span><br><span class="line"><span class="params">    batch_gt_instances: <span class="type">Sequence</span>[InstanceData],</span></span><br><span class="line"><span class="params">    batch_img_metas: <span class="type">Sequence</span>[<span class="built_in">dict</span>],</span></span><br><span class="line"><span class="params">    batch_gt_instances_ignore: OptInstanceList = <span class="literal">None</span></span>) -&gt; <span class="built_in">dict</span>:</span><br></pre></td></tr></table></figure>
<h4 id="来源总结"><a class="header-anchor" href="#来源总结"></a>来源总结</h4>
<ul>
<li><code>cls_scores / bbox_preds / bbox_dist_preds</code>：由 <code>YOLOWorldHeadModule.forward</code> 函数通过 <code>multi_apply</code> 机制，汇总各检测层级（P3, P4, P5）的结果生成的。</li>
</ul>
<blockquote>
<p><code>cls_scores</code> (分类/匹配分数)<a href="#my-anchor2">跳转</a></p>
<ul>
<li><strong>代表意义</strong>：图像每个网格点与给定文本类别之间的匹配分数（相似度）。在 YOLO-World 中，它不再是简单的类别概率，而是跨模态的相似度对数。</li>
<li><strong>形状</strong>：是一个 <code>Sequence</code>（列表），通常包含 3 个 Tensor（对应 3 个尺度）。每个 Tensor 的形状为 <strong><code>[Batch, Num_Classes, H, W]</code></strong>。</li>
<li><code>Num_Classes</code>：当前文本提示（Text Prompt）中的单词数量。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>来源</strong>：由 <code>YOLOWorldHeadModule.forward_single</code> 生成。</li>
<li><strong>生成路径</strong>：图像特征先通过 <code>cls_pred</code>（卷积层）生成 512 维的物体向量 <code>cls_embed</code>，然后由 <code>cls_contrast</code>（比对器，如 <code>ContrastiveHead</code>）将其与文本特征 <code>txt_feat</code> 进行点积运算得到 <code>cls_logit</code>。</li>
</ul>
</blockquote>
<blockquote>
<p><code>bbox_dist_preds</code> (框的分布预测)</p>
<ul>
<li><strong>代表意义</strong>：这是框边界的概率分布，用于实现更精准的 <strong>DFL (Distribution Focal Loss)</strong>。它不直接给出坐标，而是预测坐标可能在某个范围内的概率。</li>
<li><strong>形状</strong>：也是一个列表。每个 Tensor 的形状为 <strong><code>[Batch, 4 * reg_max, H, W]</code></strong>。</li>
<li><code>reg_max</code>：预设的离散分布范围（通常为 16）。<code>4</code> 代表框的四个边（左、上、右、下）。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>来源</strong>：直接由 <code>YOLOWorldHeadModule.forward_single</code> 中的回归分支 <code>reg_pred</code>（卷积层）输出。</li>
</ul>
</blockquote>
<blockquote>
<p><code>bbox_preds</code> (精修后的框预测)</p>
<ul>
<li><strong>代表意义</strong>：根据上面的分布预测转换出来的、在当前特征图尺度下的具体框坐标偏移量。</li>
<li><strong>形状</strong>：列表形式。每个 Tensor 的形状为 <strong><code>[Batch, 4, H, W]</code></strong>。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>生成路径</strong>：在 <code>forward_single</code> 函数内部，利用 <code>bbox_dist_preds.softmax(3).matmul(self.proj)</code> 操作，将离散概率分布转化为具体的数值坐标。</li>
</ul>
</blockquote>
<blockquote>
<p><code>batch_text_masks</code> (文本掩码)</p>
<ul>
<li><strong>代表意义</strong>：标记这一批次中，哪些文本类别是真实有效的，哪些是因为为了凑齐长度而填充的“空位”（Padding）。</li>
<li><strong>形状</strong>：单 Tensor，形状通常为 <strong><code>[Batch, Num_Classes]</code></strong>。数值为 1 表示有效单词，0 表示填充词。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>来源</strong>：由数据预处理器（DataPreprocessor）从原始标注中提取。</li>
<li><strong>生成路径</strong>：在模型外部的数据流中，分词器（Tokenizer）会将变长的 Prompt 统一补齐到固定长度（如 80 个词），补齐的部分在 <code>batch_text_masks</code> 中标记为 0。</li>
</ul>
</blockquote>
<blockquote>
<p><code>batch_gt_instances</code> (真实框与标签)</p>
<ul>
<li><strong>代表意义</strong>：每一张图片的“标准答案”，包含了真正的物体框坐标和对应的类别 ID。</li>
<li><strong>形状</strong>：是一个 <code>Sequence</code>，里面装着多个 <code>InstanceData</code> 对象（每个对象对应一张图）。</li>
<li>每个 <code>InstanceData</code> 包含 <code>bboxes</code>（形状为 <code>[N, 4]</code>）和 <code>labels</code>（形状为 <code>[N]</code>）。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>生成路径</strong>：由数据集（Dataset）读取标注文件，并经过 <code>YOLOWorldHead.loss</code> 函数中的 <code>unpack_gt_instances</code> 方法解包得到。</li>
</ul>
<p><code>batch_img_metas</code> (图像元数据)</p>
<ul>
<li><strong>代表意义</strong>：包含了图像的身份信息，比如原始宽高、缩放比例、填充像素等。</li>
<li><strong>形状</strong>：一个包含字典（Dict）的列表，每个字典对应一张图。</li>
<li><strong>来源与生成函数</strong>：</li>
<li><strong>生成路径</strong>：在数据增强流水线（Transforms，如 <code>Resize</code> 或 <code>Pad</code>）中生成并记录，确保在计算 Loss 时能把预测框还原到正确的比例。</li>
</ul>
<p><code>batch_gt_instances_ignore</code> (忽略的实例)</p>
<ul>
<li><strong>代表意义</strong>：标注中标记为“不计入评价”的模糊物体，模型检测到或没检测到它们都不算错。</li>
<li><strong>形状</strong>：可选参数，结构与 <code>batch_gt_instances</code> 相同。</li>
<li><strong>来源</strong>：标注文件中特定的 <code>ignore_flag</code> 标记物体。</li>
</ul>
<hr>
<p>数据流向全景图</p>
<ol>
<li><strong>数据层</strong>：产生 <code>batch_gt_instances</code> 和 <code>batch_text_masks</code>。</li>
<li><strong>卷积层</strong>：对 <code>img_feats</code> 处理，通过 <code>reg_pred</code> 得到 <code>bbox_dist_preds</code>。</li>
<li><strong>计算层</strong>：在 <code>forward_single</code> 中利用 <code>softmax</code> 和 <code>matmul</code> 把 <code>bbox_dist_preds</code> 变成 <code>bbox_preds</code>。</li>
<li><strong>比对层</strong>：利用 <code>cls_contrast</code> 将图像特征和文本特征融合，生成 <code>cls_scores</code>。</li>
<li><strong>汇总层</strong>：<code>multi_apply</code> 把所有层级（P3-P5）的上述预测值打成包，一股脑儿丢给 <code>loss_by_feat</code> 评分。</li>
</ol>
</blockquote>
<hr>
<h3 id="操作：提取featmap-size、预测点prior与步长stride"><a class="header-anchor" href="#操作：提取featmap-size、预测点prior与步长stride"></a>操作：提取featmap_size、预测点prior与步长stride</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_imgs = <span class="built_in">len</span>(batch_img_metas)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>num_imgs == batch size</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">current_featmap_sizes = [cls_score.shape[<span class="number">2</span>:] <span class="keyword">for</span> cls_score <span class="keyword">in</span> cls_scores]</span><br></pre></td></tr></table></figure>
<ul>
<li><code>cls_scores</code> 是 list（按尺度）</li>
<li>每个 <code>cls_score</code> shape 近似<code>[Batch, Num_Classes, H, W]</code></li>
</ul>
<hr>
<ul>
<li>
<p><span style="color:#FF0000">切片操作：<code>shape[2:]</code> </span></p>
<ul>
<li>
<p>这里的 <code>[2:]</code> 是 Python 里的**切片（Slicing）**语法。</p>
</li>
<li>
<p>它的意思是：<strong>“从索引为 2 的地方开始，一直取到最后。”</strong></p>
</li>
<li>
<p>索引 0 是 B，索引 1 是 C，索引 2 是 H，索引 3 是 W。</p>
</li>
<li>
<p>所以 <code>shape[2:]</code> 就会跳过开头的 Batch 和 Channel，只留下 <strong><code>(H, W)</code></strong>。</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>循环结构：列表推导式</p>
<ul>
<li>
<p>代码外层的 <code>[... for cls_score in cls_scores]</code> 叫做<strong>列表推导式</strong>。</p>
</li>
<li>
<p><code>cls_scores</code> 是一个列表，里面装着三个层级的预测结果（小、中、大物体层）。</p>
</li>
<li>
<p>这个循环的意思是：去每一个层级里看一眼，把它们的 <code>(H, W)</code> 记录下来，最后排成一个新的列表。</p>
</li>
</ul>
<blockquote>
<p>假设输入图片是 
    <span id="mjx-8126e54">
      <style>
      #mjx-8126e54{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.553ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 4222.4 699" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(1722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(2722.4,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>640</mn><mo>×</mo><mn>640</mn></math></mjx-assistive-mml></mjx-container>
    </span>
  ，经过 YOLO 的多层提取后：</p>
<ul>
<li><strong>第一层 (P3)</strong>：特征图最大，用来找小物体。形状是 <code>[Batch, Classes, 80, 80]</code>。</li>
<li><strong>第二层 (P4)</strong>：中等大小。形状是 <code>[Batch, Classes, 40, 40]</code>。</li>
<li><strong>第三层 (P5)</strong>：最小。形状是 <code>[Batch, Classes, 20, 20]</code>。</li>
</ul>
<p>执行完这行代码后，current_featmap_sizes 的结果就是：</p>
<p><code>[(80, 80), (40, 40), (20, 20)]</code></p>
</blockquote>
</li>
</ul>
<h4 id="假设：分辨率变了"><a class="header-anchor" href="#假设：分辨率变了"></a>假设：分辨率变了</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果特征图大小变了，重新生成参考点</span></span><br><span class="line"><span class="keyword">if</span> current_featmap_sizes != <span class="variable language_">self</span>.featmap_sizes_train:</span><br><span class="line">    <span class="variable language_">self</span>.featmap_sizes_train = current_featmap_sizes</span><br><span class="line"></span><br><span class="line">    mlvl_priors_with_stride = <span class="variable language_">self</span>.prior_generator.grid_priors(</span><br><span class="line">        <span class="variable language_">self</span>.featmap_sizes_train,</span><br><span class="line">        dtype=cls_scores[<span class="number">0</span>].dtype,</span><br><span class="line">        device=cls_scores[<span class="number">0</span>].device,</span><br><span class="line">        with_stride=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>.num_level_priors = [<span class="built_in">len</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> mlvl_priors_with_stride]</span><br><span class="line">    <span class="variable language_">self</span>.flatten_priors_train = torch.cat(mlvl_priors_with_stride, dim=<span class="number">0</span>)</span><br><span class="line">    <span class="variable language_">self</span>.stride_tensor = <span class="variable language_">self</span>.flatten_priors_train[..., [<span class="number">2</span>]]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>这一整段在解决什么问题？</strong></p>
<blockquote>
<p><strong>目标：为当前输入分辨率，生成“所有预测点（priors）在原图坐标系下的位置 + 它们的 stride”，并缓存起来，供后面的 decode 和 assign 使用。</strong></p>
</blockquote>
<p>更具体一点：</p>
<ul>
<li>YOLO 的每一个预测，其实都对应：</li>
<li><strong>一个网格点（grid center）</strong></li>
<li><strong>一个 stride（这个预测点在原图中代表多大区域）</strong></li>
<li>而 <strong>feature map 的大小会随着输入图片尺寸变化而变化</strong></li>
<li>所以：
👉 <strong>只要 feature map 尺寸变了，就必须重新生成这些 prior（否则 bbox 解码和匹配都会错）</strong></li>
</ul>
<p>这段代码干的事情可以总结为一句话：</p>
<blockquote>
<p><strong>“如果 feature map 尺寸变了 → 重新生成所有层的 grid priors（带 stride），并展平成一张大表。”</strong></p>
</blockquote>
</blockquote>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mlvl_priors_with_stride = <span class="variable language_">self</span>.prior_generator.grid_priors(</span><br><span class="line">    <span class="variable language_">self</span>.featmap_sizes_train,</span><br><span class="line">    dtype=cls_scores[<span class="number">0</span>].dtype,</span><br><span class="line">    device=cls_scores[<span class="number">0</span>].device,</span><br><span class="line">    with_stride=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>mlvl_priors_with_stride</code> 是什么？</p>
<p><strong>一个 list，长度 = 特征层数（P3/P4/P5），
每个元素是该层所有 grid point 的 prior 信息（包含 stride）</strong></p>
<blockquote>
<p>具体到每一层，它长什么样？</p>
<p>假设某一层 feature map 是 <code>H x W</code>，stride 是 <code>s</code>：</p>
<ul>
<li>会生成 <code>H * W</code> 个 prior</li>
<li>每个 prior 是一个 <strong>3 维向量</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;[x_center, y_center, stride]</span><br></pre></td></tr></table></figure>
<p>📌 注意：</p>
<ul>
<li>这里的 <code>x_center, y_center</code> <strong>已经是“原图尺度”上的坐标</strong></li>
<li>stride 直接存进去了（因为 <code>with_stride=True</code>）</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<p>举个非常具体的例子（非常重要）</p>
<p>假设某一层：</p>
<ul>
<li>feature map：<code>2 x 3</code></li>
<li>stride = 8</li>
</ul>
<p>那么这一层会生成 <strong>6 个 prior</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;[</span><br><span class="line"> [4, 4, 8],   [12, 4, 8],   [20, 4, 8],</span><br><span class="line"> [4,12, 8],   [12,12, 8],   [20,12, 8]</span><br><span class="line">&gt;]</span><br></pre></td></tr></table></figure>
<p>（每个 grid 的中心点在原图上的坐标）</p>
<hr>
<p>那 <code>mlvl_priors_with_stride</code> 的整体结构是？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;[</span><br><span class="line"> priors_P3,   # shape: [H3*W3, 3]</span><br><span class="line"> priors_P4,   # shape: [H4*W4, 3]</span><br><span class="line"> priors_P5    # shape: [H5*W5, 3]</span><br><span class="line">&gt;]</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.num_level_priors = [<span class="built_in">len</span>(n) <span class="keyword">for</span> n <span class="keyword">in</span> mlvl_priors_with_stride]</span><br></pre></td></tr></table></figure>
<p><strong>这一行只是记录数量</strong></p>
<p>如果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P3: 80*80 = 6400</span><br><span class="line">P4: 40*40 = 1600</span><br><span class="line">P5: 20*20 = 400</span><br></pre></td></tr></table></figure>
<p>那么：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.num_level_priors = [<span class="number">6400</span>, <span class="number">1600</span>, <span class="number">400</span>]</span><br><span class="line"><span class="comment">#告诉模型：第一层有 6400 个点，第二层有 1600 个点... 以后算 Loss 的时候，我们需要根据这些数字把混在一起的数据拆回对应的层级。</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.flatten_priors_train = torch.cat(mlvl_priors_with_stride,</span><br><span class="line">                                      dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong><code>torch.cat(..., dim=0)</code></strong>：将不同层级的参考点列表“首尾相接”，拼成一个巨大的矩阵。</p>
</li>
<li>
<p><strong>形状变化</strong>：从三组数据合并成一个形状为 <strong><code>[所有总点数, 3]</code></strong> 的大 Tensor（比如 
    <span id="mjx-ca42ed8">
      <style>
      #mjx-ca42ed8{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.186ex;" xmlns="http://www.w3.org/2000/svg" width="25.517ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 11278.4 759" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g><g data-mml-node="mo" transform="translate(2222.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(3222.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g><g data-mml-node="mo" transform="translate(5444.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(6444.9,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(8222.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(9278.4,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1500,0)"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>6400</mn><mo>+</mo><mn>1600</mn><mo>+</mo><mn>400</mn><mo>=</mo><mn>8400</mn></math></mjx-assistive-mml></mjx-container>
    </span>
   行）。</p>
</li>
<li>
<p><strong>意义</strong>：合并后，我们可以用一个矩阵乘法处理全图所有的预测结果，效率极高。</p>
</li>
</ul>
<blockquote>
<p><span style="color:#FF0000">具体例子</span></p>
<p>我们假设一个 <strong>极简 YOLO</strong>：</p>
<ul>
<li><strong>只有 2 个 feature level</strong></li>
<li>输入图像大小：<code>32 × 32</code></li>
<li>feature maps：</li>
</ul>
<table>
<thead>
<tr>
<th>level</th>
<th>stride</th>
<th>feature map</th>
</tr>
</thead>
<tbody>
<tr>
<td>P3</td>
<td>8</td>
<td>4 × 4</td>
</tr>
<tr>
<td>P4</td>
<td>16</td>
<td>2 × 2</td>
</tr>
</tbody>
</table>
<p>👉 总预测点数 = <code>4×4 + 2×2 = 16 + 4 = 20</code></p>
<p>1️⃣ P3 层（4×4，stride=8）</p>
<p>grid 中心点坐标（原图尺度）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;x = (j + 0.5) * 8</span><br><span class="line">&gt;y = (i + 0.5) * 8</span><br></pre></td></tr></table></figure>
<p>P3 生成的 priors（16 个）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;priors_P3 = tensor([</span><br><span class="line">[ 4,  4,  8], [12,  4,  8], [20,  4,  8], [28,  4,  8],</span><br><span class="line">[ 4, 12,  8], [12, 12,  8], [20, 12,  8], [28, 12,  8],</span><br><span class="line">[ 4, 20,  8], [12, 20,  8], [20, 20,  8], [28, 20,  8],</span><br><span class="line">[ 4, 28,  8], [12, 28,  8], [20, 28,  8], [28, 28,  8],</span><br><span class="line">&gt;])  # shape: [16, 3]</span><br></pre></td></tr></table></figure>
<hr>
<p>2️⃣ P4 层（2×2，stride=16）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;priors_P4 = tensor([</span><br><span class="line">[ 8,  8, 16], [24,  8, 16],</span><br><span class="line">[ 8, 24, 16], [24, 24, 16],</span><br><span class="line">&gt;])  # shape: [4, 3]</span><br></pre></td></tr></table></figure>
<hr>
<p>3️⃣ 此时 <code>mlvl_priors_with_stride</code> 是什么？</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;mlvl_priors_with_stride = [</span><br><span class="line">  priors_P3,   # [16, 3]</span><br><span class="line">  priors_P4    # [ 4, 3]</span><br><span class="line">&gt;]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>❗注意：
这是一个 <strong>Python list</strong>
里面是 <strong>两个 Tensor，行数不同，但列数都是 3</strong></p>
</blockquote>
<hr>
<p>1️⃣ <code>torch.cat(..., dim=0)</code> 的规则</p>
<p><code>torch.cat(list_of_tensors, dim=0)</code> 的意思是：</p>
<blockquote>
<p><strong>沿着第 0 维（行）拼接</strong></p>
</blockquote>
<p>前提条件：</p>
<ul>
<li>所有 tensor <strong>列数必须相同</strong></li>
<li>行数可以不同</li>
</ul>
<p>现在满足吗？</p>
<table>
<thead>
<tr>
<th>tensor</th>
<th>shape</th>
</tr>
</thead>
<tbody>
<tr>
<td>priors_P3</td>
<td>[16, 3]</td>
</tr>
<tr>
<td>priors_P4</td>
<td>[4, 3]</td>
</tr>
</tbody>
</table>
<p>✔ 列数都是 3
✔ 行数不同没关系</p>
<hr>
<p>2️⃣ 拼接之后，结果长什么样？</p>
<p>拼接顺序 <strong>完全等于 list 的顺序</strong>：<a name="2401"></a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt;flatten_priors_train = tensor([</span><br><span class="line"># ---------- P3 priors ----------</span><br><span class="line">[ 4,  4,  8],</span><br><span class="line">[12,  4,  8],</span><br><span class="line">[20,  4,  8],</span><br><span class="line">[28,  4,  8],</span><br><span class="line">[ 4, 12,  8],</span><br><span class="line">[12, 12,  8],</span><br><span class="line">[20, 12,  8],</span><br><span class="line">[28, 12,  8],</span><br><span class="line">[ 4, 20,  8],</span><br><span class="line">[12, 20,  8],</span><br><span class="line">[20, 20,  8],</span><br><span class="line">[28, 20,  8],</span><br><span class="line">[ 4, 28,  8],</span><br><span class="line">[12, 28,  8],</span><br><span class="line">[20, 28,  8],</span><br><span class="line">[28, 28,  8],</span><br><span class="line"></span><br><span class="line"># ---------- P4 priors ----------</span><br><span class="line">[ 8,  8, 16],</span><br><span class="line">[24,  8, 16],</span><br><span class="line">[ 8, 24, 16],</span><br><span class="line">[24, 24, 16],</span><br><span class="line">&gt;])</span><br></pre></td></tr></table></figure>
<h3 id="形状："><a class="header-anchor" href="#形状："></a>形状：</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;flatten_priors_train.shape == [20, 3]</span><br></pre></td></tr></table></figure>
<hr>
<p>四、总结</p>
<blockquote>
<p><strong>把“分层的 grid priors（P3 / P4 / …）按顺序拼成一张统一的大表，每一行对应一个预测点”。</strong></p>
</blockquote>
<p>你现在可以把它想成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;index   x   y   stride   ← 这就是一个 prior</span><br><span class="line">&gt;------------------------------------------</span><br><span class="line">&gt;0       4   4     8</span><br><span class="line">&gt;1      12   4     8</span><br><span class="line">&gt;...</span><br><span class="line">&gt;15     28  28     8</span><br><span class="line">&gt;16      8   8    16</span><br><span class="line">&gt;17     24   8    16</span><br><span class="line">&gt;18      8  24    16</span><br><span class="line">&gt;19     24  24    16</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>对表达式求值</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.flatten_priors_train.shape, self.flatten_priors_train[:3], self.flatten_priors_train[-3:]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226164627340.png" alt="image-20251226164627340.png"></p>
<ul>
<li>
<p><code>self.flatten_priors_train.shape = (8400, 4)</code>
这说明 <strong>三层 priors 拼在一起的总点数就是 N=8400</strong>（和你前面算的 6400+1600+400 一致）。</p>
</li>
<li>
<p>前 3 行是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[ 4,  4,  8,  8]</span><br><span class="line">[12,  4,  8,  8]</span><br><span class="line">[20,  4,  8,  8]</span><br></pre></td></tr></table></figure>
<p>这非常像：<strong>(x, y, stride_w, stride_h)</strong></p>
<ul>
<li>前两列：网格点中心坐标（单位是输入图像像素坐标）</li>
<li>后两列：stride（这里是 8，说明这是 P3 的点）</li>
</ul>
</li>
<li>
<p>最后 3 行是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[560, 624, 32, 32]</span><br><span class="line">[592, 624, 32, 32]</span><br><span class="line">[624, 624, 32, 32]</span><br></pre></td></tr></table></figure>
<p>stride 是 32，说明最后这些点来自 <strong>P5</strong>（最粗尺度）</p>
</li>
</ul>
<p>这一步的意义是：</p>
<blockquote>
<p><strong>每一个预测点（N=8400）都有一个对应的 prior（坐标+stride），后面 decode bbox、assign 正负样本都靠它对齐。</strong></p>
</blockquote>
<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.stride_tensor = self.flatten_priors_train[..., [2]]</span><br></pre></td></tr></table></figure>
<p><code>[..., [2]]</code> 是什么意思？<a name="2402"></a></p>
<p>这是 <strong>PyTorch 的高级索引</strong>：</p>
<ul>
<li><code>...</code> 表示“保留前面所有维度”</li>
<li><code>[2]</code> 表示“取第 2 列”</li>
<li><strong>用 list <code>[2]</code> 而不是整数 <code>2</code>，是为了保留维度</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">flatten_priors_train[..., 2]</span><br><span class="line">--&gt;形状是[20]</span><br><span class="line">flatten_priors_train[..., [2]]</span><br><span class="line">--&gt;[20, 1]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接上面的例子</span></span><br><span class="line">stride_tensor =</span><br><span class="line">tensor([</span><br><span class="line">  [ <span class="number">8</span>],</span><br><span class="line">  [ <span class="number">8</span>],</span><br><span class="line">  [ <span class="number">8</span>],</span><br><span class="line">  [ <span class="number">8</span>],</span><br><span class="line">  ...</span><br><span class="line">  [ <span class="number">8</span>],</span><br><span class="line">  [<span class="number">16</span>],</span><br><span class="line">  [<span class="number">16</span>],</span><br><span class="line">  [<span class="number">16</span>],</span><br><span class="line">  [<span class="number">16</span>],</span><br><span class="line">])   <span class="comment"># shape: [20, 1]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="标注框GT-预处理（gt-labels-gt-bboxes-pad-bbox-flag）"><a class="header-anchor" href="#标注框GT-预处理（gt-labels-gt-bboxes-pad-bbox-flag）"></a>标注框GT 预处理（gt_labels/gt_bboxes/pad_bbox_flag）</h3>
<p><span style="color:rgb(0, 210, 106)"><strong>把每张图不等数量的 GT（bbox+label）整理成一个统一形状的张量（padding 对齐），并生成一个 mask 标记哪些行是真 GT、哪些行是 padding。</strong></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gt_info = gt_instances_preprocess(batch_gt_instances, num_imgs)</span><br><span class="line">gt_labels = gt_info[:, :, :<span class="number">1</span>]</span><br><span class="line">gt_bboxes = gt_info[:, :, <span class="number">1</span>:]  <span class="comment"># xyxy</span></span><br><span class="line">pad_bbox_flag = (gt_bboxes.<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) &gt; <span class="number">0</span>).<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<h4 id="操作：找出最大标注框数-统一标注形状"><a class="header-anchor" href="#操作：找出最大标注框数-统一标注形状"></a>操作：找出最大标注框数+统一标注形状</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gt_info = gt_instances_preprocess(batch_gt_instances, num_imgs)</span><br></pre></td></tr></table></figure>
<p><span style="color:#FF0000">问题A:<code>batch_gt_instances</code> 是什么？</span></p>
<p>它是一个长度为 <code>num_imgs</code>（也就是 batch size B）的列表：</p>
<ul>
<li><code>batch_gt_instances[i]</code> 代表第 i 张图的 GT</li>
<li>里面通常有：
<ul>
<li><code>bboxes</code>: shape <code>[Mi, 4]</code>（Mi 是第 i 张图的目标数量）</li>
<li><code>labels</code>: shape <code>[Mi]</code> 或 <code>[Mi, 1]</code></li>
</ul>
</li>
</ul>
<p>关键问题是：<strong>每张图的 Mi 不一样</strong>，比如：</p>
<ul>
<li>图0有 2 个目标</li>
<li>图1有 1 个目标</li>
<li>图2有 7 个目标</li>
</ul>
<p>这就导致没法直接堆成一个规整的张量给 assigner（因为 assigner 更喜欢吃张量，不喜欢 ragged list）。</p>
<hr>
<p><span style="color:#FF0000">问题B:<code>gt_instances_preprocess</code> 做了什么？</span></p>
<p>它通常会做两步（你可以把它当作“对齐器”）：</p>
<ol>
<li>找到本 batch 里最大的 GT 数：</li>
</ol>
<ul>
<li><code>M = max(M0, M1, ..., MB-1)</code></li>
</ul>
<ol>
<li>把每张图的 GT 都 pad 到 M 行（不足的补 0）
最终输出一个统一张量 <code>gt_info</code>：</li>
</ol>
<ul>
<li><strong>shape：<code>[B, M, 5]</code></strong>
<ul>
<li>第 0 列：label（类别 id）</li>
<li>第 1~4 列：bbox（xyxy）</li>
</ul>
</li>
</ul>
<p>也就是每一行是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[label, x1, y1, x2, y2]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这就是后面 <code>gt_info[:, :, :1]</code> 和 <code>gt_info[:, :, 1:]</code> 能切出来 label 和 bbox 的原因。</p>
</blockquote>
<hr>
<p><span style="color:#FF0000">具体例子</span></p>
<p>假设 batch size <code>B=2</code>（两张图）：</p>
<p>图0：有 2 个目标</p>
<ul>
<li>labels: <code>[3, 7]</code></li>
<li>bboxes (xyxy):
<ul>
<li><code>[10, 20, 50, 80]</code></li>
<li><code>[100, 40, 140, 90]</code></li>
</ul>
</li>
</ul>
<p>图1：有 1 个目标</p>
<ul>
<li>labels: <code>[2]</code></li>
<li>bbox:
<ul>
<li><code>[15, 10, 40, 30]</code></li>
</ul>
</li>
</ul>
<p>那么 <code>M = max(2,1)=2</code>，需要把图1补到 2 行。</p>
<p>最终 <code>gt_info</code> 会是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">gt_info shape = [2, 2, 5]</span><br><span class="line"></span><br><span class="line">gt_info[0] (图0) =</span><br><span class="line">[</span><br><span class="line">  [ 3,  10, 20,  50, 80],</span><br><span class="line">  [ 7, 100, 40, 140, 90],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">gt_info[1] (图1) =</span><br><span class="line">[</span><br><span class="line">  [ 2,  15, 10,  40, 30],</span><br><span class="line">  [ 0,   0,  0,   0,  0],   # padding 行</span><br><span class="line">]</span><br><span class="line">#可以看到padding 的那一行全是 0（label 也通常补 0）。</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="操作：取标签与标注框数据"><a class="header-anchor" href="#操作：取标签与标注框数据"></a>操作：取标签与标注框数据</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">gt_labels = gt_info[:, :, :<span class="number">1</span>]</span><br><span class="line">gt_bboxes = gt_info[:, :, <span class="number">1</span>:]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>维度切片规则</strong></p>
<p>对 3 维张量 <code>gt_info</code>：</p>
<ul>
<li>第 1 个 <code>:</code> 选 <strong>所有 batch</strong>（0..B-1）</li>
<li>第 2 个 <code>:</code> 选 <strong>所有 gt slot</strong>（0..M-1）</li>
<li>第 3 个是对 <strong>最后一维字段</strong> 的切片</li>
</ul>
<hr>
<p><code>gt_info[:, :, :1]</code></p>
<ul>
<li><code>:1</code> 表示“从 0 开始，到 1 结束（不包含 1）”</li>
<li>所以只取最后一维的第 0 列（label）</li>
<li>得到形状：<code>[B, M, 1]</code></li>
</ul>
<p>For example</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;gt_labels shape = [B, M, 1] = [2, 2, 1]</span><br><span class="line"></span><br><span class="line">&gt;gt_labels =</span><br><span class="line">&gt;[</span><br><span class="line"> [[3], [7]],</span><br><span class="line"> [[2], [0]],   # padding 行 label=0</span><br><span class="line">&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p><code>gt_info[:, :, 1:]</code></p>
<ul>
<li><code>1:</code> 表示“从 1 开始一直取到最后”</li>
<li>所以取最后一维的第 1~4 列（bbox）</li>
<li>得到形状：<code>[B, M, 4]</code></li>
</ul>
<p>For example</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;gt_bboxes shape = [B, M, 4] = [2, 2, 4]</span><br><span class="line"></span><br><span class="line">&gt;gt_bboxes =</span><br><span class="line">&gt;[</span><br><span class="line"> [[10,20,50,80],  [100,40,140,90]],</span><br><span class="line"> [[15,10,40,30],  [  0, 0,  0, 0]],   # padding 行 bbox 全 0</span><br><span class="line">&gt;]</span><br><span class="line">&gt;#注释 # xyxy 是在提醒你：这里 bbox 格式是 (x1, y1, x2, y2)，不是 cxcywh。</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="操作：区分真实标注数据与pad数据"><a class="header-anchor" href="#操作：区分真实标注数据与pad数据"></a>操作：区分真实标注数据与pad数据</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pad_bbox_flag = (gt_bboxes.<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) &gt; <span class="number">0</span>).<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>gt_bboxes.sum(-1, keepdim=True)</code></p>
<ul>
<li><code>sum(-1)</code>：对 bbox 的 4 个坐标求和</li>
<li>如果这一行是 padding 行，那么 bbox 是 <code>[0,0,0,0]</code>，求和就是 0</li>
<li>如果是真实 bbox，通常坐标 &gt;0（至少 x2、y2 会 &gt;0），求和 &gt; 0</li>
</ul>
<p>For example</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;gt_bboxes.<span class="built_in">sum</span>(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) =</span><br><span class="line">&gt;[</span><br><span class="line"> [[<span class="number">160</span>], [<span class="number">370</span>]],</span><br><span class="line"> [[ <span class="number">95</span>], [  <span class="number">0</span>]],</span><br><span class="line">&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<p><code>&gt; 0</code></p>
<p>变成布尔 mask：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;[</span><br><span class="line"> [[True], [True]],</span><br><span class="line"> [[True], [False]],</span><br><span class="line">&gt;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p><code>.float()</code></p>
<p>把 True/False 转成 1.0/0.0：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;pad_bbox_flag =</span><br><span class="line">&gt;[</span><br><span class="line"> [[1.], [1.]],</span><br><span class="line"> [[1.], [0.]],</span><br><span class="line">&gt;]</span><br><span class="line">&gt;shape = [B, M, 1]</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p><code>gt_instances_preprocess</code> 把每张图的 GT pad 成同样数量 M，得到 <code>gt_info[B,M,5]</code>；
然后拆出 <code>gt_labels[B,M,1]</code> 和 <code>gt_bboxes[B,M,4]</code>；
再用 bbox 是否全 0 来生成 <code>pad_bbox_flag[B,M,1]</code>，标记哪些 GT 行是真实的。</p>
</blockquote>
<h3 id="数据预处理：预测值-flatten"><a class="header-anchor" href="#数据预处理：预测值-flatten"></a>数据预处理：预测值 flatten</h3>
<h4 id="输出：flatten-分类分支"><a class="header-anchor" href="#输出：flatten-分类分支"></a>输出：flatten--&gt; 分类分支</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds = [</span><br><span class="line">    cls_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>, <span class="variable language_">self</span>.num_classes)</span><br><span class="line">    <span class="keyword">for</span> cls_pred <span class="keyword">in</span> cls_scores</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>注意混淆点</strong></p>
<p><code>YOLOWorldHeadModule.forward_single</code> 里的 <code>cls_pred</code> 是「一个模块（nn.Module）」
<code>loss_by_feat</code> 里的 <code>cls_pred</code> 是「一个 Tensor（预测结果）」
它们只是名字一样，<strong>不是同一个东西，也不在同一个作用域里</strong>。</p>
<hr>
<p>这里的 <code>cls_pred</code>是一个 <strong>for 循环里的临时变量名</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="keyword">for</span> cls_pred <span class="keyword">in</span> cls_scores:</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;<span class="keyword">for</span> cls_logit_tensor <span class="keyword">in</span> cls_scores:</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>现在的 <code>cls_pred</code></th>
<th>实际含义</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>cls_pred</code></td>
<td><code>cls_scores[i]</code></td>
</tr>
<tr>
<td>类型</td>
<td><code>Tensor</code></td>
</tr>
<tr>
<td>shape</td>
<td><code>[B, num_classes, Hi, Wi]</code></td>
</tr>
</tbody>
</table>
</blockquote>
<p>每个尺度：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cls_pred.shape = [B, num_classes, H, W]</span><br><span class="line">cls_pred.permute(0, 2, 3, 1):[B, num_classes, H, W]--&gt;[B, H, W, num_classes]</span><br><span class="line">reshape(num_imgs, -1, self.num_classes): --&gt;[B, H*W, num_classes]</span><br><span class="line">#----举例----</span><br><span class="line">cls_pred.shape = [2, 3, 2, 2]---&gt;[2,4,3]</span><br><span class="line">batch 0:</span><br><span class="line">  point 0 → [c0,c1,c2]</span><br><span class="line">  point 1 → [c0,c1,c2]</span><br><span class="line">  point 2 → [c0,c1,c2]</span><br><span class="line">  point 3 → [c0,c1,c2]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最终 <code>flatten_cls_preds</code> 是什么？</p>
<ul>
<li>一个 <strong>list</strong></li>
<li>长度 = feature level 数（如 3）</li>
<li>每个元素 shape = <code>[B, Hi*Wi, num_classes]</code></li>
</ul>
<h4 id="输出：flatten-回归分支"><a class="header-anchor" href="#输出：flatten-回归分支"></a>输出：flatten --&gt;回归分支</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes = [</span><br><span class="line">    bbox_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> bbox_pred <span class="keyword">in</span> bbox_preds</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bbox_pred.shape = [B, 4, H, W]</span><br><span class="line">.permute(0, 2, 3, 1) --&gt;[B, H, W, 4]</span><br><span class="line">.reshape(num_imgs, -1, 4) --&gt;[B, H*W, 4]</span><br><span class="line">#含义;每个 grid 点，对应一个 4 维 bbox 向量</span><br></pre></td></tr></table></figure>
<h4 id="输出：-flatten-回归dist-分支（给-DFL-用）"><a class="header-anchor" href="#输出：-flatten-回归dist-分支（给-DFL-用）"></a>输出： flatten--&gt; 回归dist 分支（给 DFL 用）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_dists = [</span><br><span class="line">    bbox_pred_org.reshape(num_imgs, -<span class="number">1</span>, <span class="variable language_">self</span>.head_module.reg_max * <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> bbox_pred_org <span class="keyword">in</span> bbox_dist_preds</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bbox_pred_org.shape = [B, H*W, 4, reg_max]</span><br><span class="line">---&gt;[B, H*W, 4*reg_max]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>含义</strong></p>
<ul>
<li>每一个 <strong>prior（像素点）</strong></li>
<li>不再按 <code>(left, top, right, bottom)</code> × <code>reg_max</code> 分开</li>
<li>而是<strong>摊平成一个向量</strong></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[l_0 ... l_&#123;reg_max-1&#125;,</span><br><span class="line"> t_0 ... t_&#123;reg_max-1&#125;,</span><br><span class="line"> r_0 ... r_&#123;reg_max-1&#125;,</span><br><span class="line"> b_0 ... b_&#123;reg_max-1&#125;]</span><br></pre></td></tr></table></figure>
<h3 id="操作：跨尺度拼接"><a class="header-anchor" href="#操作：跨尺度拼接"></a>操作：跨尺度拼接</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flatten_dist_preds = torch.cat(flatten_pred_dists, dim=<span class="number">1</span>)</span><br><span class="line">flatten_cls_preds = torch.cat(flatten_cls_preds, dim=<span class="number">1</span>)</span><br><span class="line">flatten_pred_bboxes = torch.cat(flatten_pred_bboxes, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>flatten_pred_dists[i]</code>：每个 level 的 DFL 分布 logits<code>[B, Hi*Wi, 4*reg_max]</code></li>
<li><code>flatten_cls_preds[i]</code>：每个 level 的分类输出 <code>[B, Hi*Wi, num_classes]</code></li>
<li><code>flatten_pred_bboxes[i]</code>：每个 level 的回归输出（<strong>已经是 DFL 期望值后的 4 个数</strong>）<code>[B, Hi*Wi, 4]</code></li>
</ul>
<h4 id="拼接1：DFL-分布预测"><a class="header-anchor" href="#拼接1：DFL-分布预测"></a>拼接1：DFL 分布预测</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_dist_preds = torch.cat(flatten_pred_dists, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>**做什么：**把所有层的 DFL 分布预测拼起来。</p>
<ul>
<li><code>flatten_pred_dists</code> 是一个 list：<code>[level0_dist, level1_dist, level2_dist, ...]</code></li>
<li>每个元素形状：<code>(bs, Ni, 4*reg_max)</code>，其中 <code>Ni = Hi*Wi</code>（该层所有网格点数）</li>
<li><code>dim=1</code> 表示沿着 “点的数量 Ni” 这个维度拼接，得到全尺度总点数 <code>N = ΣNi</code></li>
</ul>
<p><strong>拼完形状：</strong></p>
<ul>
<li><code>flatten_dist_preds</code> → <code>(bs, N, 4*reg_max)</code></li>
</ul>
<p>**为什么要拼：**后面算 DFL loss 时，会用 <code>fg_mask_pre_prior</code> 选出正样本点：<code>pred_dist_pos = flatten_dist_preds[fg_mask_pre_prior]</code>（你代码下面就会用到）。拼成一个大张量，mask/索引会非常方便。 <a target="_blank" rel="noopener" href="https://mmyolo.readthedocs.io/zh_CN/stable/_modules/mmyolo/models/dense_heads/yolov8_head.html">MMYOLO</a></p>
<hr>
<h4 id="拼接2：分类预测"><a class="header-anchor" href="#拼接2：分类预测"></a>拼接2：分类预测</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds = torch.cat(flatten_cls_preds, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>同理，把所有层的分类预测拼起来：</p>
<ul>
<li>每层：<code>(bs, Ni, num_classes)</code></li>
<li>拼完：<code>(bs, N, num_classes)</code></li>
</ul>
<p>后面 assigner 要用它的 <code>sigmoid()</code> 作为分类分数参与匹配（你下面几行 <code>flatten_cls_preds.detach().sigmoid()</code>）。 <a target="_blank" rel="noopener" href="https://mmyolo.readthedocs.io/zh_CN/stable/_modules/mmyolo/models/dense_heads/yolov8_head.html">MMYOLO</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226185137634.png" alt="image-20251226185137634.png"></p>
<hr>
<h4 id="拼接3：-bbox-回归值-flatten-pred-bboxes"><a class="header-anchor" href="#拼接3：-bbox-回归值-flatten-pred-bboxes"></a>拼接3： bbox 回归值--flatten_pred_bboxes</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes = torch.cat(flatten_pred_bboxes, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>同理，把所有层的 “回归 4 个数” 拼起来：</p>
<ul>
<li>每层：<code>(bs, Ni, 4)</code></li>
<li>拼完：<code>(bs, N, 4)</code></li>
</ul>
<p>注意：此时这 4 个数 <strong>还不是最终 xyxy bbox</strong>，它仍然是“相对先验点的回归量”（在 YOLOv8/DFL 体系里通常是 <code>ltrb</code> 距离，且往往在 feature 尺度上）。后面一行 decode 就是把它变成真正的 bbox。 <a target="_blank" rel="noopener" href="https://mmyolo.readthedocs.io/zh_CN/stable/_modules/mmyolo/models/dense_heads/yolov8_head.html">MMYOLO</a></p>
<hr>
<p>拼完之后：</p>
<ul>
<li><code>flatten_cls_preds</code>：<code>[B, N, num_classes]</code></li>
<li><code>flatten_pred_bboxes</code>：<code>[B, N, 4]</code></li>
<li><code>flatten_dist_preds</code>：<code>[B, N, 4*reg_max]</code></li>
<li>其中 <code>N = sum_i (Hi*Wi)</code>（比如常见 80* 80+40* 40+20*20=8400）</li>
</ul>
<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_dist_preds.shape, flatten_cls_preds.shape, flatten_pred_bboxes.shape</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226181431695.png" alt="image-20251226181431695.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_dist_preds</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226181656540.png" alt="image-20251226181656540.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes</span><br></pre></td></tr></table></figure>
<p><code>flatten_pred_bboxes</code>：<code>[B, N, 4]</code></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226181932971.png" alt="image-20251226181932971.png"></p>
<h3 id="解码：flatten-还原真实-xyxy坐标"><a class="header-anchor" href="#解码：flatten-还原真实-xyxy坐标"></a>解码：flatten--还原真实 xyxy坐标</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes = <span class="variable language_">self</span>.bbox_coder.decode(</span><br><span class="line">    <span class="variable language_">self</span>.flatten_priors_train[..., :<span class="number">2</span>], flatten_pred_bboxes,</span><br><span class="line">    <span class="variable language_">self</span>.stride_tensor[..., <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p><strong>总结：</strong></p>
<p><u>把“相对某个 point 的预测（4 个数）”解码成“真实坐标系里的 bbox(x1,y1,x2,y2)”</u></p>
<h4 id="输入-3"><a class="header-anchor" href="#输入-3"></a>输入</h4>
<p><code>self.flatten_priors_train[..., :2]</code></p>
<ul>
<li>来自 <code>prior_generator.grid_priors(..., with_stride=True)</code> 拼起来的先验点（priors）<a href="#2401">点击跳转</a></li>
<li><code>[..., :2]</code> 取的是每个点的 <code>(x, y)</code>（通常是网格中心点） <a target="_blank" rel="noopener" href="https://mmyolo.readthedocs.io/zh_CN/stable/_modules/mmyolo/models/dense_heads/yolov8_head.html">MMYOLO</a></li>
<li><u>也就是把 priors 里的 stride 列丢掉，只保留点坐标 (x,y)</u></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.flatten_priors_train[..., :2]= [ 	[x, y],</span><br><span class="line">                         				[x, y],</span><br><span class="line">                         				... ]</span><br></pre></td></tr></table></figure>
<hr>
<p><code>flatten_pred_bboxes</code></p>
<ul>
<li>刚刚拼好的 <code>(bs, N, 4)</code></li>
<li>表示每个点预测的 4 个回归量（常见理解：<code>l, t, r, b</code> 距离）</li>
</ul>
<hr>
<p><code>self.stride_tensor[..., 0]</code></p>
<ul>
<li><code>stride_tensor.shape = (N,1)</code><a href="#2402">点击跳转</a></li>
<li><code>stride_tensor[..., 0]</code> 就是取最后一维第 0 个元素（唯一那一列），变成：
<ul>
<li><code>(N,1) -&gt; (N,)</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>为什么 decode 还要 stride？
因为很多实现里回归输出是 <strong>feature 尺度</strong>（以网格为单位），而真实 bbox 需要在 <strong>输入图像像素尺度</strong>。stride 就是把“网格单位”换算成“像素单位”的比例。</p>
</blockquote>
<h4 id="简单例子"><a class="header-anchor" href="#简单例子"></a>简单例子</h4>
<p>假设（为了直观）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flatten_priors_train = tensor([</span><br><span class="line">  [124.,  84.,   8.],</span><br><span class="line">  [260., 300.,  16.],</span><br><span class="line">])          # shape = (2,3)  两个点</span><br></pre></td></tr></table></figure>
<p>那么：</p>
<p><code>flatten_priors_train[..., :2]</code> 变成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([</span><br><span class="line">  [124.,  84.],</span><br><span class="line">  [260., 300.],</span><br><span class="line">])          # shape = (2,2)  (x,y)</span><br></pre></td></tr></table></figure>
<p><code>stride_tensor = flatten_priors_train[..., [2]]</code> 变成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([</span><br><span class="line">  [ 8.],</span><br><span class="line">  [16.],</span><br><span class="line">])          # shape = (2,1)</span><br></pre></td></tr></table></figure>
<p><code>stride_tensor[..., 0]</code> 变成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([ 8., 16.])  # shape = (2,)</span><br></pre></td></tr></table></figure>
<h4 id="输出-3"><a class="header-anchor" href="#输出-3"></a>输出</h4>
<p>关键点：</p>
<ul>
<li><code>self.flatten_priors_train[..., :2]</code>：prior 的中心点坐标（或网格点基准）</li>
<li><code>flatten_pred_bboxes</code>：网络预测的偏移量</li>
<li><code>stride_tensor[...,0]</code>：每个 prior 的 stride</li>
</ul>
<p>decode 后：</p>
<ul>
<li><code>flatten_pred_bboxes</code> 变成真正的 <strong>xyxy 坐标</strong>（同一个坐标系下，通常是输入尺度/像素尺度）</li>
<li>形状通常是：<code>(bs, N, 4)</code>
<ul>
<li><code>bs</code>：batch size</li>
<li><code>N</code>：所有层拼起来的点总数（
    <span id="mjx-876a2f4">
      <style>
      #mjx-876a2f4{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="9.456ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 4179.3 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6F4" d="M65 0Q58 4 58 11Q58 16 114 67Q173 119 222 164L377 304Q378 305 340 386T261 552T218 644Q217 648 219 660Q224 678 228 681Q231 683 515 683H799Q804 678 806 674Q806 667 793 559T778 448Q774 443 759 443Q747 443 743 445T739 456Q739 458 741 477T743 516Q743 552 734 574T710 609T663 627T596 635T502 637Q480 637 469 637H339Q344 627 411 486T478 341V339Q477 337 477 336L457 318Q437 300 398 265T322 196L168 57Q167 56 188 56T258 56H359Q426 56 463 58T537 69T596 97T639 146T680 225Q686 243 689 246T702 250H705Q726 250 726 239Q726 238 683 123T639 5Q637 1 610 1Q577 0 348 0H65Z"></path></g><g data-mml-node="msub" transform="translate(806,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(864,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2186.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msub" transform="translate(2908.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Σ</mi><msub><mi>H</mi><mi>i</mi></msub><mo>∗</mo><msub><mi>W</mi><mi>i</mi></msub></math></mjx-assistive-mml></mjx-container>
    </span>
  ）</li>
<li><code>4</code>：<code>[x1, y1, x2, y2]</code></li>
</ul>
</li>
</ul>
<p>这一步完成后，assigner 才能用 bbox 几何关系算匹配质量。</p>
<h4 id="debug-2"><a class="header-anchor" href="#debug-2"></a>debug</h4>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226182438951.png" alt="image-20251226182438951.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226182442278.png" alt="image-20251226182442278.png"></p>
<hr>
<h3 id="操作：assign-正负样本匹配"><a class="header-anchor" href="#操作：assign-正负样本匹配"></a>操作：assign 正负样本匹配</h3>
<h4 id="总结-5"><a class="header-anchor" href="#总结-5"></a>总结</h4>
<blockquote>
<p>把 “预测框 + 预测类别置信度 + priors(点坐标/stride)” 和 “GT 框/类别” 交给 assigner 做匹配（正负样本分配），然后拿到训练用的目标：每个 prior 对应的目标框、目标分类分数，以及正样本 mask。</p>
</blockquote>
<h4 id="操作：assign调用"><a class="header-anchor" href="#操作：assign调用"></a>操作：assign调用</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">assigned_result = <span class="variable language_">self</span>.assigner(</span><br><span class="line">    (flatten_pred_bboxes.detach()).<span class="built_in">type</span>(gt_bboxes.dtype),</span><br><span class="line">    flatten_cls_preds.detach().sigmoid(), <span class="variable language_">self</span>.flatten_priors_train,</span><br><span class="line">    gt_labels, gt_bboxes, pad_bbox_flag)</span><br></pre></td></tr></table></figure>
<p>这行调用了 <strong>样本分配器（assigner）</strong>，在 YOLOv8 系里通常是 <em>TaskAlignedAssigner</em>（或非常接近的实现）：它会根据预测框与 GT 的重叠（IoU）以及预测分类分数，给每个 prior（每个网格点/anchor point）决定：</p>
<ul>
<li>是不是正样本（foreground）</li>
<li>如果是正样本，它对应哪个 GT</li>
<li>正样本该学什么框（target bbox）</li>
<li>分类该学什么“软标签/分数”（target scores）</li>
</ul>
<hr>
<p><strong><code>(flatten_pred_bboxes.detach()).type(gt_bboxes.dtype)</code></strong></p>
<ul>
<li><code>flatten_pred_bboxes</code>：前面 decode 之后的预测框，<strong>坐标系是像素尺度的 xyxy</strong>
形状通常是：<code>(bs, N, 4)</code>
<ul>
<li><code>bs</code>：batch size</li>
<li><code>N</code>：所有层拼起来的点总数（
    <span id="mjx-70ec11e">
      <style>
      #mjx-70ec11e{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="9.456ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 4179.3 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6F4" d="M65 0Q58 4 58 11Q58 16 114 67Q173 119 222 164L377 304Q378 305 340 386T261 552T218 644Q217 648 219 660Q224 678 228 681Q231 683 515 683H799Q804 678 806 674Q806 667 793 559T778 448Q774 443 759 443Q747 443 743 445T739 456Q739 458 741 477T743 516Q743 552 734 574T710 609T663 627T596 635T502 637Q480 637 469 637H339Q344 627 411 486T478 341V339Q477 337 477 336L457 318Q437 300 398 265T322 196L168 57Q167 56 188 56T258 56H359Q426 56 463 58T537 69T596 97T639 146T680 225Q686 243 689 246T702 250H705Q726 250 726 239Q726 238 683 123T639 5Q637 1 610 1Q577 0 348 0H65Z"></path></g><g data-mml-node="msub" transform="translate(806,0)"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(864,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2186.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="msub" transform="translate(2908.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Σ</mi><msub><mi>H</mi><mi>i</mi></msub><mo>∗</mo><msub><mi>W</mi><mi>i</mi></msub></math></mjx-assistive-mml></mjx-container>
    </span>
  ）</li>
<li><code>4</code>：<code>[x1, y1, x2, y2]</code></li>
</ul>
</li>
<li><code>.detach()</code>：<strong>切断梯度</strong>
<ul>
<li>assigner 内部会做匹配（topk、阈值、冲突解决等），这些操作通常<strong>不可微</strong>，也不希望反向传播“通过匹配过程”去更新网络。</li>
<li>所以：预测结果只拿来“算分配关系”，但<strong>不让分配关系反过来影响预测分支的梯度</strong>。</li>
</ul>
</li>
<li><code>.type(gt_bboxes.dtype)</code>：把预测框的 dtype 转成和 GT 一样（通常是 <code>float32</code>）
<ul>
<li>很多训练会开 AMP/mixed precision，预测可能是 <code>float16</code>，但匹配时算 IoU、排序、topk 用 <code>float32</code> 更稳定。</li>
<li>所以这里强制对齐 dtype，减少数值误差/潜在溢出。</li>
</ul>
</li>
</ul>
<p>✅ 总结：这一项是 “用于匹配的预测框（不参与反传，dtype 稳定）”。</p>
<hr>
<p><strong><code>flatten_cls_preds.detach().sigmoid()</code></strong></p>
<ul>
<li><code>flatten_cls_preds</code>：分类预测 logits（还没 sigmoid），形状一般是：<code>(bs, N, num_classes)</code></li>
<li><code>.detach()</code>：同样切断梯度（原因同上：匹配过程不反传）</li>
<li><code>.sigmoid()</code>：把 logits 转为概率分数 <code>p ∈ (0,1)</code>
<ul>
<li>YOLO 的分类通常是 BCE/独立 sigmoid（不是 softmax 多分类互斥）</li>
<li>assigner 需要的是“这个点对某类别有多自信”的概率分数来做匹配打分</li>
</ul>
</li>
</ul>
<p>✅ 总结：这一项是 “用于匹配的分类置信度”。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds.detach().sigmoid()</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226185420644.png" alt="image-20251226185420644.png"></p>
<hr>
<p><code>self.flatten_priors_train</code></p>
<p>这个是你前面拼出来的 priors（点信息），形状常见是：</p>
<ul>
<li><code>self.flatten_priors_train.shape = (N, 3)</code> 或 <code>(N, 4)</code></li>
<li>至少前三列通常是：<code>[x, y, stride]</code></li>
</ul>
<p>assigner 需要它通常是为了：</p>
<ul>
<li>知道每个 prior 的<strong>点坐标</strong>（point / anchor point）</li>
<li>知道它属于哪个 stride（某些实现里会影响候选筛选、中心区域判断等）</li>
</ul>
<hr>
<p><code>gt_labels, gt_bboxes, pad_bbox_flag</code></p>
<p>你前面是这么构造的：</p>
<ul>
<li><code>gt_labels = gt_info[:, :, :1]</code> → 形状 <code>(bs, max_gt, 1)</code></li>
<li><code>gt_bboxes = gt_info[:, :, 1:]</code> → 形状 <code>(bs, max_gt, 4)</code>，xyxy</li>
<li><code>pad_bbox_flag = (gt_bboxes.sum(-1, keepdim=True) &gt; 0).float()</code> → <code>(bs, max_gt, 1)</code></li>
</ul>
<p>这里 <code>max_gt</code> 是为了把 batch 里不同图片的 GT 数量 pad 到同一个长度。</p>
<p><code>pad_bbox_flag</code> 的意义：</p>
<ul>
<li><strong>1 表示这个位置确实有 GT</strong></li>
<li><strong>0 表示这是 padding 出来的空位</strong>（不要参与匹配）</li>
</ul>
<hr>
<h4 id="操作：assign结果取出"><a class="header-anchor" href="#操作：assign结果取出"></a>操作：assign结果取出</h4>
<h5 id="assigned-bboxes"><a class="header-anchor" href="#assigned-bboxes"></a>assigned_bboxes</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_bboxes = assigned_result[&#x27;assigned_bboxes&#x27;]</span><br></pre></td></tr></table></figure>
<p>它一般是：<code>(bs, N, 4)</code> 的张量。</p>
<p>含义：<strong>负责预测的正样本应该回归的目标框坐标</strong>。（xyxy，像素尺度）</p>
<ul>
<li>如果某个 prior 是正样本：这里就是它匹配到的 GT bbox</li>
<li>如果是负样本：通常是 0 或者无意义的占位（反正后面会用 fg_mask 过滤）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_bboxes</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226192758635.png" alt="image-20251226192758635.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226192805459.png" alt="image-20251226192805459.png"></p>
<blockquote>
<p><strong>为啥同一个值？</strong></p>
<p><code>assigned_bboxes.shape = (1, 8400, 4)</code> 表示：<strong>对每一个预测点，都给了一个“对应的目标框”</strong>。</p>
<p>但你这张图里 <code>len(gt_bboxes)=1</code>，只有 <strong>1 个 GT（bus）</strong>。
所以对于那些被 assign 成正样本的点（你刚才算出来一共 10 个），它们<strong>都匹配到同一个 GT</strong>，因此它们的 <code>assigned_bboxes</code> 都会是同一个 <code>[x1,y1,x2,y2]</code>（你截图里就是那组数）。</p>
<p>而对<strong>背景点</strong>（其余 8390 个），实现里通常也会把 <code>assigned_bboxes</code> 填成某个值（常见是 0 或者复用同一个 GT bbox），因为真正决定“算不算 bbox/dfl loss”的是 <strong>mask</strong>：</p>
<ul>
<li><code>fg_mask_pre_prior</code>（True 的才参与 bbox/dfl）</li>
<li>或后面会用它筛选正样本点</li>
</ul>
<p>所以你不要把 <code>assigned_bboxes</code> 看成“每个点都有真实意义的 bbox”，而是看成“一个对齐到 N 的容器”，<strong>真正有效的是 mask 选出来的那一小部分</strong>。</p>
</blockquote>
<hr>
<h5 id="assigned-scores"><a class="header-anchor" href="#assigned-scores"></a>assigned_scores</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_scores = assigned_result[&#x27;assigned_scores&#x27;]</span><br></pre></td></tr></table></figure>
<p>它一般是：<code>(bs, N, num_classes)</code> 的张量。</p>
<p>含义：<strong>负责预测的正样本应该逼近的分类分数</strong>。</p>
<p><strong>重点（难点）</strong>：</p>
<ul>
<li>你可能会以为：如果是猫，目标分数就是 1；不是猫，就是 0。</li>
<li><strong>但在 Task Aligned Assigner 中，不是这样的！</strong></li>
<li>这里的 <code>assigned_scores</code> 是一个 <strong>Soft Label（软标签）</strong>。</li>
<li><strong>正样本的目标分数 = IoU × 类别置信度</strong>（或者类似的质量度量）。</li>
<li><em>直观理解</em>：如果一个预测框跟真实框重叠得非常完美（IoU=0.95），模型应该非常自信（Target=0.95）；如果重叠得很勉强（IoU=0.5），模型就不应该太自信（Target=0.5）。这能教导模型：“不仅要对，还要准”。</li>
<li>负样本的目标分数仍然是 0。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_scores</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226195900367.png" alt="image-20251226195900367.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226195941487.png" alt="image-20251226195941487.png"></p>
<hr>
<h5 id="fg-mask-pre-prior"><a class="header-anchor" href="#fg-mask-pre-prior"></a>fg_mask_pre_prior</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fg_mask_pre_prior = assigned_result[&#x27;fg_mask_pre_prior&#x27;]</span><br></pre></td></tr></table></figure>
<p>形状通常是：<code>(bs, N)</code>（bool 或 0/1）</p>
<p>含义：<strong>哪些 prior 是正样本</strong>（foreground mask）。</p>
<ul>
<li><strong>作用</strong>：这是一个筛选器。
<ul>
<li><code>True</code> 的位置：表示“你是正样本，你要计算分类 Loss，也要计算回归 Loss（画框）”。</li>
<li><code>False</code> 的位置：表示“你是背景，你只需要计算分类 Loss（把分数十成 0），<strong>不需要</strong>计算回归 Loss（因为背景没有框）”。</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fg_mask_pre_prior.shape, fg_mask_pre_prior.sum()</span><br><span class="line">fg_mask_pre_prior</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226185720984.png" alt="image-20251226185720984.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226185825060.png" alt="image-20251226185825060.png"></p>
<ul>
<li><code>fg_mask_pre_prior.shape = (1, 8400)</code></li>
<li><code>fg_mask_pre_prior.sum() = 10</code></li>
</ul>
<p><strong>关键：8400 个点里只有 10 个被选为正样本</strong>（前景点）。</p>
<p>这就是你之后理解 loss 的关键：<strong>大部分点都是背景，只在少数点上回归/分类</strong></p>
<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">len(gt_bboxes), [g.shape for g in gt_bboxes], [g.shape for g in gt_labels]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251226190017547.png" alt="image-20251226190017547.png"></p>
<h4 id="示例-2"><a class="header-anchor" href="#示例-2"></a>示例</h4>
<p>假设：</p>
<ul>
<li><code>bs=1</code></li>
<li>一共 <code>N=5</code> 个 priors（来自不同层拼接）</li>
<li><code>num_classes=3</code>（类 0/1/2）</li>
<li>这张图有 2 个 GT（max_gt=4，但后两个是 padding）</li>
</ul>
<p><strong>GT</strong></p>
<ul>
<li>GT0：class=1，bbox=[100, 70, 150, 110]</li>
<li>GT1：class=0，bbox=[250, 260, 310, 330]</li>
<li>pad_bbox_flag = [1, 1, 0, 0]</li>
</ul>
<p><strong>预测（用于匹配）</strong></p>
<p>5 个 prior 对应 5 个预测框（decode 后）：</p>
<ul>
<li>P0 bbox=[10,10,20,20]</li>
<li>P1 bbox=[102,72,148,108]    （跟 GT0 很像）</li>
<li>P2 bbox=[98,68,152,112]     （跟 GT0 也很像）</li>
<li>P3 bbox=[200,200,220,220]</li>
<li>P4 bbox=[252,262,308,328]   （跟 GT1 很像）</li>
</ul>
<p>分类预测 sigmoid 后的概率（只写关键类）：</p>
<ul>
<li>P1 对 class1 = 0.80</li>
<li>P2 对 class1 = 0.60</li>
<li>P4 对 class0 = 0.90</li>
<li>其它都很低</li>
</ul>
<p>assigner 内部会算一种“对齐分数”（不同实现公式略有差异，但大概是 <strong>IoU 和 cls 分数的组合</strong>），然后为每个 GT 选 topk 个最合适的 priors，并解决冲突。</p>
<p>最后可能得到：</p>
<ul>
<li>正样本 priors：P1、P2（分给 GT0），P4（分给 GT1）</li>
<li>负样本：P0、P3</li>
</ul>
<p>那么输出大概长这样：</p>
<p><code>fg_mask_pre_prior</code> 形状 (1,5)</p>
<ul>
<li><code>[False, True, True, False, True]</code></li>
</ul>
<p><code>assigned_bboxes</code> 形状 (1,5,4)</p>
<ul>
<li>P1、P2 的目标框都等于 GT0</li>
<li>P4 的目标框等于 GT1</li>
<li>P0、P3 位置是 0（占位）</li>
</ul>
<p><code>assigned_scores</code> 形状 (1,5,3)</p>
<ul>
<li>P1 在 class1 这一维是一个正数（可能是 0.7~0.9 之间的软分）</li>
<li>P2 在 class1 这一维也是正数（可能略小）</li>
<li>P4 在 class0 这一维是正数（可能更大）</li>
<li>其它位置全 0</li>
</ul>
<p>这就是后面 loss 要用的训练目标。</p>
<hr>
<h4 id="小总结"><a class="header-anchor" href="#小总结"></a>小总结</h4>
<ol>
<li>**detach：**匹配只是“定目标”，不参与反传</li>
<li>**sigmoid：**assigner 用概率分数做匹配，不用 logits</li>
<li><strong>fg_mask / assigned_bboxes / assigned_scores：</strong>
<ul>
<li>mask 决定哪些点算回归/DFL</li>
<li>assigned_bboxes 是回归目标</li>
<li>assigned_scores 是分类目标（往往是软标签）</li>
</ul>
</li>
</ol>
<h4 id="操作：计算归一化loss分母-assigned-scores-sum"><a class="header-anchor" href="#操作：计算归一化loss分母-assigned-scores-sum"></a>操作：计算归一化loss分母--assigned_scores_sum</h4>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_scores_sum = assigned_scores.<span class="built_in">sum</span>().clamp(<span class="built_in">min</span>=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>这一行是 <strong>“算一个用于归一化 loss 的分母，并且防止分母为 0”</strong>。</p>
<hr>
<p><code>assigned_scores.sum()</code></p>
<p><code>assigned_scores</code> 是 assigner 输出的 <strong>分类目标分数</strong>，形状通常是：</p>
<ul>
<li><code>(bs, N, num_classes)</code></li>
</ul>
<p>它里面的数大致是：</p>
<ul>
<li><strong>正样本</strong>：在对应类别那一维是一个 &gt;0 的“软分数”（可能和 IoU/对齐度有关）</li>
<li><strong>负样本</strong>：全 0</li>
</ul>
<p>所以 <code>assigned_scores.sum()</code> 会把所有 batch、所有 prior、所有类别的目标分数加起来，得到一个标量：</p>
<ul>
<li>如果这批图里有正样本：这个和是一个正数（通常≈正样本个数，但因为是软分，不一定是整数）</li>
<li>如果这批图<strong>完全没有正样本</strong>（比如空图、或被 pad/过滤掉）：这个和就是 0</li>
</ul>
<hr>
<p><code>.clamp(min=1)</code></p>
<p><code>clamp(min=1)</code> 的意思是：<strong>把这个标量下限限制为 1</strong>：</p>
<ul>
<li>如果 <code>sum &gt;= 1</code>：不变</li>
<li>如果 <code>sum &lt; 1</code>（最常见就是 0）：变成 1</li>
</ul>
<p>目的：<strong>避免后面用它做除法时除以 0 或除以非常小的数导致 loss 爆炸/NaN</strong>。</p>
<p>在 YOLO/检测训练里，后面一般会出现类似：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss_cls = (cls_loss * assigned_scores).<span class="built_in">sum</span>() / assigned_scores_sum</span><br><span class="line">loss_bbox = bbox_loss.<span class="built_in">sum</span>() / assigned_scores_sum</span><br><span class="line">loss_dfl  = dfl_loss.<span class="built_in">sum</span>()  / assigned_scores_sum</span><br></pre></td></tr></table></figure>
<p>也就是说：用 <code>assigned_scores_sum</code> 作为“有效正样本量/权重总量”的近似，做归一化，让不同 batch 的正样本数量不同也能保持 loss 尺度稳定。</p>
<hr>
<p><strong>示例</strong></p>
<p>情况 A：有正样本（常见）</p>
<p>假设 <code>bs=1, N=5, num_classes=3</code>，只有 3 个 prior 是正样本：</p>
<ul>
<li>P1 对 class1 的 target score = 0.8</li>
<li>P2 对 class1 的 target score = 0.6</li>
<li>P4 对 class0 的 target score = 0.9</li>
<li>其它都是 0</li>
</ul>
<p>那么：</p>
<ul>
<li><code>assigned_scores.sum() = 0.8 + 0.6 + 0.9 = 2.3</code></li>
<li><code>clamp(min=1)</code> 后还是 <code>2.3</code></li>
</ul>
<p>这时用 2.3 去除，相当于按“目标权重总量”归一化。</p>
<p>情况 B：没有正样本（空 GT 或匹配不到）</p>
<p>如果 <code>assigned_scores</code> 全是 0：</p>
<ul>
<li><code>assigned_scores.sum() = 0</code></li>
<li><code>0.clamp(min=1) = 1</code></li>
</ul>
<p>这时后面除以 1，loss 不会 NaN，而且通常回归/DFL 部分会因为 <code>fg_mask</code> 全 False 而变成 0。</p>
<h3 id="算三个损失（分类-bbox回归-DFL分布回归）"><a class="header-anchor" href="#算三个损失（分类-bbox回归-DFL分布回归）"></a>算三个损失（分类 / bbox回归 / DFL分布回归）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> batch_text_masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    cls_weight = batch_text_masks.view(num_imgs, <span class="number">1</span>, -<span class="number">1</span>).expand(</span><br><span class="line">        -<span class="number">1</span>, flatten_cls_preds.shape[<span class="number">1</span>], -<span class="number">1</span>).to(flatten_cls_preds)</span><br><span class="line"></span><br><span class="line">    loss_cls = <span class="variable language_">self</span>.loss_cls(flatten_cls_preds, assigned_scores)</span><br><span class="line">    _loss_cls = (loss_cls * cls_weight).<span class="built_in">sum</span>(dim=-<span class="number">1</span>)</span><br><span class="line">    loss_cls = _loss_cls.<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loss_cls = <span class="variable language_">self</span>.loss_cls(flatten_cls_preds, assigned_scores).<span class="built_in">sum</span>()</span><br><span class="line">loss_cls /= assigned_scores_sum</span><br><span class="line"></span><br><span class="line"><span class="comment"># rescale bbox</span></span><br><span class="line">assigned_bboxes /= <span class="variable language_">self</span>.stride_tensor</span><br><span class="line">flatten_pred_bboxes /= <span class="variable language_">self</span>.stride_tensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># select positive samples mask</span></span><br><span class="line">num_pos = fg_mask_pre_prior.<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">if</span> num_pos &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># when num_pos &gt; 0, assigned_scores_sum will &gt;0, so the loss_bbox</span></span><br><span class="line">    <span class="comment"># will not report an error</span></span><br><span class="line">    <span class="comment"># iou loss</span></span><br><span class="line">    prior_bbox_mask = fg_mask_pre_prior.unsqueeze(-<span class="number">1</span>).repeat([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    pred_bboxes_pos = torch.masked_select(</span><br><span class="line">        flatten_pred_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    assigned_bboxes_pos = torch.masked_select(</span><br><span class="line">        assigned_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    bbox_weight = torch.masked_select(assigned_scores.<span class="built_in">sum</span>(-<span class="number">1</span>),</span><br><span class="line">                                      fg_mask_pre_prior).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    loss_bbox = <span class="variable language_">self</span>.loss_bbox(</span><br><span class="line">        pred_bboxes_pos, assigned_bboxes_pos,</span><br><span class="line">        weight=bbox_weight) / assigned_scores_sum</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dfl loss</span></span><br><span class="line">    pred_dist_pos = flatten_dist_preds[fg_mask_pre_prior]</span><br><span class="line">    assigned_ltrb = <span class="variable language_">self</span>.bbox_coder.encode(</span><br><span class="line">        <span class="variable language_">self</span>.flatten_priors_train[..., :<span class="number">2</span>] / <span class="variable language_">self</span>.stride_tensor,</span><br><span class="line">        assigned_bboxes,</span><br><span class="line">        max_dis=<span class="variable language_">self</span>.head_module.reg_max - <span class="number">1</span>,</span><br><span class="line">        eps=<span class="number">0.01</span>)</span><br><span class="line">    assigned_ltrb_pos = torch.masked_select(</span><br><span class="line">        assigned_ltrb, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    loss_dfl = <span class="variable language_">self</span>.loss_dfl(pred_dist_pos.reshape(</span><br><span class="line">        -<span class="number">1</span>, <span class="variable language_">self</span>.head_module.reg_max),</span><br><span class="line">                             assigned_ltrb_pos.reshape(-<span class="number">1</span>),</span><br><span class="line">                             weight=bbox_weight.expand(-<span class="number">1</span>,</span><br><span class="line">                                                       <span class="number">4</span>).reshape(-<span class="number">1</span>),</span><br><span class="line">                             avg_factor=assigned_scores_sum)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loss_bbox = flatten_pred_bboxes.<span class="built_in">sum</span>() * <span class="number">0</span></span><br><span class="line">    loss_dfl = flatten_pred_bboxes.<span class="built_in">sum</span>() * <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.world_size == -<span class="number">1</span>:</span><br><span class="line">    _, world_size = get_dist_info()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    world_size = <span class="variable language_">self</span>.world_size</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">dict</span>(loss_cls=loss_cls * num_imgs * world_size,</span><br><span class="line">            loss_bbox=loss_bbox * num_imgs * world_size,</span><br><span class="line">            loss_dfl=loss_dfl * num_imgs * world_size)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这段代码整体就是：<strong>算三个损失（分类 / bbox回归 / DFL分布回归），并做必要的坐标系转换、正样本筛选、归一化，最后按分布式 world_size 做缩放后返回。</strong></p>
<p>我按“这段在讲什么”→“你必须搞懂什么”→“可以略过什么”给你一个学习优先级清单。</p>
<h4 id="A-分类损失-loss-cls"><a class="header-anchor" href="#A-分类损失-loss-cls"></a>A. 分类损失 <code>loss_cls</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> batch_text_masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    cls_weight = batch_text_masks.view(num_imgs, <span class="number">1</span>, -<span class="number">1</span>).expand(-<span class="number">1</span>, N, -<span class="number">1</span>)</span><br><span class="line">    loss_cls = <span class="variable language_">self</span>.loss_cls(flatten_cls_preds, assigned_scores)   <span class="comment"># (bs,N,C)</span></span><br><span class="line">    loss_cls = (loss_cls * cls_weight).<span class="built_in">sum</span>(dim=-<span class="number">1</span>).<span class="built_in">sum</span>()           <span class="comment"># 只算mask=1的类</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loss_cls = <span class="variable language_">self</span>.loss_cls(flatten_cls_preds, assigned_scores).<span class="built_in">sum</span>()</span><br><span class="line">loss_cls /= assigned_scores_sum</span><br></pre></td></tr></table></figure>
<h5 id="一些变量来源"><a class="header-anchor" href="#一些变量来源"></a>一些变量来源</h5>
<ol>
<li><strong><code>flatten_cls_preds</code> (预测值)</strong>
<ul>
<li><strong>是什么</strong>：这是模型“做出的答案”。</li>
<li><strong>形状</strong>：<code>(bs, num_total_anchors, num_classes)</code>。
<ul>
<li><code>bs</code>：Batch Size（比如 16 张图）。</li>
<li><code>num_total_anchors</code>：这张图上一共有多少个预测框（比如 8400 个）。</li>
<li><code>num_classes</code>：<strong>当前</strong>文本提示词（Text Prompts）的数量（比如 80 类，或者 1000 类）。</li>
</ul>
</li>
<li><strong>哪里来</strong>：这是由 <code>ContrastiveHead</code> 计算出来的图像-文本相似度分数（Logits），经过 <code>permute</code> 和 <code>reshape</code> 拍扁得来的。</li>
</ul>
</li>
<li><strong><code>assigned_scores</code> (目标值/标签)</strong>
<ul>
<li><strong>是什么</strong>：这是“标准答案”。由正负样本分配器（TaskAlignedAssigner）计算出来的。</li>
<li><strong>形状</strong>：与 <code>flatten_cls_preds</code> 完全一致 <code>(bs, num_total_anchors, num_classes)</code>。</li>
<li><strong>含义</strong>：正样本位置的分数通常接近 1，负样本位置的分数是 0。</li>
</ul>
</li>
<li><strong><code>batch_text_masks</code> (关键！本次的主角)</strong>
<ul>
<li><strong>是什么</strong>：<strong>文本掩码</strong>。用来标记对于当前这张图片，哪些类别是“有效”的。</li>
<li><strong>形状</strong>：<code>(bs, num_classes)</code>。
<ul>
<li>比如第 0 张图是 COCO 数据，它只有 80 个类有效，mask 里这 80 个位置是 1，其他是 0。</li>
<li>比如第 1 张图是 Objects365 数据，它有 365 个类有效。</li>
</ul>
</li>
<li><strong>为什么需要它？</strong>：这是 <strong>YOLO-World 的精髓</strong>。因为我们在训练时，可能会混合多种数据集（Mix Data），或者每张图输入的 Prompt 不一样。<strong>我们不能强迫模型去学习它没见过的类别的负样本，所以要用 Mask 把无效的类别“遮住”，不计算 Loss。</strong></li>
</ul>
</li>
</ol>
<hr>
<h5 id="1-判断是否需要掩码"><a class="header-anchor" href="#1-判断是否需要掩码"></a>1. 判断是否需要掩码</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if batch_text_masks is not None:</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：如果 <code>batch_text_masks</code> 不是空的，说明我们在进行多数据集混合训练，或者单纯需要过滤掉某些类别，那么就要进入<strong>定制化的 Loss 计算流程</strong>。如果是 <code>None</code>，就说明所有类别都参与计算（走 <code>else</code> 分支）。</li>
</ul>
<h5 id="2-调整掩码形状-最难理解的一步"><a class="header-anchor" href="#2-调整掩码形状-最难理解的一步"></a>2. 调整掩码形状 (最难理解的一步)</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cls_weight = batch_text_masks.view(num_imgs, <span class="number">1</span>, -<span class="number">1</span>).expand(</span><br><span class="line">    -<span class="number">1</span>, flatten_cls_preds.shape[<span class="number">1</span>], -<span class="number">1</span>).to(flatten_cls_preds)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>总结</strong></p>
<p>对<code>batch_text_masks</code>做形状变换</p>
</blockquote>
<ul>
<li><strong>目标</strong>：把 <code>(bs, num_classes)</code> 的 mask，变成和预测值 <code>(bs, N, num_classes)</code> 一样的形状，以便一一对应相乘。</li>
<li><strong>逐个动作分解</strong>：
<ol>
<li><strong><code>.view(num_imgs, 1, -1)</code></strong>:
<ul>
<li>原始形状：<code>(bs, num_classes)</code></li>
<li>变换后：<code>(bs, 1, num_classes)</code>。中间加了一个维度，代表“预测框”的维度，现在只有 1，意思是“对所有预测框都一样”。</li>
</ul>
</li>
<li><strong><code>.expand(-1, flatten_cls_preds.shape[1], -1)</code></strong>:
<ul>
<li><code>flatten_cls_preds.shape[1]</code> 就是 <code>num_anchors</code> (比如 8400)。</li>
<li><strong>广播机制</strong>：这个操作把中间那个 <code>1</code> 复制了 8400 份。</li>
<li>变换后：<code>(bs, 8400, num_classes)</code>。</li>
<li><strong>物理含义</strong>：对于同一张图片，无论你是第 1 个预测框还是第 8400 个预测框，你们面对的“有效类别列表”都是一样的。</li>
</ul>
</li>
<li><strong><code>.to(flatten_cls_preds)</code></strong>:
<ul>
<li>确保数据类型（float16/float32）和设备（CPU/GPU）与预测值一致，防止报错。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h5 id="3-计算原始-Loss"><a class="header-anchor" href="#3-计算原始-Loss"></a>3. 计算原始 Loss</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_cls = <span class="variable language_">self</span>.loss_cls(flatten_cls_preds, assigned_scores)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：这里调用了损失函数（通常是 <code>BCEWithLogitsLoss</code> 或 Focal Loss）。</li>
<li><a href="####%E6%8B%BC%E6%8E%A52%EF%BC%9A%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B">flatten_cls_preds</a><a href="#####assigned_scores">assigned_scores</a></li>
<li><strong>注意</strong>：此时算出来的 <code>loss_cls</code> 形状仍然是 <code>(bs, N, num_classes)</code>。它计算了<strong>所有</strong>位置、<strong>所有</strong>类别的 Loss，其中包含了很多我们不想要的“无效类别”的 Loss。</li>
</ul>
<h5 id="4-应用掩码-Masking"><a class="header-anchor" href="#4-应用掩码-Masking"></a>4. 应用掩码 (Masking)</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_loss_cls = (loss_cls * cls_weight).<span class="built_in">sum</span>(dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：
<ul>
<li><code>loss_cls * cls_weight</code>：这是<strong>点乘（Element-wise product）</strong>。</li>
<li>如果 mask (<code>cls_weight</code>) 对应位置是 1，Loss 保留。</li>
<li><strong>如果 mask 对应位置是 0，Loss 变成 0</strong>。这就是“遮住”无效类别。</li>
<li><code>.sum(dim=-1)</code>：沿着最后一个维度（类别维度）求和。把每个预测框所有类别的 Loss 加起来。</li>
<li>变换后形状：<code>(bs, 8400)</code>。表示每个预测框的总<strong>分类</strong>损失。</li>
</ul>
</li>
</ul>
<h5 id="5-最终求和"><a class="header-anchor" href="#5-最终求和"></a>5. 最终求和</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_cls = _loss_cls.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：把整个 Batch 所有图片、所有框的 Loss 加成一个标量（Scalar），方便反向传播。</li>
</ul>
<h5 id="6-普通情况-Else-分支"><a class="header-anchor" href="#6-普通情况-Else-分支"></a>6. 普通情况 (Else 分支)</h5>
<p>Python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">else:</span><br><span class="line">    loss_cls = self.loss_cls(flatten_cls_preds, assigned_scores).sum()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：如果没有掩码（比如传统的 YOLOv5/v8 训练 COCO，80 类全都要算），那就直接计算 Loss 并求和，不需要中间那个乘以权重归零的步骤。</li>
</ul>
<h5 id="7-归一化-Normalization"><a class="header-anchor" href="#7-归一化-Normalization"></a>7. 归一化 (Normalization)</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_cls /= assigned_scores_sum</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：Loss 的绝对值通常和正样本的数量有关。正样本越多，Loss 越大。为了让梯度稳定，我们需要除以一个归一化因子 <code>assigned_scores_sum</code>（通常对应正样本的数量或者分数的总和）。这样无论图里有 1 只猫还是 100 只猫，Loss 的规模都在一个合理的范围内。</li>
</ul>
<hr>
<h5 id="总结-6"><a class="header-anchor" href="#总结-6"></a>总结</h5>
<ol>
<li><strong>Python 技巧</strong>：
<ul>
<li><code>view</code> + <code>expand</code> 是 PyTorch 中最经典的**广播（Broadcasting）**手动实现方式，用于将低维张量对齐高维张量。</li>
</ul>
</li>
<li><strong>算法原理</strong>：
<ul>
<li><strong>Open-Vocabulary 的数据处理</strong>：在 YOLO-World 中，因为每次输入的类别 Prompt 可能不同，或者数据集混合训练，必须使用 <code>txt_masks</code> 来告诉 Loss 函数：“别瞎算，这张图只管这几个词，其他的词（类别）虽然在词表里，但是这张图里没有标注，不要惩罚模型。”</li>
</ul>
</li>
</ol>
<h5 id="debug-3"><a class="header-anchor" href="#debug-3"></a>debug</h5>
<p><strong>走的else分支，且在运行之后</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_preds.shape, assigned_scores.shape, assigned_scores.sum(), (assigned_scores &gt; 0).sum()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228110545523.png" alt="image-20251228110545523.png"></p>
<p>正样本数=10，但分类 target 是软分数，因此 sum 不等于 10。</p>
<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">归一化前后的 loss_cls</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228111749978.png" alt="image-20251228111749978.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228111818234.png" alt="image-20251228111818234.png"></p>
<hr>
<h4 id="B-坐标系转换（非常关键）"><a class="header-anchor" href="#B-坐标系转换（非常关键）"></a>B. 坐标系转换（非常关键）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">assigned_bboxes /= <span class="variable language_">self</span>.stride_tensor</span><br><span class="line">flatten_pred_bboxes /= <span class="variable language_">self</span>.stride_tensor</span><br></pre></td></tr></table></figure>
<ul>
<li><a href="#####assigned_bboxes">assigned_bboxes</a><code>(bs, N, 4)</code></li>
<li>[flatten_pred_bboxes](###解码：flatten--还原真实 xyxy坐标)<code>(bs, N, 4)</code>|4:<code>[x1, y1, x2, y2]</code></li>
<li><strong>做什么</strong>：把 bbox 从“像素尺度”转回“特征层尺度 / stride尺度”。</li>
<li><strong>为什么</strong>：很多 YOLOv8/DFL 的 bbox loss / 编码方式是按 stride 归一化的（否则不同层 stride 不同会导致量纲不一致）。</li>
</ul>
<h5 id="debug-4"><a class="header-anchor" href="#debug-4"></a>debug</h5>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assigned_bboxes前后</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228142151058.png" alt="image-20251228142151058.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228142233769.png" alt="image-20251228142233769.png"></p>
<hr>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_pred_bboxes前后</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228142911509.png" alt="image-20251228142911509.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228142935028.png" alt="image-20251228142935028.png"></p>
<h4 id="C-只对正样本算回归相关损失"><a class="header-anchor" href="#C-只对正样本算回归相关损失"></a>C. 只对正样本算回归相关损失</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_pos = fg_mask_pre_prior.<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">if</span> num_pos &gt; <span class="number">0</span>:</span><br><span class="line">    prior_bbox_mask = fg_mask_pre_prior.unsqueeze(-<span class="number">1</span>).repeat([<span class="number">1</span>,<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">    pred_bboxes_pos = masked_select(flatten_pred_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">    assigned_bboxes_pos = masked_select(assigned_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">    bbox_weight = masked_select(assigned_scores.<span class="built_in">sum</span>(-<span class="number">1</span>), fg_mask_pre_prior).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">    loss_bbox = <span class="variable language_">self</span>.loss_bbox(pred_bboxes_pos, assigned_bboxes_pos, weight=bbox_weight) / assigned_scores_sum</span><br><span class="line">    ...</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    loss_bbox = <span class="number">0</span></span><br><span class="line">    loss_dfl = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>刚才我们搞定了分类损失（Classification Loss），那时候我们还得小心翼翼地用 <code>batch_text_masks</code> 把无效类别的 Loss 屏蔽掉。</p>
<p>现在进入 <strong>Bbox 回归损失（Regression Loss）</strong> 阶段。这部分代码的逻辑完全不同：分类是要看“所有样本”（正样本要分对，负样本也要分对），但<strong>回归只看“正样本”</strong>（只有在这个位置真的有物体时，去修正框才有意义，背景是不需要修框的）。</p>
<p>这段代码就是 <strong>“如何从成千上万个预测中，只把正样本挑出来算账”</strong> 的过程。</p>
<hr>
<h5 id="num-pos-数正样本"><a class="header-anchor" href="#num-pos-数正样本"></a>num_pos--数正样本</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select positive samples mask</span></span><br><span class="line">num_pos = fg_mask_pre_prior.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>fg_mask_pre_prior</code> 是什么？</strong><a href="#####fg_mask_pre_prior">fg_mask_pre_prior</a>
<ul>
<li><strong>含义</strong>：Foreground Mask（前景掩码）。这是标签分配器（Assigner）告诉我们的结果。它是一个布尔类型的 Tensor，标记了哪些 Anchor Point 是“正样本”。</li>
<li><strong>形状</strong>：<code>(bs, N)</code>。在你的 debug 配置里是 <code>(1, 8400)</code>。</li>
<li><strong>数值</strong>：大部分是 <code>False</code>（背景），只有少数几个（比如那 10 个匹配到 bus 的点）是 <code>True</code>。</li>
</ul>
</li>
<li><strong><code>num_pos</code></strong>：就是一个整数（Scalar），比如 <code>10</code>。</li>
</ul>
<p>你好！同学，欢迎回到课堂。刚才我们搞定了分类损失（Classification Loss），那时候我们还得小心翼翼地用 <code>batch_text_masks</code> 把无效类别的 Loss 屏蔽掉。</p>
<p>现在进入 <strong>Bbox 回归损失（Regression Loss）</strong> 阶段。这部分代码的逻辑完全不同：分类是要看“所有样本”（正样本要分对，负样本也要分对），但<strong>回归只看“正样本”</strong>（只有在这个位置真的有物体时，去修正框才有意义，背景是不需要修框的）。</p>
<p>这段代码就是 <strong>“如何从成千上万个预测中，只把正样本挑出来算账”</strong> 的过程。</p>
<p>我们继续结合你的 <code>debug</code> 场景（1张图，假设匹配到了 10 个正样本）来逐行“断点调试”。</p>
<hr>
<h5 id="判空保护"><a class="header-anchor" href="#判空保护"></a>判空保护</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> num_pos &gt; <span class="number">0</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：这行代码是为了防止“训练崩塌”。如果这张图里一个正样本都没匹配上（比如图太烂，或者物体太小），<code>num_pos</code> 就是 0。这时候如果强行算 Loss，除数是 0 会报错，或者梯度消失/爆炸。如果是 0，就跳过，Loss 记为 0。</li>
</ul>
<h5 id="prior-bbox-mask"><a class="header-anchor" href="#prior-bbox-mask"></a>prior_bbox_mask</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prior_bbox_mask = fg_mask_pre_prior.unsqueeze(-<span class="number">1</span>).repeat([<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<p>这是很多新手看不懂的地方，为什么要 <code>repeat</code>？</p>
<ol>
<li>
<p><strong>原始 <code>fg_mask_pre_prior</code></strong>：形状 <code>(bs, N)</code>。它只管“哪个<strong>点</strong>是正样本”。</p>
</li>
<li>
<p><strong>预测框 <code>flatten_pred_bboxes</code></strong>：形状 <code>(1, 8400, 4)</code>。每个点有 <code>x, y, w, h</code> <strong>4个数值</strong>。</p>
</li>
<li>
<p><strong>冲突</strong>：PyTorch 的 <code>masked_select</code> 是把 Tensor 拍扁了挑数据的。如果你直接用 <code>(1, 8400)</code> 的 mask 去挑 <code>(1, 8400, 4)</code> 的数据，形状对不上，会报错或者挑错。</p>
</li>
<li>
<p><strong>操作流程</strong>：</p>
<ul>
<li><code>unsqueeze(-1)</code>：变身 <code>(1, 8400, 1)</code>。</li>
<li><code>.repeat([1, 1, 4])</code>：变身 <code>(1, 8400, 4)</code>。</li>
<li><strong>效果</strong>：如果第 5 个点是正样本，那么它的 mask 从 <code>True</code> 变成了 <code>[True, True, True, True]</code>。意思就是：“把这个点的 x, y, w, h 这 4 个数全都给我拿出来！”</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228144752694.png" alt="image-20251228144752694.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228144744921.png" alt="image-20251228144744921.png"></p>
</li>
</ol>
<h5 id="masked-select-pred-bboxes-pos和assigned-bboxes-pos"><a class="header-anchor" href="#masked-select-pred-bboxes-pos和assigned-bboxes-pos"></a>masked_select--pred_bboxes_pos和assigned_bboxes_pos</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 拿出“模型”在正样本位置填的答案</span></span><br><span class="line">pred_bboxes_pos = torch.masked_select(</span><br><span class="line">    flatten_pred_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong><code>flatten_pred_bboxes</code></strong>：模型预测出来的所有框，形状 <code>(1, 8400, 4)</code>。</p>
</li>
<li>
<p><strong><code>torch.masked_select</code></strong>：</p>
<ul>
<li>它会把输入 <code>flatten_pred_bboxes</code> <strong>拍扁</strong>成一维 <code>(33600,)</code> (8400*4)。</li>
<li>只保留 <code>prior_bbox_mask</code> 为 <code>True</code> 的元素。</li>
<li>假设有 10 个正样本，就会挑出 <code>10 * 4 = 40</code> 个数值。此时形状是 <code>(40,)</code>。</li>
</ul>
</li>
<li>
<p><strong><code>.reshape([-1, 4])</code></strong>：</p>
<ul>
<li>把这一堆散乱的数值，重新整理成 <code>(N, 4)</code> 的格式。</li>
<li><strong>最终形状</strong>：<code>(10, 4)</code>。</li>
<li><strong>物理含义</strong>：这 10 行，每一行就是一个正样本预测框的 <code>(cx, cy, w, h)</code>（或者 <code>ltrb</code>，看具体的编解码方式）。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228145615789.png" alt="image-20251228145615789.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228145620293.png" alt="image-20251228145620293.png"></p>
</li>
</ul>
<p>同理，对**标签（Ground Truth）**做同样的操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2. 拿出“标准答案”在对应位置的值</span></span><br><span class="line"> assigned_bboxes_pos = torch.masked_select(</span><br><span class="line">     assigned_bboxes, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>结果</strong>：拿出这 10 个正样本对应的“标准答案”框。形状也是 <code>(10, 4)</code>。</li>
</ul>
<h5 id="bbox-weight"><a class="header-anchor" href="#bbox-weight"></a>bbox_weight</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bbox_weight = torch.masked_select(assigned_scores.<span class="built_in">sum</span>(-<span class="number">1</span>),</span><br><span class="line">                                  fg_mask_pre_prior).unsqueeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>注意区别</strong>：这里用的是原始 mask <code>fg_mask_pre_prior</code> (1, 8400)，而不是那个重复 4 次的 <code>prior_bbox_mask</code>。</li>
<li><strong>为什么？</strong>：因为权重是对<strong>每个框</strong>给一个分值，而不是对每个坐标给分值。</li>
<li><strong><code>assigned_scores.sum(-1)</code></strong>：
<ul>
<li><code>assigned_scores</code> 是 <code>(1, 8400, num_classes)</code>。</li>
<li><code>.sum(-1)</code> 变成 <code>(1, 8400)</code>。表示每个位置的总分（在 Task Aligned Assignment 中，这个分值通常反映了预测框和 GT 的 IoU 质量）。</li>
</ul>
</li>
<li><strong>结果</strong>：挑出那 10 个正样本的权重，形状 <code>(10)</code>。</li>
<li><strong><code>.unsqueeze(-1)</code></strong>：变成 <code>(10, 1)</code>，方便后面和 <code>(10, 4)</code> 的 Loss 矩阵做广播乘法。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228155008378.png" alt="image-20251228155008378.png"></p>
<h5 id="loss-bbox"><a class="header-anchor" href="#loss-bbox"></a>loss_bbox</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss_bbox = <span class="variable language_">self</span>.loss_bbox(</span><br><span class="line">    pred_bboxes_pos, assigned_bboxes_pos,</span><br><span class="line">    weight=bbox_weight) / assigned_scores_sum</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>self.loss_bbox</code></strong>：通常是 IoU Loss、GIoU Loss 或 CIoU Loss。
<ul>
<li>输入：10 个预测框 <code>(10, 4)</code> vs 10 个真实框 <code>(10, 4)</code>。</li>
<li>计算：算出 10 个 IoU 值，转换成 Loss。</li>
<li><strong>加权</strong>：乘以 <code>bbox_weight</code>。也就是说，<strong>质量越高的样本（分类分数高、匹配得好），在这个 Loss 里贡献越大</strong>，模型越重视修它的框。</li>
</ul>
</li>
<li><strong><code>/ assigned_scores_sum</code></strong>：
<ul>
<li>再次归一化。和分类损失一样，要把 Loss 的规模控制住，除以正样本权重的总和。</li>
</ul>
</li>
</ul>
<hr>
<h5 id="数据流"><a class="header-anchor" href="#数据流"></a>数据流</h5>
<p>想象一个漏斗：</p>
<ol>
<li><strong>输入（所有预测）</strong>：形状规整的 <code>(Batch, 8400, 4)</code> 张量，里面混杂着大量无效的背景框。</li>
<li><strong>过滤器（Mask）</strong>：<code>fg_mask</code> 就像一个筛子，只允许“正样本”通过。</li>
<li><strong>筛选（Select &amp; Reshape）</strong>：经过 <code>masked_select</code>，我们丢弃了所有背景，只剩下一个紧凑的列表 <code>(N_pos, 4)</code>。</li>
<li><strong>计算</strong>：只对这 <code>N_pos</code> 个框计算 IoU Loss。</li>
</ol>
<hr>
<h4 id="D-DFL-loss（分布式回归）"><a class="header-anchor" href="#D-DFL-loss（分布式回归）"></a>D. DFL loss（分布式回归）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pred_dist_pos = flatten_dist_preds[fg_mask_pre_prior]</span><br><span class="line">assigned_ltrb = <span class="variable language_">self</span>.bbox_coder.encode(priors_xy/stride, assigned_bboxes, max_dis=reg_max-<span class="number">1</span>, eps=<span class="number">0.01</span>)</span><br><span class="line">assigned_ltrb_pos = masked_select(assigned_ltrb, prior_bbox_mask).reshape([-<span class="number">1</span>,<span class="number">4</span>])</span><br><span class="line">loss_dfl = <span class="variable language_">self</span>.loss_dfl(pred_dist_pos.reshape(-<span class="number">1</span>, reg_max),</span><br><span class="line">                         assigned_ltrb_pos.reshape(-<span class="number">1</span>),</span><br><span class="line">                         weight=bbox_weight.expand(-<span class="number">1</span>,<span class="number">4</span>).reshape(-<span class="number">1</span>),</span><br><span class="line">                         avg_factor=assigned_scores_sum)</span><br></pre></td></tr></table></figure>
<p>刚才我们计算了 IoU Loss，那是衡量“预测框”和“真实框”重合度好不好的（宏观结果）。</p>
<p>现在我们要讲的 DFL (Distribution Focal Loss)，是 YOLOv8 引入的一个非常高级的概念，它关注的是**“微观细节”，特别是“边缘的不确定性”**。</p>
<p>简单说：IoU Loss 管“准不准”，DFL Loss 管“稳不稳”。</p>
<p>这段代码稍微有点抽象，因为涉及到了<strong>坐标系转换</strong>和<strong>概率分布</strong>。我们还是结合你的 <code>Debug</code> 场景（1 张图，8400 个点，10 个正样本）来逐行拆解。</p>
<hr>
<h5 id="pred-dist-pos-拿出“概率分布”预测值"><a class="header-anchor" href="#pred-dist-pos-拿出“概率分布”预测值"></a><code>pred_dist_pos</code>--拿出“概率分布”预测值</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pred_dist_pos = flatten_dist_preds[fg_mask_pre_prior]</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong><code>flatten_dist_preds</code> 是什么？</strong></p>
<ul>
<li>
<p>还记得我们之前说的 <code>flatten_pred_bboxes</code> 是最终算出来的坐标 <code>(x1, y1, x2, y2)</code> 吗？那个其实是经过解码（Decode）后的结果。</p>
</li>
<li>
<p>这里的 <code>flatten_dist_preds</code> 是<strong>原始输出（Raw Logits）</strong>。</p>
</li>
<li>
<p><strong>形状</strong>：<code>(1, 8400,64)</code>--&gt;<code>(1, 8400,4*16)</code>。</p>
<ul>
<li><code>4</code>：代表上、下、左、右 4 条边。</li>
<li><code>16</code> (<code>reg_max</code>)：模型不是直接预测一个数（比如“距离左边 5.5 像素”），而是预测一个<strong>长度为 16 的直方图（概率分布）</strong>。它会告诉你：距离是 0 的概率是多少，是 1 的概率是多少……是 15 的概率是多少。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228161534099.png" alt="image-20251228161534099.png"></p>
</li>
</ul>
</li>
<li>
<p><strong>操作</strong>：</p>
<ul>
<li>利用 <code>fg_mask_pre_prior</code>（正样本掩码），把那 10 个“中奖”的 Anchor Point 对应的分布拿出来。</li>
<li><strong>结果 <code>pred_dist_pos</code></strong>：形状 <code>(10, 4*16)</code>。这 10 个正样本，每个样本 4 条边，每条边有 16 个概率值。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228161700706.png" alt="image-20251228161700706.png"></p>
</li>
</ul>
<hr>
<h5 id="assigned-ltrb-——制作“新”标准答案"><a class="header-anchor" href="#assigned-ltrb-——制作“新”标准答案"></a><code>assigned_ltrb</code> ——制作“新”标准答案</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">assigned_ltrb = <span class="variable language_">self</span>.bbox_coder.encode(</span><br><span class="line">    <span class="variable language_">self</span>.flatten_priors_train[..., :<span class="number">2</span>] / <span class="variable language_">self</span>.stride_tensor,</span><br><span class="line">    assigned_bboxes,</span><br><span class="line">    max_dis=<span class="variable language_">self</span>.head_module.reg_max - <span class="number">1</span>,</span><br><span class="line">    eps=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<p>这里发生了<strong>坐标系的剧烈变换</strong>。DFL 这种损失函数，不吃 <code>(x1, y1, x2, y2)</code> 这种绝对坐标，它只吃**“相对距离”**。</p>
<ol>
<li><strong><code>assigned_bboxes</code></strong>：这是原始的标准答案（Ground Truth），比如 <code>(100, 100, 50, 50)</code>（绝对像素坐标）。</li>
<li><strong><code>self.flatten_priors_train[..., :2] / self.stride_tensor</code></strong>：
<ul>
<li>这是 Anchor Point 在**特征图（Feature Map）**上的坐标。</li>
<li>比如 stride=32，原始图上 <code>(320, 320)</code> 的点，在这里就是 <code>(10, 10)</code>。</li>
</ul>
</li>
<li><strong><code>self.bbox_coder.encode</code></strong>：
<ul>
<li>这个函数在算：<strong>真实框的 4 条边，距离我的 Anchor Point 中心，分别有多远？</strong></li>
<li>而且是<strong>归一化</strong>的距离（除以了 Stride）。</li>
<li><strong>例子</strong>：如果 Anchor 在 <code>(10, 10)</code>，真实框的左边在 <code>8.5</code>。那么左边的距离（Left）就是 <code>10 - 8.5 = 1.5</code>。</li>
<li><strong>LTRB</strong>：所以算出来是 <code>(Left, Top, Right, Bottom)</code> 四个数值。</li>
</ul>
</li>
<li><strong>结果 <code>assigned_ltrb</code></strong>：形状 <code>(1, 8400, 4)</code>。每个点都算了一个相对距离（虽然大部分背景点的距离没意义）。</li>
</ol>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228163713739.png" alt="image-20251228163713739.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228163723503.png" alt="image-20251228163723503.png"></p>
<hr>
<h5 id="assigned-ltrb-pos——-再次筛选正样本"><a class="header-anchor" href="#assigned-ltrb-pos——-再次筛选正样本"></a><code>assigned_ltrb_pos</code>—— 再次筛选正样本</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">assigned_ltrb_pos = torch.masked_select(</span><br><span class="line">    assigned_ltrb, prior_bbox_mask).reshape([-<span class="number">1</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>逻辑</strong>：这步和之前算 Bbox Loss 一模一样。</p>
</li>
<li>
<p><strong>动作</strong>：从那 8400 个相对距离里，把 10 个正样本的数据挑出来。</p>
</li>
<li>
<p><strong>结果</strong>：<code>(10, 4)</code>。</p>
<ul>
<li>例如，第一行可能是 <code>[1.5, 2.3, 3.1, 0.8]</code>。意思就是：对于这个正样本，真实边缘分别距离中心 1.5, 2.3, 3.1, 0.8 个单位（特征图尺度）。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228164044615.png" alt="image-20251228164044615.png"><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251228164046169.png" alt="image-20251228164046169.png"></p>
</li>
</ul>
<hr>
<h5 id="loss-dfl——计算-DFL-损失"><a class="header-anchor" href="#loss-dfl——计算-DFL-损失"></a><code>loss_dfl</code>——计算 DFL 损失</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">loss_dfl = <span class="variable language_">self</span>.loss_dfl(</span><br><span class="line">    pred_dist_pos.reshape(-<span class="number">1</span>, <span class="variable language_">self</span>.head_module.reg_max),  <span class="comment"># 输入1：预测分布</span></span><br><span class="line">    assigned_ltrb_pos.reshape(-<span class="number">1</span>),                        <span class="comment"># 输入2：真实标签</span></span><br><span class="line">    weight=bbox_weight.expand(-<span class="number">1</span>, <span class="number">4</span>).reshape(-<span class="number">1</span>),         <span class="comment"># 输入3：权重</span></span><br><span class="line">    avg_factor=assigned_scores_sum                        <span class="comment"># 输入4：归一化因子</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这是 DFL 的核心魔法。</p>
<ul>
<li><strong>输入对比</strong>：
<ul>
<li><strong>预测值 (Prediction)</strong>：<code>pred_dist_pos</code> 变形为 <code>(40, 16)</code>。（10个样本 * 4条边）。每一行是一个长度 16 的概率分布。</li>
<li><strong>真实值 (Target)</strong>：<code>assigned_ltrb_pos</code> 变形为 <code>(40,)</code>。（10个样本 * 4条边）。每一行是一个浮点数，比如 <code>1.5</code>。</li>
</ul>
</li>
<li><strong>DFL 想要干什么？</strong>
<ul>
<li>模型预测了一个分布（比如它觉得距离是 1 的概率是 0.1，距离是 2 的概率是 0.1）。</li>
<li>真实值是 <code>1.5</code>。</li>
<li>DFL 会惩罚模型，<strong>强迫模型把概率集中在 <code>1</code> 和 <code>2</code> 这两个离 <code>1.5</code> 最近的整数上</strong>。</li>
<li>理想情况下，模型应该预测：距离 1 的概率 0.5，距离 2 的概率 0.5，其他是 0。这样 <code>1*0.5 + 2*0.5 = 1.5</code>。</li>
</ul>
</li>
<li><strong>权重 (<code>weight</code>)</strong>：
<ul>
<li>同样使用了 <code>bbox_weight</code>（基于分类分数和 IoU 质量）。</li>
<li>质量越高的样本，我们要让它的边界预测得越“笃定”。</li>
</ul>
</li>
</ul>
<blockquote>
<p><code>self.loss_dfl</code> 就是一个被封装好的“黑盒子”（通常是 MMDetection 库中的 <code>DistributionFocalLoss</code> 类）。你不需要自己去写那些复杂的积分、Softmax 求和、交叉熵公式。<strong>你的任务仅仅是——把数据“喂”给它，而且要“喂”对格式。</strong></p>
</blockquote>
<hr>
<h4 id="E-分布式缩放与返回"><a class="header-anchor" href="#E-分布式缩放与返回"></a>E. 分布式缩放与返回</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">world_size = get_dist_info() ...</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">dict</span>(loss_cls=loss_cls * num_imgs * world_size,</span><br><span class="line">            loss_bbox=loss_bbox * num_imgs * world_size,</span><br><span class="line">            loss_dfl=loss_dfl * num_imgs * world_size)</span><br></pre></td></tr></table></figure>
<p>你好！同学，我们继续攻克这最后一块高地！</p>
<p>刚才我们讲了有正样本（<code>if</code>）的情况，那如果没有正样本（<code>else</code>）怎么办？还有，最后那个奇怪的 <code>return</code> 里的乘法是怎么回事？</p>
<p>来，我们把这段“收尾”代码逐行吃透。</p>
<hr>
<h5 id="else-分支"><a class="header-anchor" href="#else-分支"></a><code>else</code> 分支</h5>
<p>Python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">else:</span><br><span class="line">    loss_bbox = flatten_pred_bboxes.sum() * 0</span><br><span class="line">    loss_dfl = flatten_pred_bboxes.sum() * 0</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>场景</strong>：<code>num_pos == 0</code>。意味着这张图里没有你要找的物体，或者所有 Anchor 都没匹配上（全是背景）。</li>
<li><strong>直觉反应</strong>：既然没物体，Loss 不就是 0 吗？直接写 <code>loss_bbox = 0</code> 不行吗？</li>
<li><strong>教授敲黑板（重点技巧）</strong>：<strong>绝对不能直接写 0！</strong>
<ul>
<li><strong>为什么？</strong> 在多卡训练（DDP）中，PyTorch 要求每张显卡上的<strong>计算图（Computation Graph）必须是连通的</strong>。</li>
<li>如果你直接写 <code>0</code>，<code>loss_bbox</code> 就和前面的网络断开了。PyTorch 会发现：“哎？有些网络层的参数（比如回归分支的卷积层）怎么没参与计算？” 然后它就会报错，或者在同步梯度时卡死。</li>
<li><strong>神操作</strong>：<code>flatten_pred_bboxes.sum() * 0</code>。
<ul>
<li><code>flatten_pred_bboxes</code> 是网络输出，带有梯度。</li>
<li>把它求和再乘 0，结果数值上是 <strong>0</strong>。</li>
<li>但是！<strong>它保留了“导线”</strong>。反向传播时，0 的梯度会沿着这条线传回去（虽然传回去的是 0），这样 PyTorch 就安心了，觉得所有参数都参与了干活。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h5 id="world-size-获取“世界”的大小"><a class="header-anchor" href="#world-size-获取“世界”的大小"></a><code>world_size</code> --获取“世界”的大小</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.world_size == -<span class="number">1</span>:</span><br><span class="line">    _, world_size = get_dist_info()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    world_size = <span class="variable language_">self</span>.world_size</span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>world_size</code> 是什么？</strong>
<ul>
<li>它代表<strong>参与训练的显卡总数</strong>（或者说进程总数）。</li>
<li>比如你是单卡训练，<code>world_size = 1</code>。</li>
<li>如果你用了 8 张 A100 分布式训练，<code>world_size = 8</code>。</li>
</ul>
</li>
<li><strong>逻辑</strong>：如果初始化时没设置（-1），就去系统环境里查一下；如果设置了就用设置的。这主要为了兼容单机和多机训练。</li>
</ul>
<hr>
<h5 id="return-dict-“打包”与“神秘乘法”"><a class="header-anchor" href="#return-dict-“打包”与“神秘乘法”"></a>return dict--“打包”与“神秘乘法”</h5>
<p>Python</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">return dict(loss_cls=loss_cls * num_imgs * world_size,</span><br><span class="line">            loss_bbox=loss_bbox * num_imgs * world_size,</span><br><span class="line">            loss_dfl=loss_dfl * num_imgs * world_size)</span><br></pre></td></tr></table></figure>
<p>这里你肯定会问：<strong>“老师，刚才好不容易除以了 <code>assigned_scores_sum</code> 做归一化，为什么现在又要乘回去？而且还要乘 <code>world_size</code>？”</strong></p>
<p>这是 MMYOLO/MMDetection 框架的一个<strong>核心约定</strong>，主要是为了配合<strong>分布式训练的梯度平均</strong>机制。我们来做个数学题：</p>
<ol>
<li><strong>之前的归一化</strong>：
<ul>
<li>我们算的 <code>loss_cls</code> 是 <strong>“每个正样本（或分数单位）的平均 Loss”</strong>。</li>
<li>公式大约是：
    <span id="mjx-00fac93">
      <style>
      #mjx-00fac93{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -1.24ex;" xmlns="http://www.w3.org/2000/svg" width="14.331ex" height="3.609ex" role="img" focusable="false" viewBox="0 -1047.1 6334.5 1595.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(783,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(1216,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1745,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2486.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(3542.2,0)"><g data-mml-node="mrow" transform="translate(220,516.8) scale(0.707)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="mi" transform="translate(1222.7,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(1903.7,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(2388.7,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(2857.7,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g><g data-mml-node="msub" transform="translate(718.7,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(836,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(988,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g><rect width="2552.3" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><mfrac><mrow><mo data-mjx-texclass="OP">∑</mo><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><msub><mi>N</mi><mrow data-mjx-texclass="ORD"><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mfrac></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
</ul>
</li>
<li><strong>DDP 的默认行为</strong>：
<ul>
<li>当多卡训练时，PyTorch DDP 会在反向传播结束时，把所有显卡的梯度加起来，然后<strong>除以 <code>world_size</code>（取平均）</strong>。</li>
<li>
    <span id="mjx-7b70c71">
      <style>
      #mjx-7b70c71{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.88ex;" xmlns="http://www.w3.org/2000/svg" width="28.055ex" height="3.029ex" role="img" focusable="false" viewBox="0 -950.1 12400.5 1338.9" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mi" transform="translate(786,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1237,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1766,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(2286,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2631,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(3097,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(3697,0)"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="TeXAtom" transform="translate(394,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(550,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(895,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1495,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2024,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g><g data-mml-node="mo" transform="translate(6060.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(7116.5,0)"><g data-mml-node="mrow" transform="translate(220,451.6) scale(0.707)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mn" transform="translate(819,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1222.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(2000.6,0)"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mn" transform="translate(819,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(3223.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(4001.1,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(4279.1,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(4557.1,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mo" transform="translate(4835.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(5613.1,0)"><g data-mml-node="mi"><path data-c="1D43A" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path></g><g data-mml-node="mi" transform="translate(819,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(975,-345) scale(0.707)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(716,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1201,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1652,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(1950,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(2470,0)"><path data-c="5F" d="M0 -62V-25H499V-62H0Z"></path></g><g data-mml-node="mi" transform="translate(2970,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(3439,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3784,0)"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(4249,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g></g><rect width="5044" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mrow data-mjx-texclass="ORD"><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>G</mi><mn>1</mn></msub><mo>+</mo><msub><mi>G</mi><mn>2</mn></msub><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><msub><mi>G</mi><mi>k</mi></msub></mrow><mrow><mi>w</mi><mi>o</mi><mi>r</mi><mi>l</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></mfrac></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
</ul>
</li>
<li><strong>为什么要乘？</strong>
<ul>
<li>如果我们直接返回 
    <span id="mjx-3cf0fa8">
      <style>
      #mjx-3cf0fa8{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.997ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 2208.6 840.8" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(298,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(783,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(1216,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(1745,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>L</mi><mrow data-mjx-texclass="ORD"><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>
    </span>
  ，那么不同显卡因为正样本数量（
    <span id="mjx-567b12e">
      <style>
      #mjx-567b12e{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" style="position: relative;"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="4.335ex" height="2.195ex" role="img" focusable="false" viewBox="0 -683 1916.3 970.2" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(836,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(988,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>N</mi><mrow data-mjx-texclass="ORD"><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></math></mjx-assistive-mml></mjx-container>
    </span>
  ）不一样，Loss 的“分量”其实是不对等的。</li>
<li>为了让梯度更新的<strong>幅度</strong>与<strong>全局的总样本量</strong>（Global Batch Size）相匹配，通常需要把 Loss 重新放大到“Batch 级别”。</li>
<li><strong><code>num_imgs</code></strong>：把“单张图的平均”还原成“当前显卡 Batch 的总和”。</li>
<li><strong><code>world_size</code></strong>：这是为了抵消 DDP 那个“除以 world_size”的操作，或者是为了对齐学习率（Learning Rate）。因为通常学习率是根据 <strong>总 Batch Size</strong> (比如 Batch=128) 设定的。如果你的 Loss 被平均得很小，原来的学习率可能就推不动模型了。</li>
</ul>
</li>
</ol>
<p>一句话总结：</p>
<p>这个乘法是为了保证：无论你用 1 张卡还是 100 张卡训练，无论每个 Batch 里有几个正样本，模型最终更新参数的“步子大小”都是稳定且合理的。</p>
<hr>
<h2 id="小结"><a class="header-anchor" href="#小结"></a>小结</h2>
<p>你现在能用自己的话描述完整链路了：</p>
<ol>
<li><code>img_feats</code> 三层 (80/40/20) → head 输出三路 list</li>
<li>在 <code>loss_by_feat</code> 里 flatten+cat → 得到 <code>N=8400</code> 个点的三路预测</li>
<li>priors 同样 cat → <code>flatten_priors_train</code> 也是 8400 点，每点含坐标+stride</li>
<li>assigner 用 priors+预测+gt → 得到：
<ul>
<li><code>fg_mask_pre_prior</code>（10 个正样本）</li>
<li><code>assigned_scores</code>（软标签，10 个&gt;0，总和约 4.75）</li>
<li><code>assigned_bboxes</code>（对齐容器，但只对 mask=True 的点有效）</li>
</ul>
</li>
<li>三项 loss：
<ul>
<li>cls：对 8400 点算，但 target score 控制贡献</li>
<li>bbox：只对 10 点算（mask select）</li>
<li>dfl：只对 10 点算，并展开成 40 条边 × 16 bins</li>
</ul>
</li>
</ol>
<h2 id="def-loss-and-predict"><a class="header-anchor" href="#def-loss-and-predict"></a>def loss_and_predict</h2>
<p>你好！同学，欢迎回来。我们刚刚攻克了最复杂的 Loss 计算（<code>loss_by_feat</code>），现在我们要看的 <code>loss_and_predict</code> 就轻松多了。</p>
<p>你可以把它看作是一个 <strong>“二合一”套餐</strong>。</p>
<p>在深度学习的训练循环（Training Loop）中，通常我们只需要算 Loss 来更新梯度。但在**验证循环（Validation Loop）<strong>或者</strong>测试（Test）**的时候，我们往往既想知道模型现在的 Loss 是多少（作为性能指标），又想看看它实际预测出来的框准不准。</p>
<p>如果分别调用 <code>loss()</code> 和 <code>predict()</code>，模型的前向传播（Forward）就要跑两次，太浪费计算资源了。所以 <code>loss_and_predict</code> 就是为了**省钱（省算力）**而生的。</p>
<p>我们来逐行拆解它的逻辑：</p>
<hr>
<h3 id="函数签名-4"><a class="header-anchor" href="#函数签名-4"></a>函数签名</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_and_predict</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    img_feats: <span class="type">Tuple</span>[Tensor],</span></span><br><span class="line"><span class="params">    txt_feats: Tensor,</span></span><br><span class="line"><span class="params">    txt_masks: Tensor,</span></span><br><span class="line"><span class="params">    batch_data_samples: SampleList,</span></span><br><span class="line"><span class="params">    proposal_cfg: <span class="type">Optional</span>[ConfigDict] = <span class="literal">None</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">dict</span>, InstanceList]:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>输入</strong>：</p>
</li>
<li>
<p><code>img_feats</code>：图像特征（来自 Neck，比如 PANet/FPN）。</p>
</li>
<li>
<p><code>txt_feats</code>：文本特征（来自 CLIP Text Encoder）。</p>
</li>
<li>
<p><code>txt_masks</code>：文本掩码（我们在 Loss 部分重点讲过）。</p>
</li>
<li>
<p><code>batch_data_samples</code>：包含了 Ground Truth（真实框）和图片元信息的数据包。</p>
</li>
<li>
<p><code>proposal_cfg</code>：预测框的后处理配置（比如 NMS 阈值）。</p>
</li>
<li>
<p><strong>输出</strong>：<code>Tuple[dict, InstanceList]</code></p>
</li>
<li>
<p><code>dict</code>：各种 Loss 的数值（Cls Loss, Bbox Loss, DFL Loss）。</p>
</li>
<li>
<p><code>InstanceList</code>：最终预测出来的检测框结果。</p>
</li>
</ul>
<hr>
<h3 id="步骤拆解"><a class="header-anchor" href="#步骤拆解"></a>步骤拆解</h3>
<h4 id="第一步：拆包“标准答案”"><a class="header-anchor" href="#第一步：拆包“标准答案”"></a>第一步：拆包“标准答案”</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">outputs = unpack_gt_instances(batch_data_samples)</span><br><span class="line">(batch_gt_instances, batch_gt_instances_ignore,</span><br><span class="line"> batch_img_metas) = outputs</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>动作</strong>：从 <code>batch_data_samples</code> 这个大包裹里，把我们需要的三个东西拆出来：</li>
</ul>
<ol>
<li><code>batch_gt_instances</code>: 真实的物体框和类别（用来算 Loss）。</li>
<li><code>batch_gt_instances_ignore</code>: 需要忽略的区域（通常很少用到）。</li>
<li><code>batch_img_metas</code>: 图片的尺寸、缩放比例等信息（用来把预测框还原回原图大小）。</li>
</ol>
<h4 id="第二步：模型前向推理（只跑一次！）"><a class="header-anchor" href="#第二步：模型前向推理（只跑一次！）"></a>第二步：模型前向推理（只跑一次！）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outs = <span class="variable language_">self</span>(img_feats, txt_feats, txt_masks)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：这里调用了 <code>forward</code>。</li>
<li><strong>结果 <code>outs</code></strong>：包含了三个列表（对应不同尺度 P3, P4, P5）：</li>
</ul>
<ol>
<li><code>cls_logits</code>: 分类分数（未经过 Sigmoid）。</li>
<li><code>bbox_preds</code>: 预测框的偏移量/坐标。</li>
<li><code>bbox_dist_preds</code>: DFL 用的分布预测（如果是训练模式会有这个，但在预测时通常只需要前两个，不过 YOLO-World 这里为了统一可能都返回了）。</li>
</ol>
<h4 id="第三步：计算-Loss"><a class="header-anchor" href="#第三步：计算-Loss"></a>第三步：计算 Loss</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">loss_inputs = outs + (txt_masks, batch_gt_instances, batch_img_metas,</span><br><span class="line">                      batch_gt_instances_ignore)</span><br><span class="line">losses = <span class="variable language_">self</span>.loss_by_feat(*loss_inputs)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>动作</strong>：把刚才算出来的 <code>outs</code> 和拆包出来的 GT 组合在一起，丢给 <code>loss_by_feat</code>（就是我们上一节课花大力气讲的那个函数）。</li>
<li><strong>结果</strong>：得到一个字典，比如 <code>&#123;'loss_cls': 0.5, 'loss_bbox': 0.3, ...&#125;</code>。</li>
</ul>
<h4 id="第三步：生成预测结果"><a class="header-anchor" href="#第三步：生成预测结果"></a>第三步：生成预测结果</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = <span class="variable language_">self</span>.predict_by_feat(*outs,</span><br><span class="line">                                   batch_img_metas=batch_img_metas,</span><br><span class="line">                                   cfg=proposal_cfg)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>动作</strong>：同样的 <code>outs</code>，这次丢给 <code>predict_by_feat</code>。</li>
<li><strong>注意</strong>：这里不需要 GT 了（预测的时候当然不能看答案），但需要 <code>batch_img_metas</code> 来做坐标还原。</li>
<li><strong><code>predict_by_feat</code> 内部干了啥？</strong>（简述）：</li>
</ul>
<ol>
<li><strong>Decode</strong>：把模型输出的偏移量，结合 Anchor Point，还原成 <code>(x1, y1, x2, y2)</code>。</li>
<li><strong>Top-K</strong>：几千个框里挑出分数最高的。</li>
<li><strong>NMS (非极大值抑制)</strong>：去除重叠的框，只留最好的。</li>
<li><strong>Rescale</strong>：把坐标从 resize 后的尺寸（比如 640x640）还原回原图尺寸（比如 1920x1080）。</li>
</ol>
<h4 id="第四步：打包返回"><a class="header-anchor" href="#第四步：打包返回"></a>第四步：打包返回</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> losses, predictions</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="教授总结"><a class="header-anchor" href="#教授总结"></a>教授总结</h3>
<p><code>loss_and_predict</code> 其实非常简单，它就是起到了一个**“调度员”**的作用。</p>
<ul>
<li><strong>核心价值</strong>：<strong>共享计算图（Computational Graph）</strong>。<code>outs</code> 是通过一次昂贵的卷积网络计算出来的，我们拿这个结果既去和 GT 比对算 Loss，又去后处理生成最终框，一鱼两吃。</li>
</ul>
<p><strong>调试建议</strong>：
如果你在 Debug 这个函数，你可以观察一下 <code>losses</code> 和 <code>predictions</code> 的关系。通常来说，如果 <code>losses</code> 很低（模型学得好），<code>predictions</code> 里的框应该就和图片上的真实物体贴合得很紧密。如果 Loss 很大，预测出来的框可能就是乱飞的。</p>
<p>这也标志着我们完成了 <code>YOLOWorldHead</code> 核心逻辑的学习！接下来你想深入了解 <code>predict_by_feat</code> 里面的解码和 NMS 细节，还是想看看它是怎么处理文本特征输入的？</p>
<h2 id="def-forward-6"><a class="header-anchor" href="#def-forward-6"></a>def forward</h2>
<p>刚才我们看的是外层的“调度员” <code>loss_and_predict</code>，现在我们要深入到<strong>真正的引擎室</strong> —— 也就是模型真正执行“前向计算”（Forward Pass）的地方。</p>
<p>代码看起来很短：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">Tuple</span>[Tensor], txt_feats: Tensor,</span></span><br><span class="line"><span class="params">            txt_masks: Tensor</span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward features from the upstream network.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.head_module(img_feats, txt_feats, txt_masks)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>但这行代码背后藏着巨大的玄机。因为 <code>self.head_module</code> 是一个 <strong><code>YOLOWorldHeadModule</code></strong>（也在同一个文件里定义），它承载了 YOLO-World 最核心的 <strong>Vision-Language（视商）交互逻辑</strong>。</p>
<p>作为教授，我必须带你跳进 <code>head_module</code> 里，看看它到底在干什么。请把目光移到文件上方的 <code>class YOLOWorldHeadModule</code>，我们重点讲解它的 <code>forward</code> 和核心的 <code>forward_single</code>。</p>
<hr>
<h3 id="第一层：分发中心-——-YOLOWorldHeadModule-forward"><a class="header-anchor" href="#第一层：分发中心-——-YOLOWorldHeadModule-forward"></a>第一层：分发中心 —— <code>YOLOWorldHeadModule.forward</code></h3>
<p>这是 FPN（特征金字塔）的处理入口。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img_feats: <span class="type">Tuple</span>[Tensor], txt_feats: Tensor,</span></span><br><span class="line"><span class="params">            txt_masks: Tensor</span>) -&gt; <span class="type">Tuple</span>[<span class="type">List</span>]:</span><br><span class="line">    <span class="comment"># 1. 检查输入层数（通常是 3 层：P3, P4, P5）</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(img_feats) == <span class="variable language_">self</span>.num_levels</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 复制文本特征</span></span><br><span class="line">    <span class="comment"># img_feats 是 (P3_feat, P4_feat, P5_feat)，是分开的</span></span><br><span class="line">    <span class="comment"># 但 txt_feats (文本) 对所有尺度都是共享的</span></span><br><span class="line">    <span class="comment"># 所以我们要把它复制成 [txt, txt, txt] 这样一个列表，方便和图片一一配对</span></span><br><span class="line">    txt_feats = [txt_feats <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels)]</span><br><span class="line">    txt_masks = [txt_masks <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_levels)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 多尺度并行计算 (核心魔法)</span></span><br><span class="line">    <span class="keyword">return</span> multi_apply(<span class="variable language_">self</span>.forward_single, img_feats, txt_feats,</span><br><span class="line">                       txt_masks, <span class="variable language_">self</span>.cls_preds, <span class="variable language_">self</span>.reg_preds,</span><br><span class="line">                       <span class="variable language_">self</span>.cls_contrasts)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>multi_apply</code> 是什么？</strong></li>
<li>这是 MM 系列库里的一个神器。它相当于一个智能的 <code>for</code> 循环。</li>
<li>它会把 <code>img_feats</code>, <code>txt_feats</code> 等列表里的东西，<strong>逐层</strong>取出来，喂给 <code>self.forward_single</code> 函数。</li>
<li><strong>效果</strong>：<code>forward_single</code> 会被调用 3 次（分别处理 P3, P4, P5），最后把结果打包返回。</li>
</ul>
<hr>
<h3 id="第二层：核心车间-——-forward-single-重中之重"><a class="header-anchor" href="#第二层：核心车间-——-forward-single-重中之重"></a>第二层：核心车间 —— <code>forward_single</code> (重中之重)</h3>
<p>这才是 YOLO-World 检测头真正的“心脏”。在这里，视觉特征和文本特征发生了“化学反应”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_single</span>(<span class="params">self, img_feat: Tensor, txt_feat: Tensor,</span></span><br><span class="line"><span class="params">                   txt_masks: Tensor, cls_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   reg_pred: nn.ModuleList,</span></span><br><span class="line"><span class="params">                   cls_contrast: nn.ModuleList</span>) -&gt; <span class="type">Tuple</span>:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们逐行拆解这个核反应堆：</p>
<h4 id="1-提取视觉特征"><a class="header-anchor" href="#1-提取视觉特征"></a>1. 提取视觉特征</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b, _, h, w = img_feat.shape</span><br><span class="line">cls_embed = cls_pred(img_feat)  <span class="comment"># 视觉分支卷积</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>img_feat</code></strong>：单层特征图，比如 P3 层 <code>(B, C_in, 80, 80)</code>。</li>
<li><strong><code>cls_pred</code></strong>：这是一组卷积层（Conv-BN-SiLU）。它把通用的特征图转换成<strong>适合做分类的 Embedding</strong>。</li>
<li><strong><code>cls_embed</code></strong>：输出形状 <code>(B, embed_dims, H, W)</code>。注意，这里的通道数不再是 80（类别数），而是 <strong><code>embed_dims</code>（比如 512，和 CLIP 文本向量维度对齐）</strong>。</li>
</ul>
<h4 id="2-视觉-语言“联姻”-Contrastive-Logic"><a class="header-anchor" href="#2-视觉-语言“联姻”-Contrastive-Logic"></a>2. 视觉-语言“联姻” (Contrastive Logic)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cls_logit = cls_contrast(cls_embed, txt_feat)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>这是 YOLO-World 与传统 YOLO 最大的不同！</strong></p>
</li>
<li>
<p>传统 YOLO：<code>Conv(C_in, 80)</code> -&gt; 直接输出 80 类分数。</p>
</li>
<li>
<p>YOLO-World：</p>
</li>
<li>
<p><code>cls_embed</code>: 图片的向量 <code>(B, 512, H, W)</code>。</p>
</li>
<li>
<p><code>txt_feat</code>: 文本的向量 <code>(B, K, 512)</code> (K 是当前 Prompt 的数量)。</p>
</li>
<li>
<p><strong><code>cls_contrast</code></strong>：这是一个计算<strong>相似度</strong>的模块（通常是点积 Dot Product）。</p>
</li>
<li>
<p>它在算：<strong>图片上每个像素点的特征，和这 K 个单词的特征，长得像不像？</strong></p>
</li>
<li>
<p><strong><code>cls_logit</code> 结果</strong>：形状 <code>(B, K, H, W)</code>。即每个点对每个单词的“相似度分数”。</p>
</li>
</ul>
<h4 id="3-掩码屏蔽-Masking-——-安全气囊"><a class="header-anchor" href="#3-掩码屏蔽-Masking-——-安全气囊"></a>3. 掩码屏蔽 (Masking) —— 安全气囊</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> txt_masks <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># 调整 mask 形状以匹配特征图: (B, K) -&gt; (B, K, 1, 1) -&gt; (B, K, H, W)</span></span><br><span class="line">    txt_masks = txt_masks.view(b, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(-<span class="number">1</span>, -<span class="number">1</span>, h, w)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">        <span class="comment"># 训练时：为了梯度稳定，既要做乘法也要做赋值</span></span><br><span class="line">        cls_logit = cls_logit * txt_masks</span><br><span class="line">        cls_logit[txt_masks == <span class="number">0</span>] = -<span class="number">10e6</span>  <span class="comment"># 设为负无穷</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 推理时：直接把无效类别的分数设为负无穷</span></span><br><span class="line">        cls_logit[txt_masks == <span class="number">0</span>] = -<span class="number">10e6</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>为什么要设为 <code>-10e6</code>？</strong></li>
<li>因为后面要接 <code>Sigmoid</code> 激活函数。</li>
<li>。</li>
<li>这确保了那些“填充的空单词”或者“不想检测的类别”，其置信度永远是 0，绝不会被检测出来。</li>
</ul>
<h4 id="4-BBox-回归与-DFL-解码-Rep-pred"><a class="header-anchor" href="#4-BBox-回归与-DFL-解码-Rep-pred"></a>4. BBox 回归与 DFL 解码 (Rep_pred)</h4>
<p>这部分负责预测框的位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bbox_dist_preds = reg_pred(img_feat)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>reg_pred</code></strong>：回归分支的卷积。</li>
<li><strong><code>bbox_dist_preds</code></strong>：形状 <code>(B, 4 * 16, H, W)</code>。这里的 <code>16</code> 是 <code>reg_max</code>，代表它预测的是**分布（Distribution）**而不是单一坐标。</li>
</ul>
<p>接下来的一段是 <strong>“积分（Integral）”</strong> 操作，把分布变成具体数值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.reg_max &gt; <span class="number">1</span>:</span><br><span class="line">    <span class="comment"># 1. 变形: 把 4条边 和 16个概率格 拆开</span></span><br><span class="line">    bbox_dist_preds = bbox_dist_preds.reshape(</span><br><span class="line">        [-<span class="number">1</span>, <span class="number">4</span>, <span class="variable language_">self</span>.reg_max, h * w]).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 积分 (Expectation): sum(P(i) * i)</span></span><br><span class="line">    <span class="comment"># softmax(3) 算出概率，matmul(proj) 算出期望值</span></span><br><span class="line">    bbox_preds = bbox_dist_preds.softmax(<span class="number">3</span>).matmul(</span><br><span class="line">        <span class="variable language_">self</span>.proj.view([-<span class="number">1</span>, <span class="number">1</span>])).squeeze(-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 还原形状: (B, 4, H, W)</span></span><br><span class="line">    bbox_preds = bbox_preds.transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(b, -<span class="number">1</span>, h, w)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong><code>self.proj</code></strong>：就是一个 <code>[0, 1, 2, ..., 15]</code> 的常量向量。</li>
<li><strong>物理意义</strong>：模型说距离是 0 的概率是 0.1，距离是 1 的概率是 0.8... 这一步算出了 <strong>加权平均距离</strong>（比如 0.95）。</li>
</ul>
<h4 id="5-返回结果"><a class="header-anchor" href="#5-返回结果"></a>5. 返回结果</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.training:</span><br><span class="line">    <span class="comment"># 训练时：需要 bbox_dist_preds (原始分布) 来算 DFL Loss</span></span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds, bbox_dist_preds</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 推理时：只需要最终的 bbox_preds 坐标</span></span><br><span class="line">    <span class="keyword">return</span> cls_logit, bbox_preds</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h3 id="教授总结-2"><a class="header-anchor" href="#教授总结-2"></a>教授总结</h3>
<p><code>forward</code> 函数其实展示了 YOLO-World 极其优雅的解耦设计：</p>
<ol>
<li><strong>Vision Branch</strong>：提取图像特征。</li>
<li><strong>Language Branch</strong>：文本特征由外部传入（CLIP），这里只负责接收。</li>
<li><strong>Interaction (Head)</strong>：通过 <code>cls_contrast</code> 里的矩阵乘法，瞬间完成<strong>任意类别</strong>的分类预测。</li>
<li><strong>Geometry Branch</strong>：回归分支依然沿用 YOLOv8 的优秀设计（DFL），保证了定位的精度。</li>
</ol>
<p>这下你看懂为什么 YOLO-World 可以“即插即用”各种文本 Prompt 了吗？因为它本质上是在算<strong>图像和文本的相似度矩阵</strong>，而不是在做一个固定的 80 类分类器。</p>
<h2 id="def-predict"><a class="header-anchor" href="#def-predict"></a>def predict</h2>
<p>你好！同学，欢迎继续回到课堂。刚才我们看了“边算 Loss 边预测”的 <code>loss_and_predict</code>，以及“核反应堆”般的 <code>forward</code>。</p>
<p>现在我们要讲解的 <strong><code>predict</code></strong> 函数，是模型在 <strong>“纯推理模式”</strong> 下的入口。当你做 Demo 演示、在生产环境部署，或者跑测试集评估（Evaluation）时，调用的就是它。</p>
<p>它的代码虽然短，但它起到了 <strong>“承上启下”</strong> 的关键作用：承接神经网络的输出，开启后处理（NMS）的流程。</p>
<p>我们来逐行拆解：</p>
<hr>
<h3 id="第一步：收集情报-——-batch-img-metas"><a class="header-anchor" href="#第一步：收集情报-——-batch-img-metas"></a>第一步：收集情报 —— <code>batch_img_metas</code></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_img_metas = [</span><br><span class="line">    data_samples.metainfo <span class="keyword">for</span> data_samples <span class="keyword">in</span> batch_data_samples</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：</li>
<li><code>batch_data_samples</code> 是一个大包裹。在推理时，我们不再需要里面的 <code>gt_instances</code>（真实框），因为我们不知道答案。</li>
<li>我们最需要的是 <strong><code>metainfo</code>（元信息）</strong>。</li>
<li><strong>为什么需要它？</strong></li>
<li>模型看到的图片通常是 <strong>经过缩放和填充（Resize &amp; Pad）</strong> 的 <code>640x640</code> 的正方形。</li>
<li>但你原始的图片可能是 <code>1920x1080</code> 的长方形。</li>
<li><code>metainfo</code> 里记录了 <code>scale_factor</code>（缩放比例，比如 0.33）和 <code>pad_shape</code>（填充后的尺寸）。</li>
<li><strong>伏笔</strong>：后面的函数需要用这些信息，把预测出来的框 <strong>“还原”</strong> 到原始图片的坐标系上去。</li>
</ul>
<hr>
<h3 id="第二步：引擎点火-——-self"><a class="header-anchor" href="#第二步：引擎点火-——-self"></a>第二步：引擎点火 —— <code>self(...)</code></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outs = <span class="variable language_">self</span>(img_feats, txt_feats, txt_masks)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：</li>
<li>这里直接调用了 <code>self.__call__</code>，也就是我们上一节课详细拆解的 <strong><code>forward</code></strong> 函数。</li>
<li><strong>回顾一下</strong>：</li>
<li>它把 <strong>视觉特征</strong> (<code>img_feats</code>) 和 <strong>文本特征</strong> (<code>txt_feats</code>) 扔进 <code>head_module</code>。</li>
<li>它进行了 <strong>Vision-Language 交互</strong>（点积计算相似度）。</li>
<li>它输出了 <strong>Raw Predictions（原始预测）</strong>：</li>
</ul>
<ol>
<li><code>cls_logit</code>: 还没经过 Sigmoid 的分类分数。</li>
<li><code>bbox_preds</code>: 还没经过解码的框坐标/分布。</li>
</ol>
<ul>
<li>注意：这里算的只是“特征图上的数值”，人类是看不懂的。</li>
</ul>
<hr>
<h3 id="第三步：翻译官上场-——-predict-by-feat-核心委托"><a class="header-anchor" href="#第三步：翻译官上场-——-predict-by-feat-核心委托"></a>第三步：翻译官上场 —— <code>predict_by_feat</code> (核心委托)</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predictions = <span class="variable language_">self</span>.predict_by_feat(*outs,</span><br><span class="line">                                   batch_img_metas=batch_img_metas,</span><br><span class="line">                                   rescale=rescale)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这是本函数的 <strong>重头戏</strong>。<code>predict</code> 自己不干脏活累活，它全权委托给了 <strong><code>predict_by_feat</code></strong>。</p>
<ul>
<li>
<p>输入 <code>outs</code>：刚才算出来的原始分数和坐标。</p>
</li>
<li>
<p>输入 <code>rescale=rescale</code>：</p>
</li>
<li>
<p>这是一个布尔值开关。</p>
</li>
<li>
<p>If <code>False</code>：输出的框坐标是基于 <code>640x640</code> 输入图的。</p>
</li>
<li>
<p>**If <code>True</code>：函数内部会自动利用 <code>batch_img_metas</code> 里的缩放比例，把框的坐标映射回原始的 <code>1920x1080</code> 图片上。**这在 Demo 和实际应用中非常重要，否则你的框会画歪。</p>
</li>
<li>
<p><strong><code>predict_by_feat</code> 内部大概会做什么？</strong>（预告）</p>
</li>
</ul>
<ol>
<li><strong>Decode</strong>：把偏移量变成 <code>(x1, y1, x2, y2)</code>。</li>
<li><strong>Filter</strong>：扔掉置信度低于 0.05 的垃圾框。</li>
<li><strong>NMS</strong>：去除重叠的框。</li>
<li><strong>Rescale</strong>：坐标还原。</li>
</ol>
<hr>
<h3 id="第四步：交付结果"><a class="header-anchor" href="#第四步：交付结果"></a>第四步：交付结果</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> predictions</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>输出类型</strong>：<code>InstanceList</code> (List of <code>InstanceData</code>)。</li>
<li><strong>内容</strong>：每个元素对应一张图片，里面包含了最终筛选出来的：</li>
<li><code>bboxes</code>: N 个最终的检测框。</li>
<li><code>scores</code>: 对应的置信度。</li>
<li><code>labels</code>: 对应的类别 ID（对应你输入的 Prompt 里的第几个词）。</li>
</ul>
<hr>
<h3 id="教授总结-3"><a class="header-anchor" href="#教授总结-3"></a>教授总结</h3>
<p><code>predict</code> 函数就像一个 <strong>“转换插头”</strong>：</p>
<ol>
<li><strong>左边</strong> 接的是神经网络的张量世界（Tensor, GPU, 梯度）。</li>
<li><strong>右边</strong> 接的是人类理解的物体世界（Bounding Box, 像素坐标, 类别名）。</li>
<li>它本身逻辑很简单，就是把数据透传给 <code>head_module</code> 算特征，再把特征透传给 <code>predict_by_feat</code> 做后处理。</li>
</ol>
<p><strong>接下来的学习建议：</strong>
既然 <code>predict</code> 把最复杂的活儿都甩锅给了 <code>predict_by_feat</code>，我们接下来的重中之重就是去拆解 <strong><code>predict_by_feat</code></strong>。那里藏着 YOLO-World 如何把成千上万个预测框变成最后那几个精准框的秘密（包括 NMS 和坐标解码）。</p>
<p>准备好进入这个充满细节的函数了吗？</p>
<h2 id="def-aug-test"><a class="header-anchor" href="#def-aug-test"></a>def aug_test</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">aug_test</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             aug_batch_feats,</span></span><br><span class="line"><span class="params">             aug_batch_img_metas,</span></span><br><span class="line"><span class="params">             rescale=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             with_ori_nms=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">             **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Test function with test time augmentation.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;aug_test is not implemented yet.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>你好！同学，你非常细心，连这个“隐藏的小角落”都注意到了。</p>
<p>这段代码虽然只有寥寥几行，而且还是个“报错”函数，但它引出了目标检测竞赛和高精度应用中一个非常重要的概念 —— <strong>TTA (Test Time Augmentation，测试时增强)</strong>。</p>
<h3 id="1-这段代码在干什么？"><a class="header-anchor" href="#1-这段代码在干什么？"></a>1. 这段代码在干什么？</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">aug_test</span>(<span class="params">self, ...</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Test function with test time augmentation.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;aug_test is not implemented yet.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>直译</strong>：如果你试图调用这个函数（也就是试图开启“测试时增强”功能），程序会直接抛出一个错误：“<code>aug_test</code> 还没写好呢（Not Implemented）！”</li>
<li><strong>现状</strong>：在当前的官方 YOLO-World 代码库中，作者<strong>并没有实现</strong>针对 YOLO-World 的 TTA 逻辑。这只是一个为了保持 MMDetection 接口兼容性而存在的占位符。</li>
</ul>
<hr>
<h3 id="2-什么是-aug-test-TTA？（知识扩展）"><a class="header-anchor" href="#2-什么是-aug-test-TTA？（知识扩展）"></a>2. 什么是 <code>aug_test</code> / TTA？（知识扩展）</h3>
<p>作为教授，我得借机给你补补课。虽然这里没实现，但 TTA 是打比赛（比如 Kaggle、COCO 榜单）时的<strong>刷分神器</strong>。</p>
<p><strong>普通测试（Standard Testing）：</strong></p>
<ul>
<li><strong>动作</strong>：拿一张图 -&gt; 预测一次 -&gt; 出结果。</li>
<li><strong>缺点</strong>：如果物体正好被遮挡了一点点，或者角度刁钻，模型可能就漏检了。</li>
</ul>
<p><strong>TTA 测试（Augmented Testing）：</strong></p>
<ul>
<li><strong>动作</strong>：</li>
</ul>
<ol>
<li><strong>变换（Augment）</strong>：把这一张测试图，变成多张图（比如：<strong>原图</strong>、<strong>水平翻转</strong>、<strong>放大 1.2 倍</strong>、<strong>缩小 0.8 倍</strong>）。</li>
<li><strong>推理（Inference）</strong>：让模型对这 4 张图分别进行预测。</li>
<li><strong>融合（Merge）</strong>：把 4 次预测出来的几十个框，通过算法（比如 WBF - Weighted Box Fusion）合并起来。</li>
<li><strong>结果</strong>：通常能涨 1~3 个点的 AP（精度），但速度会慢 4~5 倍。</li>
</ol>
<h3 id="3-为什么-YOLO-World-没写它？"><a class="header-anchor" href="#3-为什么-YOLO-World-没写它？"></a>3. 为什么 YOLO-World 没写它？</h3>
<p>这可能有几个原因：</p>
<ol>
<li><strong>定位是实时检测（Real-Time）</strong>：YOLO-World 主打的是“快”和“开放词汇”。TTA 会极大拖慢速度，违背了“Real-Time”的初衷。</li>
<li><strong>实现复杂</strong>：YOLO-World 有 Vision-Language 的交互。如果是翻转图片，文本特征是不变的；但如果是剪裁图片，可能需要考虑 Prompt 是否还匹配，逻辑比纯视觉模型稍微麻烦一点。</li>
<li><strong>还没来得及</strong>：可能只是开发优先级比较低（To Do List）。</li>
</ol>
<h3 id="4-对你的影响"><a class="header-anchor" href="#4-对你的影响"></a>4. 对你的影响</h3>
<ul>
<li><strong>日常使用</strong>：<strong>毫无影响</strong>。你正常的 <code>demo.py</code> 或者 <code>test.py</code> 默认走的是 <code>simple_test</code>（也就是调用 <code>predict</code>），根本不会进这里。</li>
<li><strong>避坑指南</strong>：<strong>千万不要</strong>在配置文件或者命令行里开启 TTA 选项（比如不要设置 <code>tta=True</code> 或者使用 <code>--tta</code> 参数），否则你的程序跑到这里就会崩掉。</li>
</ul>
<p>好，这个小插曲我们看懂了：它就是一个**“施工中，请绕行”**的牌子。</p>
<p>接下来，我们要进入真正的重头戏 —— <strong><code>predict_by_feat</code></strong>，去看看模型吐出来的几千个数字，是如何变成我们肉眼看到的“框”的！准备好了吗？</p>
<h2 id="def-predict-by-feat"><a class="header-anchor" href="#def-predict-by-feat"></a>def predict_by_feat</h2>
<p>没问题！同学，你的提议非常明智。<code>predict_by_feat</code> 确实是整个后处理流程中最繁琐、变量最多的地方。如果一次性讲完，脑子里很容易变成一团浆糊。</p>
<p>按照我的教学经验，我们可以把这个函数拆解成 <strong>“四大战役”</strong>，我们一个一个来攻克：</p>
<ol>
<li><strong>第一战：战前准备 (Anchors &amp; Config)</strong> —— 生成网格点，准备配置。</li>
<li><strong>第二战：全军集结 (Flatten &amp; Decode)</strong> —— 把 3 层特征图拍扁，把相对坐标解算成绝对坐标。</li>
<li><strong>第三战：初步筛选 (Score Filtering)</strong> —— 这一步至关重要，进入单张图循环，先把置信度低的垃圾框扔掉，减轻 NMS 的压力。</li>
<li><strong>第四战：最终决战 (NMS &amp; Rescale)</strong> —— 去重，把坐标还原回原图尺寸，打包交卷。</li>
</ol>
<hr>
<h3 id="第一战：战前准备-Anchors-Config"><a class="header-anchor" href="#第一战：战前准备-Anchors-Config"></a>第一战：战前准备 (Anchors &amp; Config)</h3>
<hr>
<h4 id="1-核心输入：-cls-scores-bbox-preds"><a class="header-anchor" href="#1-核心输入：-cls-scores-bbox-preds"></a>1. 核心输入： <code>cls_scores</code> &amp; <code>bbox_preds</code></h4>
<p>这两个是我们在 <code>forward</code> 函数里千辛万苦算出来的。</p>
<h5 id="cls-scores-List-Tensor-分类分数"><a class="header-anchor" href="#cls-scores-List-Tensor-分类分数"></a><code>cls_scores: List[Tensor]</code> (分类分数)</h5>
<ul>
<li><strong>物理含义</strong>：模型对特征图上每个点“像什么类别”的打分。</li>
<li><strong>数据结构</strong>：
<ul>
<li><strong>List</strong>: 列表长度通常是 <strong>3</strong>。因为它对应特征金字塔的三个层级（P3, P4, P5）。
<ul>
<li><code>cls_scores[0]</code> (P3): 负责检测小物体（特征图大，80x80）。</li>
<li><code>cls_scores[1]</code> (P4): 负责检测中物体（40x40）。</li>
<li><code>cls_scores[2]</code> (P5): 负责检测大物体（20x20）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>形状 (Shape)</strong>：<code>(B, K, H, W)</code>
<ul>
<li><strong>B</strong>: Batch Size（比如 1）。</li>
<li><strong>K (关键点!)</strong>：在传统 YOLO 里是 80 (COCO类别)。<strong>但在 YOLO-World 里，K = 当前输入的 Prompt 数量</strong>。如果你只输入了 &quot;bus&quot;, &quot;person&quot; 两个词，这里 K 就是 2。</li>
<li><strong>H, W</strong>: 特征图的高宽。</li>
</ul>
</li>
<li><strong>来源</strong>：<code>forward</code> 函数里，图像 Embedding 和 文本 Embedding 做**点积（Dot Product）**的结果。</li>
</ul>
<h5 id="bbox-preds-List-Tensor-框回归预测"><a class="header-anchor" href="#bbox-preds-List-Tensor-框回归预测"></a><code>bbox_preds: List[Tensor]</code> (框回归预测)</h5>
<ul>
<li><strong>物理含义</strong>：模型对特征图上每个点预测的“框长什么样”。</li>
<li><strong>数据结构</strong>：同样是长度为 3 的 List。</li>
<li><strong>形状 (Shape)</strong>：<code>(B, 4, H, W)</code>
<ul>
<li><strong>4</strong>: 代表 4 个数值。</li>
<li><strong>注意</strong>：在进入这个函数之前，DFL（分布焦点损失）的积分操作通常已经在 <code>forward</code> 里做完了。所以这里的 4 通常代表 <strong>(Left, Top, Right, Bottom)</strong> 四个距离值（相对于网格中心的距离），或者是解码后的坐标（取决于具体实现分支，YOLO-World 这里通常是 <strong>LTRB 距离</strong>）。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-可选输入：objectnesses-YOLO-World-中通常为空"><a class="header-anchor" href="#2-可选输入：objectnesses-YOLO-World-中通常为空"></a>2. 可选输入：<code>objectnesses</code> (YOLO-World 中通常为空)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objectnesses: <span class="type">Optional</span>[<span class="type">List</span>[Tensor]] = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>背景知识</strong>：在早期的 YOLO（如 YOLOv3, v5）或者 FCOS 中，会有一个专门的分支预测“这里是不是物体”（0或1）。</li>
<li><strong>YOLO-World 现状</strong>：YOLOv8 和 YOLO-World 采用了 <strong>Decoupled Head（解耦头）</strong> 且去掉了专门的 Objectness 分支。<strong>类别的分数本身就代表了置信度</strong>。</li>
<li><strong>结论</strong>：在 YOLO-World 的调试中，你会发现这个变量一直是 <code>None</code>。代码里写它主要是为了兼容 MMDetection 的其他检测器接口。</li>
</ul>
<hr>
<h4 id="3-环境信息：batch-img-metas-坐标还原的关键"><a class="header-anchor" href="#3-环境信息：batch-img-metas-坐标还原的关键"></a>3. 环境信息：<code>batch_img_metas</code> (坐标还原的关键)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch_img_metas: <span class="type">Optional</span>[<span class="type">List</span>[<span class="built_in">dict</span>]] = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>是什么</strong>：这是从 DataLoader 一路传下来的“档案袋”。</li>
<li><strong>里面有什么</strong>：每个元素是一个字典，包含：
<ul>
<li><code>img_shape</code>: 模型看到的图片大小（比如 <code>(640, 640)</code>）。</li>
<li><code>ori_shape</code>: 原始图片大小（比如 <code>(1920, 1080)</code>）。</li>
<li><code>scale_factor</code>: 缩放比例（比如 <code>0.333</code>）。</li>
</ul>
</li>
<li><strong>作用</strong>：模型输出的坐标是在 640x640 的图上的。最后如果要画回原图，必须除以 <code>scale_factor</code>。没有它，框的位置就全错了。</li>
</ul>
<hr>
<h4 id="4-调节开关：cfg-rescale-with-nms"><a class="header-anchor" href="#4-调节开关：cfg-rescale-with-nms"></a>4. 调节开关：<code>cfg</code>, <code>rescale</code>, <code>with_nms</code></h4>
<ul>
<li><strong><code>cfg</code> (配置)</strong>：
<ul>
<li>即 <code>test_cfg</code>。里面装着 NMS 的参数，比如：</li>
<li><code>score_thr</code>: 0.05 (分数低于这个的直接扔掉，看都不看)。</li>
<li><code>nms_thr</code>: 0.65 (两个框重叠度超过这个，删掉分低的)。</li>
</ul>
</li>
<li><strong><code>rescale</code> (是否还原)</strong>：
<ul>
<li><code>True</code> (默认)：输出原图坐标（1920x1080）。</li>
<li><code>False</code>：输出模型输入图坐标（640x640）。<strong>Debug 时如果发现框画不准，先检查这个开关。</strong></li>
</ul>
</li>
<li><strong><code>with_nms</code> (是否去重)</strong>：
<ul>
<li><code>True</code> (默认)：执行 NMS。</li>
<li><code>False</code>：不执行。你会得到成千上万个重叠的框。通常用于导出 ONNX 或者计算 FPS 时节省时间。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-判断是否有Objectness-分支"><a class="header-anchor" href="#5-判断是否有Objectness-分支"></a>5. 判断是否有Objectness 分支</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(cls_scores) == <span class="built_in">len</span>(bbox_preds)</span><br><span class="line"><span class="comment"># 确保分类和回归的层数对得上（都是 3 层）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> objectnesses <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    with_objectnesses = <span class="literal">False</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    with_objectnesses = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(cls_scores) == <span class="built_in">len</span>(objectnesses)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：这段代码是在做“入参安检”。它确认了到底有没有 Objectness 分支。对于 YOLO-World，<code>with_objectnesses</code> 会被标记为 <code>False</code>。</li>
</ul>
<hr>
<h4 id="6-小结"><a class="header-anchor" href="#6-小结"></a>6.小结</h4>
<p>在进入 <code>predict_by_feat</code> 的第一行代码时，你的脑海里应该有这样一幅图：</p>
<ol>
<li><strong>手里拿着</strong>：3 个尺度的特征图预测结果。
<ul>
<li>P3: <code>(1, 2, 80, 80)</code> (假设 2 个 Prompt)</li>
<li>P4: <code>(1, 2, 40, 40)</code></li>
<li>P5: <code>(1, 2, 20, 20)</code></li>
</ul>
</li>
<li><strong>目标</strong>：把这 <code>80*80 + 40*40 + 20*20 = 8400</code> 个预测点，转换成最终几十个清晰的检测框。</li>
</ol>
<hr>
<p>请把目光锁定在 <code>predict_by_feat</code> 函数的<strong>前半部分</strong>（进入循环之前）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 配置准备</span></span><br><span class="line">cfg = <span class="variable language_">self</span>.test_cfg <span class="keyword">if</span> cfg <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> cfg</span><br><span class="line">cfg = copy.deepcopy(cfg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多标签开关：是否允许一个框同时属于多个类？</span></span><br><span class="line">multi_label = cfg.multi_label</span><br><span class="line">multi_label &amp;= <span class="variable language_">self</span>.num_classes &gt; <span class="number">1</span></span><br><span class="line">cfg.multi_label = multi_label</span><br><span class="line"></span><br><span class="line">num_imgs = <span class="built_in">len</span>(batch_img_metas)</span><br><span class="line"><span class="comment"># 获取特征图尺寸，比如 [(80,80), (40,40), (20,20)]</span></span><br><span class="line">featmap_sizes = [cls_score.shape[<span class="number">2</span>:] <span class="keyword">for</span> cls_score <span class="keyword">in</span> cls_scores]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 生成 Anchor Points (网格点) - 核心！</span></span><br><span class="line"><span class="keyword">if</span> featmap_sizes != <span class="variable language_">self</span>.featmap_sizes:</span><br><span class="line">    <span class="variable language_">self</span>.mlvl_priors = <span class="variable language_">self</span>.prior_generator.grid_priors(</span><br><span class="line">        featmap_sizes,</span><br><span class="line">        dtype=cls_scores[<span class="number">0</span>].dtype,</span><br><span class="line">        device=cls_scores[<span class="number">0</span>].device)</span><br><span class="line">    <span class="variable language_">self</span>.featmap_sizes = featmap_sizes</span><br><span class="line"><span class="comment"># 拍扁成 (Total_Anchors, 2) 的张量，Total=8400</span></span><br><span class="line">flatten_priors = torch.cat(<span class="variable language_">self</span>.mlvl_priors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 准备 Stride 张量</span></span><br><span class="line">mlvl_strides = [</span><br><span class="line">    flatten_priors.new_full(</span><br><span class="line">        (featmap_size.numel() * <span class="variable language_">self</span>.num_base_priors, ), stride) <span class="keyword">for</span></span><br><span class="line">    featmap_size, stride <span class="keyword">in</span> <span class="built_in">zip</span>(featmap_sizes, <span class="variable language_">self</span>.featmap_strides)</span><br><span class="line">]</span><br><span class="line">flatten_stride = torch.cat(mlvl_strides)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="7-cfg"><a class="header-anchor" href="#7-cfg"></a>7.cfg</h4>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229164143073.png" alt="image-20251229164143073.png"></p>
<ul>
<li><code>multi_label: True</code></li>
<li><code>nms_pre: 30000</code></li>
<li><code>score_thr: 0.001</code></li>
<li><code>nms: &#123;'type': 'nms', 'iou_threshold': 0.7&#125;</code></li>
<li><code>max_per_img: 300</code></li>
</ul>
<hr>
<ol>
<li><strong>score_thr = 0.001</strong>
这是“第一道门槛”：分数太低的候选框会被提前丢掉（后面你会看到 <code>conf_inds = scores &gt; score_thr</code> 之类）。</li>
<li><strong>nms_pre = 30000</strong>
这是“进 NMS 之前最多保留多少个候选”（先 topk，避免候选太多跑不动）。</li>
<li><strong>nms iou_threshold = 0.7</strong>
这是 NMS 的“去重强度”：两个框 IoU 超过 0.7，分数低的会被抑制掉。</li>
<li><strong>max_per_img = 300</strong>
最终每张图最多输出 300 个框。</li>
<li><strong>multi_label = True</strong>
一个框位置是否允许属于多个类别（你这里只有 1 类，影响不大，但以后多类会重要）。</li>
</ol>
<h4 id="8-为什么要有-multi-label？"><a class="header-anchor" href="#8-为什么要有-multi-label？"></a>8. 为什么要有 <code>multi_label</code>？</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">multi_label = cfg.multi_label</span><br><span class="line">multi_label &amp;= <span class="variable language_">self</span>.num_classes &gt; <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>普通检测（COCO）</strong>：通常认为一个框就是一种东西（要么是猫，要么是狗）。</li>
<li><strong>开放词汇/属性检测</strong>：一个框可能既是 &quot;person&quot; 又是 &quot;man&quot;，甚至还有 &quot;blue shirt&quot;。</li>
<li><strong>逻辑</strong>：如果你的 <code>num_classes &gt; 1</code> 且配置允许，后续 NMS 策略会变（使用 <code>batched_nms</code> 或者允许重叠）。这个开关在这里先定好。</li>
</ul>
<h4 id="9-特征图尺寸"><a class="header-anchor" href="#9-特征图尺寸"></a>9.特征图尺寸</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_imgs = <span class="built_in">len</span>(batch_img_metas)</span><br><span class="line"><span class="comment"># 获取特征图尺寸，比如 [(80,80), (40,40), (20,20)]</span></span><br><span class="line">featmap_sizes = [cls_score.shape[<span class="number">2</span>:] <span class="keyword">for</span> cls_score <span class="keyword">in</span> cls_scores]</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229165020841.png" alt="image-20251229165020841.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229180824556.png" alt="image-20251229180824556.png"></p>
<h4 id="10-prior-generator-是什么？-难点"><a class="header-anchor" href="#10-prior-generator-是什么？-难点"></a>10. <code>prior_generator</code> 是什么？ (难点)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> featmap_sizes != <span class="variable language_">self</span>.featmap_sizes:</span><br><span class="line">    <span class="variable language_">self</span>.mlvl_priors = <span class="variable language_">self</span>.prior_generator.grid_priors(</span><br><span class="line">        featmap_sizes,</span><br><span class="line">        dtype=cls_scores[<span class="number">0</span>].dtype,</span><br><span class="line">        device=cls_scores[<span class="number">0</span>].device)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>教授解读</strong>：</li>
<li><strong>缓存机制</strong>：<code>if featmap_sizes != self.featmap_sizes:</code>。如果输入图片大小没变（比如一直是 640x640），这 8400 个点就不用重复算，直接用缓存的，省时间。</li>
<li>YOLOv8/World 是 <strong>Anchor-Free</strong> 的。但代码里为什么还要生成 <code>priors</code>？</li>
<li>这里的 <code>priors</code> 其实就是 <strong>Grid Points（网格中心点）</strong>。</li>
<li><strong>例子</strong>：</li>
<li>对于 <code>80x80</code> 的 P3 特征图，它会生成 <code>6400</code> 个点：<code>[(0.5, 0.5), (1.5, 0.5), ... (79.5, 79.5)]</code>。</li>
<li>这些点是模型预测框的 <strong>“锚点”</strong>。模型预测出来的偏移量，都是相对于这些点算的。</li>
</ul>
<p>生成 Anchor Points (网格点)</p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229181206113.png" alt="image-20251229181206113.png"></p>
<h4 id="11-flatten-priors"><a class="header-anchor" href="#11-flatten-priors"></a>11. <code>flatten_priors</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">flatten_priors = torch.cat(<span class="variable language_">self</span>.mlvl_priors)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>动作</strong>：</p>
</li>
<li>
<p>P3 层有 6400 个点。</p>
</li>
<li>
<p>P4 层有 1600 个点。</p>
</li>
<li>
<p>P5 层有 400 个点。</p>
</li>
<li>
<p><code>torch.cat</code> 把它们串起来，变成一个 <strong>(8400, 2)</strong> 的巨大张量。</p>
</li>
<li>
<p><strong>目的</strong>：为了能够和后面同样被“拍扁”的预测结果一一对应。</p>
</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229181339720.png" alt="image-20251229181339720.png"></p>
<h4 id="12-mlvl-strides"><a class="header-anchor" href="#12-mlvl-strides"></a>12.mlvl_strides</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mlvl_strides = [</span><br><span class="line">    flatten_priors.new_full(</span><br><span class="line">        (featmap_size.numel() * <span class="variable language_">self</span>.num_base_priors, ), stride) </span><br><span class="line">    <span class="keyword">for</span> featmap_size, stride <span class="keyword">in</span> <span class="built_in">zip</span>(featmap_sizes, <span class="variable language_">self</span>.featmap_strides)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h5 id="先验知识"><a class="header-anchor" href="#先验知识"></a>先验知识</h5>
<ul>
<li><code>featmap_sizes</code>：不同尺度特征图的尺寸列表，每个元素是一个表示特征图高 × 宽的张量（如<code>(H, W)</code>），对应模型输出的 3 个尺度：大、中、小特征图。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230093146503.png" alt="image-20251230093146503.png"></p>
<ul>
<li><code>self.featmap_strides</code>：每个特征图对应的步长列表，步长是输入图像到该特征图的下采样倍数（如 8、16、32，意味着特征图上 1 个像素对应输入图像上 8/16/32 个像素）。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230093219292.png" alt="image-20251230093219292.png"></p>
<ul>
<li><code>flatten_priors</code>：所有尺度先验框（anchor）拼接后的张量，先验框是预定义的候选框，用于辅助目标检测的边界框预测。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251229181339720.png" alt="image-20251229181339720.png"></p>
<ul>
<li><code>self.num_base_priors</code>：每个特征图网格点上的先验框数量,这里是1。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230093327551.png" alt="image-20251230093327551.png"></p>
<p>代码是一个<strong>列表推导式</strong>，作用是遍历每个尺度的特征图，为该尺度的所有先验框生成一个步长张量，最终收集到<code>mlvl_strides</code>列表中</p>
<h5 id="步骤-1：遍历特征图尺度与对应步长"><a class="header-anchor" href="#步骤-1：遍历特征图尺度与对应步长"></a>步骤 1：遍历特征图尺度与对应步长</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> featmap_size, stride <span class="keyword">in</span> <span class="built_in">zip</span>(featmap_sizes, <span class="variable language_">self</span>.featmap_strides)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>zip(featmap_sizes, self.featmap_strides)</code>将特征图尺寸列表与步长列表按顺序配对，每次循环取出一对<code>(当前特征图尺寸, 当前步长)</code>。</li>
<li>例如：若<code>featmap_sizes = [(80,80), (40,40),(20,20)]</code>，<code>self.featmap_strides = [8, 16,32]</code>，则第一次循环取<code>featmap_size=(80,80), stride=8</code>，第二次取<code>featmap_size=(40,40), stride=16</code>;.....</li>
</ul>
<h5 id="步骤-2：计算当前尺度的先验框总数"><a class="header-anchor" href="#步骤-2：计算当前尺度的先验框总数"></a>步骤 2：计算当前尺度的先验框总数</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">featmap_size.numel() * <span class="variable language_">self</span>.num_base_priors</span><br></pre></td></tr></table></figure>
<ul>
<li><code>featmap_size.numel()</code>：计算当前特征图的<strong>网格点总数</strong>（<code>numel()</code>是 PyTorch 张量方法，返回张量元素总数）。例如<code>featmap_size=(20,20)</code>时，<code>numel()=20*20=400</code>。</li>
<li>乘以<code>self.num_base_priors</code>（每个网格的先验框数量），得到当前尺度的<strong>总先验框数量</strong>。例如若<code>self.num_base_priors=1</code>，则当前尺度总先验框数为<code>400*1=400</code>。</li>
</ul>
<h5 id="步骤-3：生成当前尺度的步长张量"><a class="header-anchor" href="#步骤-3：生成当前尺度的步长张量"></a>步骤 3：生成当前尺度的步长张量</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flatten_priors.new_full((featmap_size.numel() * <span class="variable language_">self</span>.num_base_priors, ), stride)</span><br></pre></td></tr></table></figure>
<ul>
<li>
<pre><code>flatten_priors.new_full(size, value)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  ：PyTorch 张量的方法，用于创建一个新张量，特点是：</span><br><span class="line"></span><br><span class="line">  - 与`flatten_priors`保持相同的数据类型（如`float32`）和设备（如 GPU/CPU），避免后续计算中因类型 / 设备不匹配报错。</span><br><span class="line">  - `size`参数指定新张量的形状，这里是`(当前尺度总先验框数, )`（一维张量）。</span><br><span class="line">  - `value`参数指定新张量的所有元素值，这里是当前尺度的步长`stride`。</span><br><span class="line"></span><br><span class="line">- 例如：当前尺度总先验框数为 400，步长为 32，则生成一个形状为`(400, )`的张量，每个元素都是 32。</span><br><span class="line"></span><br><span class="line">##### 步骤 4：收集所有尺度的步长张量</span><br><span class="line"></span><br><span class="line">循环结束后，`mlvl_strides`成为一个列表，其中每个元素是对应尺度的步长张量。例如：</span><br><span class="line"></span><br><span class="line">- 3个尺度，第一个尺度生成`(6400, )`的步长 8 张量，第二个生成`(1600, )`的步长 16 张量，第三个生成`(400, )`的步长 32 张量，则`mlvl_strides = [tensor([8,8,...,8]), tensor([16,16,...,16]), tensor([32,32,...,32])]`。</span><br><span class="line"></span><br><span class="line">![image-20251230094225379.png](image-20251230094225379.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 12. `flatten_stride` 是什么？</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">        mlvl_strides = [ ... stride ... ]</span><br><span class="line">        flatten_stride = torch.cat(mlvl_strides)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</code></pre>
</li>
</ul>
<ul>
<li>
<p><strong>教授解读</strong>：</p>
</li>
<li>
<p>每个点都在不同的层级，它们代表的“步长”不一样。</p>
</li>
<li>
<p>前 6400 个点，stride=8。</p>
</li>
<li>
<p>中间 1600 个点，stride=16。</p>
</li>
<li>
<p>后 400 个点，stride=32。</p>
</li>
<li>
<p>**生成的 <code>flatten_stride</code>：长这样 <code>[8, 8, ..., 16, 16, ..., 32, 32]</code>，形状也是 **(8400,)。</p>
</li>
<li>
<p><strong>作用</strong>：后面解码的时候，模型预测的偏移量是“倍数”，必须乘以这个 stride 才能变成真实的像素距离。</p>
</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230094414222.png" alt="image-20251230094414222.png"></p>
<hr>
<h4 id="第一阶段总结："><a class="header-anchor" href="#第一阶段总结："></a>第一阶段总结：</h4>
<p>现在你的内存里已经准备好了两把“尺子”：</p>
<ol>
<li><strong><code>flatten_priors</code></strong>：告诉我们在图的哪个位置预测（基准点）。</li>
<li><strong><code>flatten_stride</code></strong>：告诉我们那个位置的缩放比例是多少。</li>
</ol>
<p>这部分代码虽然没有涉及复杂的计算，但是是后续所有计算的<strong>坐标基准</strong>。如果这里搞错了（比如 stride 没对齐），后面预测出来的框就会全部飘到天上去。</p>
<p>理解了“两把尺子”之后，我们就可以进入下一部分：<strong>把模型的预测结果拿出来，和这两把尺子配合，还原出真正的坐标。</strong></p>
<h3 id="第二战：全军集结-Flatten-Decode"><a class="header-anchor" href="#第二战：全军集结-Flatten-Decode"></a>第二战：全军集结 (Flatten &amp; Decode)</h3>
<p>你好！同学，欢迎回到战场。我们刚刚完成了 <strong>第一战：战前准备</strong>，手里已经有了 <code>flatten_priors</code>（网格锚点）和 <code>flatten_stride</code>（步长尺子）。</p>
<p>现在，我们进入 <strong>第二战：全军集结 (Flatten &amp; Decode)</strong>。</p>
<p>这一阶段的任务是：<strong>把散落在 P3、P4、P5 三层特征图上的“连队”，全部集合到一个大广场上，并且把他们报上来的“相对坐标”翻译成“绝对坐标”。</strong></p>
<hr>
<p>请看这部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 整理分类分数 (Flatten Cls)</span></span><br><span class="line">flatten_cls_scores = [</span><br><span class="line">    cls_score.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>,</span><br><span class="line">                                          <span class="variable language_">self</span>.num_classes)</span><br><span class="line">    <span class="keyword">for</span> cls_score <span class="keyword">in</span> cls_scores</span><br><span class="line">]</span><br><span class="line">flatten_cls_scores = torch.cat(flatten_cls_scores, dim=<span class="number">1</span>).sigmoid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 整理回归预测 (Flatten Bbox)</span></span><br><span class="line">flatten_bbox_preds = [</span><br><span class="line">    bbox_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> bbox_pred <span class="keyword">in</span> bbox_preds</span><br><span class="line">]</span><br><span class="line">flatten_bbox_preds = torch.cat(flatten_bbox_preds, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 坐标解码 (Decode) - 核心动作！</span></span><br><span class="line">flatten_decoded_bboxes = <span class="variable language_">self</span>.bbox_coder.decode(</span><br><span class="line">    flatten_priors[<span class="literal">None</span>], </span><br><span class="line">    flatten_bbox_preds, </span><br><span class="line">    stride=flatten_stride)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>我们逐个击破：</p>
<hr>
<h4 id="第一步：-flatten-cls-scores"><a class="header-anchor" href="#第一步：-flatten-cls-scores"></a>第一步： <code>flatten_cls_scores</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">flatten_cls_scores = [</span><br><span class="line">    cls_score.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>,</span><br><span class="line">                                          <span class="variable language_">self</span>.num_classes)</span><br><span class="line">    <span class="keyword">for</span> cls_score <span class="keyword">in</span> cls_scores</span><br><span class="line">]</span><br><span class="line">flatten_cls_scores = torch.cat(flatten_cls_scores, dim=<span class="number">1</span>).sigmoid()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>原来的样子</strong>：<code>cls_scores</code> 是一个列表 <code>[P3, P4, P5]</code>。</li>
<li>P3 形状：<code>(Batch, K, 80, 80)</code>。（K 是 Prompt 类别数，比如 1）。</li>
<li>数据排列是：<code>[Batch, 类别, 高, 宽]</code>。这种排列方便卷积计算，但不方便后续处理。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230095117448.png" alt="image-20251230095117448.png"></p>
<ul>
<li>
<p><strong><code>.permute(0, 2, 3, 1)</code></strong>：</p>
</li>
<li>
<p><strong>动作</strong>：把维度顺序变成 <code>[Batch, 高, 宽, 类别]</code>。</p>
</li>
<li>
<p><strong>形状</strong>：<code>(Batch, 80, 80, K)</code>。把“类别”扔到最后去，因为我们要把 80x80 拍扁。</p>
</li>
<li>
<p><strong><code>.reshape(num_imgs, -1, self.num_classes)</code></strong>：</p>
</li>
<li>
<p><strong>动作</strong>：把 <code>80 * 80</code> 拍扁成 <code>6400</code>。</p>
</li>
<li>
<p><strong>形状</strong>：<code>(Batch, 6400, K)</code>。现在每个点都是一个独立的预测单元。</p>
</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230095548877.png" alt="image-20251230095548877.png"></p>
<ul>
<li>
<p><strong><code>torch.cat(..., dim=1)</code></strong>：</p>
</li>
<li>
<p>把 P3 (6400个), P4 (1600个), P5 (400个) 拼起来。</p>
</li>
<li>
<p><strong>结果形状</strong>：<code>(Batch, 8400, K)</code>。所有士兵都在这了。</p>
</li>
<li>
<p><strong><code>.sigmoid()</code></strong>：</p>
</li>
<li>
<p><strong>关键点</strong>：之前在 <code>forward</code> 里算出来的只是 Logits（原始分数，范围 -inf 到 +inf）。</p>
</li>
<li>
<p><strong>动作</strong>：通过 Sigmoid 映射到 <code>(0, 1)</code> 区间，变成真正的<strong>概率</strong>。</p>
</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230100102741.png" alt="image-20251230100102741.png"></p>
<hr>
<h4 id="第二步：-flatten-bbox-preds"><a class="header-anchor" href="#第二步：-flatten-bbox-preds"></a>第二步： <code>flatten_bbox_preds</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">flatten_bbox_preds = [</span><br><span class="line">    bbox_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">for</span> bbox_pred <span class="keyword">in</span> bbox_preds</span><br><span class="line">]</span><br><span class="line">flatten_bbox_preds = torch.cat(flatten_bbox_preds, dim=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>逻辑</strong>：和上面完全一样。</li>
<li>bbox_preds</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230095818756.png" alt="image-20251230095818756.png"></p>
<ul>
<li>flatten_bbox_preds</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230095911723.png" alt="image-20251230095911723.png"></p>
<ul>
<li>torch.cat后的flatten_bbox_preds</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230100030727.png" alt="image-20251230100030727.png"></p>
<ul>
<li><strong>唯一的区别</strong>：这里最后维度是 <code>4</code> <code>(Left, Top, Right, Bottom)</code>。</li>
<li><strong>结果形状</strong>：<code>(Batch, 8400, 4)</code>。</li>
<li><strong>注意</strong>：这里的 4 个数值，通常是<strong>距离</strong>（Distances）。即：预测框的四条边，距离网格中心点有多少个“单位长度”。</li>
</ul>
<hr>
<h4 id="第三步：-bbox-coder-decode-最核心"><a class="header-anchor" href="#第三步：-bbox-coder-decode-最核心"></a>第三步： <code>bbox_coder.decode</code> (最核心)</h4>
<p>这一步是将“只有模型懂的相对数值”翻译成“人类懂的像素坐标”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">flatten_decoded_bboxes = <span class="variable language_">self</span>.bbox_coder.decode(</span><br><span class="line">    flatten_priors[<span class="literal">None</span>], </span><br><span class="line">    flatten_bbox_preds, </span><br><span class="line">    stride=flatten_stride)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><strong>输入 1：<code>flatten_priors[None]</code> (锚点)</strong></p>
</li>
<li>
<p>原始 <code>flatten_priors</code> 形状 <code>(8400, 2)</code>，代表 <code>(cx, cy)</code>。</p>
</li>
<li>
<p><code>[None]</code> 增加一个维度变成 <code>(1, 8400, 2)</code>。</p>
</li>
<li>
<p><strong>作用</strong>：<strong>“我站在哪里？”</strong> 这是预测的基准点。</p>
</li>
<li>
<p><strong>输入 2：<code>flatten_bbox_preds</code> (预测值)</strong></p>
</li>
<li>
<p>形状 <code>(Batch, 8400, 4)</code>，代表 <code>(l, t, r, b)</code>。</p>
</li>
<li>
<p><strong>作用</strong>：<strong>“边界离我有多远？”</strong></p>
</li>
<li>
<p><strong>输入 3：<code>stride=flatten_stride</code> (步长)</strong></p>
</li>
<li>
<p>形状 <code>(8400,)</code>。</p>
</li>
<li>
<p><strong>作用</strong>：<strong>“一把尺子代表多少像素？”</strong></p>
</li>
<li>
<p>在 P3 层，预测值 <code>1</code> 代表 8 像素；在 P5 层，预测值 <code>1</code> 代表 32 像素。</p>
</li>
<li>
<p><strong><code>decode</code> 内部公式（Anchor Point 解码逻辑）</strong>：
解码后的坐标 <code>(x1, y1, x2, y2)</code> 是这样算出来的：</p>
</li>
</ul>

    <span id="mjx-d8e238b">
      <style>
      #mjx-d8e238b{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="85.835ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 37939 1000" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1286.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2342.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2731.1,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(3164.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3958.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4958.6,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mo" transform="translate(5478.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(6479,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(6948,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(7309,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7760,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(8105,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(8625,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(9091,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mspace" transform="translate(9480,0)"></g><g data-mml-node="msub" transform="translate(9480,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(10684.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(11740.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(12129.1,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(12562.1,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(13274.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(14274.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(14857.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(15858,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(16327,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(16688,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17139,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17484,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(18004,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(18470,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mspace" transform="translate(18859,0)"></g><g data-mml-node="msub" transform="translate(18859,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(20145.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(21201.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(21590.1,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(22023.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(22817.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(23817.5,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(24490.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(25491,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(25960,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(26321,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(26772,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(27117,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(27637,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(28103,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mspace" transform="translate(28492,0)"></g><g data-mml-node="msub" transform="translate(28492,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mn" transform="translate(523,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(29696.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(30752.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(31141.1,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(31574.1,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(32286.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(33286.5,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(33937.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(34938,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(35407,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(35768,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(36219,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(36564,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(37084,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(37550,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mi>c</mi><mi>x</mi><mo>−</mo><mi>l</mi><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mi>c</mi><mi>y</mi><mo>−</mo><mi>t</mi><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mi>c</mi><mi>x</mi><mo>+</mo><mi>r</mi><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><msub><mi>y</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">(</mo><mi>c</mi><mi>y</mi><mo>+</mo><mi>b</mi><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>
    </span>
  <ul>
<li>输出结果 <code>flatten_decoded_bboxes</code>：</li>
<li>形状：<code>(Batch, 8400, 4)</code>。</li>
<li><strong>含义</strong>：这是真实的、基于模型输入图片（比如 640x640）的绝对像素坐标 <code>(x1, y1, x2, y2)</code>。</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230102934629.png" alt="image-20251230102934629.png"></p>
<hr>
<h4 id="第二阶段总结：目前的战况"><a class="header-anchor" href="#第二阶段总结：目前的战况"></a>第二阶段总结：目前的战况</h4>
<p>经过这一波操作，我们手里的数据变成了这样：</p>
<ol>
<li><strong><code>flatten_cls_scores</code></strong>: <code>(Batch, 8400, K)</code> —— 每一行代表一个候选框的<strong>概率</strong>。</li>
<li><strong><code>flatten_decoded_bboxes</code></strong>: <code>(Batch, 8400, 4)</code> —— 每一行代表一个候选框的<strong>真实位置</strong>。</li>
</ol>
<p><strong>教授的 Debug 提示</strong>：
此时你会发现一个大问题：<strong>8400 个框里，大概有 8300 个都是垃圾！</strong>（背景的概率极低，比如 0.001）。如果我们把这 8400 个框全拿去做 NMS，计算量会大到爆炸，显卡会冒烟。</p>
<p>所以，下一阶段（Stage 3）的任务非常紧迫：<strong>大清洗（Filtering）</strong>。我们要把那些置信度太低的框，在进入 NMS 之前就统统扔掉！</p>
<h3 id="第三战：初步筛选"><a class="header-anchor" href="#第三战：初步筛选"></a>第三战：初步筛选</h3>
<p>刚才在 <strong>第二战</strong> 中，我们把所有层级的预测结果都拍扁并解码了，得到了 8400 个框的<strong>位置</strong>（<code>flatten_decoded_bboxes</code>）和 8400 个位置的<strong>概率</strong>（<code>flatten_cls_scores</code>）。</p>
<p>现在，我们进入 <strong>第三战：初步筛选 (Score Filtering)</strong>。</p>
<p>这一步至关重要。你要想象一下，8400 个框里，绝大多数都是对着墙壁、天空、地面的“瞎猜”，置信度只有 0.001 甚至更低。如果我们把这些垃圾全扔给 NMS（非极大值抑制）去算，计算量会极其恐怖。</p>
<p>所以，我们需要先用一个“粗筛子”过滤一遍。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> with_objectnesses:</span><br><span class="line">    <span class="comment"># 1. 如果有 Objectness 分支，就把它也拍扁</span></span><br><span class="line">    flatten_objectness = [</span><br><span class="line">        objectness.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(num_imgs, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> objectness <span class="keyword">in</span> objectnesses</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 2. 拼接 + Sigmoid 归一化</span></span><br><span class="line">    flatten_objectness = torch.cat(flatten_objectness, dim=<span class="number">1</span>).sigmoid()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 3. 如果没有，就设为 None</span></span><br><span class="line">    flatten_objectness = [<span class="literal">None</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_imgs)]</span><br></pre></td></tr></table></figure>
<p>YOLO-World 继承了 YOLOv8 的设计，采用了 <strong>Decoupled Head（解耦头）</strong> 且 <strong>移除了 Objectness 分支</strong>。</p>
<ul>
<li><strong>设计理念</strong>：预测“是什么”的分数，本身就应该包含“有没有”的信息。</li>
<li><strong>现状</strong>：
<ul>
<li>如果背景（没有物体），所有类别的分类分数都应该趋近于 0。</li>
<li>如果有一只猫，猫的分类分数就是 0.9。</li>
</ul>
</li>
<li><strong>省流</strong>：少算一个分支，模型更轻，速度更快，而且效果没掉。</li>
<li>如果是 <strong>YOLO-World</strong> 调这个函数，这段代码就是个摆设。</li>
</ul>
<hr>
<p>在进入你这段循环之前，代码已经做了这些事（你调试时最好先在这里确认 shape）：</p>
<ul>
<li><code>flatten_cls_scores</code>: 把每个 level 的 <code>cls_score</code> 从 <code>[B,C,H,W]</code> 变到 <code>[B, HW, num_classes]</code>，再 cat 成 <code>[B, N, num_classes]</code> 并 <code>sigmoid()</code></li>
<li><code>flatten_bbox_preds</code>: 类似展平后 cat 成 <code>[B, N, 4]</code></li>
<li><code>flatten_decoded_bboxes = self.bbox_coder.decode(...)</code>: 把 <code>[B,N,4]</code> 的预测解码成真实坐标框 <code>[B,N,4]</code></li>
</ul>
<h4 id="results-list"><a class="header-anchor" href="#results-list"></a><code>results_list = []</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results_list = []</span><br></pre></td></tr></table></figure>
<p><strong>作用</strong>：收集每张图的最终检测结果（每个元素通常是一个 <code>InstanceData</code>）。</p>
<hr>
<h4 id="for-in-zip"><a class="header-anchor" href="#for-in-zip"></a><code>for (...) in zip(...)</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (bboxes, scores, objectness,</span><br><span class="line">     img_meta) <span class="keyword">in</span> <span class="built_in">zip</span>(flatten_decoded_bboxes, flatten_cls_scores,</span><br><span class="line">                      flatten_objectness, batch_img_metas):</span><br></pre></td></tr></table></figure>
<p>这里 <code>zip</code> 做的是“按 batch 逐张图”迭代：</p>
<ul>
<li><strong><code>bboxes</code></strong>：当前这张图的 8400 个预测框，形状 <code>(8400, 4)</code>。注意，这时候的坐标是在 <strong>640x640（输入尺寸）</strong> 上的绝对坐标。</li>
<li><strong><code>scores</code></strong>：当前这张图的 8400 个分类概率，形状 <code>(8400, K)</code>。（已 sigmoid）</li>
<li><strong><code>objectness</code></strong>：当前这张图的置信度。在 YOLO-World 里，因为刚才走了 <code>else</code> 分支，这里拿到的就是 <strong><code>None</code></strong>。</li>
<li><code>img_meta</code>: 这张图的 meta（缩放、pad、原图尺寸等）</li>
</ul>
<p>对应代码位置：</p>
<p>✅ <strong>断点建议</strong>：就在 <code>for</code> 这一行打断点（或在循环体第一行打断点）。</p>
<ul>
<li>
<p>重点在 <em>Evaluate Expression</em> 里依次看：</p>
<ul>
<li><code>bboxes.shape</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230113728629.png" alt="image-20251230113728629.png"></p>
<ul>
<li><code>scores.shape</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230113749761.png" alt="image-20251230113749761.png"></p>
<blockquote>
<p><strong>小结：</strong></p>
<ul>
<li><code>scores.shape = [8400, 1]</code></li>
<li><code>bboxes.shape = [8400, 4]</code></li>
</ul>
<p>这说明在 for 循环里，已经把 batch 维度去掉了，现在就是**“一张图的 8400 个候选点”**，每个候选点：</p>
<ul>
<li>1 个分数</li>
<li>1 个框（4 个数）</li>
</ul>
</blockquote>
<ul>
<li><code>objectness is None</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230113806655.png" alt="image-20251230113806655.png"></p>
<ul>
<li><code>img_meta.keys()</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230113849860.png" alt="image-20251230113849860.png"></p>
</li>
</ul>
<hr>
<h4 id="取出-ori-shape-scale-factor-pad-param"><a class="header-anchor" href="#取出-ori-shape-scale-factor-pad-param"></a>取出 <code>ori_shape / scale_factor / pad_param</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ori_shape = img_meta[<span class="string">&#x27;ori_shape&#x27;</span>]</span><br><span class="line">scale_factor = img_meta[<span class="string">&#x27;scale_factor&#x27;</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;pad_param&#x27;</span> <span class="keyword">in</span> img_meta:</span><br><span class="line">    pad_param = img_meta[<span class="string">&#x27;pad_param&#x27;</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    pad_param = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p><code>ori_shape</code>：原图尺寸。比如<code>(1080,810)</code></p>
</li>
<li>
<p><code>scale_factor</code>：缩放因子</p>
</li>
<li>
<p>这是一个元组，比如 <code>(0.5925926, 0.5925926)</code>。</p>
<p><strong>来源</strong>：预处理时，把原图 <code>1080</code> 缩小到 <code>640</code>，缩放因子就是 <code>640 / 1080 ≈ 0.5925926</code>。</p>
<p><strong>关键作用</strong>：稍后我们要把预测框的坐标 <strong>除以</strong> 这个因子，才能从 640 还原回 1080。</p>

    <span id="mjx-49c413a">
      <style>
      #mjx-49c413a{
        display:contents;
        mjx-assistive-mml {
          user-select: text !important;
          clip: auto !important;
          color: rgba(0,0,0,0);
        }
        
mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

      }
      </style>
      <mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg style="vertical-align: -1.692ex;" xmlns="http://www.w3.org/2000/svg" width="26.637ex" height="4.919ex" role="img" focusable="false" viewBox="0 -1426 11773.6 2174" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">实</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">坐</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">标</text></g><g data-mml-node="mo" transform="translate(4277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(5333.6,0)"><g data-mml-node="mtext" transform="translate(220,676)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">模</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">型</text><text data-variant="normal" transform="translate(2000,0) scale(1,-1)" font-size="884px" font-family="serif">预</text><text data-variant="normal" transform="translate(3000,0) scale(1,-1)" font-size="884px" font-family="serif">测</text><text data-variant="normal" transform="translate(4000,0) scale(1,-1)" font-size="884px" font-family="serif">坐</text><text data-variant="normal" transform="translate(5000,0) scale(1,-1)" font-size="884px" font-family="serif">标</text></g><g data-mml-node="mtext" transform="translate(674.5,-686)"><path data-c="73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(394,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(838,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1338,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1616,0)"></path><path data-c="5F" d="M0 -62V-25H499V-62H0Z" transform="translate(2060,0)"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(2560,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2866,0)"></path><path data-c="63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z" transform="translate(3366,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(3810,0)"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(4199,0)"></path><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" transform="translate(4699,0)"></path></g><rect width="6200" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>真实坐标</mtext><mo>=</mo><mfrac><mtext>模型预测坐标</mtext><mtext>scale_factor</mtext></mfrac></math></mjx-assistive-mml></mjx-container>
    </span>
  </li>
<li>
<p><code>pad_param</code>：处理黑边</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">&#x27;pad_param&#x27;</span> <span class="keyword">in</span> img_meta:</span><br><span class="line">        pad_param = img_meta[<span class="string">&#x27;pad_param&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pad_param = <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<p><strong>背景知识</strong>：</p>
<ul>
<li>为了保持图片比例，我们在 Resize 的时候通常会做 <strong>Letterbox Padding（黑边填充）</strong>。</li>
<li>比如原图是长方形，输入模型要求正方形，我们就会在上下或者左右填充灰色的像素。</li>
</ul>
<p><strong><code>pad_param</code></strong>：</p>
<ul>
<li>记录了具体填了多少像素，比如 <code>(0, 100, 0, 0)</code> （上、下、左、右）。</li>
</ul>
<p><strong>隐形的地雷</strong>：</p>
<ul>
<li>如果模型预测的框落在了黑边上，那是无效的。</li>
<li>在还原坐标时，不仅要除以缩放比例，还得先<strong>减去</strong>这个 padding 的偏移量。虽然这段代码只是把它取出来，但后面的坐标还原函数（如果启用了高级还原）会用到它。</li>
</ul>
<p>✅ <strong>断点建议</strong>：在 <code>pad_param = ...</code> 下一行打断点：</p>
<ul>
<li>看 <code>ori_shape</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230114433395.png" alt="image-20251230114433395.png"></p>
<ul>
<li>看 <code>scale_factor</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230114510243.png" alt="image-20251230114510243.png"></p>
<hr>
<h4 id="score-thr-cfg-get-score-thr-1"><a class="header-anchor" href="#score-thr-cfg-get-score-thr-1"></a><code>score_thr = cfg.get('score_thr', -1)</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score_thr = cfg.get(<span class="string">&#x27;score_thr&#x27;</span>, -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>从配置 <code>cfg</code> 里读取 <code>score_thr</code>（这里是0.001）。</p>
<p>如果配置里没写，默认给 -1（表示不过滤，全都要）</p>
<p>✅ <strong>断点建议</strong>：在这行打断点，Evaluate：</p>
<ul>
<li><code>score_thr</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230143627689.png" alt="image-20251230143627689.png"></p>
<ul>
<li><code>cfg.get('yolox_style', False)</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230143709692.png" alt="image-20251230143709692.png"></p>
<ul>
<li><code>cfg.multi_label</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230143723721.png" alt="image-20251230143723721.png"></p>
<p>因为这三个开关会决定接下来走哪条分支。</p>
<hr>
<blockquote>
<p><strong>小结：</strong></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230163630792.png" alt="image-20251230163630792.png"></p>
<p>得到的是：<code>(0.001, 2000, 8400)</code></p>
<p>逐个解释：</p>
<ul>
<li><code>score_thr = 0.001</code></li>
<li><strong>有 2000 个候选点</strong>的 score &gt; 0.001</li>
<li>总共有 8400 个候选点</li>
</ul>
<p>✅ 所以第一轮阈值过滤之后：<strong>8400 → 2000</strong>（减少到大约 24%）</p>
</blockquote>
<hr>
<h4 id="objectness-预过滤（只在特定条件触发）"><a class="header-anchor" href="#objectness-预过滤（只在特定条件触发）"></a><s>objectness 预过滤（只在特定条件触发）</s></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> objectness <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> score_thr &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> cfg.get(<span class="string">&#x27;yolox_style&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">    conf_inds = objectness &gt; score_thr</span><br><span class="line">    bboxes = bboxes[conf_inds, :]</span><br><span class="line">    scores = scores[conf_inds, :]</span><br><span class="line">    objectness = objectness[conf_inds]</span><br></pre></td></tr></table></figure>
<p>意思是：<strong>先用 objectness 做一次“粗过滤”</strong>，减少候选数量（加速）。注意它明确说 “yolox_style 不需要下面这些操作”。</p>
<ul>
<li><strong>对 YOLO-World 的影响</strong>：
<ul>
<li>因为 <code>objectness</code> 是 <strong><code>None</code></strong>。</li>
<li><strong>结论</strong>：这个 <code>if</code> 进不去。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="把最终置信度融合成-obj-conf-cls-conf"><a class="header-anchor" href="#把最终置信度融合成-obj-conf-cls-conf"></a><s>把最终置信度融合成 <code>obj_conf * cls_conf</code></s></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> objectness <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    scores *= objectness[:, <span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
<p>这是典型 YOLO 逻辑：分类分数再乘 objectness，得到最终“框-类”的置信度。</p>
<p><strong>对 YOLO-World 的影响</strong>：</p>
<ul>
<li>依然是因为 <code>objectness</code> 是 <strong><code>None</code></strong>。</li>
<li><strong>结论</strong>：这个 <code>if</code> 也进不去。</li>
</ul>
<h3 id="第四战：最终决战-NMS-Rescale"><a class="header-anchor" href="#第四战：最终决战-NMS-Rescale"></a>第四战：最终决战 (NMS &amp; Rescale)</h3>
<p>接下来这段就是 <strong>“大清洗 → 组装 results → 坐标还原 → NMS/限额 → clamp”</strong> 的完整链路。下面按代码顺序逐行讲，并穿插你在 PyCharm 里该怎么打断点、看哪些张量。</p>
<hr>
<h4 id="1-空结果兜底：if-scores-shape-0-0-continue"><a class="header-anchor" href="#1-空结果兜底：if-scores-shape-0-0-continue"></a>1) 空结果兜底：<code>if scores.shape[0] == 0: ... continue</code></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> scores.shape[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">    empty_results = InstanceData()</span><br><span class="line">    empty_results.bboxes = bboxes</span><br><span class="line">    empty_results.scores = scores[:, <span class="number">0</span>]</span><br><span class="line">    empty_results.labels = scores[:, <span class="number">0</span>].<span class="built_in">int</span>()</span><br><span class="line">    results_list.append(empty_results)</span><br><span class="line">    <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>这是代码的**“熔断机制”**。</p>
</li>
<li>
<p>这段的语义是：<strong>如果经过阈值/obj 融合后，一个候选都没了，就直接返回空的 InstanceData</strong>，避免后面 NMS / topk 报错。</p>
</li>
</ul>
<hr>
<h4 id="2-nms-pre：进-NMS-前先-topK-裁剪候选规模"><a class="header-anchor" href="#2-nms-pre：进-NMS-前先-topK-裁剪候选规模"></a>2) <code>nms_pre</code>：进 NMS 前先 topK 裁剪候选规模</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nms_pre = cfg.get(<span class="string">&#x27;nms_pre&#x27;</span>, <span class="number">100000</span>)</span><br></pre></td></tr></table></figure>
<p><strong><code>nms_pre</code> (NMS 前的最大保留数)</strong>：</p>
<ul>
<li>为了防止 NMS 计算量太大，我们规定：不管你预测了多少框，我最多只取分数最高的 <strong>100,000 个</strong>进入下一轮。这个数字很大，通常只有超大图才会触发限制</li>
</ul>
<hr>
<h4 id="3-分叉点：cfg-multi-label-决定“一个框能否对应多个类别”"><a class="header-anchor" href="#3-分叉点：cfg-multi-label-决定“一个框能否对应多个类别”"></a>3) 分叉点：<code>cfg.multi_label</code> 决定“一个框能否对应多个类别”</h4>
<h5 id="3-1-单标签模式：cfg-multi-label-is-False"><a class="header-anchor" href="#3-1-单标签模式：cfg-multi-label-is-False"></a>3.1 单标签模式：<code>cfg.multi_label is False</code></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> cfg.multi_label <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">    scores, labels = scores.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    scores, _, keep_idxs, results = filter_scores_and_topk(</span><br><span class="line">        scores,</span><br><span class="line">        score_thr,</span><br><span class="line">        nms_pre,</span><br><span class="line">        results=<span class="built_in">dict</span>(labels=labels[:, <span class="number">0</span>]))</span><br><span class="line">    labels = results[<span class="string">&#x27;labels&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p>含义分 3 步：</p>
<ol>
<li><code>scores.max(1, keepdim=True)</code></li>
</ol>
<ul>
<li>
<p>输入 <code>scores</code> 是 <code>[N, num_classes]</code></p>
</li>
<li>
<p>输出：</p>
<ul>
<li><code>scores</code> 变成 <code>[N, 1]</code>：每个框只取“最像的那个类”的分数</li>
<li><code>labels</code> 变成 <code>[N, 1]</code>：对应 argmax 的类别 id</li>
</ul>
</li>
</ul>
<ol start="2">
<li><code>filter_scores_and_topk(...)</code>
它会做两件事（你可以理解成“过滤 + topK”）：</li>
</ol>
<ul>
<li>按 <code>score_thr</code> 过滤低分</li>
<li>如果还太多，再按分数取前 <code>nms_pre</code>
返回的关键是：</li>
<li><code>scores</code>, <code>labels</code>：筛选后的分数和类别。</li>
<li><code>keep_idxs</code>：保留下来的框在原来 N 个框中的索引</li>
<li><code>results['labels']</code>：把 labels 也一起对齐筛完</li>
</ul>
<ol start="3">
<li><code>labels = results['labels']</code>
把筛完后的 labels 拿回来（形状一般是 <code>[M]</code> 或 <code>[M,]</code> 这种）。</li>
</ol>
<hr>
<p><strong>你在 PyCharm 里怎么打断点看懂它</strong></p>
<p>建议在这 3 行分别打断点：</p>
<ul>
<li>
<p><code>scores, labels = scores.max(1, keepdim=True)</code></p>
<ul>
<li>看：<code>scores.shape</code> 从 <code>(N,K)</code> 变 <code>(N,1)</code></li>
<li>看：<code>labels.shape</code></li>
<li>不用看了，对debug这个例子没有变化，因为就一个类别</li>
</ul>
</li>
<li>
<p><code>scores, _, keep_idxs, results = filter_scores_and_topk(...)</code></p>
<ul>
<li>看：<code>keep_idxs.shape</code>（M）</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230151036951.png" alt="image-20251230151036951.png"></p>
<ul>
<li>看：<code>keep_idxs[:20]</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230151119901.png" alt="image-20251230151119901.png"></p>
<ul>
<li>看：<code>scores[:10]</code>（注意此时 scores 已经是过滤后的）</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230151144449.png" alt="image-20251230151144449.png"></p>
</li>
<li>
<p><code>labels = results['labels']</code></p>
<ul>
<li>看：<code>labels.shape</code> 是否和 <code>scores.shape[0]</code> 一致</li>
<li>结论一致</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230151229712.png" alt="image-20251230151229712.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230151247000.png" alt="image-20251230151247000.png"></p>
</li>
</ul>
<hr>
<h5 id="3-2-多标签模式：cfg-multi-label-is-True"><a class="header-anchor" href="#3-2-多标签模式：cfg-multi-label-is-True"></a>3.2 多标签模式：<code>cfg.multi_label is True</code></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    scores, labels, keep_idxs, _ = filter_scores_and_topk(</span><br><span class="line">        scores, score_thr, nms_pre)</span><br></pre></td></tr></table></figure>
<p>这时输入 <code>scores</code> 还是 <code>[N, K]</code>，<code>filter_scores_and_topk</code> 会把它**“裂变”**成一堆 <code>(框, 类别)</code> 对（例如同一个 bbox 对 “animal” 和 “cat” 都过阈值，就会变成两条候选）。
所以此分支出来常见是：</p>
<ul>
<li><code>scores</code>: <code>[M]</code></li>
<li><code>labels</code>: <code>[M]</code></li>
<li><code>keep_idxs</code>: <code>[M]</code>（指向原来 N 个框的索引）</li>
</ul>
<hr>
<h4 id="4-组装-InstanceData：把筛选结果“落地”成结构体"><a class="header-anchor" href="#4-组装-InstanceData：把筛选结果“落地”成结构体"></a>4) 组装 InstanceData：把筛选结果“落地”成结构体</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">results = InstanceData(scores=scores,</span><br><span class="line">                       labels=labels,</span><br><span class="line">                       bboxes=bboxes[keep_idxs])</span><br></pre></td></tr></table></figure>
<p><strong>动作</strong>：</p>
<ul>
<li>这里利用 <code>keep_idxs</code>，把对应的 <strong>预测框坐标 (<code>bboxes</code>)</strong> 提取出来。</li>
<li>把分数、类别、坐标打包进 <code>InstanceData</code> 对象。</li>
<li><strong>注意</strong>：此时的 <code>bboxes</code> 还是 <strong>640x640</strong> 尺度下的坐标，且可能还包含黑边。</li>
</ul>
<hr>
<h4 id="5-rescale：把坐标从“网络输入尺度”还原到“原图尺度”"><a class="header-anchor" href="#5-rescale：把坐标从“网络输入尺度”还原到“原图尺度”"></a>5) rescale：把坐标从“网络输入尺度”还原到“原图尺度”</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> rescale:</span><br><span class="line">        <span class="keyword">if</span> pad_param <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 1. 减去黑边 (Un-pad)</span></span><br><span class="line">            results.bboxes -= results.bboxes.new_tensor([</span><br><span class="line">                pad_param[<span class="number">2</span>], pad_param[<span class="number">0</span>], pad_param[<span class="number">2</span>], pad_param[<span class="number">0</span>]</span><br><span class="line">            ])</span><br><span class="line">        <span class="comment"># 2. 除以缩放比例 (Un-scale)</span></span><br><span class="line">        results.bboxes /= results.bboxes.new_tensor(</span><br><span class="line">            scale_factor).repeat((<span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p><strong>逻辑流</strong>：</p>
<ul>
<li><code>pad_param</code> 格式通常是 <code>(top, bottom, left, right)</code>。</li>
<li>代码里取 <code>pad_param[2]</code> (left) 和 <code>pad_param[0]</code> (top)。</li>
<li><code>[left, top, left, top]</code> 正好对应 <code>[x1, y1, x2, y2]</code> 的偏移量。</li>
<li><strong>先减后除</strong>：这是铁律。因为预处理是 <code>(原图 * scale) + pad</code>，反过来就是 <code>(预测 - pad) / scale</code>。</li>
</ul>
<p><strong>debug 必看（超级常见的坑）</strong></p>
<p>在 <code>results.bboxes /= ...</code> 这一行打断点，分三次看：</p>
<ul>
<li>进入 rescale 前：<code>results.bboxes</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155418140-17670812596971.png" alt="image-20251230155418140-17670812596971.png"></p>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155430321.png" alt="image-20251230155430321.png"></p>
<ul>
<li>去 pad 后：<code>results.bboxes[:3]</code>（如果 pad_param 不对，这里会整体偏移）</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155549653.png" alt="image-20251230155549653.png"></p>
<ul>
<li>除 scale 后：<code>results.bboxes</code>（如果 scale_factor 维度/顺序不对，会导致缩放畸形）</li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155647293.png" alt="image-20251230155647293.png"></p>
<p>同时 Evaluate：</p>
<ul>
<li><code>pad_param</code></li>
</ul>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155729980.png" alt="image-20251230155729980.png"></p>
<ul>
<li>
<p><code>scale_factor</code></p>
</li>
<li>
<p><img src="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/image-20251230155800635.png" alt="image-20251230155800635.png"></p>
</li>
</ul>
<hr>
<h4 id="6-yolox-style-特判：放开-max-per-img"><a class="header-anchor" href="#6-yolox-style-特判：放开-max-per-img"></a>6) yolox_style 特判：放开 max_per_img</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> cfg.get(<span class="string">&#x27;yolox_style&#x27;</span>, <span class="literal">False</span>):</span><br><span class="line">    <span class="comment"># do not need max_per_img</span></span><br><span class="line">    cfg.max_per_img = <span class="built_in">len</span>(results)</span><br></pre></td></tr></table></figure>
<p>如果是 yolox_style，它认为不需要再按 <code>max_per_img</code> 截断，所以把 <code>max_per_img</code> 设成当前候选数量（等于“不截断”）。</p>
<blockquote>
<p>注意：这里改的是 <code>cfg</code> 的副本（前面 deepcopied），不会污染全局配置。</p>
</blockquote>
<hr>
<h4 id="7-最终决战：-bbox-post-process（NMS-限额-输出整理）"><a class="header-anchor" href="#7-最终决战：-bbox-post-process（NMS-限额-输出整理）"></a>7) 最终决战：<code>_bbox_post_process</code>（NMS + 限额 + 输出整理）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">results = <span class="variable language_">self</span>._bbox_post_process(results=results,</span><br><span class="line">                                  cfg=cfg,</span><br><span class="line">                                  rescale=<span class="literal">False</span>,</span><br><span class="line">                                  with_nms=with_nms,</span><br><span class="line">                                  img_meta=img_meta)</span><br><span class="line">results.bboxes[:, <span class="number">0</span>::<span class="number">2</span>].clamp_(<span class="number">0</span>, ori_shape[<span class="number">1</span>])</span><br><span class="line">results.bboxes[:, <span class="number">1</span>::<span class="number">2</span>].clamp_(<span class="number">0</span>, ori_shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">results_list.append(results)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>_bbox_post_process(...)</code>：通常内部会做 <strong>NMS</strong>（如果 <code>with_nms=True</code>），并按 <code>cfg.max_per_img</code> 截断输出等。</li>
<li>这里传 <code>rescale=False</code> 是因为你在上面已经手动 rescale 过了，别再重复还原</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">results.bboxes[:, <span class="number">0</span>::<span class="number">2</span>].clamp_(<span class="number">0</span>, ori_shape[<span class="number">1</span>])</span><br><span class="line">    results.bboxes[:, <span class="number">1</span>::<span class="number">2</span>].clamp_(<span class="number">0</span>, ori_shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    results_list.append(results)</span><br><span class="line"><span class="keyword">return</span> results_list</span><br></pre></td></tr></table></figure>
<p><strong>动作</strong>：</p>
<ul>
<li><code>ori_shape[1]</code> 是宽，<code>ori_shape[0]</code> 是高。</li>
<li><code>0::2</code> 选出 <code>x1, x2</code>，<code>1::2</code> 选出 <code>y1, y2</code>。</li>
<li><strong><code>clamp_(min, max)</code></strong>：一刀切。不管你模型预测到哪里去了，只要超出了图片边界，统统切掉。比如 x=1925 (原图宽1920)，就强制变成 1920。</li>
<li>这就保证了画图的时候不会报错。</li>
</ul>
<blockquote>
<p><code>scores/bboxes</code> flatten：8400</p>
<p><code>score_thr</code> 过滤：8400 → 2000</p>
<p><code>nms_pre</code>：因为 2000 &lt; 30000，不裁</p>
<p><code>batched_nms</code>：2000 → 321</p>
<p><code>max_per_img</code>：321 → 300</p>
<p><code>clamp/rescale</code>：把框限制到图像边界、映射回原图坐标</p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://qieliqiean.github.io/blog">lian</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qieliqiean.github.io/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/">https://qieliqiean.github.io/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://qieliqiean.github.io/blog" target="_blank">且离且安的碎碎念</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/blog/tags/Yolo-World/">Yolo-World</a></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/blog/2025/11/12/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ATowards-Open-Vocabulary-Learning-A-Survey/" title="论文阅读：Towards Open Vocabulary Learning:  A Survey"><img class="cover" src="/blog/image/A1-3.webp" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文阅读：Towards Open Vocabulary Learning:  A Survey</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   论文阅读  1 INTRODUCTION 一、研究动机与现实困境 作者一开篇就指出，深度神经网络在视觉场景理解中取得了突破性进展——从目标检测（Object Detection）、图像分割（Segmentation）到目标跟踪（Tracking）都能取得极高精度。然而，传统方法普遍依赖“封闭类集合（Closed-set...</div></div></div></a><a class="pagination-related" href="/blog/2025/12/18/%E6%9D%82%E8%AE%B0/YOLOv8%20Anchor%20Free%E4%B8%8EDFL%E5%8E%9F%E7%90%86/" title="YOLOv8 Anchor Free与DFL原理"><img class="cover" src="/blog/image/s625d11592724c.jpg" onerror="onerror=null;src='/blog/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">YOLOv8 Anchor Free与DFL原理</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   杂记  YOLOv8 深度架构解析报告：Anchor-Free 范式变革与分布焦点损失 (DFL) 的数学原理及工程实践 1. 执行摘要 本研究报告旨在对 Ultralytics 公司于 2023 年发布的 YOLOv8 目标检测算法进行详尽的解构与分析，重点聚焦于其核心的架构范式转变——Anchor-Free（无锚框）机制与分布焦点损失（Distribution Focal Loss,...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/" title="代码解读：yolo_world-models-necks-yolo_world_pafpn.py"><img class="cover" src="/blog/image/A1-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">代码解读：yolo_world-models-necks-yolo_world_pafpn.py</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  class YOLOWorldPAFPN(YOLOv8PAFPN) def init 1234567891011121314151617@MODELS.register_module()def __init__(self,             in_channels: List[int],             out_channels:...</div></div></div></a><a class="pagination-related" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py"><img class="cover" src="/blog/image/q4SynOBjcxn5gA6.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-18</div><div class="info-item-2">代码解读：yolo_world-models-detectors-yolo_world.py</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  yolo_world yolo_world/models/detectors/yolo_world.py 这份分析将结合 YOLO-World 论文（Cheng et al., 2024）的核心概念，逐行解读 yolo_world/models/detectors/yolo_world.py 代码。 这份代码实现了论文中提出的 YOLO-World...</div></div></div></a><a class="pagination-related" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"><img class="cover" src="/blog/image/A1-2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-24</div><div class="info-item-2">论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection</div></div><div class="info-2"><div class="info-item-1">   系列文章   /   开放词汇检测 / yolo-world  1 Introduction 1.1这节在回答什么问题？  现实动机：传统检测器（例如在 COCO 上训练的模型）只能识别固定词表中的类别（COCO 只有80类）。一旦训练好的类别被定死，模型就无法识别不在词表里的目标，这在开放场景里很受限。作者先明确了这个“固定词表的天花板”问题。 需求与挑战：我们需要的是开放词汇检测（Open-Vocabulary...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/blog/image/IMG_20250131_155849.jpg" onerror="this.onerror=null;this.src='/blog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">lian</div><div class="author-info-description">读研，尝试新技术与记录生活。</div><div class="site-data"><a href="/blog/archives/"><div class="headline">文章</div><div class="length-num">42</div></a><a href="/blog/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/blog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qieliqiean"><i class="fab fa-github"></i><span>访问 GitHub</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qieliqiean" target="_blank" title="GitHub"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2895014608@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎交流：2895014608@qq.com</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#class-ContrastiveHead-BaseModule"><span class="toc-text">class ContrastiveHead(BaseModule)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ContrastiveHead%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-text">ContrastiveHead的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ContrastiveHead-forward-x-w-%E7%9A%84%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E4%B8%8E%E5%BD%A2%E7%8A%B6"><span class="toc-text">ContrastiveHead.forward(x, w) 的输入输出与形状</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5"><span class="toc-text">输入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E4%BA%8Eembed-dims"><span class="toc-text">关于embed_dims</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA"><span class="toc-text">输出</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ContrastiveHead-%E5%9C%A8%E6%95%B4%E4%B8%AA-head-%E9%87%8C%E7%9A%84%E2%80%9C%E5%89%8D%E5%90%8E%E8%BF%9E%E6%8E%A5%E5%85%B3%E7%B3%BB%E2%80%9D"><span class="toc-text">ContrastiveHead 在整个 head 里的“前后连接关系”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%92%8C-BNContrastiveHead-RepBNContrastiveHead-%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-text">和 BNContrastiveHead &#x2F; RepBNContrastiveHead 的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-ContrastiveHead-%E7%B1%BB%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">1) ContrastiveHead 类定义与初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%80%90%E8%A1%8C%E8%A7%A3%E6%9E%90"><span class="toc-text">2) 逐行解析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5-2"><span class="toc-text">输入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA-2"><span class="toc-text">输出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E9%80%9A%E9%81%93%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-text">操作：通道归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%EF%BC%88%E4%B8%A4%E7%A7%8D%E7%AD%89%E4%BB%B7%E5%AE%9E%E7%8E%B0%EF%BC%89"><span class="toc-text">操作：相似度计算（两种等价实现）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%B3%951"><span class="toc-text">方法1</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-text">示例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%AF%E8%BF%90%E8%A1%8C%E7%9A%84%E4%BC%AA%E4%BB%A3%E7%A0%81"><span class="toc-text">可运行的伪代码</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%B3%952"><span class="toc-text">方法2</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%B8%A9%E5%BA%A6%E7%BC%A9%E6%94%BE-bias"><span class="toc-text">操作：温度缩放 + bias</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-BNContrastiveHead-BaseModule"><span class="toc-text">class BNContrastiveHead(BaseModule)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-2"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-2"><span class="toc-text">def init</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-2"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9AF-normalize-%E4%B8%8Eself-norm"><span class="toc-text">操作：F.normalize()与self.norm()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%EF%BC%88%E4%B8%A4%E7%A7%8D%E7%AD%89%E4%BB%B7%E5%AE%9E%E7%8E%B0%EF%BC%89-2"><span class="toc-text">操作：相似度计算（两种等价实现）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%B8%A9%E5%BA%A6%E7%BC%A9%E6%94%BE-bias-2"><span class="toc-text">操作：温度缩放 + bias</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-RepBNContrastiveHead-BaseModule"><span class="toc-text">class RepBNContrastiveHead(BaseModule)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-3"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B1%BB%E6%B3%A8%E9%87%8A"><span class="toc-text">类注释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0"><span class="toc-text">初始化参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#super-init-init-cfg-init-cfg"><span class="toc-text">super().__init__(init_cfg&#x3D;init_cfg)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#def-forward-3"><span class="toc-text">def forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8CContrastiveHead-BNContrastiveHead%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-text">同ContrastiveHead &#x2F; BNContrastiveHead的对比</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-YOLOWorldHeadModule-YOLOv8HeadModule"><span class="toc-text">class YOLOWorldHeadModule(YOLOv8HeadModule)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-4"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0-2"><span class="toc-text">初始化参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%9E%E6%80%A7%E8%B5%8B%E5%80%BC"><span class="toc-text">属性赋值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-weights"><span class="toc-text">def init_weights</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-layers"><span class="toc-text">def _init_layers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%89%E4%B8%AA%E5%88%86%E6%94%AF%E5%AE%B9%E5%99%A8"><span class="toc-text">操作：创建三个分支容器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E8%AE%A1%E7%AE%97%E5%9B%9E%E5%BD%92-%E5%88%86%E7%B1%BB%E5%88%86%E6%94%AF%E7%9A%84%E4%B8%AD%E9%97%B4%E9%80%9A%E9%81%93%E6%95%B0"><span class="toc-text">操作：计算回归&#x2F;分类分支的中间通道数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%AF%B9%E6%AF%8F%E4%B8%AA%E7%89%B9%E5%BE%81%E5%B1%82%E5%BB%BA%E4%B8%80%E5%A5%97-head%EF%BC%88%E5%88%86%E7%B1%BB%E3%80%81%E5%9B%9E%E5%BD%92%E3%80%81%E5%AF%B9%E6%AF%94%EF%BC%89"><span class="toc-text">操作：对每个特征层建一套 head（分类、回归、对比）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E5%88%86%E6%94%AF-reg-preds%EF%BC%9A%E4%B8%A4%E5%B1%82-3%C3%973-%E4%B8%80%E5%B1%82-1%C3%971-%E8%BE%93%E5%87%BA%E5%88%86%E5%B8%83"><span class="toc-text">回归分支 reg_preds：两层 3×3 + 一层 1×1 输出分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB-embedding-%E5%88%86%E6%94%AF-cls-preds%EF%BC%9A%E4%B8%A4%E5%B1%82-3%C3%973-%E4%B8%80%E5%B1%82-1%C3%971-%E8%BE%93%E5%87%BA-embed-dims"><span class="toc-text">分类 embedding 分支 cls_preds：两层 3×3 + 一层 1×1 输出 embed_dims</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%A4%B4%E5%88%86%E6%94%AF-BN%E7%89%88-or-L2%E7%89%88"><span class="toc-text">对比头分支---BN版 or L2版</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%B3%A8%E5%86%8C-DFL-%E7%94%A8%E7%9A%84%E6%8A%95%E5%BD%B1%E5%90%91%E9%87%8F-proj%EF%BC%88buffer%EF%BC%89"><span class="toc-text">操作：注册 DFL 用的投影向量 proj（buffer）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%86%BB%E7%BB%93%E6%95%B4%E4%B8%AA-head%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="toc-text">操作：冻结整个 head（可选）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-freeze-all"><span class="toc-text">def _freeze_all</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%96%B9%E6%B3%95%E4%BD%9C%E7%94%A8"><span class="toc-text">1. 方法作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BB%A3%E7%A0%81%E9%80%90%E5%8F%A5%E8%A7%A3%E6%9E%90"><span class="toc-text">2. 代码逐句解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-text">3. 应用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-3"><span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-train"><span class="toc-text">def train</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-4"><span class="toc-text">def forward</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-single"><span class="toc-text">def forward_single</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D"><span class="toc-text">函数签名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%8F%96-batch-%E4%B8%8E%E7%A9%BA%E9%97%B4%E5%B0%BA%E5%AF%B8"><span class="toc-text">操作：取 batch 与空间尺寸</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA1-%E5%88%86%E7%B1%BB%E5%88%86%E6%94%AF-embed-dims"><span class="toc-text">输出1:分类分支 --embed_dims</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA2%EF%BC%9A%E5%AF%B9%E6%AF%94%E5%A4%B4-%E7%B1%BB%E5%88%AB-logit"><span class="toc-text">输出2：对比头--类别 logit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%9C%AC-mask-%E5%A4%84%E7%90%86%EF%BC%88%E6%8A%8A%E6%97%A0%E6%95%88%E7%B1%BB%E5%88%AB%E5%BD%BB%E5%BA%95%E5%8E%8B%E4%B8%8B%E5%8E%BB%EF%BC%89"><span class="toc-text">文本 mask 处理（把无效类别彻底压下去）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%97%B6%EF%BC%9A"><span class="toc-text">训练时：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E6%97%B6%EF%BC%9A"><span class="toc-text">推理时：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA3%EF%BC%9A%E5%9B%9E%E5%BD%92%E5%88%86%E6%94%AF-bbox-dist-preds%EF%BC%88DFL%EF%BC%89"><span class="toc-text">输出3：回归分支-- bbox_dist_preds（DFL）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA4%EF%BC%9A%E5%9B%9E%E5%BD%92%E5%88%86%E6%94%AF%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-bbox-preds"><span class="toc-text">输出4：回归分支数据处理--bbox_preds</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%87%E8%AE%BE1%EF%BC%9A%E4%BD%BF%E7%94%A8-DFL%EF%BC%88reg-max-1%EF%BC%89"><span class="toc-text">假设1：使用 DFL（reg_max &gt; 1）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9ADFL%E8%BF%98%E5%8E%9F%E8%BF%9E%E7%BB%AD%E8%B7%9D%E7%A6%BB"><span class="toc-text">操作：DFL还原连续距离</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%87%E8%AE%BE2%EF%BC%9A%E4%B8%8D%E4%BD%BF%E7%94%A8-DFL%EF%BC%88reg-max-1%EF%BC%89"><span class="toc-text">假设2：不使用 DFL（reg_max &lt;&#x3D; 1）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E5%80%BC%EF%BC%9A%E8%AE%AD%E7%BB%83-vs-%E6%8E%A8%E7%90%86%E4%B8%8D%E4%B8%80%E6%A0%B7"><span class="toc-text">返回值：训练 vs 推理不一样</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-RepYOLOWorldHeadModule-YOLOWorldHeadModule"><span class="toc-text">class RepYOLOWorldHeadModule(YOLOWorldHeadModule)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-4"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-5"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D"><span class="toc-text">1) 函数签名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%B0%83%E7%88%B6%E7%B1%BB%E6%9E%84%E9%80%A0%EF%BC%8C%E4%BD%86%E2%80%9C%E5%BC%BA%E5%88%B6%E6%94%B9%E4%BA%86%E4%B8%A4%E4%B8%AA%E5%85%B3%E9%94%AE%E5%BC%80%E5%85%B3%E2%80%9D"><span class="toc-text">2) 调父类构造，但“强制改了两个关键开关”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E2%80%9Cusing-rep-head%E2%80%9D%EF%BC%9A%E5%BC%80%E5%A7%8B%E9%87%8D%E5%BB%BA-cls-contrasts"><span class="toc-text">3) “using rep head”：开始重建 cls_contrasts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%9E%84%E5%BB%BA-RepBNContrastiveHead-%E7%9A%84%E5%8F%82%E6%95%B0%E5%90%AB%E4%B9%89"><span class="toc-text">4) 构建 RepBNContrastiveHead 的参数含义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%9C%80%E5%90%8E%E4%B8%80%E8%A1%8C%EF%BC%9A%E6%8A%8A%E6%96%B0-head-%E6%B3%A8%E5%86%8C%E6%88%90-ModuleList%EF%BC%88%E5%B9%B6%E8%A6%86%E7%9B%96%E7%88%B6%E7%B1%BB%E7%9A%84%EF%BC%89"><span class="toc-text">5) 最后一行：把新 head 注册成 ModuleList（并覆盖父类的）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%8A%93%E9%87%8D%E7%82%B9"><span class="toc-text">一句话抓重点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-single-2"><span class="toc-text">def forward_single</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%88%E9%AA%8C%E7%9F%A5%E8%AF%86%EF%BC%9Acls-pred-reg-pred-cls-contrast"><span class="toc-text">先验知识：cls_pred &#x2F; reg_pred &#x2F; cls_contrast</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89RepYOLOWorldHeadModule%EF%BC%9A%E5%AE%83%E5%88%B0%E5%BA%95%E2%80%9CRep%E2%80%9D%E5%9C%A8%E5%93%AA%EF%BC%9F"><span class="toc-text">1）RepYOLOWorldHeadModule：它到底“Rep”在哪？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E9%80%90%E8%A1%8C%E8%AE%B2%E8%A7%A3%EF%BC%9ARepYOLOWorldHeadModule-forward-single"><span class="toc-text">2）逐行讲解：RepYOLOWorldHeadModule.forward_single</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%8F%96-batch-%E4%B8%8E%E7%A9%BA%E9%97%B4%E5%B0%BA%E5%AF%B8-2"><span class="toc-text">操作：取 batch 与空间尺寸</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%88%86%E7%B1%BB%E5%88%86%E6%94%AF%E5%81%9A-embedding"><span class="toc-text">操作：分类分支做 embedding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9ARep-%E5%AF%B9%E6%AF%94%E5%A4%B4%EF%BC%88%E5%AE%9E%E9%99%85%E4%B8%8A%E6%98%AF%E2%80%9CBN-1x1-conv%E2%80%9D%EF%BC%89"><span class="toc-text">操作：Rep 对比头（实际上是“BN + 1x1 conv”）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%9B%9E%E5%BD%92%E5%88%86%E6%94%AF%E8%BE%93%E5%87%BA-bbox-%E5%88%86%E5%B8%83"><span class="toc-text">操作：回归分支输出 bbox 分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%8A%8A%E5%88%86%E5%B8%83%E8%BD%AC%E6%88%90%E5%AE%9E%E9%99%85-bbox-offset%EF%BC%88%E5%A6%82%E6%9E%9C-reg-max-1%EF%BC%89"><span class="toc-text">操作：把分布转成实际 bbox offset（如果 reg_max &gt; 1）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%A6%82%E6%9E%9C-reg-max-1%EF%BC%8C%E5%B0%B1%E7%9B%B4%E6%8E%A5%E7%94%A8%E5%9B%9E%E5%BD%92%E8%BE%93%E5%87%BA"><span class="toc-text">操作：如果 reg_max &#x3D;&#x3D; 1，就直接用回归输出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E8%AE%AD%E7%BB%83-%E6%8E%A8%E7%90%86%E8%BF%94%E5%9B%9E%E5%80%BC%E4%B8%8D%E5%90%8C"><span class="toc-text">操作：训练&#x2F;推理返回值不同</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89Rep%E7%89%88-forward-single-%E5%92%8C%E6%99%AE%E9%80%9A%E7%89%88-forward-single-%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">3）Rep版 forward_single 和普通版 forward_single 的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-5"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%BC%89RepYOLOWorldHeadModule-forward%EF%BC%9A%E8%BF%99%E4%B8%80%E6%AE%B5%E6%98%AF%E2%80%9C%E6%8A%8A%E6%AF%8F%E4%B8%AA%E5%B0%BA%E5%BA%A6%E8%B7%91%E4%B8%80%E9%81%8D-forward-single%E2%80%9D"><span class="toc-text">1）RepYOLOWorldHeadModule.forward：这一段是“把每个尺度跑一遍 forward_single”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-img-feats-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1.1 img_feats 是什么？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E5%85%B3%E9%94%AE%EF%BC%9Amulti-apply-%E5%88%B0%E5%BA%95%E5%B9%B2%E4%BA%86%E5%95%A5%EF%BC%9F"><span class="toc-text">1.2 关键：multi_apply(...) 到底干了啥？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-Rep%E7%89%88-forward-single-%E6%AF%8F%E5%B1%82%E8%BE%93%E5%87%BA%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1.3 Rep版 forward_single 每层输出是什么？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%BC%89%E6%8A%8A-RepHeadModule-%E7%9A%84%E8%BE%93%E5%87%BA%EF%BC%8C%E6%8E%A5%E5%88%B0-YOLOWorldHead%EF%BC%9A%E8%BF%99%E4%B8%80%E5%B1%82%E5%8F%AA%E6%98%AF%E2%80%9C%E8%BD%AC%E5%8F%91%E2%80%9D"><span class="toc-text">2）把 RepHeadModule 的输出，接到 YOLOWorldHead：这一层只是“转发”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%BC%89%E4%B8%BA%E4%BB%80%E4%B9%88-loss-by-feat-%E9%87%8C%E6%8A%8A-cls-score-reshape-%E6%88%90-num-classes%EF%BC%9F%E8%BF%99%E7%82%B9%E5%BE%88%E5%AE%B9%E6%98%93%E8%AE%A9%E4%BA%BA%E6%87%B5"><span class="toc-text">3）为什么 loss_by_feat 里把 cls_score reshape 成 num_classes？这点很容易让人懵</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4%EF%BC%89%E6%8A%8A%E4%BD%A0%E5%85%B3%E5%BF%83%E7%9A%84%E2%80%9C%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B%E9%80%BB%E8%BE%91%E2%80%9D%E7%94%A8%E4%B8%80%E5%8F%A5%E8%AF%9D%E4%B8%B2%E8%B5%B7%E6%9D%A5"><span class="toc-text">4）把你关心的“整体流程逻辑”用一句话串起来</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#class-YOLOWorldHead-YOLOv8Head"><span class="toc-text">class YOLOWorldHead(YOLOv8Head)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#def-init-6"><span class="toc-text">def init</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D-2"><span class="toc-text">函数签名</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-loss"><span class="toc-text">def loss</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#debug"><span class="toc-text">debug</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93%EF%BC%9A-init-%E5%92%8C-loss-%E5%9C%A8%E6%95%B4%E4%B8%AA-Head-%E4%B8%AD%E7%9A%84%E8%A7%92%E8%89%B2"><span class="toc-text">小结：__init__ 和 loss 在整个 Head 中的角色</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-loss-by-feat"><span class="toc-text">def loss_by_feat</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%B3%E7%90%86%EF%BC%9Aloss-by-feat-%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-text">梳理：loss_by_feat 的流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D-3"><span class="toc-text">函数签名</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A5%E6%BA%90%E6%80%BB%E7%BB%93"><span class="toc-text">来源总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%8F%90%E5%8F%96featmap-size%E3%80%81%E9%A2%84%E6%B5%8B%E7%82%B9prior%E4%B8%8E%E6%AD%A5%E9%95%BFstride"><span class="toc-text">操作：提取featmap_size、预测点prior与步长stride</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%87%E8%AE%BE%EF%BC%9A%E5%88%86%E8%BE%A8%E7%8E%87%E5%8F%98%E4%BA%86"><span class="toc-text">假设：分辨率变了</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%A2%E7%8A%B6%EF%BC%9A"><span class="toc-text">形状：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E6%B3%A8%E6%A1%86GT-%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%88gt-labels-gt-bboxes-pad-bbox-flag%EF%BC%89"><span class="toc-text">标注框GT 预处理（gt_labels&#x2F;gt_bboxes&#x2F;pad_bbox_flag）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E6%89%BE%E5%87%BA%E6%9C%80%E5%A4%A7%E6%A0%87%E6%B3%A8%E6%A1%86%E6%95%B0-%E7%BB%9F%E4%B8%80%E6%A0%87%E6%B3%A8%E5%BD%A2%E7%8A%B6"><span class="toc-text">操作：找出最大标注框数+统一标注形状</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%8F%96%E6%A0%87%E7%AD%BE%E4%B8%8E%E6%A0%87%E6%B3%A8%E6%A1%86%E6%95%B0%E6%8D%AE"><span class="toc-text">操作：取标签与标注框数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%8C%BA%E5%88%86%E7%9C%9F%E5%AE%9E%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E4%B8%8Epad%E6%95%B0%E6%8D%AE"><span class="toc-text">操作：区分真实标注数据与pad数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%EF%BC%9A%E9%A2%84%E6%B5%8B%E5%80%BC-flatten"><span class="toc-text">数据预处理：预测值 flatten</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%EF%BC%9Aflatten-%E5%88%86%E7%B1%BB%E5%88%86%E6%94%AF"><span class="toc-text">输出：flatten--&gt; 分类分支</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%EF%BC%9Aflatten-%E5%9B%9E%E5%BD%92%E5%88%86%E6%94%AF"><span class="toc-text">输出：flatten --&gt;回归分支</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%EF%BC%9A-flatten-%E5%9B%9E%E5%BD%92dist-%E5%88%86%E6%94%AF%EF%BC%88%E7%BB%99-DFL-%E7%94%A8%EF%BC%89"><span class="toc-text">输出： flatten--&gt; 回归dist 分支（给 DFL 用）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E8%B7%A8%E5%B0%BA%E5%BA%A6%E6%8B%BC%E6%8E%A5"><span class="toc-text">操作：跨尺度拼接</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A51%EF%BC%9ADFL-%E5%88%86%E5%B8%83%E9%A2%84%E6%B5%8B"><span class="toc-text">拼接1：DFL 分布预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A52%EF%BC%9A%E5%88%86%E7%B1%BB%E9%A2%84%E6%B5%8B"><span class="toc-text">拼接2：分类预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A53%EF%BC%9A-bbox-%E5%9B%9E%E5%BD%92%E5%80%BC-flatten-pred-bboxes"><span class="toc-text">拼接3： bbox 回归值--flatten_pred_bboxes</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%EF%BC%9Aflatten-%E8%BF%98%E5%8E%9F%E7%9C%9F%E5%AE%9E-xyxy%E5%9D%90%E6%A0%87"><span class="toc-text">解码：flatten--还原真实 xyxy坐标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5-3"><span class="toc-text">输入</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E4%BE%8B%E5%AD%90"><span class="toc-text">简单例子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%87%BA-3"><span class="toc-text">输出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#debug-2"><span class="toc-text">debug</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9Aassign-%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E5%8C%B9%E9%85%8D"><span class="toc-text">操作：assign 正负样本匹配</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-5"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9Aassign%E8%B0%83%E7%94%A8"><span class="toc-text">操作：assign调用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9Aassign%E7%BB%93%E6%9E%9C%E5%8F%96%E5%87%BA"><span class="toc-text">操作：assign结果取出</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#assigned-bboxes"><span class="toc-text">assigned_bboxes</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#assigned-scores"><span class="toc-text">assigned_scores</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#fg-mask-pre-prior"><span class="toc-text">fg_mask_pre_prior</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B-2"><span class="toc-text">示例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B0%8F%E6%80%BB%E7%BB%93"><span class="toc-text">小总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%EF%BC%9A%E8%AE%A1%E7%AE%97%E5%BD%92%E4%B8%80%E5%8C%96loss%E5%88%86%E6%AF%8D-assigned-scores-sum"><span class="toc-text">操作：计算归一化loss分母--assigned_scores_sum</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E4%B8%89%E4%B8%AA%E6%8D%9F%E5%A4%B1%EF%BC%88%E5%88%86%E7%B1%BB-bbox%E5%9B%9E%E5%BD%92-DFL%E5%88%86%E5%B8%83%E5%9B%9E%E5%BD%92%EF%BC%89"><span class="toc-text">算三个损失（分类 &#x2F; bbox回归 &#x2F; DFL分布回归）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#A-%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1-loss-cls"><span class="toc-text">A. 分类损失 loss_cls</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E5%8F%98%E9%87%8F%E6%9D%A5%E6%BA%90"><span class="toc-text">一些变量来源</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E6%8E%A9%E7%A0%81"><span class="toc-text">1. 判断是否需要掩码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E8%B0%83%E6%95%B4%E6%8E%A9%E7%A0%81%E5%BD%A2%E7%8A%B6-%E6%9C%80%E9%9A%BE%E7%90%86%E8%A7%A3%E7%9A%84%E4%B8%80%E6%AD%A5"><span class="toc-text">2. 调整掩码形状 (最难理解的一步)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E8%AE%A1%E7%AE%97%E5%8E%9F%E5%A7%8B-Loss"><span class="toc-text">3. 计算原始 Loss</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E5%BA%94%E7%94%A8%E6%8E%A9%E7%A0%81-Masking"><span class="toc-text">4. 应用掩码 (Masking)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E6%9C%80%E7%BB%88%E6%B1%82%E5%92%8C"><span class="toc-text">5. 最终求和</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E6%99%AE%E9%80%9A%E6%83%85%E5%86%B5-Else-%E5%88%86%E6%94%AF"><span class="toc-text">6. 普通情况 (Else 分支)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E5%BD%92%E4%B8%80%E5%8C%96-Normalization"><span class="toc-text">7. 归一化 (Normalization)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-6"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#debug-3"><span class="toc-text">debug</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#B-%E5%9D%90%E6%A0%87%E7%B3%BB%E8%BD%AC%E6%8D%A2%EF%BC%88%E9%9D%9E%E5%B8%B8%E5%85%B3%E9%94%AE%EF%BC%89"><span class="toc-text">B. 坐标系转换（非常关键）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#debug-4"><span class="toc-text">debug</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#C-%E5%8F%AA%E5%AF%B9%E6%AD%A3%E6%A0%B7%E6%9C%AC%E7%AE%97%E5%9B%9E%E5%BD%92%E7%9B%B8%E5%85%B3%E6%8D%9F%E5%A4%B1"><span class="toc-text">C. 只对正样本算回归相关损失</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#num-pos-%E6%95%B0%E6%AD%A3%E6%A0%B7%E6%9C%AC"><span class="toc-text">num_pos--数正样本</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A4%E7%A9%BA%E4%BF%9D%E6%8A%A4"><span class="toc-text">判空保护</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#prior-bbox-mask"><span class="toc-text">prior_bbox_mask</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#masked-select-pred-bboxes-pos%E5%92%8Cassigned-bboxes-pos"><span class="toc-text">masked_select--pred_bboxes_pos和assigned_bboxes_pos</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bbox-weight"><span class="toc-text">bbox_weight</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#loss-bbox"><span class="toc-text">loss_bbox</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="toc-text">数据流</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#D-DFL-loss%EF%BC%88%E5%88%86%E5%B8%83%E5%BC%8F%E5%9B%9E%E5%BD%92%EF%BC%89"><span class="toc-text">D. DFL loss（分布式回归）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#pred-dist-pos-%E6%8B%BF%E5%87%BA%E2%80%9C%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E2%80%9D%E9%A2%84%E6%B5%8B%E5%80%BC"><span class="toc-text">pred_dist_pos--拿出“概率分布”预测值</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#assigned-ltrb-%E2%80%94%E2%80%94%E5%88%B6%E4%BD%9C%E2%80%9C%E6%96%B0%E2%80%9D%E6%A0%87%E5%87%86%E7%AD%94%E6%A1%88"><span class="toc-text">assigned_ltrb ——制作“新”标准答案</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#assigned-ltrb-pos%E2%80%94%E2%80%94-%E5%86%8D%E6%AC%A1%E7%AD%9B%E9%80%89%E6%AD%A3%E6%A0%B7%E6%9C%AC"><span class="toc-text">assigned_ltrb_pos—— 再次筛选正样本</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#loss-dfl%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97-DFL-%E6%8D%9F%E5%A4%B1"><span class="toc-text">loss_dfl——计算 DFL 损失</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#E-%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%A9%E6%94%BE%E4%B8%8E%E8%BF%94%E5%9B%9E"><span class="toc-text">E. 分布式缩放与返回</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#else-%E5%88%86%E6%94%AF"><span class="toc-text">else 分支</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#world-size-%E8%8E%B7%E5%8F%96%E2%80%9C%E4%B8%96%E7%95%8C%E2%80%9D%E7%9A%84%E5%A4%A7%E5%B0%8F"><span class="toc-text">world_size --获取“世界”的大小</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#return-dict-%E2%80%9C%E6%89%93%E5%8C%85%E2%80%9D%E4%B8%8E%E2%80%9C%E7%A5%9E%E7%A7%98%E4%B9%98%E6%B3%95%E2%80%9D"><span class="toc-text">return dict--“打包”与“神秘乘法”</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-text">小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-loss-and-predict"><span class="toc-text">def loss_and_predict</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D-4"><span class="toc-text">函数签名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4%E6%8B%86%E8%A7%A3"><span class="toc-text">步骤拆解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%8B%86%E5%8C%85%E2%80%9C%E6%A0%87%E5%87%86%E7%AD%94%E6%A1%88%E2%80%9D"><span class="toc-text">第一步：拆包“标准答案”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%89%8D%E5%90%91%E6%8E%A8%E7%90%86%EF%BC%88%E5%8F%AA%E8%B7%91%E4%B8%80%E6%AC%A1%EF%BC%81%EF%BC%89"><span class="toc-text">第二步：模型前向推理（只跑一次！）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%AE%A1%E7%AE%97-Loss"><span class="toc-text">第三步：计算 Loss</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E7%94%9F%E6%88%90%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-text">第三步：生成预测结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E6%89%93%E5%8C%85%E8%BF%94%E5%9B%9E"><span class="toc-text">第四步：打包返回</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%99%E6%8E%88%E6%80%BB%E7%BB%93"><span class="toc-text">教授总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-forward-6"><span class="toc-text">def forward</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E5%B1%82%EF%BC%9A%E5%88%86%E5%8F%91%E4%B8%AD%E5%BF%83-%E2%80%94%E2%80%94-YOLOWorldHeadModule-forward"><span class="toc-text">第一层：分发中心 —— YOLOWorldHeadModule.forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%B1%82%EF%BC%9A%E6%A0%B8%E5%BF%83%E8%BD%A6%E9%97%B4-%E2%80%94%E2%80%94-forward-single-%E9%87%8D%E4%B8%AD%E4%B9%8B%E9%87%8D"><span class="toc-text">第二层：核心车间 —— forward_single (重中之重)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%8F%90%E5%8F%96%E8%A7%86%E8%A7%89%E7%89%B9%E5%BE%81"><span class="toc-text">1. 提取视觉特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E8%A7%86%E8%A7%89-%E8%AF%AD%E8%A8%80%E2%80%9C%E8%81%94%E5%A7%BB%E2%80%9D-Contrastive-Logic"><span class="toc-text">2. 视觉-语言“联姻” (Contrastive Logic)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%8E%A9%E7%A0%81%E5%B1%8F%E8%94%BD-Masking-%E2%80%94%E2%80%94-%E5%AE%89%E5%85%A8%E6%B0%94%E5%9B%8A"><span class="toc-text">3. 掩码屏蔽 (Masking) —— 安全气囊</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-BBox-%E5%9B%9E%E5%BD%92%E4%B8%8E-DFL-%E8%A7%A3%E7%A0%81-Rep-pred"><span class="toc-text">4. BBox 回归与 DFL 解码 (Rep_pred)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C"><span class="toc-text">5. 返回结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%99%E6%8E%88%E6%80%BB%E7%BB%93-2"><span class="toc-text">教授总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-predict"><span class="toc-text">def predict</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%94%B6%E9%9B%86%E6%83%85%E6%8A%A5-%E2%80%94%E2%80%94-batch-img-metas"><span class="toc-text">第一步：收集情报 —— batch_img_metas</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E5%BC%95%E6%93%8E%E7%82%B9%E7%81%AB-%E2%80%94%E2%80%94-self"><span class="toc-text">第二步：引擎点火 —— self(...)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E7%BF%BB%E8%AF%91%E5%AE%98%E4%B8%8A%E5%9C%BA-%E2%80%94%E2%80%94-predict-by-feat-%E6%A0%B8%E5%BF%83%E5%A7%94%E6%89%98"><span class="toc-text">第三步：翻译官上场 —— predict_by_feat (核心委托)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E4%BA%A4%E4%BB%98%E7%BB%93%E6%9E%9C"><span class="toc-text">第四步：交付结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%99%E6%8E%88%E6%80%BB%E7%BB%93-3"><span class="toc-text">教授总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-aug-test"><span class="toc-text">def aug_test</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%BF%99%E6%AE%B5%E4%BB%A3%E7%A0%81%E5%9C%A8%E5%B9%B2%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-text">1. 这段代码在干什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BB%80%E4%B9%88%E6%98%AF-aug-test-TTA%EF%BC%9F%EF%BC%88%E7%9F%A5%E8%AF%86%E6%89%A9%E5%B1%95%EF%BC%89"><span class="toc-text">2. 什么是 aug_test &#x2F; TTA？（知识扩展）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%B8%BA%E4%BB%80%E4%B9%88-YOLO-World-%E6%B2%A1%E5%86%99%E5%AE%83%EF%BC%9F"><span class="toc-text">3. 为什么 YOLO-World 没写它？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AF%B9%E4%BD%A0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">4. 对你的影响</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#def-predict-by-feat"><span class="toc-text">def predict_by_feat</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%88%98%EF%BC%9A%E6%88%98%E5%89%8D%E5%87%86%E5%A4%87-Anchors-Config"><span class="toc-text">第一战：战前准备 (Anchors &amp; Config)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E8%BE%93%E5%85%A5%EF%BC%9A-cls-scores-bbox-preds"><span class="toc-text">1. 核心输入： cls_scores &amp; bbox_preds</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#cls-scores-List-Tensor-%E5%88%86%E7%B1%BB%E5%88%86%E6%95%B0"><span class="toc-text">cls_scores: List[Tensor] (分类分数)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bbox-preds-List-Tensor-%E6%A1%86%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B"><span class="toc-text">bbox_preds: List[Tensor] (框回归预测)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%8F%AF%E9%80%89%E8%BE%93%E5%85%A5%EF%BC%9Aobjectnesses-YOLO-World-%E4%B8%AD%E9%80%9A%E5%B8%B8%E4%B8%BA%E7%A9%BA"><span class="toc-text">2. 可选输入：objectnesses (YOLO-World 中通常为空)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E7%8E%AF%E5%A2%83%E4%BF%A1%E6%81%AF%EF%BC%9Abatch-img-metas-%E5%9D%90%E6%A0%87%E8%BF%98%E5%8E%9F%E7%9A%84%E5%85%B3%E9%94%AE"><span class="toc-text">3. 环境信息：batch_img_metas (坐标还原的关键)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E8%B0%83%E8%8A%82%E5%BC%80%E5%85%B3%EF%BC%9Acfg-rescale-with-nms"><span class="toc-text">4. 调节开关：cfg, rescale, with_nms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E6%9C%89Objectness-%E5%88%86%E6%94%AF"><span class="toc-text">5. 判断是否有Objectness 分支</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E5%B0%8F%E7%BB%93"><span class="toc-text">6.小结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-cfg"><span class="toc-text">7.cfg</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89-multi-label%EF%BC%9F"><span class="toc-text">8. 为什么要有 multi_label？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-%E7%89%B9%E5%BE%81%E5%9B%BE%E5%B0%BA%E5%AF%B8"><span class="toc-text">9.特征图尺寸</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-prior-generator-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F-%E9%9A%BE%E7%82%B9"><span class="toc-text">10. prior_generator 是什么？ (难点)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-flatten-priors"><span class="toc-text">11. flatten_priors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-mlvl-strides"><span class="toc-text">12.mlvl_strides</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%88%E9%AA%8C%E7%9F%A5%E8%AF%86"><span class="toc-text">先验知识</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-1%EF%BC%9A%E9%81%8D%E5%8E%86%E7%89%B9%E5%BE%81%E5%9B%BE%E5%B0%BA%E5%BA%A6%E4%B8%8E%E5%AF%B9%E5%BA%94%E6%AD%A5%E9%95%BF"><span class="toc-text">步骤 1：遍历特征图尺度与对应步长</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-2%EF%BC%9A%E8%AE%A1%E7%AE%97%E5%BD%93%E5%89%8D%E5%B0%BA%E5%BA%A6%E7%9A%84%E5%85%88%E9%AA%8C%E6%A1%86%E6%80%BB%E6%95%B0"><span class="toc-text">步骤 2：计算当前尺度的先验框总数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%AD%A5%E9%AA%A4-3%EF%BC%9A%E7%94%9F%E6%88%90%E5%BD%93%E5%89%8D%E5%B0%BA%E5%BA%A6%E7%9A%84%E6%AD%A5%E9%95%BF%E5%BC%A0%E9%87%8F"><span class="toc-text">步骤 3：生成当前尺度的步长张量</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-text">第一阶段总结：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%88%98%EF%BC%9A%E5%85%A8%E5%86%9B%E9%9B%86%E7%BB%93-Flatten-Decode"><span class="toc-text">第二战：全军集结 (Flatten &amp; Decode)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A-flatten-cls-scores"><span class="toc-text">第一步： flatten_cls_scores</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A-flatten-bbox-preds"><span class="toc-text">第二步： flatten_bbox_preds</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A-bbox-coder-decode-%E6%9C%80%E6%A0%B8%E5%BF%83"><span class="toc-text">第三步： bbox_coder.decode (最核心)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%80%BB%E7%BB%93%EF%BC%9A%E7%9B%AE%E5%89%8D%E7%9A%84%E6%88%98%E5%86%B5"><span class="toc-text">第二阶段总结：目前的战况</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%88%98%EF%BC%9A%E5%88%9D%E6%AD%A5%E7%AD%9B%E9%80%89"><span class="toc-text">第三战：初步筛选</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#results-list"><span class="toc-text">results_list &#x3D; []</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#for-in-zip"><span class="toc-text">for (...) in zip(...)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%96%E5%87%BA-ori-shape-scale-factor-pad-param"><span class="toc-text">取出 ori_shape &#x2F; scale_factor &#x2F; pad_param</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#score-thr-cfg-get-score-thr-1"><span class="toc-text">score_thr &#x3D; cfg.get(&#39;score_thr&#39;, -1)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#objectness-%E9%A2%84%E8%BF%87%E6%BB%A4%EF%BC%88%E5%8F%AA%E5%9C%A8%E7%89%B9%E5%AE%9A%E6%9D%A1%E4%BB%B6%E8%A7%A6%E5%8F%91%EF%BC%89"><span class="toc-text">objectness 预过滤（只在特定条件触发）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%8A%E6%9C%80%E7%BB%88%E7%BD%AE%E4%BF%A1%E5%BA%A6%E8%9E%8D%E5%90%88%E6%88%90-obj-conf-cls-conf"><span class="toc-text">把最终置信度融合成 obj_conf * cls_conf</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%88%98%EF%BC%9A%E6%9C%80%E7%BB%88%E5%86%B3%E6%88%98-NMS-Rescale"><span class="toc-text">第四战：最终决战 (NMS &amp; Rescale)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%A9%BA%E7%BB%93%E6%9E%9C%E5%85%9C%E5%BA%95%EF%BC%9Aif-scores-shape-0-0-continue"><span class="toc-text">1) 空结果兜底：if scores.shape[0] &#x3D;&#x3D; 0: ... continue</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-nms-pre%EF%BC%9A%E8%BF%9B-NMS-%E5%89%8D%E5%85%88-topK-%E8%A3%81%E5%89%AA%E5%80%99%E9%80%89%E8%A7%84%E6%A8%A1"><span class="toc-text">2) nms_pre：进 NMS 前先 topK 裁剪候选规模</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%88%86%E5%8F%89%E7%82%B9%EF%BC%9Acfg-multi-label-%E5%86%B3%E5%AE%9A%E2%80%9C%E4%B8%80%E4%B8%AA%E6%A1%86%E8%83%BD%E5%90%A6%E5%AF%B9%E5%BA%94%E5%A4%9A%E4%B8%AA%E7%B1%BB%E5%88%AB%E2%80%9D"><span class="toc-text">3) 分叉点：cfg.multi_label 决定“一个框能否对应多个类别”</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-%E5%8D%95%E6%A0%87%E7%AD%BE%E6%A8%A1%E5%BC%8F%EF%BC%9Acfg-multi-label-is-False"><span class="toc-text">3.1 单标签模式：cfg.multi_label is False</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-%E5%A4%9A%E6%A0%87%E7%AD%BE%E6%A8%A1%E5%BC%8F%EF%BC%9Acfg-multi-label-is-True"><span class="toc-text">3.2 多标签模式：cfg.multi_label is True</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E7%BB%84%E8%A3%85-InstanceData%EF%BC%9A%E6%8A%8A%E7%AD%9B%E9%80%89%E7%BB%93%E6%9E%9C%E2%80%9C%E8%90%BD%E5%9C%B0%E2%80%9D%E6%88%90%E7%BB%93%E6%9E%84%E4%BD%93"><span class="toc-text">4) 组装 InstanceData：把筛选结果“落地”成结构体</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-rescale%EF%BC%9A%E6%8A%8A%E5%9D%90%E6%A0%87%E4%BB%8E%E2%80%9C%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E5%B0%BA%E5%BA%A6%E2%80%9D%E8%BF%98%E5%8E%9F%E5%88%B0%E2%80%9C%E5%8E%9F%E5%9B%BE%E5%B0%BA%E5%BA%A6%E2%80%9D"><span class="toc-text">5) rescale：把坐标从“网络输入尺度”还原到“原图尺度”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-yolox-style-%E7%89%B9%E5%88%A4%EF%BC%9A%E6%94%BE%E5%BC%80-max-per-img"><span class="toc-text">6) yolox_style 特判：放开 max_per_img</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E6%9C%80%E7%BB%88%E5%86%B3%E6%88%98%EF%BC%9A-bbox-post-process%EF%BC%88NMS-%E9%99%90%E9%A2%9D-%E8%BE%93%E5%87%BA%E6%95%B4%E7%90%86%EF%BC%89"><span class="toc-text">7) 最终决战：_bbox_post_process（NMS + 限额 + 输出整理）</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/" title="代码解读：yolo_world-models-necks-yolo_world_pafpn.py"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-necks-yolo_world_pafpn.py"></a><div class="content"><a class="title" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-necks-yolo_world_pafpn.py/" title="代码解读：yolo_world-models-necks-yolo_world_pafpn.py">代码解读：yolo_world-models-necks-yolo_world_pafpn.py</a><time datetime="2025-12-18T02:04:06.000Z" title="发表于 2025-12-18 10:04:06">2025-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py"><img src="/blog/image/q4SynOBjcxn5gA6.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-detectors-yolo_world.py"></a><div class="content"><a class="title" href="/blog/2025/12/18/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-detectors-yolo_world.py/" title="代码解读：yolo_world-models-detectors-yolo_world.py">代码解读：yolo_world-models-detectors-yolo_world.py</a><time datetime="2025-12-18T02:04:06.000Z" title="发表于 2025-12-18 10:04:06">2025-12-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/" title="代码解读：yolo_world-models-dense_heads-yolo_world_head.py"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="代码解读：yolo_world-models-dense_heads-yolo_world_head.py"></a><div class="content"><a class="title" href="/blog/2025/12/01/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%9Ayolo_world-models-dense_heads-yolo_world_head.py/" title="代码解读：yolo_world-models-dense_heads-yolo_world_head.py">代码解读：yolo_world-models-dense_heads-yolo_world_head.py</a><time datetime="2025-12-01T03:04:06.000Z" title="发表于 2025-12-01 11:04:06">2025-12-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"><img src="/blog/image/A1-2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection"></a><div class="content"><a class="title" href="/blog/2025/10/24/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/yolo-world/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AYOLO-World-Real-Time-Open-Vocabulary-Object-Detection/" title="论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection">论文阅读：YOLO-World: Real-Time Open-Vocabulary Object Detection</a><time datetime="2025-10-24T07:19:06.000Z" title="发表于 2025-10-24 15:19:06">2025-10-24</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/easter-egg/" title="彩蛋"><img src="/blog/image/cover/IMG_20260217_201822.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="彩蛋"/></a><div class="content"><a class="title" href="/blog/easter-egg/" title="彩蛋">彩蛋</a><time datetime="2026-02-18T05:09:03.000Z" title="发表于 2026-02-18 13:09:03">2026-02-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/21/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/WeDetect/%E3%80%90WeDetect%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【WeDetect】论文阅读"><img src="/blog/image/cover/9.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="【WeDetect】论文阅读"/></a><div class="content"><a class="title" href="/blog/2026/01/21/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/WeDetect/%E3%80%90WeDetect%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【WeDetect】论文阅读">【WeDetect】论文阅读</a><time datetime="2026-01-21T01:41:58.000Z" title="发表于 2026-01-21 09:41:58">2026-01-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/20/AI%E7%9B%B8%E5%85%B3/AI%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="AI使用手册"><img src="/blog/image/cover/13.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="AI使用手册"/></a><div class="content"><a class="title" href="/blog/2026/01/20/AI%E7%9B%B8%E5%85%B3/AI%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/" title="AI使用手册">AI使用手册</a><time datetime="2026-01-20T01:21:48.000Z" title="发表于 2026-01-20 09:21:48">2026-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/19/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/OV-DQUO/%E3%80%90OV-DQUO%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【OV-DQUO】论文阅读"><img src="/blog/image/cover/2.jpg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="【OV-DQUO】论文阅读"/></a><div class="content"><a class="title" href="/blog/2026/01/19/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/OV-DQUO/%E3%80%90OV-DQUO%E3%80%91%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" title="【OV-DQUO】论文阅读">【OV-DQUO】论文阅读</a><time datetime="2026-01-19T07:59:50.000Z" title="发表于 2026-01-19 15:59:50">2026-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/2026/01/14/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/YOLO-UniOW/%E3%80%90YOLO-UniOW%E3%80%91%E6%8C%87%E6%A0%87%E8%A7%A3%E9%87%8A/" title="YOLO-UniOW-指标解释"><img src="/blog/image/cover/6.jpeg" onerror="this.onerror=null;this.src='/blog/img/404.jpg'" alt="YOLO-UniOW-指标解释"/></a><div class="content"><a class="title" href="/blog/2026/01/14/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B/YOLO-UniOW/%E3%80%90YOLO-UniOW%E3%80%91%E6%8C%87%E6%A0%87%E8%A7%A3%E9%87%8A/" title="YOLO-UniOW-指标解释">YOLO-UniOW-指标解释</a><time datetime="2026-01-14T01:44:34.000Z" title="发表于 2026-01-14 09:44:34">2026-01-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 - 2026 By lian</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">岁岁平，岁岁安，岁岁平安</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/blog/js/utils.js"></script><script src="/blog/js/main.js"></script><script src="/blog/true"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark_dimmed' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qieliqiean/blog',
      'data-repo-id': 'R_kgDONvpdYw',
      'data-category-id': 'DIC_kwDONvpdY84C1DqB',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !true) {
    if (true) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script defer src="/blog/js/site.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/blog/js/search/local-search.js"></script></div></div></body></html>